code	desc
protected final void bindindexed ( configurationpropertyname name , bindable < ? > target , aggregateelementbinder elementbinder , resolvabletype aggregatetype , resolvabletype elementtype , indexedcollectionsupplier result ) { for ( configurationpropertysource source : getcontext ( ) . getsources ( ) ) { bindindexed ( source , name , target , elementbinder , result , aggregatetype , elementtype ) ; if ( result . wassupplied ( ) && result . get ( ) != null ) { return ; } } }	Bind indexed elements to the supplied collection.
public void setservletnames ( collection < string > servletnames ) { assert . notnull ( servletnames , str_ ) ; this . servletnames = new linkedhashset < > ( servletnames ) ; }	Set servlet names that the filter will be registered against.
public void addservletnames ( string ... servletnames ) { assert . notnull ( servletnames , str_ ) ; this . servletnames . addall ( arrays . aslist ( servletnames ) ) ; }	Add servlet names for the filter.
public void seturlpatterns ( collection < string > urlpatterns ) { assert . notnull ( urlpatterns , str_ ) ; this . urlpatterns = new linkedhashset < > ( urlpatterns ) ; }	Set the URL patterns that the filter will be registered against.
public void addurlpatterns ( string ... urlpatterns ) { assert . notnull ( urlpatterns , str_ ) ; collections . addall ( this . urlpatterns , urlpatterns ) ; }	Add URL patterns, as defined in the Servlet specification, that the filter will beregistered against.
public file getdir ( string subdir ) { file dir = new file ( getdir ( ) , subdir ) ; dir . mkdirs ( ) ; return dir ; }	Return a sub-directory of the application temp.
public file getdir ( ) { if ( this . dir == null ) { synchronized ( this ) { byte [ ] hash = generatehash ( this . sourceclass ) ; this . dir = new file ( gettempdirectory ( ) , tohexstring ( hash ) ) ; this . dir . mkdirs ( ) ; assert . state ( this . dir . exists ( ) , ( ) -> str_ + this . dir ) ; } } return this . dir ; }	Return the directory to be used for application specific temp files.
protected map < string , object > generatecontent ( ) { map < string , object > content = extractcontent ( topropertysource ( ) ) ; postprocesscontent ( content ) ; return content ; }	Extract the content to contribute to the info endpoint.
@ suppresswarnings ( str_ ) protected map < string , object > getnestedmap ( map < string , object > map , string key ) { object value = map . get ( key ) ; if ( value == null ) { return collections . emptymap ( ) ; } return ( map < string , object > ) value ; }	Return the nested map with the specified key or empty map if the specified mapcontains no mapping for the key.
public static < c , a > callback < c , a > callback ( class < c > callbacktype , c callbackinstance , a argument , object ... additionalarguments ) { assert . notnull ( callbacktype , str_ ) ; assert . notnull ( callbackinstance , str_ ) ; return new callback < > ( callbacktype , callbackinstance , argument , additionalarguments ) ; }	Start a call to a single callback instance, dealing with common generic typeconcerns and exceptions.
public static < c , a > callbacks < c , a > callbacks ( class < c > callbacktype , collection < ? extends c > callbackinstances , a argument , object ... additionalarguments ) { assert . notnull ( callbacktype , str_ ) ; assert . notnull ( callbackinstances , str_ ) ; return new callbacks < > ( callbacktype , callbackinstances , argument , additionalarguments ) ; }	Start a call to callback instances, dealing with common generic type concerns andexceptions.
public < r > stream < r > invokeand ( function < c , r > invoker ) { function < c , invocationresult < r > > mapper = ( callbackinstance ) -> invoke ( callbackinstance , ( ) -> invoker . apply ( callbackinstance ) ) ; return this . callbackinstances . stream ( ) . map ( mapper ) . filter ( invocationresult :: hasresult ) . map ( invocationresult :: get ) ; }	Invoke the callback instances where the callback method returns a result.
public int start ( ) throws ioexception { synchronized ( this . monitor ) { assert . state ( ! isstarted ( ) , str_ ) ; logger . debug ( str_ + this . port ) ; this . serversocket = new serversocket ( this . port ) ; int localport = this . serversocket . getlocalport ( ) ; this . listenthread = this . threadfactory . newthread ( this :: acceptconnections ) ; this . listenthread . setdaemon ( bool_ ) ; this . listenthread . setname ( str_ ) ; this . listenthread . start ( ) ; return localport ; } }	Start the livereload server and accept incoming connections.
public void stop ( ) throws ioexception { synchronized ( this . monitor ) { if ( this . listenthread != null ) { closeallconnections ( ) ; try { this . executor . shutdown ( ) ; this . executor . awaittermination ( num_ , timeunit . minutes ) ; } catch ( interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; } this . serversocket . close ( ) ; try { this . listenthread . join ( ) ; } catch ( interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; } this . listenthread = null ; this . serversocket = null ; } } }	Gracefully stop the livereload server.
public void triggerreload ( ) { synchronized ( this . monitor ) { synchronized ( this . connections ) { for ( connection connection : this . connections ) { try { connection . triggerreload ( ) ; } catch ( exception ex ) { logger . debug ( str_ , ex ) ; } } } } }	Trigger livereload of all connected clients.
public springapplicationbuilder child ( class < ? > ... sources ) { springapplicationbuilder child = new springapplicationbuilder ( ) ; child . sources ( sources ) ;	Create a child application with the provided sources.
public springapplicationbuilder parent ( class < ? > ... sources ) { if ( this . parent == null ) { this . parent = new springapplicationbuilder ( sources ) . web ( webapplicationtype . none ) . properties ( this . defaultproperties ) . environment ( this . environment ) ; } else { this . parent . sources ( sources ) ; } return this . parent ; }	Add a parent application with the provided sources.
public springapplicationbuilder parent ( configurableapplicationcontext parent ) { this . parent = new springapplicationbuilder ( ) ; this . parent . context = parent ; this . parent . running . set ( bool_ ) ; return this ; }	Add an already running parent context to an existing application.
public springapplicationbuilder properties ( map < string , object > defaults ) { this . defaultproperties . putall ( defaults ) ; this . application . setdefaultproperties ( this . defaultproperties ) ; if ( this . parent != null ) { this . parent . properties ( this . defaultproperties ) ; this . parent . environment ( this . environment ) ; } return this ; }	Default properties for the environment.
public static void addapplicationconverters ( converterregistry registry ) { adddelimitedstringconverters ( registry ) ; registry . addconverter ( new stringtodurationconverter ( ) ) ; registry . addconverter ( new durationtostringconverter ( ) ) ; registry . addconverter ( new numbertodurationconverter ( ) ) ; registry . addconverter ( new durationtonumberconverter ( ) ) ; registry . addconverter ( new stringtodatasizeconverter ( ) ) ; registry . addconverter ( new numbertodatasizeconverter ( ) ) ; registry . addconverterfactory ( new stringtoenumignoringcaseconverterfactory ( ) ) ; }	Add converters useful for most Spring Boot applications.
public static void adddelimitedstringconverters ( converterregistry registry ) { conversionservice service = ( conversionservice ) registry ; registry . addconverter ( new arraytodelimitedstringconverter ( service ) ) ; registry . addconverter ( new collectiontodelimitedstringconverter ( service ) ) ; registry . addconverter ( new delimitedstringtoarrayconverter ( service ) ) ; registry . addconverter ( new delimitedstringtocollectionconverter ( service ) ) ; }	Add converters to support delimited strings.
public static void addapplicationformatters ( formatterregistry registry ) { registry . addformatter ( new chararrayformatter ( ) ) ; registry . addformatter ( new inetaddressformatter ( ) ) ; registry . addformatter ( new isooffsetformatter ( ) ) ; }	Add formatters useful for most Spring Boot applications.
public string determinedriverclassname ( ) { if ( stringutils . hastext ( this . driverclassname ) ) { assert . state ( driverclassisloadable ( ) , ( ) -> str_ + this . driverclassname ) ; return this . driverclassname ; } string driverclassname = null ; if ( stringutils . hastext ( this . url ) ) { driverclassname = databasedriver . fromjdbcurl ( this . url ) . getdriverclassname ( ) ; } if ( ! stringutils . hastext ( driverclassname ) ) { driverclassname = this . embeddeddatabaseconnection . getdriverclassname ( ) ; } if ( ! stringutils . hastext ( driverclassname ) ) { throw new datasourcebeancreationexception ( str_ , this , this . embeddeddatabaseconnection ) ; } return driverclassname ; }	Determine the driver to use based on this configuration and the environment.
public string determineurl ( ) { if ( stringutils . hastext ( this . url ) ) { return this . url ; } string databasename = determinedatabasename ( ) ; string url = ( databasename != null ) ? this . embeddeddatabaseconnection . geturl ( databasename ) : null ; if ( ! stringutils . hastext ( url ) ) { throw new datasourcebeancreationexception ( str_ , this , this . embeddeddatabaseconnection ) ; } return url ; }	Determine the url to use based on this configuration and the environment.
public string determinedatabasename ( ) { if ( this . generateuniquename ) { if ( this . uniquename == null ) { this . uniquename = uuid . randomuuid ( ) . tostring ( ) ; } return this . uniquename ; } if ( stringutils . haslength ( this . name ) ) { return this . name ; } if ( this . embeddeddatabaseconnection != embeddeddatabaseconnection . none ) { return str_ ; } return null ; }	Determine the name to used based on this configuration.
public string determineusername ( ) { if ( stringutils . hastext ( this . username ) ) { return this . username ; } if ( embeddeddatabaseconnection . isembedded ( determinedriverclassname ( ) ) ) { return str_ ; } return null ; }	Determine the username to use based on this configuration and the environment.
public string determinepassword ( ) { if ( stringutils . hastext ( this . password ) ) { return this . password ; } if ( embeddeddatabaseconnection . isembedded ( determinedriverclassname ( ) ) ) { return str_ ; } return null ; }	Determine the password to use based on this configuration and the environment.
private closeablehttpresponse executeinitializrmetadataretrieval ( string url ) { httpget request = new httpget ( url ) ; request . setheader ( new basicheader ( httpheaders . accept , accept_meta_data ) ) ; return execute ( request , url , str_ ) ; }	Retrieves the meta-data of the service at the specified URL.
public void compileandrun ( ) throws exception { synchronized ( this . monitor ) { try { stop ( ) ; class < ? > [ ] compiledsources = compile ( ) ; monitorforchanges ( ) ;	Compile and run the application.
protected final boolean anymatches ( conditioncontext context , annotatedtypemetadata metadata , condition ... conditions ) { for ( condition condition : conditions ) { if ( matches ( context , metadata , condition ) ) { return bool_ ; } } return bool_ ; }	Return true if any of the specified conditions match.
protected final boolean matches ( conditioncontext context , annotatedtypemetadata metadata , condition condition ) { if ( condition instanceof springbootcondition ) { return ( ( springbootcondition ) condition ) . getmatchoutcome ( context , metadata ) . ismatch ( ) ; } return condition . matches ( context , metadata ) ; }	Return true if any of the specified condition matches.
private boolean islogconfigurationmessage ( throwable ex ) { if ( ex instanceof invocationtargetexception ) { return islogconfigurationmessage ( ex . getcause ( ) ) ; } string message = ex . getmessage ( ) ; if ( message != null ) { for ( string candidate : log_configuration_messages ) { if ( message . contains ( candidate ) ) { return bool_ ; } } } return bool_ ; }	Check if the exception is a log configuration message, i.e.
public taskschedulerbuilder awaitterminationperiod ( duration awaitterminationperiod ) { return new taskschedulerbuilder ( this . poolsize , this . awaittermination , awaitterminationperiod , this . threadnameprefix , this . customizers ) ; }	Set the maximum time the executor is supposed to block on shutdown.
public taskschedulerbuilder threadnameprefix ( string threadnameprefix ) { return new taskschedulerbuilder ( this . poolsize , this . awaittermination , this . awaitterminationperiod , threadnameprefix , this . customizers ) ; }	Set the prefix to use for the names of newly created threads.
public static loggingsystem get ( classloader classloader ) { string loggingsystem = system . getproperty ( system_property ) ; if ( stringutils . haslength ( loggingsystem ) ) { if ( none . equals ( loggingsystem ) ) { return new nooploggingsystem ( ) ; } return get ( classloader , loggingsystem ) ; } return systems . entryset ( ) . stream ( ) . filter ( ( entry ) -> classutils . ispresent ( entry . getkey ( ) , classloader ) ) . map ( ( entry ) -> get ( classloader , entry . getvalue ( ) ) ) . findfirst ( ) . orelsethrow ( ( ) -> new illegalstateexception ( str_ ) ) ; }	Detect and return the logging system in use.
public void start ( ) { synchronized ( this . monitor ) { saveinitialsnapshots ( ) ; if ( this . watchthread == null ) { map < file , foldersnapshot > localfolders = new hashmap < > ( ) ; localfolders . putall ( this . folders ) ; this . watchthread = new thread ( new watcher ( this . remainingscans , new arraylist < > ( this . listeners ) , this . triggerfilter , this . pollinterval , this . quietperiod , localfolders ) ) ; this . watchthread . setname ( str_ ) ; this . watchthread . setdaemon ( this . daemon ) ; this . watchthread . start ( ) ; } } }	Start monitoring the source folder for changes.
void stopafter ( int remainingscans ) { thread thread ; synchronized ( this . monitor ) { thread = this . watchthread ; if ( thread != null ) { this . remainingscans . set ( remainingscans ) ; if ( remainingscans <= num_ ) { thread . interrupt ( ) ; } } this . watchthread = null ; } if ( thread != null && thread . currentthread ( ) != thread ) { try { thread . join ( ) ; } catch ( interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; } } }	Stop monitoring the source folders.
protected map < string , object > geterrorattributes ( serverrequest request , boolean includestacktrace ) { return this . errorattributes . geterrorattributes ( request , includestacktrace ) ; }	Extract the error attributes from the current request, to be used to populate errorviews or JSON payloads.
protected boolean istraceenabled ( serverrequest request ) { string parameter = request . queryparam ( str_ ) . orelse ( str_ ) ; return ! str_ . equalsignorecase ( parameter ) ; }	Check whether the trace attribute has been set on the given request.
public void stop ( ) throws mojoexecutionexception , ioexception , instancenotfoundexception { try { this . connection . invoke ( this . objectname , str_ , null , null ) ; } catch ( reflectionexception ex ) { throw new mojoexecutionexception ( str_ , ex . getcause ( ) ) ; } catch ( mbeanexception ex ) { throw new mojoexecutionexception ( str_ , ex ) ; } }	Stop the application managed by this instance.
public string generate ( string url ) throws ioexception { object content = this . initializrservice . loadservicecapabilities ( url ) ; if ( content instanceof initializrservicemetadata ) { return generatehelp ( url , ( initializrservicemetadata ) content ) ; } return content . tostring ( ) ; }	Generate a report for the specified service.
protected mono < serverresponse > rendererrorview ( serverrequest request ) { boolean includestacktrace = isincludestacktrace ( request , mediatype . text_html ) ; map < string , object > error = geterrorattributes ( request , includestacktrace ) ; httpstatus errorstatus = gethttpstatus ( error ) ; serverresponse . bodybuilder responsebody = serverresponse . status ( errorstatus ) . contenttype ( mediatype . text_html ) ; return flux . just ( str_ + errorstatus . value ( ) , str_ + series_views . get ( errorstatus . series ( ) ) , str_ ) . flatmap ( ( viewname ) -> rendererrorview ( viewname , responsebody , error ) ) . switchifempty ( this . errorproperties . getwhitelabel ( ) . isenabled ( ) ? renderdefaulterrorview ( responsebody , error ) : mono . error ( geterror ( request ) ) ) . next ( ) ; }	Render the error information as an HTML view.
protected mono < serverresponse > rendererrorresponse ( serverrequest request ) { boolean includestacktrace = isincludestacktrace ( request , mediatype . all ) ; map < string , object > error = geterrorattributes ( request , includestacktrace ) ; return serverresponse . status ( gethttpstatus ( error ) ) . contenttype ( mediatype . application_json_utf8 ) . body ( bodyinserters . fromobject ( error ) ) ; }	Render the error information as a JSON payload.
protected httpstatus gethttpstatus ( map < string , object > errorattributes ) { int statuscode = ( int ) errorattributes . get ( str_ ) ; return httpstatus . valueof ( statuscode ) ; }	Get the HTTP error status information from the error map.
private boolean shouldextract ( projectgenerationrequest request , projectgenerationresponse response ) { if ( request . isextract ( ) ) { return bool_ ; }	Detect if the project should be extracted.
@ safevarargs public final set < class < ? > > scan ( class < ? extends annotation > ... annotationtypes ) throws classnotfoundexception { list < string > packages = getpackages ( ) ; if ( packages . isempty ( ) ) { return collections . emptyset ( ) ; } classpathscanningcandidatecomponentprovider scanner = new classpathscanningcandidatecomponentprovider ( bool_ ) ; scanner . setenvironment ( this . context . getenvironment ( ) ) ; scanner . setresourceloader ( this . context ) ; for ( class < ? extends annotation > annotationtype : annotationtypes ) { scanner . addincludefilter ( new annotationtypefilter ( annotationtype ) ) ; } set < class < ? > > entityset = new hashset < > ( ) ; for ( string basepackage : packages ) { if ( stringutils . hastext ( basepackage ) ) { for ( beandefinition candidate : scanner . findcandidatecomponents ( basepackage ) ) { entityset . add ( classutils . forname ( candidate . getbeanclassname ( ) , this . context . getclassloader ( ) ) ) ; } } } return entityset ; }	Scan for entities with the specified annotations.
private void resolvename ( configurationmetadataitem item ) { item . setname ( item . getid ( ) ) ;	Resolve the name of an item against this instance.
protected void restart ( set < url > urls , classloaderfiles files ) { restarter restarter = restarter . getinstance ( ) ; restarter . addurls ( urls ) ; restarter . addclassloaderfiles ( files ) ; restarter . restart ( ) ; }	Called to restart the application.
public final void load ( class < ? > relativeclass , string ... resourcenames ) { resource [ ] resources = new resource [ resourcenames . length ] ; for ( int i = num_ ; i < resourcenames . length ; i ++ ) { resources [ i ] = new classpathresource ( resourcenames [ i ] , relativeclass ) ; } this . reader . loadbeandefinitions ( resources ) ; }	Load bean definitions from the given XML resources.
public void ifbound ( consumer < ? super t > consumer ) { assert . notnull ( consumer , str_ ) ; if ( this . value != null ) { consumer . accept ( this . value ) ; } }	Invoke the specified consumer with the bound value, or do nothing if no value hasbeen bound.
public < u > bindresult < u > map ( function < ? super t , ? extends u > mapper ) { assert . notnull ( mapper , str_ ) ; return of ( ( this . value != null ) ? mapper . apply ( this . value ) : null ) ; }	Apply the provided mapping function to the bound value, or return an updatedunbound result if no value has been bound.
public t orelsecreate ( class < ? extends t > type ) { assert . notnull ( type , str_ ) ; return ( this . value != null ) ? this . value : beanutils . instantiateclass ( type ) ; }	Return the object that was bound, or a new instance of the specified class if novalue has been bound.
protected classloader createclassloader ( list < archive > archives ) throws exception { list < url > urls = new arraylist < > ( archives . size ( ) ) ; for ( archive archive : archives ) { urls . add ( archive . geturl ( ) ) ; } return createclassloader ( urls . toarray ( new url [ num_ ] ) ) ; }	Create a classloader for the specified archives.
public static string todashedform ( string name , int start ) { stringbuilder result = new stringbuilder ( ) ; string replaced = name . replace ( str_ , str_ ) ; for ( int i = start ; i < replaced . length ( ) ; i ++ ) { char ch = replaced . charat ( i ) ; if ( character . isuppercase ( ch ) && result . length ( ) > num_ && result . charat ( result . length ( ) - num_ ) != str_ ) { result . append ( str_ ) ; } result . append ( character . tolowercase ( ch ) ) ; } return result . tostring ( ) ; }	Return the specified Java Bean property name in dashed form.
public void replayto ( log destination ) { synchronized ( this . lines ) { for ( line line : this . lines ) { logto ( destination , line . getlevel ( ) , line . getmessage ( ) , line . getthrowable ( ) ) ; } this . lines . clear ( ) ; } }	Replay deferred logging to the specified destination.
public static colorconverter newinstance ( configuration config , string [ ] options ) { if ( options . length < num_ ) { logger . error ( str_ + str_ , options . length ) ; return null ; } if ( options [ num_ ] == null ) { logger . error ( str_ ) ; return null ; } patternparser parser = patternlayout . createpatternparser ( config ) ; list < patternformatter > formatters = parser . parse ( options [ num_ ] ) ; ansielement element = ( options . length != num_ ) ? elements . get ( options [ num_ ] ) : null ; return new colorconverter ( formatters , element ) ; }	Creates a new instance of the class.
public void run ( ) throws exception { if ( this . header . contains ( str_ ) && this . header . contains ( str_ ) ) { runwebsocket ( ) ; } if ( this . header . contains ( str_ ) ) { this . outputstream . writehttp ( getclass ( ) . getresourceasstream ( str_ ) , str_ ) ; } }	Run the connection.
@ suppresswarnings ( str_ ) public final object bind ( configurationpropertyname name , bindable < ? > target , aggregateelementbinder elementbinder ) { object result = bindaggregate ( name , target , elementbinder ) ; supplier < ? > value = target . getvalue ( ) ; if ( result == null || value == null ) { return result ; } return merge ( ( supplier < t > ) value , ( t ) result ) ; }	Perform binding for the aggregate.
protected void addpropertysources ( configurableenvironment environment , resourceloader resourceloader ) { randomvaluepropertysource . addtoenvironment ( environment ) ; new loader ( environment , resourceloader ) . load ( ) ; }	Add config file property sources to the specified environment.
public void setstatusmapping ( map < string , integer > statusmapping ) { assert . notnull ( statusmapping , str_ ) ; this . statusmapping = new hashmap < > ( statusmapping ) ; }	Set specific status mappings.
public void addstatusmapping ( map < string , integer > statusmapping ) { assert . notnull ( statusmapping , str_ ) ; this . statusmapping . putall ( statusmapping ) ; }	Add specific status mappings to the existing set.
public string getrelativename ( ) { file folder = this . sourcefolder . getabsolutefile ( ) ; file file = this . file . getabsolutefile ( ) ; string foldername = stringutils . cleanpath ( folder . getpath ( ) ) ; string filename = stringutils . cleanpath ( file . getpath ( ) ) ; assert . state ( filename . startswith ( foldername ) , ( ) -> str_ + filename + str_ + foldername ) ; return filename . substring ( foldername . length ( ) + num_ ) ; }	Return the name of the file relative to the source folder.
ansistring append ( string text , code ... codes ) { if ( codes . length == num_ || ! isansisupported ( ) ) { this . value . append ( text ) ; return this ; } ansi ansi = ansi . ansi ( ) ; for ( code code : codes ) { ansi = applycode ( ansi , code ) ; } this . value . append ( ansi . a ( text ) . reset ( ) . tostring ( ) ) ; return this ; }	Append text with the given ANSI codes.
protected void logdisabledfork ( ) { if ( getlog ( ) . iswarnenabled ( ) ) { if ( hasagent ( ) ) { getlog ( ) . warn ( str_ ) ; } if ( hasjvmargs ( ) ) { runarguments runarguments = resolvejvmarguments ( ) ; getlog ( ) . warn ( str_ + arrays . stream ( runarguments . asarray ( ) ) . collect ( collectors . joining ( str_ ) ) + str_ ) ; } if ( hasworkingdirectoryset ( ) ) { getlog ( ) . warn ( str_ ) ; } } }	Log a warning indicating that fork mode has been explicitly disabled while someconditions are present that require to enable it.
protected runarguments resolvejvmarguments ( ) { stringbuilder stringbuilder = new stringbuilder ( ) ; if ( this . systempropertyvariables != null ) { stringbuilder . append ( this . systempropertyvariables . entryset ( ) . stream ( ) . map ( ( e ) -> systempropertyformatter . format ( e . getkey ( ) , e . getvalue ( ) ) ) . collect ( collectors . joining ( str_ ) ) ) ; } if ( this . jvmarguments != null ) { stringbuilder . append ( str_ ) . append ( this . jvmarguments ) ; } return new runarguments ( stringbuilder . tostring ( ) ) ; }	Resolve the JVM arguments to use.
protected conditionoutcome getresourceoutcome ( conditioncontext context , annotatedtypemetadata metadata ) { list < string > found = new arraylist < > ( ) ; for ( string location : this . resourcelocations ) { resource resource = context . getresourceloader ( ) . getresource ( location ) ; if ( resource != null && resource . exists ( ) ) { found . add ( location ) ; } } if ( found . isempty ( ) ) { conditionmessage message = startconditionmessage ( ) . didnotfind ( str_ , str_ ) . items ( style . quote , arrays . aslist ( this . resourcelocations ) ) ; return conditionoutcome . nomatch ( message ) ; } conditionmessage message = startconditionmessage ( ) . found ( str_ , str_ ) . items ( style . quote , found ) ; return conditionoutcome . match ( message ) ; }	Check if one of the default resource locations actually exists.
public static list < string > get ( beanfactory beanfactory ) { try { return beanfactory . getbean ( bean , basepackages . class ) . get ( ) ; } catch ( nosuchbeandefinitionexception ex ) { throw new illegalstateexception ( str_ ) ; } }	Return the auto-configuration base packages for the given bean factory.
public void clearcache ( ) { for ( url url : geturls ( ) ) { try { urlconnection connection = url . openconnection ( ) ; if ( connection instanceof jarurlconnection ) { clearcache ( connection ) ; } } catch ( ioexception ex ) {	Clear URL caches.
public int start ( ) throws ioexception { synchronized ( this . monitor ) { assert . state ( this . serverthread == null , str_ ) ; serversocketchannel serversocketchannel = serversocketchannel . open ( ) ; serversocketchannel . socket ( ) . bind ( new inetsocketaddress ( this . listenport ) ) ; int port = serversocketchannel . socket ( ) . getlocalport ( ) ; logger . trace ( str_ + port ) ; this . serverthread = new serverthread ( serversocketchannel ) ; this . serverthread . start ( ) ; return port ; } }	Start the client and accept incoming connections.
public void stop ( ) throws ioexception { synchronized ( this . monitor ) { if ( this . serverthread != null ) { this . serverthread . close ( ) ; try { this . serverthread . join ( num_ ) ; } catch ( interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; } this . serverthread = null ; } } }	Stop the client, disconnecting any servers.
protected final file createtempdir ( string prefix ) { try { file tempdir = file . createtempfile ( prefix + str_ , str_ + getport ( ) ) ; tempdir . delete ( ) ; tempdir . mkdir ( ) ; tempdir . deleteonexit ( ) ; return tempdir ; } catch ( ioexception ex ) { throw new webserverexception ( str_ + system . getproperty ( str_ ) , ex ) ; } }	Return the absolute temp dir for given web server.
private scope peek ( ) throws jsonexception { if ( this . stack . isempty ( ) ) { throw new jsonexception ( str_ ) ; } return this . stack . get ( this . stack . size ( ) - num_ ) ; }	Returns the value on the top of the stack.
protected map < string , object > aggregatedetails ( map < string , health > healths ) { return new linkedhashmap < > ( healths ) ; }	Return the map of 'aggregate' details that should be used from the specifiedhealths.
public void setlistener ( t listener ) { assert . notnull ( listener , str_ ) ; assert . istrue ( issupportedtype ( listener ) , str_ ) ; this . listener = listener ; }	Set the listener that will be registered.
public int determineport ( ) { if ( collectionutils . isempty ( this . parsedaddresses ) ) { return getport ( ) ; } address address = this . parsedaddresses . get ( num_ ) ; return address . port ; }	Returns the port from the first address, or the configured port if no addresseshave been set.
public void setstatusorder ( status ... statusorder ) { string [ ] order = new string [ statusorder . length ] ; for ( int i = num_ ; i < statusorder . length ; i ++ ) { order [ i ] = statusorder [ i ] . getcode ( ) ; } setstatusorder ( arrays . aslist ( order ) ) ; }	Set the ordering of the status.
protected boolean shouldregisterjspservlet ( ) { return this . jsp != null && this . jsp . getregistered ( ) && classutils . ispresent ( this . jsp . getclassname ( ) , getclass ( ) . getclassloader ( ) ) ; }	Returns whether or not the JSP servlet should be registered with the web server.
protected void logstartupprofileinfo ( configurableapplicationcontext context ) { log log = getapplicationlog ( ) ; if ( log . isinfoenabled ( ) ) { string [ ] activeprofiles = context . getenvironment ( ) . getactiveprofiles ( ) ; if ( objectutils . isempty ( activeprofiles ) ) { string [ ] defaultprofiles = context . getenvironment ( ) . getdefaultprofiles ( ) ; log . info ( str_ + stringutils . arraytocommadelimitedstring ( defaultprofiles ) ) ; } else { log . info ( str_ + stringutils . arraytocommadelimitedstring ( activeprofiles ) ) ; } } }	Called to log active profile information.
protected void load ( applicationcontext context , object [ ] sources ) { if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ + stringutils . arraytocommadelimitedstring ( sources ) ) ; } beandefinitionloader loader = createbeandefinitionloader ( getbeandefinitionregistry ( context ) , sources ) ; if ( this . beannamegenerator != null ) { loader . setbeannamegenerator ( this . beannamegenerator ) ; } if ( this . resourceloader != null ) { loader . setresourceloader ( this . resourceloader ) ; } if ( this . environment != null ) { loader . setenvironment ( this . environment ) ; } loader . load ( ) ; }	Load beans into the application context.
private beandefinitionregistry getbeandefinitionregistry ( applicationcontext context ) { if ( context instanceof beandefinitionregistry ) { return ( beandefinitionregistry ) context ; } if ( context instanceof abstractapplicationcontext ) { return ( beandefinitionregistry ) ( ( abstractapplicationcontext ) context ) . getbeanfactory ( ) ; } throw new illegalstateexception ( str_ ) ; }	Get the bean definition registry.
protected void registerloggedexception ( throwable exception ) { springbootexceptionhandler handler = getspringbootexceptionhandler ( ) ; if ( handler != null ) { handler . registerloggedexception ( exception ) ; } }	Register that the given exception has been logged.
public string add ( string extension , string mimetype ) { mapping previous = this . map . put ( extension , new mapping ( extension , mimetype ) ) ; return ( previous != null ) ? previous . getmimetype ( ) : null ; }	Add a new mime mapping.
public string get ( string extension ) { mapping mapping = this . map . get ( extension ) ; return ( mapping != null ) ? mapping . getmimetype ( ) : null ; }	Get a mime mapping for the given extension.
public string remove ( string extension ) { mapping previous = this . map . remove ( extension ) ; return ( previous != null ) ? previous . getmimetype ( ) : null ; }	Remove an existing mapping.
public void setbeannamegenerator ( beannamegenerator beannamegenerator ) { this . annotatedreader . setbeannamegenerator ( beannamegenerator ) ; this . xmlreader . setbeannamegenerator ( beannamegenerator ) ; this . scanner . setbeannamegenerator ( beannamegenerator ) ; }	Set the bean name generator to be used by the underlying readers and scanner.
public void setresourceloader ( resourceloader resourceloader ) { this . resourceloader = resourceloader ; this . xmlreader . setresourceloader ( resourceloader ) ; this . scanner . setresourceloader ( resourceloader ) ; }	Set the resource loader to be used by the underlying readers and scanner.
public void setenvironment ( configurableenvironment environment ) { this . annotatedreader . setenvironment ( environment ) ; this . xmlreader . setenvironment ( environment ) ; this . scanner . setenvironment ( environment ) ; }	Set the environment to be used by the underlying readers and scanner.
public void putall ( map < ? , ? > map ) { assert . notnull ( map , str_ ) ; assertnotreadonlysystemattributesmap ( map ) ; map . foreach ( this :: put ) ; }	Add all entries from the specified map.
public void put ( object name , object value ) { this . source . put ( ( name != null ) ? name . tostring ( ) : null , value ) ; }	Add an individual entry.
protected serverthread getserverthread ( ) throws ioexception { synchronized ( this ) { if ( this . serverthread == null ) { bytechannel channel = this . serverconnection . open ( this . longpolltimeout ) ; this . serverthread = new serverthread ( channel ) ; this . serverthread . start ( ) ; } return this . serverthread ; } }	Returns the active server thread, creating and starting it if necessary.
public mono < accesslevel > getaccesslevel ( string token , string applicationid ) throws cloudfoundryauthorizationexception { string uri = getpermissionsuri ( applicationid ) ; return this . webclient . get ( ) . uri ( uri ) . header ( str_ , str_ + token ) . retrieve ( ) . bodytomono ( map . class ) . map ( this :: getaccesslevel ) . onerrormap ( this :: maperror ) ; }	Return a Mono of the access level that should be granted to the given token.
public mono < string > getuaaurl ( ) { this . uaaurl = this . webclient . get ( ) . uri ( this . cloudcontrollerurl + str_ ) . retrieve ( ) . bodytomono ( map . class ) . map ( ( response ) -> ( string ) response . get ( str_ ) ) . cache ( ) . onerrormap ( ( ex ) -> new cloudfoundryauthorizationexception ( reason . service_unavailable , str_ ) ) ; return this . uaaurl ; }	Return a Mono of URL of the UAA.
protected final filterartifacts getfilters ( artifactsfilter ... additionalfilters ) { filterartifacts filters = new filterartifacts ( ) ; for ( artifactsfilter additionalfilter : additionalfilters ) { filters . addfilter ( additionalfilter ) ; } filters . addfilter ( new matchinggroupidfilter ( cleanfilterconfig ( this . excludegroupids ) ) ) ; if ( this . includes != null && ! this . includes . isempty ( ) ) { filters . addfilter ( new includefilter ( this . includes ) ) ; } if ( this . excludes != null && ! this . excludes . isempty ( ) ) { filters . addfilter ( new excludefilter ( this . excludes ) ) ; } return filters ; }	Return artifact filters configured for this MOJO.
public int size ( ) { int size = num_ ; for ( sourcefolder sourcefolder : this . sourcefolders . values ( ) ) { size += sourcefolder . getfiles ( ) . size ( ) ; } return size ; }	Return the size of the collection.
public int getexitcode ( ) { int exitcode = num_ ; for ( exitcodegenerator generator : this . generators ) { try { int value = generator . getexitcode ( ) ; if ( value > num_ && value > exitcode || value < num_ && value < exitcode ) { exitcode = value ; } } catch ( exception ex ) { exitcode = ( exitcode != num_ ) ? exitcode : num_ ; ex . printstacktrace ( ) ; } } return exitcode ; }	Get the final exit code that should be returned based on all contained generators.
public void handle ( serverhttprequest request , serverhttpresponse response ) throws ioexception { try { assert . state ( request . getheaders ( ) . getcontentlength ( ) > num_ , str_ ) ; objectinputstream objectinputstream = new objectinputstream ( request . getbody ( ) ) ; classloaderfiles files = ( classloaderfiles ) objectinputstream . readobject ( ) ; objectinputstream . close ( ) ; this . server . updateandrestart ( files ) ; response . setstatuscode ( httpstatus . ok ) ; } catch ( exception ex ) { logger . warn ( str_ , ex ) ; response . setstatuscode ( httpstatus . internal_server_error ) ; } }	Handle a server request.
protected file getportfile ( applicationcontext applicationcontext ) { string namespace = getservernamespace ( applicationcontext ) ; if ( stringutils . isempty ( namespace ) ) { return this . file ; } string name = this . file . getname ( ) ; string extension = stringutils . getfilenameextension ( this . file . getname ( ) ) ; name = name . substring ( num_ , name . length ( ) - extension . length ( ) - num_ ) ; if ( isuppercase ( name ) ) { name = name + str_ + namespace . touppercase ( locale . english ) ; } else { name = name + str_ + namespace . tolowercase ( locale . english ) ; } if ( stringutils . haslength ( extension ) ) { name = name + str_ + extension ; } return new file ( this . file . getparentfile ( ) , name ) ; }	Return the actual port file that should be written for the given applicationcontext.
public static operationinvoker apply ( operationinvoker invoker , long timetolive ) { if ( timetolive > num_ ) { return new cachingoperationinvoker ( invoker , timetolive ) ; } return invoker ; }	Apply caching configuration when appropriate to the given invoker.
public void writeto ( writablebytechannel channel ) throws ioexception { assert . notnull ( channel , str_ ) ; while ( this . data . hasremaining ( ) ) { channel . write ( this . data ) ; } }	Write the content of this payload to the given target channel.
public string tohexstring ( ) { byte [ ] bytes = this . data . array ( ) ; char [ ] hex = new char [ this . data . remaining ( ) * num_ ] ; for ( int i = this . data . position ( ) ; i < this . data . remaining ( ) ; i ++ ) { int b = bytes [ i ] & num_ ; hex [ i * num_ ] = hex_chars [ b > > > num_ ] ; hex [ i * num_ + num_ ] = hex_chars [ b & num_ ] ; } return new string ( hex ) ; }	Return the payload as a hexadecimal string.
protected boolean ismain ( thread thread ) { return thread . getname ( ) . equals ( str_ ) && thread . getcontextclassloader ( ) . getclass ( ) . getname ( ) . contains ( str_ ) ; }	Returns if the thread is for a main invocation.
public accesslevel getaccesslevel ( string token , string applicationid ) throws cloudfoundryauthorizationexception { try { uri uri = getpermissionsuri ( applicationid ) ; requestentity < ? > request = requestentity . get ( uri ) . header ( str_ , str_ + token ) . build ( ) ; map < ? , ? > body = this . resttemplate . exchange ( request , map . class ) . getbody ( ) ; if ( boolean . true . equals ( body . get ( str_ ) ) ) { return accesslevel . full ; } return accesslevel . restricted ; } catch ( httpclienterrorexception ex ) { if ( ex . getstatuscode ( ) . equals ( httpstatus . forbidden ) ) { throw new cloudfoundryauthorizationexception ( reason . access_denied , str_ ) ; } throw new cloudfoundryauthorizationexception ( reason . invalid_token , str_ , ex ) ; } catch ( httpservererrorexception ex ) { throw new cloudfoundryauthorizationexception ( reason . service_unavailable , str_ ) ; } }	Return the access level that should be granted to the given token.
public map < string , string > fetchtokenkeys ( ) { try { return extracttokenkeys ( this . resttemplate . getforobject ( getuaaurl ( ) + str_ , map . class ) ) ; } catch ( httpstatuscodeexception ex ) { throw new cloudfoundryauthorizationexception ( reason . service_unavailable , str_ ) ; } }	Return all token keys known by the UAA.
public string getuaaurl ( ) { if ( this . uaaurl == null ) { try { map < ? , ? > response = this . resttemplate . getforobject ( this . cloudcontrollerurl + str_ , map . class ) ; this . uaaurl = ( string ) response . get ( str_ ) ; } catch ( httpstatuscodeexception ex ) { throw new cloudfoundryauthorizationexception ( reason . service_unavailable , str_ ) ; } } return this . uaaurl ; }	Return the URL of the UAA.
public void addurlmappings ( string ... urlmappings ) { assert . notnull ( urlmappings , str_ ) ; this . urlmappings . addall ( arrays . aslist ( urlmappings ) ) ; }	Add URL mappings, as defined in the Servlet specification, for the servlet.
private configuration geterrorpageconfiguration ( ) { return new abstractconfiguration ( ) { @ override public void configure ( webappcontext context ) throws exception { errorhandler errorhandler = context . geterrorhandler ( ) ; context . seterrorhandler ( new jettyembeddederrorhandler ( errorhandler ) ) ; addjettyerrorpages ( errorhandler , geterrorpages ( ) ) ; } } ; }	Create a configuration object that adds error handlers.
private configuration getmimetypeconfiguration ( ) { return new abstractconfiguration ( ) { @ override public void configure ( webappcontext context ) throws exception { mimetypes mimetypes = context . getmimetypes ( ) ; for ( mimemappings . mapping mapping : getmimemappings ( ) ) { mimetypes . addmimemapping ( mapping . getextension ( ) , mapping . getmimetype ( ) ) ; } } } ; }	Create a configuration object that adds mime type mappings.
public object nextvalue ( ) throws jsonexception { int c = nextcleaninternal ( ) ; switch ( c ) { case - num_ : throw syntaxerror ( str_ ) ; case str_ : return readobject ( ) ; case str_ : return readarray ( ) ; case str_ : case str_ : return nextstring ( ( char ) c ) ; default : this . pos -- ; return readliteral ( ) ; } }	Returns the next value from the input.
public static list < repositoryconfiguration > createdefaultrepositoryconfiguration ( ) { mavensettings mavensettings = new mavensettingsreader ( ) . readsettings ( ) ; list < repositoryconfiguration > repositoryconfiguration = new arraylist < > ( ) ; repositoryconfiguration . add ( maven_central ) ; if ( ! boolean . getboolean ( str_ ) ) { repositoryconfiguration . add ( spring_milestone ) ; repositoryconfiguration . add ( spring_snapshot ) ; } adddefaultcacheasrepository ( mavensettings . getlocalrepository ( ) , repositoryconfiguration ) ; addactiveprofilerepositories ( mavensettings . getactiveprofiles ( ) , repositoryconfiguration ) ; return repositoryconfiguration ; }	Create a new default repository configuration.
protected void handleinvalidexcludes ( list < string > invalidexcludes ) { stringbuilder message = new stringbuilder ( ) ; for ( string exclude : invalidexcludes ) { message . append ( str_ ) . append ( exclude ) . append ( string . format ( str_ ) ) ; } throw new illegalstateexception ( string . format ( str_ + str_ , message ) ) ; }	Handle any invalid excludes that have been specified.
protected set < string > getexclusions ( annotationmetadata metadata , annotationattributes attributes ) { set < string > excluded = new linkedhashset < > ( ) ; excluded . addall ( aslist ( attributes , str_ ) ) ; excluded . addall ( arrays . aslist ( attributes . getstringarray ( str_ ) ) ) ; excluded . addall ( getexcludeautoconfigurationsproperty ( ) ) ; return excluded ; }	Return any exclusions that limit the candidate configurations.
protected configurations merge ( configurations other ) { set < class < ? > > mergedclasses = new linkedhashset < > ( getclasses ( ) ) ; mergedclasses . addall ( other . getclasses ( ) ) ; return merge ( mergedclasses ) ; }	Merge configurations from another source of the same type.
public static class < ? > [ ] getclasses ( collection < configurations > configurations ) { list < configurations > ordered = new arraylist < > ( configurations ) ; ordered . sort ( comparator ) ; list < configurations > collated = collate ( ordered ) ; linkedhashset < class < ? > > classes = collated . stream ( ) . flatmap ( configurations :: streamclasses ) . collect ( collectors . tocollection ( linkedhashset :: new ) ) ; return classutils . toclassarray ( classes ) ; }	Return the classes from all the specified configurations in the order that theywould be registered.
private static string coercetoepoch ( string s ) { long epoch = parseepochsecond ( s ) ; if ( epoch != null ) { return string . valueof ( epoch ) ; } simpledateformat format = new simpledateformat ( str_ ) ; try { return string . valueof ( format . parse ( s ) . gettime ( ) ) ; } catch ( parseexception ex ) { return s ; } }	Attempt to convert the specified value to epoch time.
public void write ( file file ) throws ioexception { assert . state ( this . pid != null , str_ ) ; createparentfolder ( file ) ; if ( file . exists ( ) ) { assertcanoverwrite ( file ) ; } try ( filewriter writer = new filewriter ( file ) ) { writer . append ( this . pid ) ; } }	Write the PID to the specified file.
private void preinitializeleakyclasses ( ) { try { class < ? > readerclass = classnamereader . class ; field field = readerclass . getdeclaredfield ( str_ ) ; field . setaccessible ( bool_ ) ; ( ( throwable ) field . get ( null ) ) . fillinstacktrace ( ) ; } catch ( exception ex ) { this . logger . warn ( str_ , ex ) ; } }	CGLIB has a private exception field which needs to initialized early to ensure thatthe stacktrace doesn't retain a reference to the RestartClassLoader.
public void addurls ( collection < url > urls ) { assert . notnull ( urls , str_ ) ; this . urls . addall ( urls ) ; }	Add additional URLs to be includes in the next restart.
public void restart ( failurehandler failurehandler ) { if ( ! this . enabled ) { this . logger . debug ( str_ ) ; return ; } this . logger . debug ( str_ ) ; getleaksafethread ( ) . call ( ( ) -> { restarter . this . stop ( ) ; restarter . this . start ( failurehandler ) ; return null ; } ) ; }	Restart the running application.
protected void start ( failurehandler failurehandler ) throws exception { do { throwable error = dostart ( ) ; if ( error == null ) { return ; } if ( failurehandler . handle ( error ) == outcome . abort ) { return ; } } while ( bool_ ) ; }	Start the application.
protected throwable relaunch ( classloader classloader ) throws exception { restartlauncher launcher = new restartlauncher ( classloader , this . mainclassname , this . args , this . exceptionhandler ) ; launcher . start ( ) ; launcher . join ( ) ; return launcher . geterror ( ) ; }	Relaunch the application using the specified classloader.
protected void stop ( ) throws exception { this . logger . debug ( str_ ) ; this . stoplock . lock ( ) ; try { for ( configurableapplicationcontext context : this . rootcontexts ) { context . close ( ) ; this . rootcontexts . remove ( context ) ; } cleanupcaches ( ) ; if ( this . forcereferencecleanup ) { forcereferencecleanup ( ) ; } } finally { this . stoplock . unlock ( ) ; } system . gc ( ) ; system . runfinalization ( ) ; }	Stop the application.
public string getlastelement ( form form ) { int size = getnumberofelements ( ) ; return ( size != num_ ) ? getelement ( size - num_ , form ) : empty_string ; }	Return the last element in the name in the given form.
public string getelement ( int elementindex , form form ) { charsequence element = this . elements . get ( elementindex ) ; elementtype type = this . elements . gettype ( elementindex ) ; if ( type . isindexed ( ) ) { return element . tostring ( ) ; } if ( form == form . original ) { if ( type != elementtype . non_uniform ) { return element . tostring ( ) ; } return converttooriginalform ( element ) . tostring ( ) ; } if ( form == form . dashed ) { if ( type == elementtype . uniform || type == elementtype . dashed ) { return element . tostring ( ) ; } return converttodashedelement ( element ) . tostring ( ) ; } charsequence uniformelement = this . uniformelements [ elementindex ] ; if ( uniformelement == null ) { uniformelement = ( type != elementtype . uniform ) ? converttouniformelement ( element ) : element ; this . uniformelements [ elementindex ] = uniformelement . tostring ( ) ; } return uniformelement . tostring ( ) ; }	Return an element in the name in the given form.
public void addcommands ( iterable < command > commands ) { assert . notnull ( commands , str_ ) ; for ( command command : commands ) { addcommand ( command ) ; } }	Add the specified commands.
public command findcommand ( string name ) { for ( command candidate : this . commands ) { string candidatename = candidate . getname ( ) ; if ( candidatename . equals ( name ) || ( isoptioncommand ( candidate ) && ( str_ + candidatename ) . equals ( name ) ) ) { return candidate ; } } return null ; }	Find a command by name.
public int runandhandleerrors ( string ... args ) { string [ ] argswithoutdebugflags = removedebugflags ( args ) ; boolean debug = argswithoutdebugflags . length != args . length ; if ( debug ) { system . setproperty ( str_ , str_ ) ; } try { exitstatus result = run ( argswithoutdebugflags ) ;	Run the appropriate and handle and errors.
protected exitstatus run ( string ... args ) throws exception { if ( args . length == num_ ) { throw new noargumentsexception ( ) ; } string commandname = args [ num_ ] ; string [ ] commandarguments = arrays . copyofrange ( args , num_ , args . length ) ; command command = findcommand ( commandname ) ; if ( command == null ) { throw new nosuchcommandexception ( commandname ) ; } beforerun ( command ) ; try { return command . run ( commandarguments ) ; } finally { afterrun ( command ) ; } }	Parse the arguments and run a suitable command.
private void applyserializationmodifier ( objectmapper mapper ) { serializerfactory factory = beanserializerfactory . instance . withserializermodifier ( new genericserializermodifier ( ) ) ; mapper . setserializerfactory ( factory ) ; }	Ensure only bindable and non-cyclic bean properties are reported.
@ suppresswarnings ( str_ ) private map < string , object > sanitize ( string prefix , map < string , object > map ) { map . foreach ( ( key , value ) -> { string qualifiedkey = ( prefix . isempty ( ) ? prefix : prefix + str_ ) + key ; if ( value instanceof map ) { map . put ( key , sanitize ( qualifiedkey , ( map < string , object > ) value ) ) ; } else if ( value instanceof list ) { map . put ( key , sanitize ( qualifiedkey , ( list < object > ) value ) ) ; } else { value = this . sanitizer . sanitize ( key , value ) ; value = this . sanitizer . sanitize ( qualifiedkey , value ) ; map . put ( key , value ) ; } } ) ; return map ; }	Sanitize all unwanted configuration properties to avoid leaking of sensitiveinformation.
public void setkeystosanitize ( string ... keystosanitize ) { assert . notnull ( keystosanitize , str_ ) ; this . keystosanitize = new pattern [ keystosanitize . length ] ; for ( int i = num_ ; i < keystosanitize . length ; i ++ ) { this . keystosanitize [ i ] = getpattern ( keystosanitize [ i ] ) ; } }	Keys that should be sanitized.
public object sanitize ( string key , object value ) { if ( value == null ) { return null ; } for ( pattern pattern : this . keystosanitize ) { if ( pattern . matcher ( key ) . matches ( ) ) { return str_ ; } } return value ; }	Sanitize the given value if necessary.
public static string numbertostring ( number number ) throws jsonexception { if ( number == null ) { throw new jsonexception ( str_ ) ; } double doublevalue = number . doublevalue ( ) ; json . checkdouble ( doublevalue ) ;	Encodes the number as a JSON string.
public void configure ( defaultjmslistenercontainerfactory factory , connectionfactory connectionfactory ) { assert . notnull ( factory , str_ ) ; assert . notnull ( connectionfactory , str_ ) ; factory . setconnectionfactory ( connectionfactory ) ; factory . setpubsubdomain ( this . jmsproperties . ispubsubdomain ( ) ) ; if ( this . transactionmanager != null ) { factory . settransactionmanager ( this . transactionmanager ) ; } else { factory . setsessiontransacted ( bool_ ) ; } if ( this . destinationresolver != null ) { factory . setdestinationresolver ( this . destinationresolver ) ; } if ( this . messageconverter != null ) { factory . setmessageconverter ( this . messageconverter ) ; } jmsproperties . listener listener = this . jmsproperties . getlistener ( ) ; factory . setautostartup ( listener . isautostartup ( ) ) ; if ( listener . getacknowledgemode ( ) != null ) { factory . setsessionacknowledgemode ( listener . getacknowledgemode ( ) . getmode ( ) ) ; } string concurrency = listener . formatconcurrency ( ) ; if ( concurrency != null ) { factory . setconcurrency ( concurrency ) ; } }	Configure the specified jms listener container factory.
public void include ( configurationmetadatarepository repository ) { for ( configurationmetadatagroup group : repository . getallgroups ( ) . values ( ) ) { configurationmetadatagroup existinggroup = this . allgroups . get ( group . getid ( ) ) ; if ( existinggroup == null ) { this . allgroups . put ( group . getid ( ) , group ) ; } else {	Merge the content of the specified repository to this repository.
protected void configuressl ( sslcontextfactory factory , ssl ssl , sslstoreprovider sslstoreprovider ) { factory . setprotocol ( ssl . getprotocol ( ) ) ; configuresslclientauth ( factory , ssl ) ; configuresslpasswords ( factory , ssl ) ; factory . setcertalias ( ssl . getkeyalias ( ) ) ; if ( ! objectutils . isempty ( ssl . getciphers ( ) ) ) { factory . setincludeciphersuites ( ssl . getciphers ( ) ) ; factory . setexcludeciphersuites ( ) ; } if ( ssl . getenabledprotocols ( ) != null ) { factory . setincludeprotocols ( ssl . getenabledprotocols ( ) ) ; } if ( sslstoreprovider != null ) { try { factory . setkeystore ( sslstoreprovider . getkeystore ( ) ) ; factory . settruststore ( sslstoreprovider . gettruststore ( ) ) ; } catch ( exception ex ) { throw new illegalstateexception ( str_ , ex ) ; } } else { configuresslkeystore ( factory , ssl ) ; configuressltruststore ( factory , ssl ) ; } }	Configure the SSL connection.
public void configure ( concurrentkafkalistenercontainerfactory < object , object > listenerfactory , consumerfactory < object , object > consumerfactory ) { listenerfactory . setconsumerfactory ( consumerfactory ) ; configurelistenerfactory ( listenerfactory ) ; configurecontainer ( listenerfactory . getcontainerproperties ( ) ) ; }	Configure the specified Kafka listener container factory.
public resource resolveconfiglocation ( ) { if ( this . config == null ) { return null ; } assert . istrue ( this . config . exists ( ) , ( ) -> str_ + str_ + this . config . getdescription ( ) + str_ ) ; return this . config ; }	Resolve the config location if set.
public < t > t execute ( long wait , int maxattempts , callable < t > callback ) throws exception { getlog ( ) . debug ( str_ ) ; for ( int i = num_ ; i < maxattempts ; i ++ ) { t result = callback . call ( ) ; if ( result != null ) { return result ; } string message = str_ + wait + str_ + ( i + num_ ) + str_ ; getlog ( ) . debug ( message ) ; synchronized ( this . lock ) { try { this . lock . wait ( wait ) ; } catch ( interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; throw new illegalstateexception ( str_ ) ; } } } throw new mojoexecutionexception ( str_ + str_ + ( wait * maxattempts ) + str_ ) ; }	Execute a task, retrying it on failure.
public void setinitparameters ( map < string , string > initparameters ) { assert . notnull ( initparameters , str_ ) ; this . initparameters = new linkedhashmap < > ( initparameters ) ; }	Set init-parameters for this registration.
public void addinitparameter ( string name , string value ) { assert . notnull ( name , str_ ) ; this . initparameters . put ( name , value ) ; }	Add a single init-parameter, replacing any existing parameter with the same name.
protected final string getordeducename ( object value ) { return ( this . name != null ) ? this . name : conventions . getvariablename ( value ) ; }	Deduces the name for this registration.
@ suppresswarnings ( str_ ) public < a extends annotation > a getannotation ( class < a > type ) { for ( annotation annotation : this . annotations ) { if ( type . isinstance ( annotation ) ) { return ( a ) annotation ; } } return null ; }	Return a single associated annotations that could affect binding.
@ suppresswarnings ( str_ ) protected class < ? extends t > getcausetype ( ) { return ( class < ? extends t > ) resolvabletype . forclass ( abstractfailureanalyzer . class , getclass ( ) ) . resolvegeneric ( ) ; }	Return the cause type being handled by the analyzer.
private map < string , object > flatten ( map < string , object > map ) { map < string , object > result = new linkedhashmap < > ( ) ; flatten ( null , result , map ) ; return result ; }	Flatten the map keys using period separator.
public void recordconditionevaluation ( string source , condition condition , conditionoutcome outcome ) { assert . notnull ( source , str_ ) ; assert . notnull ( condition , str_ ) ; assert . notnull ( outcome , str_ ) ; this . unconditionalclasses . remove ( source ) ; if ( ! this . outcomes . containskey ( source ) ) { this . outcomes . put ( source , new conditionandoutcomes ( ) ) ; } this . outcomes . get ( source ) . add ( condition , outcome ) ; this . addedancestoroutcomes = bool_ ; }	Record the occurrence of condition evaluation.
public void recordexclusions ( collection < string > exclusions ) { assert . notnull ( exclusions , str_ ) ; this . exclusions . addall ( exclusions ) ; }	Records the names of the classes that have been excluded from condition evaluation.
public void recordevaluationcandidates ( list < string > evaluationcandidates ) { assert . notnull ( evaluationcandidates , str_ ) ; this . unconditionalclasses . addall ( evaluationcandidates ) ; }	Records the names of the classes that are candidates for condition evaluation.
public map < string , conditionandoutcomes > getconditionandoutcomesbysource ( ) { if ( ! this . addedancestoroutcomes ) { this . outcomes . foreach ( ( source , sourceoutcomes ) -> { if ( ! sourceoutcomes . isfullmatch ( ) ) { addnomatchoutcometoancestors ( source ) ; } } ) ; this . addedancestoroutcomes = bool_ ; } return collections . unmodifiablemap ( this . outcomes ) ; }	Returns condition outcomes from this report, grouped by the source.
public set < string > getunconditionalclasses ( ) { set < string > filtered = new hashset < > ( this . unconditionalclasses ) ; filtered . removeall ( this . exclusions ) ; return collections . unmodifiableset ( filtered ) ; }	Returns the names of the classes that were evaluated but were not conditional.
public boolean createschema ( ) { list < resource > scripts = getscripts ( str_ , this . properties . getschema ( ) , str_ ) ; if ( ! scripts . isempty ( ) ) { if ( ! isenabled ( ) ) { logger . debug ( str_ ) ; return bool_ ; } string username = this . properties . getschemausername ( ) ; string password = this . properties . getschemapassword ( ) ; runscripts ( scripts , username , password ) ; } return ! scripts . isempty ( ) ; }	Create the schema if necessary.
public void initschema ( ) { list < resource > scripts = getscripts ( str_ , this . properties . getdata ( ) , str_ ) ; if ( ! scripts . isempty ( ) ) { if ( ! isenabled ( ) ) { logger . debug ( str_ ) ; return ; } string username = this . properties . getdatausername ( ) ; string password = this . properties . getdatapassword ( ) ; runscripts ( scripts , username , password ) ; } }	Initialize the schema if necessary.
public void settldskippatterns ( collection < string > patterns ) { assert . notnull ( patterns , str_ ) ; this . tldskippatterns = new linkedhashset < > ( patterns ) ; }	Set the patterns that match jars to ignore for TLD scanning.
public void addtldskippatterns ( string ... patterns ) { assert . notnull ( patterns , str_ ) ; this . tldskippatterns . addall ( arrays . aslist ( patterns ) ) ; }	Add patterns that match jars to ignore for TLD scanning.
public static boolean isterminal ( arraylist < configuration > beam ) { for ( configuration configuration : beam ) if ( ! configuration . state . isterminalstate ( ) ) return bool_ ; return bool_ ; }	Shows true if all of the configurations in the beam are in the terminal state.
public string [ ] [ ] towordtagnerarray ( nertagset tagset ) { list < string [ ] > tuplelist = utility . convertsentencetoner ( this , tagset ) ; string [ ] [ ] result = new string [ num_ ] [ tuplelist . size ( ) ] ; iterator < string [ ] > iterator = tuplelist . iterator ( ) ; for ( int i = num_ ; i < result [ num_ ] . length ; i ++ ) { string [ ] tuple = iterator . next ( ) ; for ( int j = num_ ; j < num_ ; ++ j ) { result [ j ] [ i ] = tuple [ j ] ; } } return result ; }	word pos ner.
protected int addwordtovocab ( string word ) { vocab [ vocabsize ] = new vocabword ( word ) ; vocabsize ++ ;	Adds a word to the vocabulary.
int searchvocab ( string word ) { if ( word == null ) return - num_ ; integer pos = vocabindexmap . get ( word ) ; return pos == null ? - num_ : pos . intvalue ( ) ; }	Returns position of a word in the vocabulary; if the word is not found, returns -1.
void sortvocab ( ) { arrays . sort ( vocab , num_ , vocabsize ) ;	Sorts the vocabulary by frequency using word counts.
void createbinarytree ( ) { int [ ] point = new int [ vocabword . max_code_length ] ; char [ ] code = new char [ vocabword . max_code_length ] ; int [ ] count = new int [ vocabsize * num_ + num_ ] ; char [ ] binary = new char [ vocabsize * num_ + num_ ] ; int [ ] parentnode = new int [ vocabsize * num_ + num_ ] ; for ( int i = num_ ; i < vocabsize ; i ++ ) count [ i ] = vocab [ i ] . cn ; for ( int i = vocabsize ; i < vocabsize * num_ ; i ++ ) count [ i ] = integer . max_value ; int pos1 = vocabsize - num_ ; int pos2 = vocabsize ;	Create binary Huffman tree using the word counts.Frequent words will have short uniqe binary codes.
@ override public int [ ] toidlist ( int codepoint ) { int count ; if ( codepoint < num_ ) count = num_ ; else if ( codepoint < num_ ) count = num_ ; else if ( codepoint < num_ ) count = num_ ; else if ( codepoint < num_ ) count = num_ ; else if ( codepoint < num_ ) count = num_ ; else if ( codepoint <= num_ ) count = num_ ; else return emptylist ; int [ ] r = new int [ count ] ; switch ( count ) { case num_ : r [ num_ ] = ( char ) ( num_ | ( codepoint & num_ ) ) ; codepoint = codepoint > > num_ ; codepoint |= num_ ; case num_ : r [ num_ ] = ( char ) ( num_ | ( codepoint & num_ ) ) ; codepoint = codepoint > > num_ ; codepoint |= num_ ; case num_ : r [ num_ ] = ( char ) ( num_ | ( codepoint & num_ ) ) ; codepoint = codepoint > > num_ ; codepoint |= num_ ; case num_ : r [ num_ ] = ( char ) ( num_ | ( codepoint & num_ ) ) ; codepoint = codepoint > > num_ ; codepoint |= num_ ; case num_ : r [ num_ ] = ( char ) ( num_ | ( codepoint & num_ ) ) ; codepoint = codepoint > > num_ ; codepoint |= num_ ; case num_ : r [ num_ ] = ( char ) codepoint ; } return r ; }	codes ported from iconv lib in utf8.h utf8_codepointtomb.
void normalize ( ) { double nrm = norm ( ) ; for ( map . entry < integer , double > d : entryset ( ) ) { d . setvalue ( d . getvalue ( ) / nrm ) ; } }	Normalize a vector.
void multiply_constant ( double x ) { for ( map . entry < integer , double > entry : entryset ( ) ) { entry . setvalue ( entry . getvalue ( ) * x ) ; } }	Multiply each value of avector by a constant value.
void add_vector ( sparsevector vec ) { for ( map . entry < integer , double > entry : vec . entryset ( ) ) { double v = get ( entry . getkey ( ) ) ; if ( v == null ) v = num_ ; put ( entry . getkey ( ) , v + entry . getvalue ( ) ) ; } }	Add other vector.
static double inner_product ( sparsevector vec1 , sparsevector vec2 ) { iterator < map . entry < integer , double > > it ; sparsevector other ; if ( vec1 . size ( ) < vec2 . size ( ) ) { it = vec1 . entryset ( ) . iterator ( ) ; other = vec2 ; } else { it = vec2 . entryset ( ) . iterator ( ) ; other = vec1 ; } double prod = num_ ; while ( it . hasnext ( ) ) { map . entry < integer , double > entry = it . next ( ) ; prod += entry . getvalue ( ) * other . get ( entry . getkey ( ) ) ; } return prod ; }	Calculate the inner product value between vectors.
double cosine ( sparsevector vec1 , sparsevector vec2 ) { double norm1 = vec1 . norm ( ) ; double norm2 = vec2 . norm ( ) ; double result = num_ ; if ( norm1 == num_ && norm2 == num_ ) { return result ; } else { double prod = inner_product ( vec1 , vec2 ) ; result = prod / ( norm1 * norm2 ) ; return double . isnan ( result ) ? num_ : result ; } }	Calculate the cosine value between vectors.
void reducevocab ( ) { table = new int [ vocabsize ] ; int j = num_ ; for ( int i = num_ ; i < vocabsize ; i ++ ) { if ( vocab [ i ] . cn > minreduce ) { vocab [ j ] . cn = vocab [ i ] . cn ; vocab [ j ] . word = vocab [ i ] . word ; table [ vocabindexmap . get ( vocab [ j ] . word ) ] = j ; j ++ ; } else { table [ vocabindexmap . get ( vocab [ j ] . word ) ] = - num_ ; } }	Reduces the vocabulary by removing infrequent tokens.
string readword ( bufferedreader raf ) throws ioexception { while ( bool_ ) {	Reads a single word from a file, assuming space + tab + EOL to be word boundaries.
void set_composite_vector ( ) { composite_ . clear ( ) ; for ( document < k > document : documents_ ) { composite_ . add_vector ( document . feature ( ) ) ; } }	Add the vectors of all documents to a composite vector.
sparsevector centroid_vector ( ) { if ( documents_ . size ( ) > num_ && composite_ . size ( ) == num_ ) set_composite_vector ( ) ; centroid_ = ( sparsevector ) composite_vector ( ) . clone ( ) ; centroid_ . normalize ( ) ; return centroid_ ; }	Get the pointer of a centroid vector.
void refresh ( ) { listiterator < document < k > > listiterator = documents_ . listiterator ( ) ; while ( listiterator . hasnext ( ) ) { if ( listiterator . next ( ) == null ) listiterator . remove ( ) ; } }	Delete removed documents from the internal container.
void set_sectioned_gain ( ) { double gain = num_ ; if ( sectioned_gain_ == num_ && sectioned_clusters_ . size ( ) > num_ ) { for ( cluster < k > cluster : sectioned_clusters_ ) { gain += cluster . composite_vector ( ) . norm ( ) ; } gain -= composite_ . norm ( ) ; } sectioned_gain_ = gain ; }	Set a gain when the cluster sectioned.
public static list < string > parseorexit ( object target , string [ ] args ) { try { return parse ( target , args ) ; } catch ( illegalargumentexception e ) { system . err . println ( e . getmessage ( ) ) ; args . usage ( target ) ; system . exit ( num_ ) ; throw e ; } }	A convenience method for parsing and automatically producing error messages.
public static matrix constructwithcopy ( double [ ] [ ] a ) { int m = a . length ; int n = a [ num_ ] . length ; matrix x = new matrix ( m , n ) ; double [ ] [ ] c = x . getarray ( ) ; for ( int i = num_ ; i < m ; i ++ ) { if ( a [ i ] . length != n ) { throw new illegalargumentexception ( str_ ) ; } for ( int j = num_ ; j < n ; j ++ ) { c [ i ] [ j ] = a [ i ] [ j ] ; } } return x ; }	Construct a matrix from a copy of a 2-D array.
public matrix copy ( ) { matrix x = new matrix ( m , n ) ; double [ ] [ ] c = x . getarray ( ) ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { c [ i ] [ j ] = a [ i ] [ j ] ; } } return x ; }	Make a deep copy of a matrix.
public double [ ] [ ] getarraycopy ( ) { double [ ] [ ] c = new double [ m ] [ n ] ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { c [ i ] [ j ] = a [ i ] [ j ] ; } } return c ; }	Copy the internal two-dimensional array.
public matrix plus ( matrix b ) { checkmatrixdimensions ( b ) ; matrix x = new matrix ( m , n ) ; double [ ] [ ] c = x . getarray ( ) ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { c [ i ] [ j ] = a [ i ] [ j ] + b . a [ i ] [ j ] ; } } return x ; }	C = A + B.
public matrix plusequals ( matrix b ) { checkmatrixdimensions ( b ) ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { a [ i ] [ j ] = a [ i ] [ j ] + b . a [ i ] [ j ] ; } } return this ; }	A = A + B.
public double trace ( ) { double t = num_ ; for ( int i = num_ ; i < math . min ( m , n ) ; i ++ ) { t += a [ i ] [ i ] ; } return t ; }	Matrix trace.
public static matrix random ( int m , int n ) { matrix a = new matrix ( m , n ) ; double [ ] [ ] x = a . getarray ( ) ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { x [ i ] [ j ] = math . random ( ) ; } } return a ; }	Generate matrix with random elements.
public static matrix identity ( int m , int n ) { matrix a = new matrix ( m , n ) ; double [ ] [ ] x = a . getarray ( ) ; for ( int i = num_ ; i < m ; i ++ ) { for ( int j = num_ ; j < n ; j ++ ) { x [ i ] [ j ] = ( i == j ? num_ : num_ ) ; } } return a ; }	Generate identity matrix.
public void print ( int w , int d ) { print ( new printwriter ( system . out , bool_ ) , w , d ) ; }	Print the matrix to stdout.
public void print ( printwriter output , int w , int d ) { decimalformat format = new decimalformat ( ) ; format . setdecimalformatsymbols ( new decimalformatsymbols ( locale . us ) ) ; format . setminimumintegerdigits ( num_ ) ; format . setmaximumfractiondigits ( d ) ; format . setminimumfractiondigits ( d ) ; format . setgroupingused ( bool_ ) ; print ( output , format , w + num_ ) ; }	Print the matrix to the output stream.
public void print ( numberformat format , int width ) { print ( new printwriter ( system . out , bool_ ) , format , width ) ; }	Print the matrix to stdout.
public final void addstrings ( collection < string > strcollection ) { if ( sourcenode != null ) { string previousstring = str_ ;	Adds a Collection of Strings to the MDAG.
public void addstring ( string str ) { if ( sourcenode != null ) { addstringinternal ( str ) ; replaceorregister ( sourcenode , str ) ; } else { unsimplify ( ) ; addstring ( str ) ; } }	Adds a string to the MDAG.
private int calculatesoletransitionpathlength ( string str ) { stack < mdagnode > transitionpathnodestack = sourcenode . gettransitionpathnodes ( str ) ; transitionpathnodestack . pop ( ) ;	Calculates the length of the the sub-path in a _transition path, that is used only by a given string.
public void removestring ( string str ) { if ( sourcenode != null ) {	Removes a String from the MDAG.
private string determinelongestprefixinmdag ( string str ) { mdagnode currentnode = sourcenode ; int numberofchars = str . length ( ) ; int onepastprefixendindex = num_ ;	Determines the longest prefix of a given String that isthe prefix of another String previously added to the MDAG.
private int createsimplemdagtransitionset ( mdagnode node , simplemdagnode [ ] mdagdataarray , int onepastlastcreatedtransitionsetindex ) { int pivotindex = onepastlastcreatedtransitionsetindex ;	Creates a SimpleMDAGNode version of an MDAGNode's outgoing _transition set in mdagDataArray.
private static boolean isacceptnode ( object nodeobj ) { if ( nodeobj != null ) { class nodeobjclass = nodeobj . getclass ( ) ; if ( nodeobjclass . equals ( mdagnode . class ) ) return ( ( mdagnode ) nodeobj ) . isacceptnode ( ) ; else if ( nodeobjclass . equals ( simplemdagnode . class ) ) return ( ( simplemdagnode ) nodeobj ) . isacceptnode ( ) ; } throw new illegalargumentexception ( str_ ) ; }	Determines if a child node object is accepting.
public simplemdagnode transition ( simplemdagnode [ ] mdagdataarray , char letter ) { simplemdagnode targetnode = null ; int offset = binarysearch ( mdagdataarray , letter ) ; if ( offset >= num_ ) { targetnode = mdagdataarray [ offset ] ; }	Follows an outgoing _transition from this node.
public static simplemdagnode traversemdag ( simplemdagnode [ ] mdagdataarray , simplemdagnode sourcenode , string str ) {	Follows a _transition path starting from the source node of a MDAG.
public boolean isnonprojective ( ) { for ( int dep1 : golddependencies . keyset ( ) ) { int head1 = golddependencies . get ( dep1 ) . headindex ; for ( int dep2 : golddependencies . keyset ( ) ) { int head2 = golddependencies . get ( dep2 ) . headindex ; if ( head1 < num_ || head2 < num_ ) continue ; if ( dep1 > head1 && head1 != head2 ) if ( ( dep1 > head2 && dep1 < dep2 && head1 < head2 ) || ( dep1 < head2 && dep1 > dep2 && head1 < dep2 ) ) return bool_ ; if ( dep1 < head1 && head1 != head2 ) if ( ( head1 > head2 && head1 < dep2 && dep1 < head2 ) || ( head1 < head2 && head1 > dep2 && dep1 < dep2 ) ) return bool_ ; } } return bool_ ; }	Shows whether the tree to train is projective or not.
public void save ( outputstream stream ) throws ioexception { dataoutputstream out = null ; try { out = new dataoutputstream ( new bufferedoutputstream ( stream ) ) ; for ( int i = num_ ; i < _array . length ; ++ i ) { out . writeint ( _array [ i ] ) ; } } finally { if ( out != null ) { out . close ( ) ; } } }	Saves the trie data into a stream.
public int exactmatchsearch ( byte [ ] key ) { int unit = _array [ num_ ] ; int nodepos = num_ ; for ( byte b : key ) {	Returns the corresponding value if the key is found.
public list < pair < integer , integer > > commonprefixsearch ( byte [ ] key , int offset , int maxresults ) { arraylist < pair < integer , integer > > result = new arraylist < pair < integer , integer > > ( ) ; int unit = _array [ num_ ] ; int nodepos = num_ ;	Returns the keys that begins with the given key and its corresponding values.The first of the returned pair represents the length of the found key.
private void writearrayheader ( bytebufallocator allocator , arrayheaderredismessage msg , list < object > out ) { writearrayheader ( allocator , msg . isnull ( ) , msg . length ( ) , out ) ; }	Write array header only without body.
private void writearraymessage ( bytebufallocator allocator , arrayredismessage msg , list < object > out ) { if ( msg . isnull ( ) ) { writearrayheader ( allocator , msg . isnull ( ) , redisconstants . null_value , out ) ; } else { writearrayheader ( allocator , msg . isnull ( ) , msg . children ( ) . size ( ) , out ) ; for ( redismessage child : msg . children ( ) ) { writeredismessage ( allocator , child , out ) ; } } }	Write full constructed array message.
public static bytebuf wrappedbuffer ( bytebuffer buffer ) { if ( ! buffer . hasremaining ( ) ) { return empty_buffer ; } if ( ! buffer . isdirect ( ) && buffer . hasarray ( ) ) { return wrappedbuffer ( buffer . array ( ) , buffer . arrayoffset ( ) + buffer . position ( ) , buffer . remaining ( ) ) . order ( buffer . order ( ) ) ; } else if ( platformdependent . hasunsafe ( ) ) { if ( buffer . isreadonly ( ) ) { if ( buffer . isdirect ( ) ) { return new readonlyunsafedirectbytebuf ( alloc , buffer ) ; } else { return new readonlybytebufferbuf ( alloc , buffer ) ; } } else { return new unpooledunsafedirectbytebuf ( alloc , buffer , buffer . remaining ( ) ) ; } } else { if ( buffer . isreadonly ( ) ) { return new readonlybytebufferbuf ( alloc , buffer ) ; } else { return new unpooleddirectbytebuf ( alloc , buffer , buffer . remaining ( ) ) ; } } }	Creates a new buffer which wraps the specified NIO buffer's currentslice.
public static bytebuf wrappedbuffer ( bytebuf buffer ) { if ( buffer . isreadable ( ) ) { return buffer . slice ( ) ; } else { buffer . release ( ) ; return empty_buffer ; } }	Creates a new buffer which wraps the specified buffer's readable bytes.A modification on the specified buffer's content will be visible to thereturned buffer.
public static bytebuf wrappedbuffer ( int maxnumcomponents , bytebuf ... buffers ) { switch ( buffers . length ) { case num_ : break ; case num_ : bytebuf buffer = buffers [ num_ ] ; if ( buffer . isreadable ( ) ) { return wrappedbuffer ( buffer . order ( big_endian ) ) ; } else { buffer . release ( ) ; } break ; default : for ( int i = num_ ; i < buffers . length ; i ++ ) { bytebuf buf = buffers [ i ] ; if ( buf . isreadable ( ) ) { return new compositebytebuf ( alloc , bool_ , maxnumcomponents , buffers , i ) ; } buf . release ( ) ; } break ; } return empty_buffer ; }	Creates a new big-endian composite buffer which wraps the readable bytes of thespecified buffers without copying them.
public static bytebuf wrappedbuffer ( int maxnumcomponents , bytebuffer ... buffers ) { return wrappedbuffer ( maxnumcomponents , compositebytebuf . byte_buffer_wrapper , buffers ) ; }	Creates a new big-endian composite buffer which wraps the slices of the specifiedNIO buffers without copying them.
public static bytebuf copyint ( int value ) { bytebuf buf = buffer ( num_ ) ; buf . writeint ( value ) ; return buf ; }	Creates a new 4-byte big-endian buffer that holds the specified 32-bit integer.
public static bytebuf copyint ( int ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( int v : values ) { buffer . writeint ( v ) ; } return buffer ; }	Create a big-endian buffer that holds a sequence of the specified 32-bit integers.
public static bytebuf copyshort ( int value ) { bytebuf buf = buffer ( num_ ) ; buf . writeshort ( value ) ; return buf ; }	Creates a new 2-byte big-endian buffer that holds the specified 16-bit integer.
public static bytebuf copyshort ( short ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( int v : values ) { buffer . writeshort ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified 16-bit integers.
public static bytebuf copymedium ( int value ) { bytebuf buf = buffer ( num_ ) ; buf . writemedium ( value ) ; return buf ; }	Creates a new 3-byte big-endian buffer that holds the specified 24-bit integer.
public static bytebuf copymedium ( int ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( int v : values ) { buffer . writemedium ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified 24-bit integers.
public static bytebuf copylong ( long value ) { bytebuf buf = buffer ( num_ ) ; buf . writelong ( value ) ; return buf ; }	Creates a new 8-byte big-endian buffer that holds the specified 64-bit integer.
public static bytebuf copylong ( long ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( long v : values ) { buffer . writelong ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified 64-bit integers.
public static bytebuf copyboolean ( boolean value ) { bytebuf buf = buffer ( num_ ) ; buf . writeboolean ( value ) ; return buf ; }	Creates a new single-byte big-endian buffer that holds the specified boolean value.
public static bytebuf copyboolean ( boolean ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length ) ; for ( boolean v : values ) { buffer . writeboolean ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified boolean values.
public static bytebuf copyfloat ( float value ) { bytebuf buf = buffer ( num_ ) ; buf . writefloat ( value ) ; return buf ; }	Creates a new 4-byte big-endian buffer that holds the specified 32-bit floating point number.
public static bytebuf copyfloat ( float ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( float v : values ) { buffer . writefloat ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified 32-bit floating point numbers.
public static bytebuf copydouble ( double value ) { bytebuf buf = buffer ( num_ ) ; buf . writedouble ( value ) ; return buf ; }	Creates a new 8-byte big-endian buffer that holds the specified 64-bit floating point number.
public static bytebuf copydouble ( double ... values ) { if ( values == null || values . length == num_ ) { return empty_buffer ; } bytebuf buffer = buffer ( values . length * num_ ) ; for ( double v : values ) { buffer . writedouble ( v ) ; } return buffer ; }	Create a new big-endian buffer that holds a sequence of the specified 64-bit floating point numbers.
private static void encodeextras ( bytebuf buf , bytebuf extras ) { if ( extras == null || ! extras . isreadable ( ) ) { return ; } buf . writebytes ( extras ) ; }	Encode the extras.
public websocketserverhandshaker newhandshaker ( httprequest req ) { charsequence version = req . headers ( ) . get ( httpheadernames . sec_websocket_version ) ; if ( version != null ) { if ( version . equals ( websocketversion . v13 . tohttpheadervalue ( ) ) ) {	Instances a new handshaker.
public static channelfuture sendunsupportedversionresponse ( channel channel , channelpromise promise ) { httpresponse res = new defaultfullhttpresponse ( httpversion . http_1_1 , httpresponsestatus . upgrade_required ) ; res . headers ( ) . set ( httpheadernames . sec_websocket_version , websocketversion . v13 . tohttpheadervalue ( ) ) ; httputil . setcontentlength ( res , num_ ) ; return channel . writeandflush ( res , promise ) ; }	Return that we need cannot not support the web socket version.
public static readonlyhttp2headers serverheaders ( boolean validateheaders , asciistring status , asciistring ... otherheaders ) { return new readonlyhttp2headers ( validateheaders , new asciistring [ ] { pseudoheadername . status . value ( ) , status } , otherheaders ) ; }	Create a new read only representation of headers used by servers.
public int bwt ( ) { final int [ ] sa = this . sa ; final byte [ ] t = this . t ; final int n = this . n ; final int [ ] bucketa = new int [ bucket_a_size ] ; final int [ ] bucketb = new int [ bucket_b_size ] ; if ( n == num_ ) { return num_ ; } if ( n == num_ ) { sa [ num_ ] = t [ num_ ] ; return num_ ; } int m = sorttypebstar ( bucketa , bucketb ) ; if ( num_ < m ) { return constructbwt ( bucketa , bucketb ) ; } return num_ ; }	Performs a Burrows Wheeler Transform on the input array.
private compositebytebuf addcomponents ( boolean increaseindex , int cindex , iterable < bytebuf > buffers ) { if ( buffers instanceof bytebuf ) {	but we do in the most common case that the Iterable is a Collection).
private void consolidateifneeded ( ) {	This should only be called as last operation from a method as this may adjust the underlyingarray of components and so affect the index etc.
public asciistring decode ( bytebuf buf , int length ) throws http2exception { processor . reset ( ) ; buf . foreachbyte ( buf . readerindex ( ) , length , processor ) ; buf . skipbytes ( length ) ; return processor . end ( ) ; }	Decompresses the given Huffman coded string literal.
public static classresolver weakcachingresolver ( classloader classloader ) { return new cachingclassresolver ( new classloaderclassresolver ( defaultclassloader ( classloader ) ) , new weakreferencemap < string , class < ? > > ( new hashmap < string , reference < class < ? > > > ( ) ) ) ; }	non-aggressive non-concurrent cachegood for non-shared default cache.
public static classresolver softcachingresolver ( classloader classloader ) { return new cachingclassresolver ( new classloaderclassresolver ( defaultclassloader ( classloader ) ) , new softreferencemap < string , class < ? > > ( new hashmap < string , reference < class < ? > > > ( ) ) ) ; }	aggressive non-concurrent cachegood for non-shared cache, when we're not worried about class unloading.
public static classresolver weakcachingconcurrentresolver ( classloader classloader ) { return new cachingclassresolver ( new classloaderclassresolver ( defaultclassloader ( classloader ) ) , new weakreferencemap < string , class < ? > > ( platformdependent . < string , reference < class < ? > > > newconcurrenthashmap ( ) ) ) ; }	non-aggressive concurrent cachegood for shared cache, when we're worried about class unloading.
public static classresolver softcachingconcurrentresolver ( classloader classloader ) { return new cachingclassresolver ( new classloaderclassresolver ( defaultclassloader ( classloader ) ) , new softreferencemap < string , class < ? > > ( platformdependent . < string , reference < class < ? > > > newconcurrenthashmap ( ) ) ) ; }	aggressive concurrent cachegood for shared cache, when we're not worried about class unloading.
public static boolean ismultipart ( httprequest request ) { if ( request . headers ( ) . contains ( httpheadernames . content_type ) ) { return getmultipartdataboundary ( request . headers ( ) . get ( httpheadernames . content_type ) ) != null ; } else { return bool_ ; } }	Check if the given request is a multipart request.
protected static string [ ] getmultipartdataboundary ( string contenttype ) {	Check from the request ContentType if this request is a Multipart request.
protected sslhandler newhandler ( bytebufallocator alloc , boolean starttls , executor executor ) { return new sslhandler ( newengine ( alloc ) , starttls , executor ) ; }	Create a new SslHandler.
private static string formatsimple ( channelhandlercontext ctx , string eventname , object msg ) { string chstr = ctx . channel ( ) . tostring ( ) ; string msgstr = string . valueof ( msg ) ; stringbuilder buf = new stringbuilder ( chstr . length ( ) + num_ + eventname . length ( ) + num_ + msgstr . length ( ) ) ; return buf . append ( chstr ) . append ( str_ ) . append ( eventname ) . append ( str_ ) . append ( msgstr ) . tostring ( ) ; }	Generates the default log message of the specified event whose argument is an arbitrary object.
final void clear ( ) { while ( ! resolvecache . isempty ( ) ) { for ( iterator < entry < string , entries > > i = resolvecache . entryset ( ) . iterator ( ) ; i . hasnext ( ) ; ) { map . entry < string , entries > e = i . next ( ) ; i . remove ( ) ; e . getvalue ( ) . clearandcancel ( ) ; } } }	Remove everything from the cache.
final list < ? extends e > get ( string hostname ) { entries entries = resolvecache . get ( hostname ) ; return entries == null ? null : entries . get ( ) ; }	Returns all caches entries for the given hostname.
final void cache ( string hostname , e value , int ttl , eventloop loop ) { entries entries = resolvecache . get ( hostname ) ; if ( entries == null ) { entries = new entries ( hostname ) ; entries oldentries = resolvecache . putifabsent ( hostname , entries ) ; if ( oldentries != null ) { entries = oldentries ; } } entries . add ( value , ttl , loop ) ; }	Cache a value for the given hostname that will automatically expire once the TTL is reached.
@ suppresswarnings ( str_ ) public final v get ( ) { internalthreadlocalmap threadlocalmap = internalthreadlocalmap . get ( ) ; object v = threadlocalmap . indexedvariable ( index ) ; if ( v != internalthreadlocalmap . unset ) { return ( v ) v ; } return initialize ( threadlocalmap ) ; }	Returns the current value for the current thread.
public final void set ( v value ) { if ( value != internalthreadlocalmap . unset ) { internalthreadlocalmap threadlocalmap = internalthreadlocalmap . get ( ) ; setknownnotunset ( threadlocalmap , value ) ; } else { remove ( ) ; } }	Set the value for the current thread.
@ unstableapi public void setocspresponse ( byte [ ] response ) { if ( ! enableocsp ) { throw new illegalstateexception ( str_ ) ; } if ( clientmode ) { throw new illegalstateexception ( str_ ) ; } synchronized ( this ) { ssl . setocspresponse ( ssl , response ) ; } }	Sets the OCSP response.
public final synchronized void shutdown ( ) { if ( destroyed_updater . compareandset ( this , num_ , num_ ) ) { enginemap . remove ( ssl ) ; ssl . freessl ( ssl ) ; ssl = networkbio = num_ ; isinbounddone = outboundclosed = bool_ ; }	Destroys this engine.
private int writeplaintextdata ( final bytebuffer src , int len ) { final int pos = src . position ( ) ; final int limit = src . limit ( ) ; final int sslwrote ; if ( src . isdirect ( ) ) { sslwrote = ssl . writetossl ( ssl , bufferaddress ( src ) + pos , len ) ; if ( sslwrote > num_ ) { src . position ( pos + sslwrote ) ; } } else { bytebuf buf = alloc . directbuffer ( len ) ; try { src . limit ( pos + len ) ; buf . setbytes ( num_ , src ) ; src . limit ( limit ) ; sslwrote = ssl . writetossl ( ssl , memoryaddress ( buf ) , len ) ; if ( sslwrote > num_ ) { src . position ( pos + sslwrote ) ; } else { src . position ( pos ) ; } } finally { buf . release ( ) ; } } return sslwrote ; }	Write plaintext data to the OpenSSL internal BIOCalling this function with src.remaining == 0 is undefined.
private bytebuf writeencrypteddata ( final bytebuffer src , int len ) { final int pos = src . position ( ) ; if ( src . isdirect ( ) ) { ssl . biosetbytebuffer ( networkbio , bufferaddress ( src ) + pos , len , bool_ ) ; } else { final bytebuf buf = alloc . directbuffer ( len ) ; try { final int limit = src . limit ( ) ; src . limit ( pos + len ) ; buf . writebytes ( src ) ;	Write encrypted data to the OpenSSL network BIO.
private int readplaintextdata ( final bytebuffer dst ) { final int sslread ; final int pos = dst . position ( ) ; if ( dst . isdirect ( ) ) { sslread = ssl . readfromssl ( ssl , bufferaddress ( dst ) + pos , dst . limit ( ) - pos ) ; if ( sslread > num_ ) { dst . position ( pos + sslread ) ; } } else { final int limit = dst . limit ( ) ; final int len = min ( maxencryptedpacketlength0 ( ) , limit - pos ) ; final bytebuf buf = alloc . directbuffer ( len ) ; try { sslread = ssl . readfromssl ( ssl , memoryaddress ( buf ) , len ) ; if ( sslread > num_ ) { dst . limit ( pos + sslread ) ; buf . getbytes ( buf . readerindex ( ) , dst ) ; dst . limit ( limit ) ; } } finally { buf . release ( ) ; } } return sslread ; }	Read plaintext data from the OpenSSL internal BIO.
private sslexception shutdownwitherror ( string operations , int sslerror ) { return shutdownwitherror ( operations , sslerror , ssl . getlasterrornumber ( ) ) ; }	Log the error, shutdown the engine and throw an exception.
private string tojavaciphersuite ( string opensslciphersuite ) { if ( opensslciphersuite == null ) { return null ; } string version = ssl . getversion ( ssl ) ; string prefix = tojavaciphersuiteprefix ( version ) ; return ciphersuiteconverter . tojava ( opensslciphersuite , prefix ) ; }	Converts the specified OpenSSL cipher suite to the Java cipher suite.
static bytebuf doencode ( bytebufallocator bytebufallocator , mqttmessage message ) { switch ( message . fixedheader ( ) . messagetype ( ) ) { case connect : return encodeconnectmessage ( bytebufallocator , ( mqttconnectmessage ) message ) ; case connack : return encodeconnackmessage ( bytebufallocator , ( mqttconnackmessage ) message ) ; case publish : return encodepublishmessage ( bytebufallocator , ( mqttpublishmessage ) message ) ; case subscribe : return encodesubscribemessage ( bytebufallocator , ( mqttsubscribemessage ) message ) ; case unsubscribe : return encodeunsubscribemessage ( bytebufallocator , ( mqttunsubscribemessage ) message ) ; case suback : return encodesubackmessage ( bytebufallocator , ( mqttsubackmessage ) message ) ; case unsuback : case puback : case pubrec : case pubrel : case pubcomp : return encodemessagewithonlysinglebytefixedheaderandmessageid ( bytebufallocator , message ) ; case pingreq : case pingresp : case disconnect : return encodemessagewithonlysinglebytefixedheader ( bytebufallocator , message ) ; default : throw new illegalargumentexception ( str_ + message . fixedheader ( ) . messagetype ( ) . value ( ) ) ; } }	This is the main encoding method.It's only visible for testing.
private http2settings decodesettings ( channelhandlercontext ctx , bytebuf frame ) throws http2exception { try { final http2settings decodedsettings = new http2settings ( ) ; framereader . readframe ( ctx , frame , new http2frameadapter ( ) { @ override public void onsettingsread ( channelhandlercontext ctx , http2settings settings ) { decodedsettings . copyfrom ( settings ) ; } } ) ; return decodedsettings ; } finally { frame . release ( ) ; } }	Decodes the settings frame and returns the settings.
private static bytebuf createsettingsframe ( channelhandlercontext ctx , bytebuf payload ) { bytebuf frame = ctx . alloc ( ) . buffer ( frame_header_length + payload . readablebytes ( ) ) ; writeframeheader ( frame , payload . readablebytes ( ) , settings , new http2flags ( ) , num_ ) ; frame . writebytes ( payload ) ; payload . release ( ) ; return frame ; }	Creates an HTTP2-Settings header with the given payload.
@ override public void closestreamlocal ( http2stream stream , channelfuture future ) { switch ( stream . state ( ) ) { case half_closed_local : case open : stream . closelocalside ( ) ; break ; default : closestream ( stream , future ) ; break ; } }	Closes the local side of the given stream.
@ override public void closestreamremote ( http2stream stream , channelfuture future ) { switch ( stream . state ( ) ) { case half_closed_remote : case open : stream . closeremoteside ( ) ; break ; default : closestream ( stream , future ) ; break ; } }	Closes the remote side of the given stream.
protected void onconnectionerror ( channelhandlercontext ctx , boolean outbound , throwable cause , http2exception http2ex ) { if ( http2ex == null ) { http2ex = new http2exception ( internal_error , cause . getmessage ( ) , cause ) ; } channelpromise promise = ctx . newpromise ( ) ; channelfuture future = goaway ( ctx , http2ex , ctx . newpromise ( ) ) ; if ( http2ex . shutdownhint ( ) == http2exception . shutdownhint . graceful_shutdown ) { dogracefulshutdown ( ctx , future , promise ) ; } else { future . addlistener ( new closingchannelfuturelistener ( ctx , promise ) ) ; } }	Handler for a connection error.
protected void handleserverheaderdecodesizeerror ( channelhandlercontext ctx , http2stream stream ) { encoder ( ) . writeheaders ( ctx , stream . id ( ) , headers_too_large_headers , num_ , bool_ , ctx . newpromise ( ) ) ; }	Notifies client that this server has received headers that are larger than what it iswilling to accept.
private void checkcloseconnection ( channelfuture future ) {	Closes the connection if the graceful shutdown process has completed.
private charsequence getsettingsheadervalue ( channelhandlercontext ctx ) { bytebuf buf = null ; bytebuf encodedbuf = null ; try {	Converts the current settings for the handler to the Base64-encoded representation used inthe HTTP2-Settings upgrade header.
public static charset getcharset ( httpmessage message , charset defaultcharset ) { charsequence contenttypevalue = message . headers ( ) . get ( httpheadernames . content_type ) ; if ( contenttypevalue != null ) { return getcharset ( contenttypevalue , defaultcharset ) ; } else { return defaultcharset ; } }	Fetch charset from message's Content-Type header.
public static charsequence getcharsetassequence ( httpmessage message ) { charsequence contenttypevalue = message . headers ( ) . get ( httpheadernames . content_type ) ; if ( contenttypevalue != null ) { return getcharsetassequence ( contenttypevalue ) ; } else { return null ; } }	Fetch charset from message's Content-Type header as a char sequence.A lot of sites/possibly clients have charset="CHARSET", for example charset="utf-8".
public static charsequence getcharsetassequence ( charsequence contenttypevalue ) { if ( contenttypevalue == null ) { throw new nullpointerexception ( str_ ) ; } int indexofcharset = asciistring . indexofignorecaseascii ( contenttypevalue , charset_equals , num_ ) ; if ( indexofcharset == asciistring . index_not_found ) { return null ; } int indexofencoding = indexofcharset + charset_equals . length ( ) ; if ( indexofencoding < contenttypevalue . length ( ) ) { charsequence charsetcandidate = contenttypevalue . subsequence ( indexofencoding , contenttypevalue . length ( ) ) ; int indexofsemicolon = asciistring . indexofignorecaseascii ( charsetcandidate , semicolon , num_ ) ; if ( indexofsemicolon == asciistring . index_not_found ) { return charsetcandidate ; } return charsetcandidate . subsequence ( num_ , indexofsemicolon ) ; } return null ; }	Fetch charset from Content-Type header value as a char sequence.A lot of sites/possibly clients have charset="CHARSET", for example charset="utf-8".
public static string formathostnameforhttp ( inetsocketaddress addr ) { string hoststring = netutil . gethostname ( addr ) ; if ( netutil . isvalidipv6address ( hoststring ) ) { if ( ! addr . isunresolved ( ) ) { hoststring = netutil . toaddressstring ( addr . getaddress ( ) ) ; } return str_ + hoststring + str_ ; } return hoststring ; }	Formats the host string of an address so it can be used for computing an HTTP componentsuch as an URL or a Host header.
private static void generatehuffmancodelengths ( final int alphabetsize , final int [ ] symbolfrequencies , final int [ ] codelengths ) { final int [ ] mergedfrequenciesandindices = new int [ alphabetsize ] ; final int [ ] sortedfrequencies = new int [ alphabetsize ] ;	Generate a Huffman code length table for a given list of symbol frequencies.
private void assignhuffmancodesymbols ( ) { final int [ ] [ ] huffmanmergedcodesymbols = this . huffmanmergedcodesymbols ; final int [ ] [ ] huffmancodelengths = this . huffmancodelengths ; final int mtfalphabetsize = this . mtfalphabetsize ; final int totaltables = huffmancodelengths . length ; for ( int i = num_ ; i < totaltables ; i ++ ) { final int [ ] tablelengths = huffmancodelengths [ i ] ; int minimumlength = num_ ; int maximumlength = num_ ; for ( int j = num_ ; j < mtfalphabetsize ; j ++ ) { final int length = tablelengths [ j ] ; if ( length > maximumlength ) { maximumlength = length ; } if ( length < minimumlength ) { minimumlength = length ; } } int code = num_ ; for ( int j = minimumlength ; j <= maximumlength ; j ++ ) { for ( int k = num_ ; k < mtfalphabetsize ; k ++ ) { if ( ( huffmancodelengths [ i ] [ k ] & num_ ) == j ) { huffmanmergedcodesymbols [ i ] [ k ] = ( j << num_ ) | code ; code ++ ; } } code <<= num_ ; } } }	Assigns Canonical Huffman codes based on the calculated lengths.
private void writeselectorsandhuffmantables ( bytebuf out ) { final bzip2bitwriter writer = this . writer ; final byte [ ] selectors = this . selectors ; final int totalselectors = selectors . length ; final int [ ] [ ] huffmancodelengths = this . huffmancodelengths ; final int totaltables = huffmancodelengths . length ; final int mtfalphabetsize = this . mtfalphabetsize ; writer . writebits ( out , num_ , totaltables ) ; writer . writebits ( out , num_ , totalselectors ) ;	Write out the selector list and Huffman tables.
private void writeblockdata ( bytebuf out ) { final bzip2bitwriter writer = this . writer ; final int [ ] [ ] huffmanmergedcodesymbols = this . huffmanmergedcodesymbols ; final byte [ ] selectors = this . selectors ; final char [ ] mtf = mtfblock ; final int mtflength = this . mtflength ; int selectorindex = num_ ; for ( int mtfindex = num_ ; mtfindex < mtflength ; ) { final int groupend = math . min ( mtfindex + huffman_group_run_length , mtflength ) - num_ ; final int [ ] tablemergedcodesymbols = huffmanmergedcodesymbols [ selectors [ selectorindex ++ ] ] ; while ( mtfindex <= groupend ) { final int mergedcodesymbol = tablemergedcodesymbols [ mtf [ mtfindex ++ ] ] ; writer . writebits ( out , mergedcodesymbol > > > num_ , mergedcodesymbol ) ; } } }	Writes out the encoded block data.
void encode ( bytebuf out ) {	Encodes and writes the block data.
public void resumetransfer ( ) { final channelhandlercontext ctx = this . ctx ; if ( ctx == null ) { return ; } if ( ctx . executor ( ) . ineventloop ( ) ) { resumetransfer0 ( ctx ) ; } else {	Continues to fetch the chunks from the input.
private void initialiseinversebwt ( ) { final int bwtstartpointer = this . bwtstartpointer ; final byte [ ] bwtblock = this . bwtblock ; final int [ ] bwtmergedpointers = new int [ bwtblocklength ] ; final int [ ] characterbase = new int [ num_ ] ; if ( bwtstartpointer < num_ || bwtstartpointer >= bwtblocklength ) { throw new decompressionexception ( str_ ) ; }	Set up the Inverse Burrows-Wheeler Transform merged pointer array.
public int read ( ) { while ( rlerepeat < num_ ) { if ( bwtbytesdecoded == bwtblocklength ) { return - num_ ; } int nextbyte = decodenextbwtbyte ( ) ; if ( nextbyte != rlelastdecodedbyte ) {	Decodes a byte from the final Run-Length Encoding stage, pulling a new byte from theBurrows-Wheeler Transform stage when required.
private int decodenextbwtbyte ( ) { int mergedpointer = bwtcurrentmergedpointer ; int nextdecodedbyte = mergedpointer & num_ ; bwtcurrentmergedpointer = bwtmergedpointers [ mergedpointer > > > num_ ] ; if ( blockrandomised ) { if ( -- randomcount == num_ ) { nextdecodedbyte ^= num_ ; randomindex = ( randomindex + num_ ) % num_ ; randomcount = bzip2rand . rnums ( randomindex ) ; } } bwtbytesdecoded ++ ; return nextdecodedbyte ; }	Decodes a byte from the Burrows-Wheeler Transform stage.
public void encode ( bytebuf out , charsequence data ) { objectutil . checknotnull ( out , str_ ) ; if ( data instanceof asciistring ) { asciistring string = ( asciistring ) data ; try { encodeprocessor . out = out ; string . foreachbyte ( encodeprocessor ) ; } catch ( exception e ) { platformdependent . throwexception ( e ) ; } finally { encodeprocessor . end ( ) ; } } else { encodeslowpath ( out , data ) ; } }	Compresses the input string literal using the Huffman coding.
int getencodedlength ( charsequence data ) { if ( data instanceof asciistring ) { asciistring string = ( asciistring ) data ; try { encodedlengthprocessor . reset ( ) ; string . foreachbyte ( encodedlengthprocessor ) ; return encodedlengthprocessor . length ( ) ; } catch ( exception e ) { platformdependent . throwexception ( e ) ; return - num_ ; } } else { return getencodedlengthslowpath ( data ) ; } }	Returns the number of bytes required to Huffman encode the input string literal.
static boolean patchshadedlibraryid ( inputstream in , outputstream out , string originalname , string name ) throws ioexception { byte [ ] buffer = new byte [ num_ ] ; int length ;	Package-private for testing.
private static boolean patchshadedlibraryid ( byte [ ] bytes , string originalname , string name ) {	Try to patch shaded library to ensure it uses a unique ID.
private m invalidmessage ( exception cause ) { state = state . bad_message ; m message = buildinvalidmessage ( ) ; message . setdecoderresult ( decoderresult . failure ( cause ) ) ; return message ; }	Helper method to create a message indicating a invalid decoding result.
private memcachecontent invalidchunk ( exception cause ) { state = state . bad_message ; memcachecontent chunk = new defaultlastmemcachecontent ( unpooled . empty_buffer ) ; chunk . setdecoderresult ( decoderresult . failure ( cause ) ) ; return chunk ; }	Helper method to create a content chunk indicating a invalid decoding result.
private t retain0 ( t instance , final int increment , final int rawincrement ) { int oldref = updater ( ) . getandadd ( instance , rawincrement ) ; if ( oldref != num_ && oldref != num_ && ( oldref & num_ ) != num_ ) { throw new illegalreferencecountexception ( num_ , increment ) ; }	rawIncrement == increment << 1.
@ override public final void channelreadcomplete ( channelhandlercontext ctx ) throws exception { try { onchannelreadcomplete ( ctx ) ; } finally { parentreadinprogress = bool_ ; tail = head = null ;	Notifies any child streams of the read completion.
public static byte [ ] bestavailablemac ( ) {	Obtains the best MAC address found on local network interfaces.Generally speaking, an active network interface used on publicnetworks is better than a local network interface.
protected b maxreservedstreams ( int maxreservedstreams ) { enforceconstraint ( str_ , str_ , connection ) ; enforceconstraint ( str_ , str_ , decoder ) ; enforceconstraint ( str_ , str_ , encoder ) ; this . maxreservedstreams = checkpositiveorzero ( maxreservedstreams , str_ ) ; return self ( ) ; }	Set the maximum number of streams which can be in the reserved state at any given time.
private static boolean isupgraderequest ( httpobject msg ) { return msg instanceof httprequest && ( ( httprequest ) msg ) . headers ( ) . get ( httpheadernames . upgrade ) != null ; }	Determines whether or not the message is an HTTP upgrade request.
private static fullhttpresponse createupgraderesponse ( charsequence upgradeprotocol ) { defaultfullhttpresponse res = new defaultfullhttpresponse ( http_1_1 , switching_protocols , unpooled . empty_buffer , bool_ ) ; res . headers ( ) . add ( httpheadernames . connection , httpheadervalues . upgrade ) ; res . headers ( ) . add ( httpheadernames . upgrade , upgradeprotocol ) ; return res ; }	Creates the 101 Switching Protocols response message.
private static list < charsequence > splitheader ( charsequence header ) { final stringbuilder builder = new stringbuilder ( header . length ( ) ) ; final list < charsequence > protocols = new arraylist < charsequence > ( num_ ) ; for ( int i = num_ ; i < header . length ( ) ; ++ i ) { char c = header . charat ( i ) ; if ( character . iswhitespace ( c ) ) {	Splits a comma-separated header value.
void modify ( abstractepollchannel ch ) throws ioexception { assert ineventloop ( ) ; native . epollctlmod ( epollfd . intvalue ( ) , ch . socket . intvalue ( ) , ch . flags ) ; }	The flags of the given epoll was modified so update the registration.
void handleloopexception ( throwable t ) { logger . warn ( str_ , t ) ;	Visible only for testing!.
public static string decodename ( bytebuf in ) { int position = - num_ ; int checked = num_ ; final int end = in . writerindex ( ) ; final int readable = in . readablebytes ( ) ;	Retrieves a domain name given a buffer containing a DNS packet.
void createglobaltrafficcounter ( scheduledexecutorservice executor ) { if ( executor == null ) { throw new nullpointerexception ( str_ ) ; } trafficcounter tc = new trafficcounter ( this , executor , str_ , checkinterval ) ; settrafficcounter ( tc ) ; tc . start ( ) ; }	Create the global TrafficCounter.
@ override public void write ( channelhandlercontext ctx , object msg , channelpromise promise ) { string command = ( string ) msg ; if ( command . startswith ( str_ ) ) { string keystring = command . substring ( str_ . length ( ) ) ; bytebuf key = unpooled . wrappedbuffer ( keystring . getbytes ( charsetutil . utf_8 ) ) ; binarymemcacherequest req = new defaultbinarymemcacherequest ( key ) ; req . setopcode ( binarymemcacheopcodes . get ) ; ctx . write ( req , promise ) ; } else if ( command . startswith ( str_ ) ) { string [ ] parts = command . split ( str_ , num_ ) ; if ( parts . length < num_ ) { throw new illegalargumentexception ( str_ + command ) ; } string keystring = parts [ num_ ] ; string value = parts [ num_ ] ; bytebuf key = unpooled . wrappedbuffer ( keystring . getbytes ( charsetutil . utf_8 ) ) ; bytebuf content = unpooled . wrappedbuffer ( value . getbytes ( charsetutil . utf_8 ) ) ; bytebuf extras = ctx . alloc ( ) . buffer ( num_ ) ; extras . writezero ( num_ ) ; binarymemcacherequest req = new defaultfullbinarymemcacherequest ( key , extras , content ) ; req . setopcode ( binarymemcacheopcodes . set ) ; ctx . write ( req , promise ) ; } else { throw new illegalstateexception ( str_ + msg ) ; } }	Transforms basic string requests to binary memcache requests.
public string get ( charsequence name , string defaultvalue ) { string value = get ( name ) ; if ( value == null ) { return defaultvalue ; } return value ; }	Returns the value of a header with the specified name.
public httpheaders add ( charsequence name , object value ) { return add ( name . tostring ( ) , value ) ; }	Adds a new header with the specified name and value.If the specified value is not a {.
public httpheaders add ( charsequence name , iterable < ? > values ) { return add ( name . tostring ( ) , values ) ; }	Adds a new header with the specified name and values.This getMethod can be represented approximately as the following code: for (Object v: values) {if (v == null) {break;}headers.add(name, v);}.
public httpheaders set ( charsequence name , object value ) { return set ( name . tostring ( ) , value ) ; }	Sets a header with the specified name and value.If there is an existing header with the same name, it is removed.If the specified value is not a {.
public httpheaders set ( charsequence name , iterable < ? > values ) { return set ( name . tostring ( ) , values ) ; }	Sets a header with the specified name and values.If there is an existing header with the same name, it is removed.This getMethod can be represented approximately as the following code: headers.remove(name);for (Object v: values) {if (v == null) {break;}headers.add(name, v);}.
public defaultheaders < k , v , t > copy ( ) { defaultheaders < k , v , t > copy = new defaultheaders < k , v , t > ( hashingstrategy , valueconverter , namevalidator , entries . length ) ; copy . addimpl ( this ) ; return copy ; }	Returns a deep copy of this instance.
protected void readtimedout ( channelhandlercontext ctx ) throws exception { if ( ! closed ) { ctx . fireexceptioncaught ( readtimeoutexception . instance ) ; ctx . close ( ) ; closed = bool_ ; } }	Is called when a read timeout was detected.
public string rawquery ( ) { int start = pathendidx ( ) + num_ ; return start < uri . length ( ) ? uri . substring ( start ) : empty_string ; }	Returns raw query string of the URI.
static int getunsignedshort ( bytebuf buf , int offset ) { return ( buf . getbyte ( offset ) & num_ ) << num_ | buf . getbyte ( offset + num_ ) & num_ ; }	Reads a big-endian unsigned short integer from the buffer.
static int getunsignedmedium ( bytebuf buf , int offset ) { return ( buf . getbyte ( offset ) & num_ ) << num_ | ( buf . getbyte ( offset + num_ ) & num_ ) << num_ | buf . getbyte ( offset + num_ ) & num_ ; }	Reads a big-endian unsigned medium integer from the buffer.
static int getsignedint ( bytebuf buf , int offset ) { return ( buf . getbyte ( offset ) & num_ ) << num_ | ( buf . getbyte ( offset + num_ ) & num_ ) << num_ | ( buf . getbyte ( offset + num_ ) & num_ ) << num_ | buf . getbyte ( offset + num_ ) & num_ ; }	Reads a big-endian signed integer from the buffer.
static void validateheadername ( charsequence name ) { if ( name == null ) { throw new nullpointerexception ( str_ ) ; } if ( name . length ( ) == num_ ) { throw new illegalargumentexception ( str_ ) ; }	Validate a SPDY header name.
static void validateheadervalue ( charsequence value ) { if ( value == null ) { throw new nullpointerexception ( str_ ) ; } for ( int i = num_ ; i < value . length ( ) ; i ++ ) { char c = value . charat ( i ) ; if ( c == num_ ) { throw new illegalargumentexception ( str_ + value ) ; } } }	Validate a SPDY header value.
void free ( boolean finalizer ) {	Should be called if the Thread that uses this cache is about to exist to release resources out of the cache.
protected void cancelscheduledtasks ( ) { assert ineventloop ( ) ; priorityqueue < scheduledfuturetask < ? > > scheduledtaskqueue = this . scheduledtaskqueue ; if ( isnullorempty ( scheduledtaskqueue ) ) { return ; } final scheduledfuturetask < ? > [ ] scheduledtasks = scheduledtaskqueue . toarray ( new scheduledfuturetask < ? > [ num_ ] ) ; for ( scheduledfuturetask < ? > task : scheduledtasks ) { task . cancelwithoutremove ( bool_ ) ; } scheduledtaskqueue . clearignoringindexes ( ) ; }	Cancel all scheduled tasks.This method MUST be called only when {.
public static string inttoipaddress ( int i ) { stringbuilder buf = new stringbuilder ( num_ ) ; buf . append ( i > > num_ & num_ ) ; buf . append ( str_ ) ; buf . append ( i > > num_ & num_ ) ; buf . append ( str_ ) ; buf . append ( i > > num_ & num_ ) ; buf . append ( str_ ) ; buf . append ( i & num_ ) ; return buf . tostring ( ) ; }	Converts a 32-bit integer into an IPv4 address.
public static string bytestoipaddress ( byte [ ] bytes , int offset , int length ) { switch ( length ) { case num_ : { return new stringbuilder ( num_ ) . append ( bytes [ offset ] & num_ ) . append ( str_ ) . append ( bytes [ offset + num_ ] & num_ ) . append ( str_ ) . append ( bytes [ offset + num_ ] & num_ ) . append ( str_ ) . append ( bytes [ offset + num_ ] & num_ ) . tostring ( ) ; } case num_ : return toaddressstring ( bytes , offset , bool_ ) ; default : throw new illegalargumentexception ( str_ + length + str_ ) ; } }	Converts 4-byte or 16-byte data into an IPv4 or IPv6 string respectively.
private void destroy ( ) { lock writerlock = ctxlock . writelock ( ) ; writerlock . lock ( ) ; try { if ( ctx != num_ ) { if ( enableocsp ) { sslcontext . disableocsp ( ctx ) ; } sslcontext . free ( ctx ) ; ctx = num_ ; opensslsessioncontext context = sessioncontext ( ) ; if ( context != null ) { context . destroy ( ) ; } } } finally { writerlock . unlock ( ) ; } }	producing a segfault.
public string applicationprotocol ( ) { sslengine engine = engine ( ) ; if ( ! ( engine instanceof applicationprotocolaccessor ) ) { return null ; } return ( ( applicationprotocolaccessor ) engine ) . getnegotiatedapplicationprotocol ( ) ; }	Returns the name of the current application-level protocol.
private void sethandshakesuccess ( ) { handshakepromise . trysuccess ( ctx . channel ( ) ) ; if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ , ctx . channel ( ) , engine . getsession ( ) . getciphersuite ( ) ) ; } ctx . fireusereventtriggered ( sslhandshakecompletionevent . success ) ; if ( readduringhandshake && ! ctx . channel ( ) . config ( ) . isautoread ( ) ) { readduringhandshake = bool_ ; ctx . read ( ) ; } }	Notify all the handshake futures about the successfully handshake.
@ override public httppoststandardrequestdecoder offer ( httpcontent content ) { checkdestroyed ( ) ;	Initialized the internals from a new chunk.
@ override public boolean hasnext ( ) { checkdestroyed ( ) ; if ( currentstatus == multipartstatus . epilogue ) {	True if at current getStatus, there is an available decodedInterfaceHttpData from the Body.This getMethod works for chunked and not chunked request.
protected void addhttpdata ( interfacehttpdata data ) { if ( data == null ) { return ; } list < interfacehttpdata > datas = bodymaphttpdata . get ( data . getname ( ) ) ; if ( datas == null ) { datas = new arraylist < interfacehttpdata > ( num_ ) ; bodymaphttpdata . put ( data . getname ( ) , datas ) ; } datas . add ( data ) ; bodylisthttpdata . add ( data ) ; }	Utility function to add a new decoded data.
static int findnonwhitespace ( string sb , int offset ) { int result ; for ( result = offset ; result < sb . length ( ) ; result ++ ) { if ( ! character . iswhitespace ( sb . charat ( result ) ) ) { break ; } } return result ; }	Find the first non whitespace.
static int findendofstring ( string sb ) { int result ; for ( result = sb . length ( ) ; result > num_ ; result -- ) { if ( ! character . iswhitespace ( sb . charat ( result - num_ ) ) ) { break ; } } return result ; }	Find the end of String.
public void start ( ) { switch ( worker_state_updater . get ( this ) ) { case worker_state_init : if ( worker_state_updater . compareandset ( this , worker_state_init , worker_state_started ) ) { workerthread . start ( ) ; } break ; case worker_state_started : break ; case worker_state_shutdown : throw new illegalstateexception ( str_ ) ; default : throw new error ( str_ ) ; }	Starts the background thread explicitly.
private static string readstring ( string fieldname , bytebuf in ) { int length = in . bytesbefore ( max_field_length + num_ , ( byte ) num_ ) ; if ( length < num_ ) { throw new decoderexception ( str_ + fieldname + str_ + max_field_length + str_ ) ; } string value = in . readslice ( length ) . tostring ( charsetutil . us_ascii ) ; in . skipbytes ( num_ ) ;	Reads a variable-length NUL-terminated string as defined in SOCKS4.
long allocate ( ) { if ( elemsize == num_ ) { return tohandle ( num_ ) ; } if ( numavail == num_ || ! donotdestroy ) { return - num_ ; } final int bitmapidx = getnextavail ( ) ; int q = bitmapidx > > > num_ ; int r = bitmapidx & num_ ; assert ( bitmap [ q ] > > > r & num_ ) == num_ ; bitmap [ q ] |= num_ << r ; if ( -- numavail == num_ ) { removefrompool ( ) ; } return tohandle ( bitmapidx ) ; }	Returns the bitmap index of the subpage allocation.
private static int compressionlevel ( int blocksize ) { if ( blocksize < min_block_size || blocksize > max_block_size ) { throw new illegalargumentexception ( string . format ( str_ , blocksize , min_block_size , max_block_size ) ) ; } int compressionlevel = num_ - integer . numberofleadingzeros ( blocksize - num_ ) ;	Calculates compression level on the basis of block size.
protected void writetimedout ( channelhandlercontext ctx ) throws exception { if ( ! closed ) { ctx . fireexceptioncaught ( writetimeoutexception . instance ) ; ctx . close ( ) ; closed = bool_ ; } }	Is called when a write timeout was detected.
protected boolean doconnect ( socketaddress remoteaddress , socketaddress localaddress ) throws exception { if ( localaddress instanceof inetsocketaddress ) { checkresolvable ( ( inetsocketaddress ) localaddress ) ; } inetsocketaddress remotesocketaddr = remoteaddress instanceof inetsocketaddress ? ( inetsocketaddress ) remoteaddress : null ; if ( remotesocketaddr != null ) { checkresolvable ( remotesocketaddr ) ; } if ( remote != null ) {	Connect to the remote peer.
static string base64 ( byte [ ] data ) { bytebuf encodeddata = unpooled . wrappedbuffer ( data ) ; bytebuf encoded = base64 . encode ( encodeddata ) ; string encodedstring = encoded . tostring ( charsetutil . utf_8 ) ; encoded . release ( ) ; return encodedstring ; }	Performs base64 encoding on the specified data.
static int randomnumber ( int minimum , int maximum ) { assert minimum < maximum ; double fraction = platformdependent . threadlocalrandom ( ) . nextdouble ( ) ;	Generates a pseudo-random number.
protected final void removemessage ( http2stream stream , boolean release ) { fullhttpmessage msg = stream . removeproperty ( messagekey ) ; if ( release && msg != null ) { msg . release ( ) ; } }	The stream is out of scope for the HTTP message flow and will no longer be tracked.
protected void firechannelread ( channelhandlercontext ctx , fullhttpmessage msg , boolean release , http2stream stream ) { removemessage ( stream , release ) ; httputil . setcontentlength ( msg , msg . content ( ) . readablebytes ( ) ) ; ctx . firechannelread ( msg ) ; }	Set final headers and fire a channel read event.
public dnsnameresolverbuilder searchdomains ( iterable < string > searchdomains ) { checknotnull ( searchdomains , str_ ) ; final list < string > list = new arraylist < string > ( num_ ) ; for ( string f : searchdomains ) { if ( f == null ) { break ; }	Set the list of search domains of the resolver.
static internallogger wraplogger ( logger logger ) { return logger instanceof locationawarelogger ? new locationawareslf4jlogger ( ( locationawarelogger ) logger ) : new slf4jlogger ( logger ) ; }	package-private for testing.
private future < channel > acquirehealthyfrompoolornew ( final promise < channel > promise ) { try { final channel ch = pollchannel ( ) ; if ( ch == null ) {	Tries to retrieve healthy channel from the pool if any or creates a new channel otherwise.
private void releaseandofferifhealthy ( channel channel , promise < void > promise , future < boolean > future ) throws exception { if ( future . getnow ( ) ) {	Adds the channel back to the pool only if the channel is healthy.
public void copy ( int srcidx , byte [ ] dst , int dstidx , int length ) { if ( isoutofbounds ( srcidx , length , length ( ) ) ) { throw new indexoutofboundsexception ( str_ + str_ + srcidx + str_ + length + str_ + length ( ) + str_ ) ; } system . arraycopy ( value , srcidx + offset , checknotnull ( dst , str_ ) , dstidx , length ) ; }	Copies the content of this string to a byte array.
public asciistring concat ( charsequence string ) { int thislen = length ( ) ; int thatlen = string . length ( ) ; if ( thatlen == num_ ) { return this ; } if ( string . getclass ( ) == asciistring . class ) { asciistring that = ( asciistring ) string ; if ( isempty ( ) ) { return that ; } byte [ ] newvalue = platformdependent . allocateuninitializedarray ( thislen + thatlen ) ; system . arraycopy ( value , arrayoffset ( ) , newvalue , num_ , thislen ) ; system . arraycopy ( that . value , that . arrayoffset ( ) , newvalue , thislen , thatlen ) ; return new asciistring ( newvalue , bool_ ) ; } if ( isempty ( ) ) { return new asciistring ( string ) ; } byte [ ] newvalue = platformdependent . allocateuninitializedarray ( thislen + thatlen ) ; system . arraycopy ( value , arrayoffset ( ) , newvalue , num_ , thislen ) ; for ( int i = thislen , j = num_ ; i < newvalue . length ; i ++ , j ++ ) { newvalue [ i ] = c2b ( string . charat ( j ) ) ; } return new asciistring ( newvalue , bool_ ) ; }	Concatenates this string and the specified string.
public boolean endswith ( charsequence suffix ) { int suffixlen = suffix . length ( ) ; return regionmatches ( length ( ) - suffixlen , suffix , num_ , suffixlen ) ; }	Compares the specified string to this string to determine if the specified string is a suffix.
public boolean contentequalsignorecase ( charsequence string ) { if ( string == null || string . length ( ) != length ( ) ) { return bool_ ; } if ( string . getclass ( ) == asciistring . class ) { asciistring rhs = ( asciistring ) string ; for ( int i = arrayoffset ( ) , j = rhs . arrayoffset ( ) ; i < length ( ) ; ++ i , ++ j ) { if ( ! equalsignorecase ( value [ i ] , rhs . value [ j ] ) ) { return bool_ ; } } return bool_ ; } for ( int i = arrayoffset ( ) , j = num_ ; i < length ( ) ; ++ i , ++ j ) { if ( ! equalsignorecase ( b2c ( value [ i ] ) , string . charat ( j ) ) ) { return bool_ ; } } return bool_ ; }	Compares the specified string to this string ignoring the case of the characters and returns true if they areequal.
public char [ ] tochararray ( int start , int end ) { int length = end - start ; if ( length == num_ ) { return emptyarrays . empty_chars ; } if ( isoutofbounds ( start , length , length ( ) ) ) { throw new indexoutofboundsexception ( str_ + str_ + start + str_ + length + str_ + length ( ) + str_ ) ; } final char [ ] buffer = new char [ length ] ; for ( int i = num_ , j = start + arrayoffset ( ) ; i < length ; i ++ , j ++ ) { buffer [ i ] = b2c ( value [ j ] ) ; } return buffer ; }	Copies the characters in this string to a character array.
public void copy ( int srcidx , char [ ] dst , int dstidx , int length ) { if ( dst == null ) { throw new nullpointerexception ( str_ ) ; } if ( isoutofbounds ( srcidx , length , length ( ) ) ) { throw new indexoutofboundsexception ( str_ + str_ + srcidx + str_ + length + str_ + length ( ) + str_ ) ; } final int dstend = dstidx + length ; for ( int i = dstidx , j = srcidx + arrayoffset ( ) ; i < dstend ; i ++ , j ++ ) { dst [ i ] = b2c ( value [ j ] ) ; } }	Copied the content of this string to a character array.
public asciistring subsequence ( int start , int end , boolean copy ) { if ( isoutofbounds ( start , end - start , length ( ) ) ) { throw new indexoutofboundsexception ( str_ + start + str_ + end + str_ + length ( ) + str_ ) ; } if ( start == num_ && end == length ( ) ) { return this ; } if ( end == start ) { return empty_string ; } return new asciistring ( value , start + offset , end - start , copy ) ; }	Either copy or share a subset of underlying sub-sequence of bytes.
public int indexof ( charsequence substring , int start ) { final int subcount = substring . length ( ) ; if ( start < num_ ) { start = num_ ; } if ( subcount <= num_ ) { return start < length ? start : length ; } if ( subcount > length - start ) { return index_not_found ; } final char firstchar = substring . charat ( num_ ) ; if ( firstchar > max_char_value ) { return index_not_found ; } final byte firstcharasbyte = c2b0 ( firstchar ) ; final int len = offset + length - subcount ; for ( int i = start + offset ; i <= len ; ++ i ) { if ( value [ i ] == firstcharasbyte ) { int o1 = i , o2 = num_ ; while ( ++ o2 < subcount && b2c ( value [ ++ o1 ] ) == substring . charat ( o2 ) ) {	Searches in this string for the index of the specified string.
public boolean regionmatches ( int thisstart , charsequence string , int start , int length ) { if ( string == null ) { throw new nullpointerexception ( str_ ) ; } if ( start < num_ || string . length ( ) - start < length ) { return bool_ ; } final int thislen = length ( ) ; if ( thisstart < num_ || thislen - thisstart < length ) { return bool_ ; } if ( length <= num_ ) { return bool_ ; } final int thatend = start + length ; for ( int i = start , j = thisstart + arrayoffset ( ) ; i < thatend ; i ++ , j ++ ) { if ( b2c ( value [ j ] ) != string . charat ( i ) ) { return bool_ ; } } return bool_ ; }	Compares the specified string to this string and compares the specified range of characters to determine if theyare the same.
public boolean regionmatches ( boolean ignorecase , int thisstart , charsequence string , int start , int length ) { if ( ! ignorecase ) { return regionmatches ( thisstart , string , start , length ) ; } if ( string == null ) { throw new nullpointerexception ( str_ ) ; } final int thislen = length ( ) ; if ( thisstart < num_ || length > thislen - thisstart ) { return bool_ ; } if ( start < num_ || length > string . length ( ) - start ) { return bool_ ; } thisstart += arrayoffset ( ) ; final int thisend = thisstart + length ; while ( thisstart < thisend ) { if ( ! equalsignorecase ( b2c ( value [ thisstart ++ ] ) , string . charat ( start ++ ) ) ) { return bool_ ; } } return bool_ ; }	Compares the specified string to this string and compares the specified range of characters to determine if theyare the same.
public asciistring replace ( char oldchar , char newchar ) { if ( oldchar > max_char_value ) { return this ; } final byte oldcharasbyte = c2b0 ( oldchar ) ; final byte newcharasbyte = c2b ( newchar ) ; final int len = offset + length ; for ( int i = offset ; i < len ; ++ i ) { if ( value [ i ] == oldcharasbyte ) { byte [ ] buffer = platformdependent . allocateuninitializedarray ( length ( ) ) ; system . arraycopy ( value , offset , buffer , num_ , i - offset ) ; buffer [ i - offset ] = newcharasbyte ; ++ i ; for ( ; i < len ; ++ i ) { byte oldvalue = value [ i ] ; buffer [ i - offset ] = oldvalue != oldcharasbyte ? oldvalue : newcharasbyte ; } return new asciistring ( buffer , bool_ ) ; } } return this ; }	Copies this string replacing occurrences of the specified character with another character.
public asciistring tolowercase ( ) { boolean lowercased = bool_ ; int i , j ; final int len = length ( ) + arrayoffset ( ) ; for ( i = arrayoffset ( ) ; i < len ; ++ i ) { byte b = value [ i ] ; if ( b >= str_ && b <= str_ ) { lowercased = bool_ ; break ; } }	Converts the characters in this string to lowercase, using the default Locale.
public asciistring touppercase ( ) { boolean uppercased = bool_ ; int i , j ; final int len = length ( ) + arrayoffset ( ) ; for ( i = arrayoffset ( ) ; i < len ; ++ i ) { byte b = value [ i ] ; if ( b >= str_ && b <= str_ ) { uppercased = bool_ ; break ; } }	Converts the characters in this string to uppercase, using the default Locale.
public static charsequence trim ( charsequence c ) { if ( c . getclass ( ) == asciistring . class ) { return ( ( asciistring ) c ) . trim ( ) ; } if ( c instanceof string ) { return ( ( string ) c ) . trim ( ) ; } int start = num_ , last = c . length ( ) - num_ ; int end = last ; while ( start <= end && c . charat ( start ) <= str_ ) { start ++ ; } while ( end >= start && c . charat ( end ) <= str_ ) { end -- ; } if ( start == num_ && end == last ) { return c ; } return c . subsequence ( start , end ) ; }	Copies this string removing white space characters from the beginning and end of the string, and tries not tocopy if possible.
public asciistring trim ( ) { int start = arrayoffset ( ) , last = arrayoffset ( ) + length ( ) - num_ ; int end = last ; while ( start <= end && value [ start ] <= str_ ) { start ++ ; } while ( end >= start && value [ end ] <= str_ ) { end -- ; } if ( start == num_ && end == last ) { return this ; } return new asciistring ( value , start , end - start + num_ , bool_ ) ; }	Duplicates this string removing white space characters from the beginning and end of thestring, without copying.
public static boolean regionmatches ( final charsequence cs , final boolean ignorecase , final int csstart , final charsequence string , final int start , final int length ) { if ( cs == null || string == null ) { return bool_ ; } if ( cs instanceof string && string instanceof string ) { return ( ( string ) cs ) . regionmatches ( ignorecase , csstart , ( string ) string , start , length ) ; } if ( cs instanceof asciistring ) { return ( ( asciistring ) cs ) . regionmatches ( ignorecase , csstart , string , start , length ) ; } return regionmatchescharsequences ( cs , csstart , string , start , length , ignorecase ? generalcaseinsensitivecharequalitycomparator . instance : defaultcharequalitycomparator . instance ) ; }	This methods make regionMatches operation correctly for any chars in strings.
@ deprecated public static < t > t releaselater ( t msg , int decrement ) { if ( msg instanceof referencecounted ) { threaddeathwatcher . watch ( thread . currentthread ( ) , new releasingtask ( ( referencecounted ) msg , decrement ) ) ; } return msg ; }	Schedules the specified object to be released when the caller thread terminates.
public void windowupdateratio ( float ratio ) { assert ctx == null || ctx . executor ( ) . ineventloop ( ) ; checkvalidratio ( ratio ) ; windowupdateratio = ratio ; }	The window update ratio is used to determine when a window update must be sent.
void releasereadsuspended ( channelhandlercontext ctx ) { channel channel = ctx . channel ( ) ; channel . attr ( read_suspended ) . set ( bool_ ) ; channel . config ( ) . setautoread ( bool_ ) ; }	Release the Read suspension.
void checkwritesuspend ( channelhandlercontext ctx , long delay , long queuesize ) { if ( queuesize > maxwritesize || delay > maxwritedelay ) { setuserdefinedwritability ( ctx , bool_ ) ; } }	Check the writability according to delay and size for the channel.Set if necessary setUserDefinedWritability status.
static haproxymessage decodeheader ( string header ) { if ( header == null ) { throw new haproxyprotocolexception ( str_ ) ; } string [ ] parts = header . split ( str_ ) ; int numparts = parts . length ; if ( numparts < num_ ) { throw new haproxyprotocolexception ( str_ + header + str_ ) ; } if ( ! str_ . equals ( parts [ num_ ] ) ) { throw new haproxyprotocolexception ( str_ + parts [ num_ ] ) ; } haproxyproxiedprotocol protandfam ; try { protandfam = haproxyproxiedprotocol . valueof ( parts [ num_ ] ) ; } catch ( illegalargumentexception e ) { throw new haproxyprotocolexception ( e ) ; } if ( protandfam != haproxyproxiedprotocol . tcp4 && protandfam != haproxyproxiedprotocol . tcp6 && protandfam != haproxyproxiedprotocol . unknown ) { throw new haproxyprotocolexception ( str_ + parts [ num_ ] ) ; } if ( protandfam == haproxyproxiedprotocol . unknown ) { return v1_unknown_msg ; } if ( numparts != num_ ) { throw new haproxyprotocolexception ( str_ + header + str_ ) ; } return new haproxymessage ( haproxyprotocolversion . v1 , haproxycommand . proxy , protandfam , parts [ num_ ] , parts [ num_ ] , parts [ num_ ] , parts [ num_ ] ) ; }	Decodes a version 1, human-readable proxy protocol header.
private static string ipbytestostring ( bytebuf header , int addresslen ) { stringbuilder sb = new stringbuilder ( ) ; if ( addresslen == num_ ) { sb . append ( header . readbyte ( ) & num_ ) ; sb . append ( str_ ) ; sb . append ( header . readbyte ( ) & num_ ) ; sb . append ( str_ ) ; sb . append ( header . readbyte ( ) & num_ ) ; sb . append ( str_ ) ; sb . append ( header . readbyte ( ) & num_ ) ; } else { sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; sb . append ( str_ ) ; sb . append ( integer . tohexstring ( header . readunsignedshort ( ) ) ) ; } return sb . tostring ( ) ; }	Convert ip address bytes to string representation.
private static int portstringtoint ( string value ) { int port ; try { port = integer . parseint ( value ) ; } catch ( numberformatexception e ) { throw new haproxyprotocolexception ( str_ + value , e ) ; } if ( port <= num_ || port > num_ ) { throw new haproxyprotocolexception ( str_ + value + str_ ) ; } return port ; }	Convert port to integer.
public static fullhttpresponse tofullhttpresponse ( int streamid , http2headers http2headers , bytebufallocator alloc , boolean validatehttpheaders ) throws http2exception { httpresponsestatus status = parsestatus ( http2headers . status ( ) ) ;	Create a new object to contain the response data.
public static fullhttprequest tofullhttprequest ( int streamid , http2headers http2headers , bytebufallocator alloc , boolean validatehttpheaders ) throws http2exception {	Create a new object to contain the request data.
public static httprequest tohttprequest ( int streamid , http2headers http2headers , boolean validatehttpheaders ) throws http2exception {	Create a new object to contain the request data.
public static httpresponse tohttpresponse ( final int streamid , final http2headers http2headers , final boolean validatehttpheaders ) throws http2exception { final httpresponsestatus status = parsestatus ( http2headers . status ( ) ) ;	Create a new object to contain the response data.
static void sethttp2authority ( string authority , http2headers out ) {	package-private for testing only.
static int majorversion ( final string javaspecversion ) { final string [ ] components = javaspecversion . split ( str_ ) ; final int [ ] version = new int [ components . length ] ; for ( int i = num_ ; i < components . length ; i ++ ) { version [ i ] = integer . parseint ( components [ i ] ) ; } if ( version [ num_ ] == num_ ) { assert version [ num_ ] >= num_ ; return version [ num_ ] ; } else { return version [ num_ ] ; } }	Package-private for testing only.
private static void setextendedparentpointers ( final int [ ] array ) { final int length = array . length ; array [ num_ ] += array [ num_ ] ; for ( int headnode = num_ , tailnode = num_ , topnode = num_ ; tailnode < length - num_ ; tailnode ++ ) { int temp ; if ( topnode >= length || array [ headnode ] < array [ topnode ] ) { temp = array [ headnode ] ; array [ headnode ++ ] = tailnode ; } else { temp = array [ topnode ++ ] ; } if ( topnode >= length || ( headnode < tailnode && array [ headnode ] < array [ topnode ] ) ) { temp += array [ headnode ] ; array [ headnode ++ ] = tailnode + length ; } else { temp += array [ topnode ++ ] ; } array [ tailnode ] = temp ; } }	Fills the code array with extended parent pointers.
private static int findnodestorelocate ( final int [ ] array , final int maximumlength ) { int currentnode = array . length - num_ ; for ( int currentdepth = num_ ; currentdepth < maximumlength - num_ && currentnode > num_ ; currentdepth ++ ) { currentnode = first ( array , currentnode - num_ , num_ ) ; } return currentnode ; }	Finds the number of nodes to relocate in order to achieve a given code length limit.
private static void allocatenodelengths ( final int [ ] array ) { int firstnode = array . length - num_ ; int nextnode = array . length - num_ ; for ( int currentdepth = num_ , availablenodes = num_ ; availablenodes > num_ ; currentdepth ++ ) { final int lastnode = firstnode ; firstnode = first ( array , lastnode - num_ , num_ ) ; for ( int i = availablenodes - ( lastnode - firstnode ) ; i > num_ ; i -- ) { array [ nextnode -- ] = currentdepth ; } availablenodes = ( lastnode - firstnode ) << num_ ; } }	A final allocation pass with no code length limit.
private static void allocatenodelengthswithrelocation ( final int [ ] array , final int nodestomove , final int insertdepth ) { int firstnode = array . length - num_ ; int nextnode = array . length - num_ ; int currentdepth = insertdepth == num_ ? num_ : num_ ; int nodeslefttomove = insertdepth == num_ ? nodestomove - num_ : nodestomove ; for ( int availablenodes = currentdepth << num_ ; availablenodes > num_ ; currentdepth ++ ) { final int lastnode = firstnode ; firstnode = firstnode <= nodestomove ? firstnode : first ( array , lastnode - num_ , nodestomove ) ; int offset = num_ ; if ( currentdepth >= insertdepth ) { offset = math . min ( nodeslefttomove , num_ << ( currentdepth - insertdepth ) ) ; } else if ( currentdepth == insertdepth - num_ ) { offset = num_ ; if ( array [ firstnode ] == lastnode ) { firstnode ++ ; } } for ( int i = availablenodes - ( lastnode - firstnode + offset ) ; i > num_ ; i -- ) { array [ nextnode -- ] = currentdepth ; } nodeslefttomove -= offset ; availablenodes = ( lastnode - firstnode + offset ) << num_ ; } }	A final allocation pass that relocates nodes in order to achieve a maximum code length limit.
static void allocatehuffmancodelengths ( final int [ ] array , final int maximumlength ) { switch ( array . length ) { case num_ : array [ num_ ] = num_ ;	Allocates Canonical Huffman code lengths in place based on a sorted frequency array.
public void close ( ) throws ioexception { for ( ; ; ) { int state = this . state ; if ( isclosed ( state ) ) { return ; }	Close the file descriptor.
protected final void init ( i inboundhandler , o outboundhandler ) { validate ( inboundhandler , outboundhandler ) ; this . inboundhandler = inboundhandler ; this . outboundhandler = outboundhandler ; }	Initialized this handler with the specified handlers.
public static boolean commonsuffixoflength ( string s , string p , int len ) { return s != null && p != null && len >= num_ && s . regionmatches ( s . length ( ) - len , p , p . length ( ) - len , len ) ; }	Checks if two strings have the same suffix of specified length.
public static < t extends appendable > t bytetohexstring ( t buf , int value ) { try { buf . append ( bytetohexstring ( value ) ) ; } catch ( ioexception e ) { platformdependent . throwexception ( e ) ; } return buf ; }	Converts the specified byte value into a hexadecimal integer and appends it to the specified buffer.
public static byte decodehexbyte ( charsequence s , int pos ) { int hi = decodehexnibble ( s . charat ( pos ) ) ; int lo = decodehexnibble ( s . charat ( pos + num_ ) ) ; if ( hi == - num_ || lo == - num_ ) { throw new illegalargumentexception ( string . format ( str_ , s . subsequence ( pos , pos + num_ ) , pos , s ) ) ; } return ( byte ) ( ( hi << num_ ) + lo ) ; }	Decode a 2-digit hex byte from within a string.
protected final string exceptionmessage ( string msg ) { if ( msg == null ) { msg = str_ ; } stringbuilder buf = new stringbuilder ( num_ + msg . length ( ) ) . append ( protocol ( ) ) . append ( str_ ) . append ( authscheme ( ) ) . append ( str_ ) . append ( proxyaddress ) . append ( str_ ) . append ( destinationaddress ) ; if ( ! msg . isempty ( ) ) { buf . append ( str_ ) . append ( msg ) ; } return buf . tostring ( ) ; }	Decorates the specified exception message with the common information such as the current protocol,authentication scheme, proxy address, and destination address.
static void closeonflush ( channel ch ) { if ( ch . isactive ( ) ) { ch . writeandflush ( unpooled . empty_buffer ) . addlistener ( channelfuturelistener . close ) ; } }	Closes the specified channel after all queued write requests are flushed.
public future < addressedenvelope < dnsresponse , inetsocketaddress > > query ( dnsquestion question , iterable < dnsrecord > additionals ) { return query ( nextnameserveraddress ( ) , question , additionals ) ; }	Sends a DNS query with the specified question with additional records.
public future < addressedenvelope < dnsresponse , inetsocketaddress > > query ( inetsocketaddress nameserveraddr , dnsquestion question ) { return query0 ( nameserveraddr , question , empty_additionals , bool_ , ch . newpromise ( ) , ch . eventloop ( ) . < addressedenvelope < ? extends dnsresponse , inetsocketaddress > > newpromise ( ) ) ; }	Sends a DNS query with the specified question using the specified name server list.
public future < addressedenvelope < dnsresponse , inetsocketaddress > > query ( inetsocketaddress nameserveraddr , dnsquestion question , iterable < dnsrecord > additionals ) { return query0 ( nameserveraddr , question , toarray ( additionals , bool_ ) , bool_ , ch . newpromise ( ) , ch . eventloop ( ) . < addressedenvelope < ? extends dnsresponse , inetsocketaddress > > newpromise ( ) ) ; }	Sends a DNS query with the specified question with additional records using the specified name server list.
static int getindex ( charsequence name ) { integer index = static_index_by_name . get ( name ) ; if ( index == null ) { return - num_ ; } return index ; }	Returns the lowest index value for the given header field name in the static table.
static int getindex ( charsequence name , charsequence value ) { int index = getindex ( name ) ; if ( index == - num_ ) { return - num_ ; }	Returns the index value for the given header field in the static table.
private static charsequencemap < integer > createmap ( ) { int length = static_table . size ( ) ; @ suppresswarnings ( str_ ) charsequencemap < integer > ret = new charsequencemap < integer > ( bool_ , unsupportedvalueconverter . < integer > instance ( ) , length ) ;	create a map CharSequenceMap header name to index value to allow quick lookup.
protected void reportuntracedleak ( string resourcetype ) { logger . error ( str_ + str_ + str_ + str_ + str_ , resourcetype , prop_level , level . advanced . name ( ) . tolowercase ( ) , simpleclassname ( this ) ) ; }	This method is called when an untraced leak is detected.
public synchronized void stop ( ) { if ( ! monitoractive ) { return ; } monitoractive = bool_ ; resetaccounting ( millisecondfromnano ( ) ) ; if ( trafficshapinghandler != null ) { trafficshapinghandler . doaccounting ( this ) ; } if ( scheduledfuture != null ) { scheduledfuture . cancel ( bool_ ) ; } }	Stop the monitoring process.
synchronized void resetaccounting ( long newlasttime ) { long interval = newlasttime - lasttime . getandset ( newlasttime ) ; if ( interval == num_ ) {	Reset the accounting on Read and Write.
public void configure ( long newcheckinterval ) { long newinterval = newcheckinterval / num_ * num_ ; if ( checkinterval . getandset ( newinterval ) != newinterval ) { if ( newinterval <= num_ ) { stop ( ) ;	Change checkInterval between two computations in millisecond.
private void updateparentsalloc ( int id ) { while ( id > num_ ) { int parentid = id > > > num_ ; byte val1 = value ( id ) ; byte val2 = value ( id ^ num_ ) ; byte val = val1 < val2 ? val1 : val2 ; setvalue ( parentid , val ) ; id = parentid ; } }	Update method used by allocateThis is triggered only when a successor is allocated and all its predecessorsneed to update their stateThe minimal depth at which subtree rooted at id has some free space.
private int allocatenode ( int d ) { int id = num_ ; int initial = - ( num_ << d ) ;	Algorithm to allocate an index in memoryMap when we query for a free nodeat depth d.
void free ( long handle , bytebuffer niobuffer ) { int memorymapidx = memorymapidx ( handle ) ; int bitmapidx = bitmapidx ( handle ) ; if ( bitmapidx != num_ ) {	Free a subpage or a run of pagesWhen a subpage is freed from PoolSubpage, it might be added back to subpage pool of the owning PoolArenaIf the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we cancompletely free the owning Page so it is available for subsequent allocations.
private static int readrawvarint32 ( bytebuf buffer ) { if ( ! buffer . isreadable ( ) ) { return num_ ; } buffer . markreaderindex ( ) ; byte tmp = buffer . readbyte ( ) ; if ( tmp >= num_ ) { return tmp ; } else { int result = tmp & num_ ; if ( ! buffer . isreadable ( ) ) { buffer . resetreaderindex ( ) ; return num_ ; } if ( ( tmp = buffer . readbyte ( ) ) >= num_ ) { result |= tmp << num_ ; } else { result |= ( tmp & num_ ) << num_ ; if ( ! buffer . isreadable ( ) ) { buffer . resetreaderindex ( ) ; return num_ ; } if ( ( tmp = buffer . readbyte ( ) ) >= num_ ) { result |= tmp << num_ ; } else { result |= ( tmp & num_ ) << num_ ; if ( ! buffer . isreadable ( ) ) { buffer . resetreaderindex ( ) ; return num_ ; } if ( ( tmp = buffer . readbyte ( ) ) >= num_ ) { result |= tmp << num_ ; } else { result |= ( tmp & num_ ) << num_ ; if ( ! buffer . isreadable ( ) ) { buffer . resetreaderindex ( ) ; return num_ ; } result |= ( tmp = buffer . readbyte ( ) ) << num_ ; if ( tmp < num_ ) { throw new corruptedframeexception ( str_ ) ; } } } } return result ; } }	Reads variable length 32bit int from buffer.
public static int splice ( int fd , long offin , int fdout , long offout , long len ) throws ioexception { int res = splice0 ( fd , offin , fdout , offout , len ) ; if ( res >= num_ ) { return res ; } return ioresult ( str_ , res , splice_connection_reset_exception , splice_closed_channel_exception ) ; }	File-descriptor operations.
void recycle ( ) { for ( int i = num_ ; i < size ; i ++ ) { array [ i ] = null ; } size = num_ ; insertsincerecycled = bool_ ; recycler . recycle ( this ) ; }	Recycle the array which will clear it and null out all entries in the internal storage.
private static int contentlength ( object msg ) { if ( msg instanceof memcachecontent ) { return ( ( memcachecontent ) msg ) . content ( ) . readablebytes ( ) ; } if ( msg instanceof bytebuf ) { return ( ( bytebuf ) msg ) . readablebytes ( ) ; } if ( msg instanceof fileregion ) { return ( int ) ( ( fileregion ) msg ) . count ( ) ; } throw new illegalstateexception ( str_ + stringutil . simpleclassname ( msg ) ) ; }	Determine the content length of the given object.
static string normalizehostname ( string hostname ) { if ( needsnormalization ( hostname ) ) { hostname = idn . toascii ( hostname , idn . allow_unassigned ) ; } return hostname . tolowercase ( locale . us ) ; }	IDNA ASCII conversion and case normalization.
public void setmaxheadertablesize ( long maxheadertablesize ) throws http2exception { if ( maxheadertablesize < min_header_table_size || maxheadertablesize > max_header_table_size ) { throw connectionerror ( protocol_error , str_ , min_header_table_size , max_header_table_size , maxheadertablesize ) ; } maxdynamictablesize = maxheadertablesize ; if ( maxdynamictablesize < encodermaxdynamictablesize ) {	Set the maximum table size.
private static int maxoutputbufferlength ( int inputlength ) { double factor ; if ( inputlength < num_ ) { factor = num_ ; } else if ( inputlength < num_ ) { factor = num_ ; } else if ( inputlength < num_ ) { factor = num_ ; } else if ( inputlength < num_ ) { factor = num_ ; } else { factor = num_ ; } return num_ + ( int ) ( inputlength * factor ) ; }	Calculates maximum possible size of output buffer for not compressible data.
@ override public channelfuture close ( channel channel , closewebsocketframe frame , channelpromise promise ) { return channel . writeandflush ( frame , promise ) ; }	Echo back the closing frame.
public void setbodyhttpdatas ( list < interfacehttpdata > datas ) throws errordataencoderexception { if ( datas == null ) { throw new nullpointerexception ( str_ ) ; } globalbodysize = num_ ; bodylistdatas . clear ( ) ; currentfileupload = null ; duringmixedmode = bool_ ; multiparthttpdatas . clear ( ) ; for ( interfacehttpdata data : datas ) { addbodyhttpdata ( data ) ; } }	Set the Body HttpDatas list.
public void addbodyattribute ( string name , string value ) throws errordataencoderexception { string svalue = value != null ? value : stringutil . empty_string ; attribute data = factory . createattribute ( request , checknotnull ( name , str_ ) , svalue ) ; addbodyhttpdata ( data ) ; }	Add a simple attribute in the body as Name=Value.
public void addbodyfileuploads ( string name , file [ ] file , string [ ] contenttype , boolean [ ] istext ) throws errordataencoderexception { if ( file . length != contenttype . length && file . length != istext . length ) { throw new illegalargumentexception ( str_ ) ; } for ( int i = num_ ; i < file . length ; i ++ ) { addbodyfileupload ( name , file [ i ] , contenttype [ i ] , istext [ i ] ) ; } }	Add a series of Files associated with one File parameter.
@ suppresswarnings ( str_ ) private string encodeattribute ( string s , charset charset ) throws errordataencoderexception { if ( s == null ) { return str_ ; } try { string encoded = urlencoder . encode ( s , charset . name ( ) ) ; if ( encodermode == encodermode . rfc3986 ) { for ( map . entry < pattern , string > entry : percentencodings ) { string replacement = entry . getvalue ( ) ; encoded = entry . getkey ( ) . matcher ( encoded ) . replaceall ( replacement ) ; } } return encoded ; } catch ( unsupportedencodingexception e ) { throw new errordataencoderexception ( charset . name ( ) , e ) ; } }	Encode one attribute.
void createhuffmandecodingtables ( ) { final int alphabetsize = this . alphabetsize ; for ( int table = num_ ; table < tablecodelengths . length ; table ++ ) { final int [ ] tablebases = codebases [ table ] ; final int [ ] tablelimits = codelimits [ table ] ; final int [ ] tablesymbols = codesymbols [ table ] ; final byte [ ] codelengths = tablecodelengths [ table ] ; int minimumlength = huffman_decode_max_code_length ; int maximumlength = num_ ;	Constructs Huffman decoding tables from lists of Canonical Huffman code lengths.
int nextsymbol ( ) {	Decodes and returns the next symbol.
public long number ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionnumber ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the current number of sessions in the internal session cache.
public long connectrenegotiate ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionconnectrenegotiate ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of start renegotiations in client mode.
public long acceptrenegotiate ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionacceptrenegotiate ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of start renegotiations in server mode.
public long cbhits ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessioncbhits ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of successfully retrieved sessions from the external session cache in server mode.
public long misses ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionmisses ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of sessions proposed by clients that were not found in the internal session cachein server mode.
public long cachefull ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessioncachefull ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of sessions that were removed because the maximum session cache size was exceeded.
public long ticketkeyfail ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionticketkeyfail ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of times a client presented a ticket that did not match any key in the list.
public long ticketkeynew ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionticketkeynew ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of times a client did not present a ticket and we issued a new one.
public long ticketkeyrenew ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionticketkeyrenew ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of times a client presented a ticket derived from an older key,and we upgraded to the primary key.
public long ticketkeyresume ( ) { lock readerlock = context . ctxlock . readlock ( ) ; readerlock . lock ( ) ; try { return sslcontext . sessionticketkeyresume ( context . ctx ) ; } finally { readerlock . unlock ( ) ; } }	Returns the number of times a client presented a ticket derived from the primary key.
@ setup public void setup ( ) { system . setproperty ( str_ , checkaccessible ) ; system . setproperty ( str_ , checkbounds ) ; buffer = buffertype . newbuffer ( ) ; }	applies only to readBatch benchmark.
@ suppresswarnings ( str_ ) private static int unsignedshortbe ( bytebuf buffer , int offset ) { return buffer . order ( ) == byteorder . big_endian ? buffer . getunsignedshort ( offset ) : buffer . getunsignedshortle ( offset ) ; }	Reads a big-endian unsigned short integer from the buffer.
static boolean isvalidhostnameforsni ( string hostname ) { return hostname != null && hostname . indexof ( str_ ) > num_ && ! hostname . endswith ( str_ ) && ! netutil . isvalidipv4address ( hostname ) && ! netutil . isvalidipv6address ( hostname ) ; }	Validate that the given hostname can be used in SNI extension.
private boolean acceptstream ( int streamid , byte priority , boolean remotesideclosed , boolean localsideclosed ) {	need to synchronize accesses to sentGoAwayFrame, lastGoodStreamId, and initial window sizes.
private static int findmatchinglength ( bytebuf in , int minindex , int inindex , int maxindex ) { int matched = num_ ; while ( inindex <= maxindex - num_ && in . getint ( inindex ) == in . getint ( minindex + matched ) ) { inindex += num_ ; matched += num_ ; } while ( inindex < maxindex && in . getbyte ( minindex + matched ) == in . getbyte ( inindex ) ) { ++ inindex ; ++ matched ; } return matched ; }	Iterates over the supplied input buffer between the supplied minIndex andmaxIndex to find how long our matched copy overlaps with an already-writtenliteral value.
static void encodeliteral ( bytebuf in , bytebuf out , int length ) { if ( length < num_ ) { out . writebyte ( length - num_ << num_ ) ; } else { int bitlength = bitstoencode ( length - num_ ) ; int bytestoencode = num_ + bitlength / num_ ; out . writebyte ( num_ + bytestoencode << num_ ) ; for ( int i = num_ ; i < bytestoencode ; i ++ ) { out . writebyte ( length - num_ > > i * num_ & num_ ) ; } } out . writebytes ( in , length ) ; }	Writes a literal to the supplied output buffer by directly copying fromthe input buffer.
private static void encodecopy ( bytebuf out , int offset , int length ) { while ( length >= num_ ) { encodecopywithoffset ( out , offset , num_ ) ; length -= num_ ; } if ( length > num_ ) { encodecopywithoffset ( out , offset , num_ ) ; length -= num_ ; } encodecopywithoffset ( out , offset , length ) ; }	Encodes a series of copies, each at most 64 bytes in length.
static int calculatechecksum ( bytebuf data , int offset , int length ) { crc32c crc32 = new crc32c ( ) ; try { crc32 . update ( data , offset , length ) ; return maskchecksum ( ( int ) crc32 . getvalue ( ) ) ; } finally { crc32 . reset ( ) ; } }	Computes the CRC32C checksum of the supplied data and performs the "mask" operationon the computed checksum.
static boolean isj2ocached ( string key , string value ) { return value . equals ( j2o . get ( key ) ) ; }	Tests if the specified key-value pair has been cached in Java-to-OpenSSL cache.
static boolean iso2jcached ( string key , string protocol , string value ) { map < string , string > p2j = o2j . get ( key ) ; if ( p2j == null ) { return bool_ ; } else { return value . equals ( p2j . get ( protocol ) ) ; } }	Tests if the specified key-value pair has been cached in OpenSSL-to-Java cache.
static string toopenssl ( string javaciphersuite , boolean boringssl ) { string converted = j2o . get ( javaciphersuite ) ; if ( converted != null ) { return converted ; } return cachefromjava ( javaciphersuite , boringssl ) ; }	Converts the specified Java cipher suite to its corresponding OpenSSL cipher suite name.
static string tojava ( string opensslciphersuite , string protocol ) { map < string , string > p2j = o2j . get ( opensslciphersuite ) ; if ( p2j == null ) { p2j = cachefromopenssl ( opensslciphersuite ) ;	Convert from OpenSSL cipher suite name convention to java cipher suite name convention.
protected long delaynanos ( long currenttimenanos ) { scheduledfuturetask < ? > scheduledtask = peekscheduledtask ( ) ; if ( scheduledtask == null ) { return schedule_purge_interval ; } return scheduledtask . delaynanos ( currenttimenanos ) ; }	Returns the amount of time left until the scheduled task with the closest dead line is executed.
protected boolean confirmshutdown ( ) { if ( ! isshuttingdown ( ) ) { return bool_ ; } if ( ! ineventloop ( ) ) { throw new illegalstateexception ( str_ ) ; } cancelscheduledtasks ( ) ; if ( gracefulshutdownstarttime == num_ ) { gracefulshutdownstarttime = scheduledfuturetask . nanotime ( ) ; } if ( runalltasks ( ) || runshutdownhooks ( ) ) { if ( isshutdown ( ) ) {	Confirm that the shutdown if the instance should be done now!.
public void setmaxheadertablesize ( bytebuf out , long maxheadertablesize ) throws http2exception { if ( maxheadertablesize < min_header_table_size || maxheadertablesize > max_header_table_size ) { throw connectionerror ( protocol_error , str_ , min_header_table_size , max_header_table_size , maxheadertablesize ) ; } if ( this . maxheadertablesize == maxheadertablesize ) { return ; } this . maxheadertablesize = maxheadertablesize ; ensurecapacity ( num_ ) ;	Set the maximum table size.
private void encodestringliteral ( bytebuf out , charsequence string ) { int huffmanlength = hpackhuffmanencoder . getencodedlength ( string ) ; if ( huffmanlength < string . length ( ) ) { encodeinteger ( out , num_ , num_ , huffmanlength ) ; hpackhuffmanencoder . encode ( out , string ) ; } else { encodeinteger ( out , num_ , num_ , string . length ( ) ) ; if ( string instanceof asciistring ) {	Encode string literal according to Section 5.2.
private void encodeliteral ( bytebuf out , charsequence name , charsequence value , indextype indextype , int nameindex ) { boolean nameindexvalid = nameindex != - num_ ; switch ( indextype ) { case incremental : encodeinteger ( out , num_ , num_ , nameindexvalid ? nameindex : num_ ) ; break ; case none : encodeinteger ( out , num_ , num_ , nameindexvalid ? nameindex : num_ ) ; break ; case never : encodeinteger ( out , num_ , num_ , nameindexvalid ? nameindex : num_ ) ; break ; default : throw new error ( str_ ) ; } if ( ! nameindexvalid ) { encodestringliteral ( out , name ) ; } encodestringliteral ( out , value ) ; }	Encode literal header field according to Section 6.2.
hpackheaderfield getheaderfield ( int index ) { headerentry entry = head ; while ( index -- >= num_ ) { entry = entry . before ; } return entry ; }	Return the header field at the given index.
private headerentry getentry ( charsequence name , charsequence value ) { if ( length ( ) == num_ || name == null || value == null ) { return null ; } int h = asciistring . hashcode ( name ) ; int i = index ( h ) ; for ( headerentry e = headerfields [ i ] ; e != null ; e = e . next ) {	Returns the header entry with the lowest index value for the header field.
private int getindex ( charsequence name ) { if ( length ( ) == num_ || name == null ) { return - num_ ; } int h = asciistring . hashcode ( name ) ; int i = index ( h ) ; for ( headerentry e = headerfields [ i ] ; e != null ; e = e . next ) { if ( e . hash == h && equalsconstanttime ( name , e . name ) != num_ ) { return getindex ( e . index ) ; } } return - num_ ; }	Returns the lowest index value for the header field name in the dynamic table.
private void add ( charsequence name , charsequence value , long headersize ) {	Add the header field to the dynamic table.
private static list < string > dedup ( list < string > encoded , map < string , integer > nametolastindex ) { boolean [ ] islastinstance = new boolean [ encoded . size ( ) ] ; for ( int idx : nametolastindex . values ( ) ) { islastinstance [ idx ] = bool_ ; } list < string > dedupd = new arraylist < string > ( nametolastindex . size ( ) ) ; for ( int i = num_ , n = encoded . size ( ) ; i < n ; i ++ ) { if ( islastinstance [ i ] ) { dedupd . add ( encoded . get ( i ) ) ; } } return dedupd ; }	Deduplicate a list of encoded cookies by keeping only the last instance with a given name.
@ override public void trace ( string format , object arg ) { if ( istraceenabled ( ) ) { formattingtuple ft = messageformatter . format ( format , arg ) ; logger . log ( fqcn , tracecapable ? level . trace : level . debug , ft . getmessage ( ) , ft . getthrowable ( ) ) ; } }	Log a message at level TRACE according to the specified format andargument.
@ override public void warn ( string msg ) { logger . log ( fqcn , level . warn , msg , null ) ; }	Log a message object at the WARN level.
public sslcontextbuilder protocols ( string ... protocols ) { this . protocols = protocols == null ? null : protocols . clone ( ) ; return this ; }	The TLS protocol versions to enable.
public int length ( ) { int length ; if ( head < tail ) { length = hpackheaderfields . length - tail + head ; } else { length = head - tail ; } return length ; }	Return the number of header fields in the dynamic table.
public void add ( hpackheaderfield header ) { int headersize = header . size ( ) ; if ( headersize > capacity ) { clear ( ) ; return ; } while ( capacity - size < headersize ) { remove ( ) ; } hpackheaderfields [ head ++ ] = header ; size += header . size ( ) ; if ( head == hpackheaderfields . length ) { head = num_ ; } }	Add the header field to the dynamic table.
public hpackheaderfield remove ( ) { hpackheaderfield removed = hpackheaderfields [ tail ] ; if ( removed == null ) { return null ; } size -= removed . size ( ) ; hpackheaderfields [ tail ++ ] = null ; if ( tail == hpackheaderfields . length ) { tail = num_ ; } return removed ; }	Remove and return the oldest header field from the dynamic table.
public void clear ( ) { while ( tail != head ) { hpackheaderfields [ tail ++ ] = null ; if ( tail == hpackheaderfields . length ) { tail = num_ ; } } head = num_ ; tail = num_ ; size = num_ ; }	Remove all entries from the dynamic table.
public void setcapacity ( long capacity ) { if ( capacity < min_header_table_size || capacity > max_header_table_size ) { throw new illegalargumentexception ( str_ + capacity ) ; }	Set the maximum size of the dynamic table.
private void setupgraderequestheaders ( channelhandlercontext ctx , httprequest request ) {	Adds all upgrade request headers necessary for an upgrade to the supported protocols.
private void sendnotmodified ( channelhandlercontext ctx ) { fullhttpresponse response = new defaultfullhttpresponse ( http_1_1 , not_modified ) ; setdateheader ( response ) ; this . sendandcleanupconnection ( ctx , response ) ; }	When file timestamp is the same as what the browser is sending up, send a "304 Not Modified".
private void bindcompressortostream ( embeddedchannel compressor , int streamid ) { if ( compressor != null ) { http2stream stream = connection ( ) . stream ( streamid ) ; if ( stream != null ) { stream . setproperty ( propertykey , compressor ) ; } } }	Called after the super class has written the headers and created any associated stream objects.
static void writerawvarint32 ( bytebuf out , int value ) { while ( bool_ ) { if ( ( value & ~ num_ ) == num_ ) { out . writebyte ( value ) ; return ; } else { out . writebyte ( ( value & num_ ) | num_ ) ; value >>>= num_ ; } } }	Writes protobuf varint32 to (.
private static mqttfixedheader decodefixedheader ( bytebuf buffer ) { short b1 = buffer . readunsignedbyte ( ) ; mqttmessagetype messagetype = mqttmessagetype . valueof ( b1 > > num_ ) ; boolean dupflag = ( b1 & num_ ) == num_ ; int qoslevel = ( b1 & num_ ) > > num_ ; boolean retain = ( b1 & num_ ) != num_ ; int remaininglength = num_ ; int multiplier = num_ ; short digit ; int loops = num_ ; do { digit = buffer . readunsignedbyte ( ) ; remaininglength += ( digit & num_ ) * multiplier ; multiplier *= num_ ; loops ++ ; } while ( ( digit & num_ ) != num_ && loops < num_ ) ;	Decodes the fixed header.
private static result < ? > decodepayload ( bytebuf buffer , mqttmessagetype messagetype , int bytesremaininginvariablepart , object variableheader ) { switch ( messagetype ) { case connect : return decodeconnectionpayload ( buffer , ( mqttconnectvariableheader ) variableheader ) ; case subscribe : return decodesubscribepayload ( buffer , bytesremaininginvariablepart ) ; case suback : return decodesubackpayload ( buffer , bytesremaininginvariablepart ) ; case unsubscribe : return decodeunsubscribepayload ( buffer , bytesremaininginvariablepart ) ; case publish : return decodepublishpayload ( buffer , bytesremaininginvariablepart ) ; default :	Decodes the payload.
public final void add ( bytebuf buf , channelfuturelistener listener ) {	Add a buffer to the end of the queue and associate a listener with it that should be completed whenall the buffers bytes have been consumed from the queue and written.
public final void copyto ( abstractcoalescingbufferqueue dest ) { dest . bufandlistenerpairs . addall ( bufandlistenerpairs ) ; dest . incrementreadablebytes ( readablebytes ) ; }	Copy all pending entries in this queue into the destination queue.
public final void writeandremoveall ( channelhandlercontext ctx ) { decrementreadablebytes ( readablebytes ) ; throwable pending = null ; bytebuf previousbuf = null ; for ( ; ; ) { object entry = bufandlistenerpairs . poll ( ) ; try { if ( entry == null ) { if ( previousbuf != null ) { ctx . write ( previousbuf , ctx . voidpromise ( ) ) ; } break ; } if ( entry instanceof bytebuf ) { if ( previousbuf != null ) { ctx . write ( previousbuf , ctx . voidpromise ( ) ) ; } previousbuf = ( bytebuf ) entry ; } else if ( entry instanceof channelpromise ) { ctx . write ( previousbuf , ( channelpromise ) entry ) ; previousbuf = null ; } else { ctx . write ( previousbuf ) . addlistener ( ( channelfuturelistener ) entry ) ; previousbuf = null ; } } catch ( throwable t ) { if ( pending == null ) { pending = t ; } else { logger . info ( str_ , pending , t ) ; } } } if ( pending != null ) { throw new illegalstateexception ( pending ) ; } }	Writes all remaining elements in this queue.
public static hostsfileentries parse ( file file , charset ... charsets ) throws ioexception { checknotnull ( file , str_ ) ; checknotnull ( charsets , str_ ) ; if ( file . exists ( ) && file . isfile ( ) ) { for ( charset charset : charsets ) { hostsfileentries entries = parse ( new bufferedreader ( new inputstreamreader ( new fileinputstream ( file ) , charset ) ) ) ; if ( entries != hostsfileentries . empty ) { return entries ; } } } return hostsfileentries . empty ; }	Parse a hosts file.
public static hostsfileentries parse ( reader reader ) throws ioexception { checknotnull ( reader , str_ ) ; bufferedreader buff = new bufferedreader ( reader ) ; try { map < string , inet4address > ipv4entries = new hashmap < string , inet4address > ( ) ; map < string , inet6address > ipv6entries = new hashmap < string , inet6address > ( ) ; string line ; while ( ( line = buff . readline ( ) ) != null ) {	Parse a reader of hosts file format.
final int calculateoutnetbufsize ( int plaintextbytes , int numbuffers ) {	Calculates the maximum size of the encrypted output buffer required to wrap the given plaintext bytes.
private static int findversion ( final bytebuf buffer ) { final int n = buffer . readablebytes ( ) ;	Returns the proxy protocol specification version in the buffer if the version is found.Returns -1 if no version was found in the buffer.
private static int findendofheader ( final bytebuf buffer ) { final int n = buffer . readablebytes ( ) ;	Returns the index in the buffer of the end of header if found.Returns -1 if no end of header was found in the buffer.
void createglobaltrafficcounter ( scheduledexecutorservice executor ) {	Create the global TrafficCounter.
public collection < trafficcounter > channeltrafficcounters ( ) { return new abstractcollection < trafficcounter > ( ) { @ override public iterator < trafficcounter > iterator ( ) { return new iterator < trafficcounter > ( ) { final iterator < perchannel > iter = channelqueues . values ( ) . iterator ( ) ; @ override public boolean hasnext ( ) { return iter . hasnext ( ) ; } @ override public trafficcounter next ( ) { return iter . next ( ) . channeltrafficcounter ; } @ override public void remove ( ) { throw new unsupportedoperationexception ( ) ; } } ; } @ override public int size ( ) { return channelqueues . size ( ) ; } } ; }	To allow for instance doAccounting to use the TrafficCounter per channel.
boolean hasreadablebits ( int count ) { if ( count < num_ ) { throw new illegalargumentexception ( str_ + count + str_ ) ; } return bitcount >= count || ( in . readablebytes ( ) << num_ & integer . max_value ) >= count - bitcount ; }	Checks that the specified number of bits available for reading.
boolean hasreadablebytes ( int count ) { if ( count < num_ || count > max_count_of_readable_bytes ) { throw new illegalargumentexception ( str_ + count + str_ + max_count_of_readable_bytes + str_ ) ; } return hasreadablebits ( count << num_ ) ; }	Checks that the specified number of bytes available for reading.
private static int parsecode ( bytebuf buffer ) { final int first = parsenumber ( buffer . readbyte ( ) ) * num_ ; final int second = parsenumber ( buffer . readbyte ( ) ) * num_ ; final int third = parsenumber ( buffer . readbyte ( ) ) ; return first + second + third ; }	Parses the io.netty.handler.codec.smtp code without any allocation, which is three digits.
private static boolean islinebased ( final bytebuf [ ] delimiters ) { if ( delimiters . length != num_ ) { return bool_ ; } bytebuf a = delimiters [ num_ ] ; bytebuf b = delimiters [ num_ ] ; if ( a . capacity ( ) < b . capacity ( ) ) { a = delimiters [ num_ ] ; b = delimiters [ num_ ] ; } return a . capacity ( ) == num_ && b . capacity ( ) == num_ && a . getbyte ( num_ ) == str_ && a . getbyte ( num_ ) == str_ && b . getbyte ( num_ ) == str_ ; }	Returns true if the delimiters are "\n" and "\r\n".
protected s state ( s newstate ) { s oldstate = state ; state = newstate ; return oldstate ; }	Sets the current state of this decoder.
private static boolean islast ( httpmessage httpmessage ) { if ( httpmessage instanceof fullhttpmessage ) { fullhttpmessage fullmessage = ( fullhttpmessage ) httpmessage ; if ( fullmessage . trailingheaders ( ) . isempty ( ) && ! fullmessage . content ( ) . isreadable ( ) ) { return bool_ ; } } return bool_ ; }	Checks if the given HTTP message should be considered as a last SPDY frame.
map < integer , streamstate > activestreams ( ) { map < integer , streamstate > streams = new treemap < integer , streamstate > ( streamcomparator ) ; streams . putall ( activestreams ) ; return streams ; }	Stream-IDs should be iterated in priority order.
public set < string > subprotocols ( ) { set < string > ret = new linkedhashset < string > ( ) ; collections . addall ( ret , subprotocols ) ; return ret ; }	Returns the CSV of supported sub protocols.
protected string selectsubprotocol ( string requestedsubprotocols ) { if ( requestedsubprotocols == null || subprotocols . length == num_ ) { return null ; } string [ ] requestedsubprotocolarray = requestedsubprotocols . split ( str_ ) ; for ( string p : requestedsubprotocolarray ) { string requestedsubprotocol = p . trim ( ) ; for ( string supportedsubprotocol : subprotocols ) { if ( sub_protocol_wildcard . equals ( supportedsubprotocol ) || requestedsubprotocol . equals ( supportedsubprotocol ) ) { selectedsubprotocol = requestedsubprotocol ; return requestedsubprotocol ; } } }	Selects the first matching supported sub protocol.
public static int indexof ( bytebuf needle , bytebuf haystack ) {	Returns the reader index of needle in haystack, or -1 if needle is not in haystack.
@ suppresswarnings ( str_ ) public static bytebuf writeshortbe ( bytebuf buf , int shortvalue ) { return buf . order ( ) == byteorder . big_endian ? buf . writeshort ( shortvalue ) : buf . writeshortle ( shortvalue ) ; }	Writes a big-endian 16-bit short integer to the buffer.
@ suppresswarnings ( str_ ) public static bytebuf setshortbe ( bytebuf buf , int index , int shortvalue ) { return buf . order ( ) == byteorder . big_endian ? buf . setshort ( index , shortvalue ) : buf . setshortle ( index , shortvalue ) ; }	Sets a big-endian 16-bit short integer to the buffer.
@ suppresswarnings ( str_ ) public static bytebuf writemediumbe ( bytebuf buf , int mediumvalue ) { return buf . order ( ) == byteorder . big_endian ? buf . writemedium ( mediumvalue ) : buf . writemediumle ( mediumvalue ) ; }	Writes a big-endian 24-bit medium integer to the buffer.
public static bytebuf threadlocaldirectbuffer ( ) { if ( thread_local_buffer_size <= num_ ) { return null ; } if ( platformdependent . hasunsafe ( ) ) { return threadlocalunsafedirectbytebuf . newinstance ( ) ; } else { return threadlocaldirectbytebuf . newinstance ( ) ; } }	Returns a cached thread-local direct buffer, if available.
public static void throwexception ( throwable t ) { if ( hasunsafe ( ) ) { platformdependent0 . throwexception ( t ) ; } else { platformdependent . < runtimeexception > throwexception0 ( t ) ; } }	Raises an exception bypassing compiler checks for checked exceptions.
public static boolean iszero ( byte [ ] bytes , int startpos , int length ) { return ! hasunsafe ( ) || ! unalignedaccess ( ) ? iszerosafe ( bytes , startpos , length ) : platformdependent0 . iszero ( bytes , startpos , length ) ; }	Determine if a subsection of an array is zero.
public static int hashcodeascii ( byte [ ] bytes , int startpos , int length ) { return ! hasunsafe ( ) || ! unalignedaccess ( ) ? hashcodeasciisafe ( bytes , startpos , length ) : platformdependent0 . hashcodeascii ( bytes , startpos , length ) ; }	Calculate a hash code of a byte array assuming ASCII character encoding.The resulting hash code will be case insensitive.
static int hashcodeasciisafe ( byte [ ] bytes , int startpos , int length ) { int hash = hash_code_ascii_seed ; final int remainingbytes = length & num_ ; final int end = startpos + remainingbytes ; for ( int i = startpos - num_ + length ; i >= end ; i -= num_ ) { hash = platformdependent0 . hashcodeasciicompute ( getlongsafe ( bytes , i ) , hash ) ; } switch ( remainingbytes ) { case num_ : return ( ( hash * hash_code_c1 + hashcodeasciisanitize ( bytes [ startpos ] ) ) * hash_code_c2 + hashcodeasciisanitize ( getshortsafe ( bytes , startpos + num_ ) ) ) * hash_code_c1 + hashcodeasciisanitize ( getintsafe ( bytes , startpos + num_ ) ) ; case num_ : return ( hash * hash_code_c1 + hashcodeasciisanitize ( getshortsafe ( bytes , startpos ) ) ) * hash_code_c2 + hashcodeasciisanitize ( getintsafe ( bytes , startpos + num_ ) ) ; case num_ : return ( hash * hash_code_c1 + hashcodeasciisanitize ( bytes [ startpos ] ) ) * hash_code_c2 + hashcodeasciisanitize ( getintsafe ( bytes , startpos + num_ ) ) ; case num_ : return hash * hash_code_c1 + hashcodeasciisanitize ( getintsafe ( bytes , startpos ) ) ; case num_ : return ( hash * hash_code_c1 + hashcodeasciisanitize ( bytes [ startpos ] ) ) * hash_code_c2 + hashcodeasciisanitize ( getshortsafe ( bytes , startpos + num_ ) ) ; case num_ : return hash * hash_code_c1 + hashcodeasciisanitize ( getshortsafe ( bytes , startpos ) ) ; case num_ : return hash * hash_code_c1 + hashcodeasciisanitize ( bytes [ startpos ] ) ; default : return hash ; } }	Package private for testing purposes only!.
private t getorcreate ( string name ) { t constant = constants . get ( name ) ; if ( constant == null ) { final t tempconstant = newconstant ( nextid ( ) , name ) ; constant = constants . putifabsent ( name , tempconstant ) ; if ( constant == null ) { return tempconstant ; } } return constant ; }	Get existing constant by name or creates new one if not exists. Threadsafe.
private t createorthrow ( string name ) { t constant = constants . get ( name ) ; if ( constant == null ) { final t tempconstant = newconstant ( nextid ( ) , name ) ; constant = constants . putifabsent ( name , tempconstant ) ; if ( constant == null ) { return tempconstant ; } } throw new illegalargumentexception ( string . format ( str_ , name ) ) ; }	Creates constant by name or throws exception. Threadsafe.
private static chunktype mapchunktype ( byte type ) { if ( type == num_ ) { return chunktype . compressed_data ; } else if ( type == num_ ) { return chunktype . uncompressed_data ; } else if ( type == ( byte ) num_ ) { return chunktype . stream_identifier ; } else if ( ( type & num_ ) == num_ ) { return chunktype . reserved_skippable ; } else { return chunktype . reserved_unskippable ; } }	Decodes the chunk type from the type tag byte.
private void setmultipart ( string contenttype ) { string [ ] databoundary = httppostrequestdecoder . getmultipartdataboundary ( contenttype ) ; if ( databoundary != null ) { multipartdataboundary = databoundary [ num_ ] ; if ( databoundary . length > num_ && databoundary [ num_ ] != null ) { charset = charset . forname ( databoundary [ num_ ] ) ; } } else { multipartdataboundary = null ; } currentstatus = multipartstatus . headerdelimiter ; }	Set from the request ContentType the multipartDataBoundary and the possible charset.
private void parsebodymultipart ( ) { if ( undecodedchunk == null || undecodedchunk . readablebytes ( ) == num_ ) {	Parse the Body for multipart.
private static void skipcontrolcharacters ( bytebuf undecodedchunk ) { if ( ! undecodedchunk . hasarray ( ) ) { try { skipcontrolcharactersstandard ( undecodedchunk ) ; } catch ( indexoutofboundsexception e1 ) { throw new notenoughdatadecoderexception ( e1 ) ; } return ; } seekaheadoptimize sao = new seekaheadoptimize ( undecodedchunk ) ; while ( sao . pos < sao . limit ) { char c = ( char ) ( sao . bytes [ sao . pos ++ ] & num_ ) ; if ( ! character . isisocontrol ( c ) && ! character . iswhitespace ( c ) ) { sao . setreadposition ( num_ ) ; return ; } } throw new notenoughdatadecoderexception ( str_ ) ; }	Skip control Characters.
private interfacehttpdata findmultipartdelimiter ( string delimiter , multipartstatus dispositionstatus , multipartstatus closedelimiterstatus ) {	Find the next Multipart Delimiter.
private void cleanmixedattributes ( ) { currentfieldattributes . remove ( httpheadervalues . charset ) ; currentfieldattributes . remove ( httpheadernames . content_length ) ; currentfieldattributes . remove ( httpheadernames . content_transfer_encoding ) ; currentfieldattributes . remove ( httpheadernames . content_type ) ; currentfieldattributes . remove ( httpheadervalues . filename ) ; }	Remove all Attributes that should be cleaned between two FileUpload inMixed mode.
private static boolean loaddatamultipartstandard ( bytebuf undecodedchunk , string delimiter , httpdata httpdata ) { final int startreaderindex = undecodedchunk . readerindex ( ) ; final int delimeterlength = delimiter . length ( ) ; int index = num_ ; int lastposition = startreaderindex ; byte prevbyte = httpconstants . lf ; boolean delimiterfound = bool_ ; while ( undecodedchunk . isreadable ( ) ) { final byte nextbyte = undecodedchunk . readbyte ( ) ;	Load the field value or file data from a Multipart request.
private static boolean loaddatamultipart ( bytebuf undecodedchunk , string delimiter , httpdata httpdata ) { if ( ! undecodedchunk . hasarray ( ) ) { return loaddatamultipartstandard ( undecodedchunk , delimiter , httpdata ) ; } final seekaheadoptimize sao = new seekaheadoptimize ( undecodedchunk ) ; final int startreaderindex = undecodedchunk . readerindex ( ) ; final int delimeterlength = delimiter . length ( ) ; int index = num_ ; int lastrealpos = sao . pos ; byte prevbyte = httpconstants . lf ; boolean delimiterfound = bool_ ; while ( sao . pos < sao . limit ) { final byte nextbyte = sao . bytes [ sao . pos ++ ] ;	Load the field value from a Multipart request.
private static string cleanstring ( string field ) { int size = field . length ( ) ; stringbuilder sb = new stringbuilder ( size ) ; for ( int i = num_ ; i < size ; i ++ ) { char nextchar = field . charat ( i ) ; switch ( nextchar ) { case httpconstants . colon : case httpconstants . comma : case httpconstants . equals : case httpconstants . semicolon : case httpconstants . ht : sb . append ( httpconstants . sp_char ) ; break ; case httpconstants . double_quote :	Clean the String from any unallowed character.
private boolean skiponeline ( ) { if ( ! undecodedchunk . isreadable ( ) ) { return bool_ ; } byte nextbyte = undecodedchunk . readbyte ( ) ; if ( nextbyte == httpconstants . cr ) { if ( ! undecodedchunk . isreadable ( ) ) { undecodedchunk . readerindex ( undecodedchunk . readerindex ( ) - num_ ) ; return bool_ ; } nextbyte = undecodedchunk . readbyte ( ) ; if ( nextbyte == httpconstants . lf ) { return bool_ ; } undecodedchunk . readerindex ( undecodedchunk . readerindex ( ) - num_ ) ; return bool_ ; } if ( nextbyte == httpconstants . lf ) { return bool_ ; } undecodedchunk . readerindex ( undecodedchunk . readerindex ( ) - num_ ) ; return bool_ ; }	Skip one empty line.
private static string [ ] splitmultipartheader ( string sb ) { arraylist < string > headers = new arraylist < string > ( num_ ) ; int namestart ; int nameend ; int colonend ; int valuestart ; int valueend ; namestart = httppostbodyutil . findnonwhitespace ( sb , num_ ) ; for ( nameend = namestart ; nameend < sb . length ( ) ; nameend ++ ) { char ch = sb . charat ( nameend ) ; if ( ch == str_ || character . iswhitespace ( ch ) ) { break ; } } for ( colonend = nameend ; colonend < sb . length ( ) ; colonend ++ ) { if ( sb . charat ( colonend ) == str_ ) { colonend ++ ; break ; } } valuestart = httppostbodyutil . findnonwhitespace ( sb , colonend ) ; valueend = httppostbodyutil . findendofstring ( sb ) ; headers . add ( sb . substring ( namestart , nameend ) ) ; string svalue = ( valuestart >= valueend ) ? stringutil . empty_string : sb . substring ( valuestart , valueend ) ; string [ ] values ; if ( svalue . indexof ( str_ ) >= num_ ) { values = splitmultipartheadervalues ( svalue ) ; } else { values = svalue . split ( str_ ) ; } for ( string value : values ) { headers . add ( value . trim ( ) ) ; } string [ ] array = new string [ headers . size ( ) ] ; for ( int i = num_ ; i < headers . size ( ) ; i ++ ) { array [ i ] = headers . get ( i ) ; } return array ; }	Split one header in Multipart.
private static string [ ] splitmultipartheadervalues ( string svalue ) { list < string > values = internalthreadlocalmap . get ( ) . arraylist ( num_ ) ; boolean inquote = bool_ ; boolean escapenext = bool_ ; int start = num_ ; for ( int i = num_ ; i < svalue . length ( ) ; i ++ ) { char c = svalue . charat ( i ) ; if ( inquote ) { if ( escapenext ) { escapenext = bool_ ; } else { if ( c == str_ ) { escapenext = bool_ ; } else if ( c == str_ ) { inquote = bool_ ; } } } else { if ( c == str_ ) { inquote = bool_ ; } else if ( c == str_ ) { values . add ( svalue . substring ( start , i ) ) ; start = i + num_ ; } } } values . add ( svalue . substring ( start ) ) ; return values . toarray ( new string [ num_ ] ) ; }	Split one header value in Multipart.
static void handle ( channelhandlercontext ctx , http2connection connection , http2framelistener listener , fullhttpmessage message ) throws http2exception { try { int streamid = getstreamid ( connection , message . headers ( ) ) ; http2stream stream = connection . stream ( streamid ) ; if ( stream == null ) { stream = connection . remote ( ) . createstream ( streamid , bool_ ) ; } message . headers ( ) . set ( httpconversionutil . extensionheadernames . scheme . text ( ) , httpscheme . http . name ( ) ) ; http2headers messageheaders = httpconversionutil . tohttp2headers ( message , bool_ ) ; boolean hascontent = message . content ( ) . isreadable ( ) ; boolean hastrailers = ! message . trailingheaders ( ) . isempty ( ) ; listener . onheadersread ( ctx , streamid , messageheaders , num_ , ! ( hascontent || hastrailers ) ) ; if ( hascontent ) { listener . ondataread ( ctx , streamid , message . content ( ) , num_ , ! hastrailers ) ; } if ( hastrailers ) { http2headers headers = httpconversionutil . tohttp2headers ( message . trailingheaders ( ) , bool_ ) ; listener . onheadersread ( ctx , streamid , headers , num_ , bool_ ) ; } stream . closeremoteside ( ) ; } finally { message . release ( ) ; } }	control, but there is not yet an API for signaling that.
private void writesymbolmap ( bytebuf out ) { bzip2bitwriter writer = this . writer ; final boolean [ ] blockvaluespresent = this . blockvaluespresent ; final boolean [ ] condensedinuse = new boolean [ num_ ] ; for ( int i = num_ ; i < condensedinuse . length ; i ++ ) { for ( int j = num_ , k = i << num_ ; j < huffman_symbol_range_size ; j ++ , k ++ ) { if ( blockvaluespresent [ k ] ) { condensedinuse [ i ] = bool_ ; } } } for ( boolean iscondensedinuse : condensedinuse ) { writer . writeboolean ( out , iscondensedinuse ) ; } for ( int i = num_ ; i < condensedinuse . length ; i ++ ) { if ( condensedinuse [ i ] ) { for ( int j = num_ , k = i << num_ ; j < huffman_symbol_range_size ; j ++ , k ++ ) { writer . writeboolean ( out , blockvaluespresent [ k ] ) ; } } } }	Write the Huffman symbol to output byte map.
private void writerun ( final int value , int runlength ) { final int blocklength = this . blocklength ; final byte [ ] block = this . block ; blockvaluespresent [ value ] = bool_ ; crc . updatecrc ( value , runlength ) ; final byte bytevalue = ( byte ) value ; switch ( runlength ) { case num_ : block [ blocklength ] = bytevalue ; this . blocklength = blocklength + num_ ; break ; case num_ : block [ blocklength ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; this . blocklength = blocklength + num_ ; break ; case num_ : block [ blocklength ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; this . blocklength = blocklength + num_ ; break ; default : runlength -= num_ ; blockvaluespresent [ runlength ] = bool_ ; block [ blocklength ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; block [ blocklength + num_ ] = bytevalue ; block [ blocklength + num_ ] = ( byte ) runlength ; this . blocklength = blocklength + num_ ; break ; } }	Writes an RLE run to the block array, updating the block CRC and present values array as required.
boolean write ( final int value ) { if ( blocklength > blocklengthlimit ) { return bool_ ; } final int rlecurrentvalue = this . rlecurrentvalue ; final int rlelength = this . rlelength ; if ( rlelength == num_ ) { this . rlecurrentvalue = value ; this . rlelength = num_ ; } else if ( rlecurrentvalue != value ) {	Writes a byte to the block, accumulating to an RLE run where possible.
int write ( final bytebuf buffer , int offset , int length ) { int index = buffer . foreachbyte ( offset , length , writeprocessor ) ; return index == - num_ ? length : index - offset ; }	Writes an array to the block.
void close ( bytebuf out ) {	Compresses and writes out the block.
private channelfuture respond ( encodable result ) { socketaddress remoteaddress = channel . remoteaddress ( ) ; return channel . writeandflush ( result ) . addlistener ( future -> { if ( future . issuccess ( ) ) { logger . trace ( str_ , result , remoteaddress ) ; } else { logger . error ( string . format ( str_ , result , remoteaddress ) , future . cause ( ) ) ; channel . close ( ) ; } } ) ; }	Responds to a single message with some Encodable object.
private void receive ( ) { try { socket socket = null ; bufferedreader reader = null ; try {	Create a socket connection and receive data until receiver is stopped.
public static storagelevel create ( boolean usedisk , boolean usememory , boolean useoffheap , boolean deserialized , int replication ) { return storagelevel . apply ( usedisk , usememory , useoffheap , deserialized , replication ) ; }	Create a new StorageLevel object.
public static columnarbatch tobatch ( structtype schema , memorymode memmode , iterator < row > row ) { int capacity = num_ * num_ ; writablecolumnvector [ ] columnvectors ; if ( memmode == memorymode . off_heap ) { columnvectors = offheapcolumnvector . allocatecolumns ( capacity , schema ) ; } else { columnvectors = onheapcolumnvector . allocatecolumns ( capacity , schema ) ; } int n = num_ ; while ( row . hasnext ( ) ) { row r = row . next ( ) ; for ( int i = num_ ; i < schema . fields ( ) . length ; i ++ ) { appendvalue ( columnvectors [ i ] , schema . fields ( ) [ i ] . datatype ( ) , r , i ) ; } n ++ ; } columnarbatch batch = new columnarbatch ( columnvectors ) ; batch . setnumrows ( n ) ; return batch ; }	Converts an iterator of rows into a single ColumnBatch.
public void registerexecutor ( string appid , string execid , executorshuffleinfo executorinfo ) { appexecid fullid = new appexecid ( appid , execid ) ; logger . info ( str_ , fullid , executorinfo ) ; if ( ! knownmanagers . contains ( executorinfo . shufflemanager ) ) { throw new unsupportedoperationexception ( str_ + executorinfo ) ; } try { if ( db != null ) { byte [ ] key = dbappexeckey ( fullid ) ; byte [ ] value = mapper . writevalueasstring ( executorinfo ) . getbytes ( standardcharsets . utf_8 ) ; db . put ( key , value ) ; } } catch ( exception e ) { logger . error ( str_ , e ) ; } executors . put ( fullid , executorinfo ) ; }	Registers a new Executor with all the configuration we need to find its shuffle files.
public void applicationremoved ( string appid , boolean cleanuplocaldirs ) { logger . info ( str_ , appid , cleanuplocaldirs ) ; iterator < map . entry < appexecid , executorshuffleinfo > > it = executors . entryset ( ) . iterator ( ) ; while ( it . hasnext ( ) ) { map . entry < appexecid , executorshuffleinfo > entry = it . next ( ) ; appexecid fullid = entry . getkey ( ) ; final executorshuffleinfo executor = entry . getvalue ( ) ;	Removes our metadata of all executors registered for the given application, and optionallyalso deletes the local directories associated with the executors of that application in aseparate thread.It is not valid to call registerExecutor() for an executor with this appId after invokingthis method.
public void executorremoved ( string executorid , string appid ) { logger . info ( str_ , executorid ) ; appexecid fullid = new appexecid ( appid , executorid ) ; final executorshuffleinfo executor = executors . get ( fullid ) ; if ( executor == null ) {	Removes all the non-shuffle files in any local directories associated with the finishedexecutor.
private void deleteexecutordirs ( string [ ] dirs ) { for ( string localdir : dirs ) { try { javautils . deleterecursively ( new file ( localdir ) ) ; logger . debug ( str_ , localdir ) ; } catch ( exception e ) { logger . error ( str_ + localdir , e ) ; } } }	Synchronously deletes each directory one at a time.Should be executed in its own thread, as this may take a long time.
private void deletenonshufflefiles ( string [ ] dirs ) { filenamefilter filter = new filenamefilter ( ) { @ override public boolean accept ( file dir , string name ) {	Synchronously deletes non-shuffle files in each directory recursively.Should be executed in its own thread, as this may take a long time.
private managedbuffer getsortbasedshuffleblockdata ( executorshuffleinfo executor , int shuffleid , int mapid , int reduceid ) { file indexfile = getfile ( executor . localdirs , executor . subdirsperlocaldir , str_ + shuffleid + str_ + mapid + str_ ) ; try { shuffleindexinformation shuffleindexinformation = shuffleindexcache . get ( indexfile ) ; shuffleindexrecord shuffleindexrecord = shuffleindexinformation . getindex ( reduceid ) ; return new filesegmentmanagedbuffer ( conf , getfile ( executor . localdirs , executor . subdirsperlocaldir , str_ + shuffleid + str_ + mapid + str_ ) , shuffleindexrecord . getoffset ( ) , shuffleindexrecord . getlength ( ) ) ; } catch ( executionexception e ) { throw new runtimeexception ( str_ + indexfile , e ) ; } }	Sort-based shuffle data uses an index called "shuffle_ShuffleId_MapId_0.index" into a data filecalled "shuffle_ShuffleId_MapId_0.data".
public void insertrecord ( long recordpointer , int partitionid ) { if ( ! hasspaceforanotherrecord ( ) ) { throw new illegalstateexception ( str_ ) ; } array . set ( pos , packedrecordpointer . packpointer ( recordpointer , partitionid ) ) ; pos ++ ; }	Inserts a record to be sorted.
public shufflesorteriterator getsortediterator ( ) { int offset = num_ ; if ( useradixsort ) { offset = radixsort . sort ( array , pos , packedrecordpointer . partition_id_start_byte_index , packedrecordpointer . partition_id_end_byte_index , bool_ , bool_ ) ; } else { memoryblock unused = new memoryblock ( array . getbaseobject ( ) , array . getbaseoffset ( ) + pos * num_ , ( array . size ( ) - pos ) * num_ ) ; longarray buffer = new longarray ( unused ) ; sorter < packedrecordpointer , longarray > sorter = new sorter < > ( new shufflesortdataformat ( buffer ) ) ; sorter . sort ( array , num_ , pos , sort_comparator ) ; } return new shufflesorteriterator ( pos , array , offset ) ; }	Return an iterator over record pointers in sorted order.
private void failoutstandingrequests ( throwable cause ) { for ( map . entry < streamchunkid , chunkreceivedcallback > entry : outstandingfetches . entryset ( ) ) { try { entry . getvalue ( ) . onfailure ( entry . getkey ( ) . chunkindex , cause ) ; } catch ( exception e ) { logger . warn ( str_ , e ) ; } } for ( map . entry < long , rpcresponsecallback > entry : outstandingrpcs . entryset ( ) ) { try { entry . getvalue ( ) . onfailure ( cause ) ; } catch ( exception e ) { logger . warn ( str_ , e ) ; } } for ( pair < string , streamcallback > entry : streamcallbacks ) { try { entry . getvalue ( ) . onfailure ( entry . getkey ( ) , cause ) ; } catch ( exception e ) { logger . warn ( str_ , e ) ; } }	Fire the failure callback for all outstanding requests.
@ override protected void serviceinit ( configuration conf ) throws exception { _conf = conf ; boolean stoponfailure = conf . getboolean ( stop_on_failure_key , default_stop_on_failure ) ; try {	Start the shuffle server with the given configuration.
@ override protected void servicestop ( ) { try { if ( shuffleserver != null ) { shuffleserver . close ( ) ; } if ( transportcontext != null ) { transportcontext . close ( ) ; } if ( blockhandler != null ) { blockhandler . close ( ) ; } if ( db != null ) { db . close ( ) ; } } catch ( exception e ) { logger . error ( str_ , e ) ; } }	Close the shuffle server to clean up any associated state.
protected file initrecoverydb ( string dbname ) { preconditions . checknotnull ( _recoverypath , str_ ) ; file recoveryfile = new file ( _recoverypath . touri ( ) . getpath ( ) , dbname ) ; if ( recoveryfile . exists ( ) ) { return recoveryfile ; }	Figure out the recovery path and handle moving the DB if YARN NM recovery gets enabledand DB exists in the local dir of NM by old version of shuffle service.
private static list < string > buildcommand ( abstractcommandbuilder builder , map < string , string > env , boolean printlaunchcommand ) throws ioexception , illegalargumentexception { list < string > cmd = builder . buildcommand ( env ) ; if ( printlaunchcommand ) { system . err . println ( str_ + join ( str_ , cmd ) ) ; system . err . println ( str_ ) ; } return cmd ; }	Prepare spark commands with the appropriate command builder.If printLaunchCommand is set then the commands will be printed to the stderr.
private static string preparewindowscommand ( list < string > cmd , map < string , string > childenv ) { stringbuilder cmdline = new stringbuilder ( ) ; for ( map . entry < string , string > e : childenv . entryset ( ) ) { cmdline . append ( string . format ( str_ , e . getkey ( ) , e . getvalue ( ) ) ) ; cmdline . append ( str_ ) ; } for ( string arg : cmd ) { cmdline . append ( quoteforbatchscript ( arg ) ) ; cmdline . append ( str_ ) ; } return cmdline . tostring ( ) ; }	Prepare a command line for execution from a Windows batch script.The method quotes all arguments so that spaces are handled as expected.
private static list < string > preparebashcommand ( list < string > cmd , map < string , string > childenv ) { if ( childenv . isempty ( ) ) { return cmd ; } list < string > newcmd = new arraylist < > ( ) ; newcmd . add ( str_ ) ; for ( map . entry < string , string > e : childenv . entryset ( ) ) { newcmd . add ( string . format ( str_ , e . getkey ( ) , e . getvalue ( ) ) ) ; } newcmd . addall ( cmd ) ; return newcmd ; }	Prepare the command for execution from a bash script.
public void zerooutnullbytes ( ) { for ( int i = num_ ; i < nullbitssize ; i += num_ ) { platform . putlong ( getbuffer ( ) , startingoffset + i , num_ ) ; } }	Clears out null bits.
clientchallenge challenge ( ) throws generalsecurityexception { this . authnonce = randombytes ( conf . encryptionkeylength ( ) / byte . size ) ; secretkeyspec authkey = generatekey ( conf . keyfactoryalgorithm ( ) , conf . keyfactoryiterations ( ) , authnonce , conf . encryptionkeylength ( ) ) ; initializeforauth ( conf . ciphertransformation ( ) , authnonce , authkey ) ; this . challenge = randombytes ( conf . encryptionkeylength ( ) / byte . size ) ; return new clientchallenge ( new string ( appid , utf_8 ) , conf . keyfactoryalgorithm ( ) , conf . keyfactoryiterations ( ) , conf . ciphertransformation ( ) , conf . encryptionkeylength ( ) , authnonce , challenge ( appid , authnonce , challenge ) ) ; }	Create the client challenge.
serverresponse respond ( clientchallenge clientchallenge ) throws generalsecurityexception { secretkeyspec authkey = generatekey ( clientchallenge . kdf , clientchallenge . iterations , clientchallenge . nonce , clientchallenge . keylength ) ; initializeforauth ( clientchallenge . cipher , clientchallenge . nonce , authkey ) ; byte [ ] challenge = validatechallenge ( clientchallenge . nonce , clientchallenge . challenge ) ; byte [ ] response = challenge ( appid , clientchallenge . nonce , rawresponse ( challenge ) ) ; byte [ ] sessionnonce = randombytes ( conf . encryptionkeylength ( ) / byte . size ) ; byte [ ] inputiv = randombytes ( conf . ivlength ( ) ) ; byte [ ] outputiv = randombytes ( conf . ivlength ( ) ) ; secretkeyspec sessionkey = generatekey ( clientchallenge . kdf , clientchallenge . iterations , sessionnonce , clientchallenge . keylength ) ; this . sessioncipher = new transportcipher ( cryptoconf , clientchallenge . cipher , sessionkey , inputiv , outputiv ) ;	Validates the client challenge, and create the encryption backend for the channel from theparameters sent by the client.
void validate ( serverresponse serverresponse ) throws generalsecurityexception { byte [ ] response = validatechallenge ( authnonce , serverresponse . response ) ; byte [ ] expected = rawresponse ( challenge ) ; preconditions . checkargument ( arrays . equals ( expected , response ) ) ; byte [ ] nonce = decrypt ( serverresponse . nonce ) ; byte [ ] inputiv = decrypt ( serverresponse . inputiv ) ; byte [ ] outputiv = decrypt ( serverresponse . outputiv ) ; secretkeyspec sessionkey = generatekey ( conf . keyfactoryalgorithm ( ) , conf . keyfactoryiterations ( ) , nonce , conf . encryptionkeylength ( ) ) ; this . sessioncipher = new transportcipher ( cryptoconf , conf . ciphertransformation ( ) , sessionkey , inputiv , outputiv ) ; }	Validates the server response and initializes the cipher to use for the session.
private byte [ ] validatechallenge ( byte [ ] nonce , byte [ ] encryptedchallenge ) throws generalsecurityexception { byte [ ] challenge = decrypt ( encryptedchallenge ) ; checksubarray ( appid , challenge , num_ ) ; checksubarray ( nonce , challenge , appid . length ) ; return arrays . copyofrange ( challenge , appid . length + nonce . length , challenge . length ) ; }	Validates an encrypted challenge as defined in the protocol, and returns the byte arraythat corresponds to the actual challenge data.
private void checksubarray ( byte [ ] test , byte [ ] data , int offset ) { preconditions . checkargument ( data . length >= test . length + offset ) ; for ( int i = num_ ; i < test . length ; i ++ ) { preconditions . checkargument ( test [ i ] == data [ i + offset ] ) ; } }	Checks that the "test" array is in the data array starting at the given offset.
private static int fmix ( int h1 , int length ) { h1 ^= length ; h1 ^= h1 > > > num_ ; h1 *= num_ ; h1 ^= h1 > > > num_ ; h1 *= num_ ; h1 ^= h1 > > > num_ ; return h1 ; }	Finalization mix - force all bits of a hash block to avalanche.
@ override public boolean acceptinboundmessage ( object msg ) throws exception { if ( msg instanceof chunkfetchrequest ) { return bool_ ; } else { return super . acceptinboundmessage ( msg ) ; } }	Overwrite acceptInboundMessage to properly delegate ChunkFetchRequest messagesto ChunkFetchRequestHandler.
public transportserver createserver ( int port , list < transportserverbootstrap > bootstraps ) { return new transportserver ( this , null , port , rpchandler , bootstraps ) ; }	Create a server which will attempt to bind to a specific port.
public transportserver createserver ( string host , int port , list < transportserverbootstrap > bootstraps ) { return new transportserver ( this , host , port , rpchandler , bootstraps ) ; }	Create a server which will attempt to bind to a specific host and port.
private chunkfetchrequesthandler createchunkfetchhandler ( transportchannelhandler channelhandler , rpchandler rpchandler ) { return new chunkfetchrequesthandler ( channelhandler . getclient ( ) , rpchandler . getstreammanager ( ) , conf . maxchunksbeingtransferred ( ) ) ; }	Creates the dedicated ChannelHandler for ChunkFetchRequest messages.
void monitorchild ( ) { process proc = childproc ; if ( proc == null ) {	Wait for the child process to exit and update the handle's state if necessary, according tothe exit code.
public t setpropertiesfile ( string path ) { checknotnull ( path , str_ ) ; builder . setpropertiesfile ( path ) ; return self ( ) ; }	Set a custom properties file with Spark configuration for the application.
public t setconf ( string key , string value ) { checknotnull ( key , str_ ) ; checknotnull ( value , str_ ) ; checkargument ( key . startswith ( str_ ) , str_ ) ; builder . conf . put ( key , value ) ; return self ( ) ; }	Set a single configuration value for the application.
public t setappname ( string appname ) { checknotnull ( appname , str_ ) ; builder . appname = appname ; return self ( ) ; }	Set the application name.
public t setmaster ( string master ) { checknotnull ( master , str_ ) ; builder . master = master ; return self ( ) ; }	Set the Spark master for the application.
public t setdeploymode ( string mode ) { checknotnull ( mode , str_ ) ; builder . deploymode = mode ; return self ( ) ; }	Set the deploy mode for the application.
public t addappargs ( string ... args ) { for ( string arg : args ) { checknotnull ( arg , str_ ) ; builder . appargs . add ( arg ) ; } return self ( ) ; }	Adds command line arguments for the application.
public t addjar ( string jar ) { checknotnull ( jar , str_ ) ; builder . jars . add ( jar ) ; return self ( ) ; }	Adds a jar file to be submitted with the application.
public t addfile ( string file ) { checknotnull ( file , str_ ) ; builder . files . add ( file ) ; return self ( ) ; }	Adds a file to be submitted with the application.
public void zeroout ( ) { for ( long off = baseoffset ; off < baseoffset + length * width ; off += width ) { platform . putlong ( baseobj , off , num_ ) ; } }	Fill this all with 0L.
private static caseinsensitivestringmap catalogoptions ( string name , sqlconf conf ) { map < string , string > allconfs = mapasjavamapconverter ( conf . getallconfs ( ) ) . asjava ( ) ; pattern prefix = pattern . compile ( str_ + name + str_ ) ; hashmap < string , string > options = new hashmap < > ( ) ; for ( map . entry < string , string > entry : allconfs . entryset ( ) ) { matcher matcher = prefix . matcher ( entry . getkey ( ) ) ; if ( matcher . matches ( ) && matcher . groupcount ( ) > num_ ) { options . put ( matcher . group ( num_ ) , entry . getvalue ( ) ) ; } } return new caseinsensitivestringmap ( options ) ; }	Extracts a named catalog's configuration from a SQLConf.
synchronized string registerhandle ( abstractapphandle handle ) { string secret = createsecret ( ) ; secrettopendingapps . put ( secret , handle ) ; return secret ; }	Registers a handle with the server, and returns the secret the child app needs to connectback.
private static long [ ] [ ] getcounts ( longarray array , long numrecords , int startbyteindex , int endbyteindex ) { long [ ] [ ] counts = new long [ num_ ] [ ] ;	Computes a value histogram for each byte in the given array.
private static long [ ] transformcountstooffsets ( long [ ] counts , long numrecords , long outputoffset , long bytesperrecord , boolean desc , boolean signed ) { assert counts . length == num_ ; int start = signed ? num_ : num_ ;	Transforms counts into the proper unsafe output offsets for the sort type.
@ override public void initialize ( string path , list < string > columns ) throws ioexception , unsupportedoperationexception { super . initialize ( path , columns ) ; initializeinternal ( ) ; }	Utility API that will read all the data in path.
public boolean nextbatch ( ) throws ioexception { for ( writablecolumnvector vector : columnvectors ) { vector . reset ( ) ; } columnarbatch . setnumrows ( num_ ) ; if ( rowsreturned >= totalrowcount ) return bool_ ; checkendofrowgroup ( ) ; int num = ( int ) math . min ( ( long ) capacity , totalcountloadedsofar - rowsreturned ) ; for ( int i = num_ ; i < columnreaders . length ; ++ i ) { if ( columnreaders [ i ] == null ) continue ; columnreaders [ i ] . readbatch ( num , columnvectors [ i ] ) ; } rowsreturned += num ; columnarbatch . setnumrows ( num ) ; numbatched = num ; batchidx = num_ ; return bool_ ; }	Advances to the next batch of rows.
public static void closequietly ( closeable closeable ) { try { if ( closeable != null ) { closeable . close ( ) ; } } catch ( ioexception e ) { logger . error ( str_ , e ) ; } }	Closes the given object, ignoring IOExceptions.
public static void deleterecursively ( file file , filenamefilter filter ) throws ioexception { if ( file == null ) { return ; }	Delete a file or directory and its contents recursively.Don't follow directories if they are symlinks.
public static byte [ ] buffertoarray ( bytebuffer buffer ) { if ( buffer . hasarray ( ) && buffer . arrayoffset ( ) == num_ && buffer . array ( ) . length == buffer . remaining ( ) ) { return buffer . array ( ) ; } else { byte [ ] bytes = new byte [ buffer . remaining ( ) ] ; buffer . get ( bytes ) ; return bytes ; } }	Returns a byte array with the buffer's contents, trying to avoid copying the data ifpossible.
public static void readfully ( readablebytechannel channel , bytebuffer dst ) throws ioexception { int expected = dst . remaining ( ) ; while ( dst . hasremaining ( ) ) { if ( channel . read ( dst ) < num_ ) { throw new eofexception ( string . format ( str_ , expected ) ) ; } } }	Fills a buffer with data read from the channel.
public void pointto ( object baseobject , long baseoffset , int sizeinbytes ) {	Update this UnsafeMapData to point to different backing data.
public void reset ( ) { if ( isconstant ) return ; if ( childcolumns != null ) { for ( columnvector c : childcolumns ) { ( ( writablecolumnvector ) c ) . reset ( ) ; } } elementsappended = num_ ; if ( numnulls > num_ ) { putnotnulls ( num_ , capacity ) ; numnulls = num_ ; } }	Resets this column for writing.
public writablecolumnvector reservedictionaryids ( int capacity ) { if ( dictionaryids == null ) { dictionaryids = reservenewcolumn ( capacity , datatypes . integertype ) ; } else { dictionaryids . reset ( ) ; dictionaryids . reserve ( capacity ) ; } return dictionaryids ; }	Reserve a integer column for ids of dictionary.
@ override public final columnararray getarray ( int rowid ) { if ( isnullat ( rowid ) ) return null ; return new columnararray ( arraydata ( ) , getarrayoffset ( rowid ) , getarraylength ( rowid ) ) ; }	array offsets and lengths in the current column vector.
@ override public final columnarmap getmap ( int rowid ) { if ( isnullat ( rowid ) ) return null ; return new columnarmap ( getchild ( num_ ) , getchild ( num_ ) , getarrayoffset ( rowid ) , getarraylength ( rowid ) ) ; }	second child column vector, and puts the offsets and lengths in the current column vector.
public static < t > typedcolumn < t , double > avg ( mapfunction < t , double > f ) { return new typedaverage < t > ( f ) . tocolumnjava ( ) ; }	Average aggregate function.
public static < t > typedcolumn < t , long > count ( mapfunction < t , object > f ) { return new typedcount < t > ( f ) . tocolumnjava ( ) ; }	Count aggregate function.
private void readasync ( ) throws ioexception { statechangelock . lock ( ) ; final byte [ ] arr = readaheadbuffer . array ( ) ; try { if ( endofstream || readinprogress ) { return ; } checkreadexception ( ) ; readaheadbuffer . position ( num_ ) ; readaheadbuffer . flip ( ) ; readinprogress = bool_ ; } finally { statechangelock . unlock ( ) ; } executorservice . execute ( ( ) -> { statechangelock . lock ( ) ; try { if ( isclosed ) { readinprogress = bool_ ; return ; }	Read data from underlyingInputStream to readAheadBuffer asynchronously.
public void cachethreadlocalrawstore ( ) { long threadid = this . getid ( ) ; rawstore threadlocalrawstore = hivemetastore . hmshandler . getrawstore ( ) ; if ( threadlocalrawstore != null && ! threadrawstoremap . containskey ( threadid ) ) { log . debug ( str_ + threadlocalrawstore + str_ + this . getname ( ) + str_ ) ; threadrawstoremap . put ( threadid , threadlocalrawstore ) ; } }	Cache the ThreadLocal RawStore object.
private string convertpattern ( final string pattern , boolean datanucleusformat ) { string wstr ; if ( datanucleusformat ) { wstr = str_ ; } else { wstr = str_ ; } return pattern . replaceall ( str_ , str_ + wstr ) . replaceall ( str_ , str_ ) . replaceall ( str_ , wstr ) . replaceall ( str_ , str_ ) . replaceall ( str_ , str_ ) . replaceall ( str_ , str_ ) ; }	Convert a pattern containing JDBC catalog search wildcards intoJava regex patterns.
public iterator < internalrow > rowiterator ( ) { final int maxrows = numrows ; final mutablecolumnarrow row = new mutablecolumnarrow ( columns ) ; return new iterator < internalrow > ( ) { int rowid = num_ ; @ override public boolean hasnext ( ) { return rowid < maxrows ; } @ override public internalrow next ( ) { if ( rowid >= maxrows ) { throw new nosuchelementexception ( ) ; } row . rowid = rowid ++ ; return row ; } @ override public void remove ( ) { throw new unsupportedoperationexception ( ) ; } } ; }	Returns an iterator over the rows in this batch.
public internalrow getrow ( int rowid ) { assert ( rowid >= num_ && rowid < numrows ) ; row . rowid = rowid ; return row ; }	Returns the row in this batch at `rowId`.
public long sendrpc ( bytebuffer message , rpcresponsecallback callback ) { if ( logger . istraceenabled ( ) ) { logger . trace ( str_ , getremoteaddress ( channel ) ) ; } long requestid = requestid ( ) ; handler . addrpcrequest ( requestid , callback ) ; rpcchannellistener listener = new rpcchannellistener ( requestid , callback ) ; channel . writeandflush ( new rpcrequest ( requestid , new niomanagedbuffer ( message ) ) ) . addlistener ( listener ) ; return requestid ; }	Sends an opaque message to the RpcHandler on the server-side.
public bytebuffer sendrpcsync ( bytebuffer message , long timeoutms ) { final settablefuture < bytebuffer > result = settablefuture . create ( ) ; sendrpc ( message , new rpcresponsecallback ( ) { @ override public void onsuccess ( bytebuffer response ) { bytebuffer copy = bytebuffer . allocate ( response . remaining ( ) ) ; copy . put ( response ) ;	Synchronously sends an opaque message to the RpcHandler on the server-side, waiting for up toa specified timeout for a response.
private boolean refill ( ) throws ioexception { if ( ! bytebuffer . hasremaining ( ) ) { bytebuffer . clear ( ) ; int nread = num_ ; while ( nread == num_ ) { nread = filechannel . read ( bytebuffer ) ; } if ( nread < num_ ) { return bool_ ; } bytebuffer . flip ( ) ; } return bool_ ; }	Checks weather data is left to be read from the input stream.
public string signcookie ( string str ) { if ( str == null || str . isempty ( ) ) { throw new illegalargumentexception ( str_ ) ; } string signature = getsignature ( str ) ; if ( log . isdebugenabled ( ) ) { log . debug ( str_ + str + str_ + signature ) ; } return str + signature + signature ; }	Sign the cookie given the string token as input.
public string verifyandextract ( string signedstr ) { int index = signedstr . lastindexof ( signature ) ; if ( index == - num_ ) { throw new illegalargumentexception ( str_ + signedstr ) ; } string originalsignature = signedstr . substring ( index + signature . length ( ) ) ; string rawvalue = signedstr . substring ( num_ , index ) ; string currentsignature = getsignature ( rawvalue ) ; if ( log . isdebugenabled ( ) ) { log . debug ( str_ + rawvalue + str_ + currentsignature ) ; } if ( ! originalsignature . equals ( currentsignature ) ) { throw new illegalargumentexception ( str_ + originalsignature + str_ + currentsignature ) ; } return rawvalue ; }	Verify a signed string and extracts the original string.
private string getsignature ( string str ) { try { messagedigest md = messagedigest . getinstance ( sha_string ) ; md . update ( str . getbytes ( ) ) ; md . update ( secretbytes ) ; byte [ ] digest = md . digest ( ) ; return new base64 ( num_ ) . encodetostring ( digest ) ; } catch ( nosuchalgorithmexception ex ) { throw new runtimeexception ( str_ + sha_string + str_ + ex . getmessage ( ) , ex ) ; } }	Get the signature of the input string based on SHA digest algorithm.
void closeiterator ( leveldbiterator < ? > it ) throws ioexception { synchronized ( this . _db ) { db _db = this . _db . get ( ) ; if ( _db != null ) { it . close ( ) ; } } }	Closes the given iterator if the DB is still open.
leveldbtypeinfo gettypeinfo ( class < ? > type ) throws exception { leveldbtypeinfo ti = types . get ( type ) ; if ( ti == null ) { leveldbtypeinfo tmp = new leveldbtypeinfo ( this , type , gettypealias ( type ) ) ; ti = types . putifabsent ( type , tmp ) ; if ( ti == null ) { ti = tmp ; } } return ti ; }	Returns metadata about indices for the given type.
db db ( ) { db _db = this . _db . get ( ) ; if ( _db == null ) { throw new illegalstateexception ( str_ ) ; } return _db ; }	Try to avoid use-after close since that has the tendency of crashing the JVM.
public void registerapp ( string appid , string shufflesecret ) {	Register an application with its secret.Executors need to first authenticate themselves with the same secret beforefetching shuffle files written by other executors in this application.
public void registerapp ( string appid , bytebuffer shufflesecret ) { registerapp ( appid , javautils . bytestostring ( shufflesecret ) ) ; }	Register an application with its secret specified as a byte buffer.
public void free ( ) { if ( consumer != null ) { if ( array != null ) { consumer . freearray ( array ) ; } array = null ; } }	Free the memory used by pointer array.
public void insertrecord ( long recordpointer , long keyprefix , boolean prefixisnull ) { if ( ! hasspaceforanotherrecord ( ) ) { throw new illegalstateexception ( str_ ) ; } if ( prefixisnull && radixsortsupport != null ) {	Inserts a record to be sorted.
public static long nextpowerof2 ( long num ) { final long highbit = long . highestonebit ( num ) ; return ( highbit == num ) ? num : highbit << num_ ; }	Returns the next number greater or equal num that is power of 2.
public static boolean arrayequals ( object leftbase , long leftoffset , object rightbase , long rightoffset , final long length ) { int i = num_ ;	Optimized byte array equality check for byte arrays.
public bytebuffer tobytebuffer ( ) {	Serializes the 'type' byte followed by the message itself.
public sparklauncher setsparkhome ( string sparkhome ) { checknotnull ( sparkhome , str_ ) ; builder . childenv . put ( env_spark_home , sparkhome ) ; return this ; }	Set a custom Spark installation location for the application.
public void addspillifnotempty ( unsafesorteriterator spillreader ) throws ioexception { if ( spillreader . hasnext ( ) ) {	Add an UnsafeSorterIterator to this merger.
private void failremainingblocks ( string [ ] failedblockids , throwable e ) { for ( string blockid : failedblockids ) { try { listener . onblockfetchfailure ( blockid , e ) ; } catch ( exception e2 ) { logger . error ( str_ , e2 ) ; } } }	Invokes the "onBlockFetchFailure" callback for every listed block id.
private string getclientnamefromcookie ( cookie [ ] cookies ) {	Retrieves the client name from cookieString.
private string tocookiestr ( cookie [ ] cookies ) { string cookiestr = str_ ; for ( cookie c : cookies ) { cookiestr += c . getname ( ) + str_ + c . getvalue ( ) + str_ ; } return cookiestr ; }	Convert cookie array to human readable cookie string.
private cookie createcookie ( string str ) throws unsupportedencodingexception { if ( log . isdebugenabled ( ) ) { log . debug ( str_ + auth_cookie + str_ + str ) ; } cookie cookie = new cookie ( auth_cookie , str ) ; cookie . setmaxage ( cookiemaxage ) ; if ( cookiedomain != null ) { cookie . setdomain ( cookiedomain ) ; } if ( cookiepath != null ) { cookie . setpath ( cookiepath ) ; } cookie . setsecure ( iscookiesecure ) ; return cookie ; }	Generate a server side cookie given the cookie value as the input.
private static string gethttponlycookieheader ( cookie cookie ) { newcookie newcookie = new newcookie ( cookie . getname ( ) , cookie . getvalue ( ) , cookie . getpath ( ) , cookie . getdomain ( ) , cookie . getversion ( ) , cookie . getcomment ( ) , cookie . getmaxage ( ) , cookie . getsecure ( ) ) ; return newcookie + str_ ; }	Generate httponly cookie from HS2 cookie.
private string dokerberosauth ( httpservletrequest request ) throws httpauthenticationexception {	Do the GSS-API kerberos authentication.We already have a logged in subject in the form of serviceUGI,which GSS-API will extract information from.In case of a SPNego request we use the httpUGI,for the authenticating service tickets.
private string getauthheader ( httpservletrequest request , string authtype ) throws httpauthenticationexception { string authheader = request . getheader ( httpauthutils . authorization ) ;	Returns the base64 encoded auth header payload.
static string join ( string sep , string ... elements ) { stringbuilder sb = new stringbuilder ( ) ; for ( string e : elements ) { if ( e != null ) { if ( sb . length ( ) > num_ ) { sb . append ( sep ) ; } sb . append ( e ) ; } } return sb . tostring ( ) ; }	Joins a list of strings using the given separator.
static string firstnonemptyvalue ( string key , map < ? , ? > ... maps ) { for ( map < ? , ? > map : maps ) { string value = ( string ) map . get ( key ) ; if ( ! isempty ( value ) ) { return value ; } } return null ; }	Returns the first non-empty value mapped to the given key in the given maps, or null otherwise.
static string firstnonempty ( string ... candidates ) { for ( string s : candidates ) { if ( ! isempty ( s ) ) { return s ; } } return null ; }	Returns the first non-empty, non-null string in the given list, or null otherwise.
static void checknotnull ( object o , string arg ) { if ( o == null ) { throw new illegalargumentexception ( string . format ( str_ , arg ) ) ; } }	Throws IllegalArgumentException if the given object is null.
static void checkargument ( boolean check , string msg , object ... args ) { if ( ! check ) { throw new illegalargumentexception ( string . format ( msg , args ) ) ; } }	Throws IllegalArgumentException with the given message if the check is false.
static void checkstate ( boolean check , string msg , object ... args ) { if ( ! check ) { throw new illegalstateexception ( string . format ( msg , args ) ) ; } }	Throws IllegalStateException with the given message if the check is false.
static string findjarsdir ( string sparkhome , string scalaversion , boolean failifnotfound ) {	Find the location of the Spark jars dir, depending on whether we're looking at a buildor a distribution directory.
public void pointto ( object baseobject , long baseoffset , int sizeinbytes ) {	Update this UnsafeArrayData to point to different backing data.
private usergroupinformation getcurrentugi ( hiveconf opconfig ) throws hivesqlexception { try { return utils . getugi ( ) ; } catch ( exception e ) { throw new hivesqlexception ( str_ , e ) ; } }	Returns the current UGI on the stack.
private rowset preparefromrow ( list < object > rows , rowset rowset ) throws exception { for ( object row : rows ) { rowset . addrow ( ( object [ ] ) row ) ; } return rowset ; }	already encoded to thrift-able object in ThriftFormatter.
private hiveconf getconfigforoperation ( ) throws hivesqlexception { hiveconf sqloperationconf = getparentsession ( ) . gethiveconf ( ) ; if ( ! getconfoverlay ( ) . isempty ( ) || shouldrunasync ( ) ) {	If there are query specific settings to overlay, then create a copy of configThere are two cases we need to clone the session config that's being passed to hive driver1.
private synchronized boolean shouldretry ( throwable e ) { boolean isioexception = e instanceof ioexception || ( e . getcause ( ) != null && e . getcause ( ) instanceof ioexception ) ; boolean hasremainingretries = retrycount < maxretries ; return isioexception && hasremainingretries ; }	Returns true if we should retry due a block fetch failure.
@ override public unsaferow appendrow ( object kbase , long koff , int klen , object vbase , long voff , int vlen ) {	Append a key value pair.It copies data into the backing MemoryBlock.Returns an UnsafeRow pointing to the value if succeeds, otherwise returns null.
public static utf8string fromstring ( string str ) { return str == null ? null : frombytes ( str . getbytes ( standardcharsets . utf_8 ) ) ; }	Creates an UTF8String from String.
public static utf8string blankstring ( int length ) { byte [ ] spaces = new byte [ length ] ; arrays . fill ( spaces , ( byte ) str_ ) ; return frombytes ( spaces ) ; }	Creates an UTF8String that contains `length` spaces.
public void writetomemory ( object target , long targetoffset ) { platform . copymemory ( base , offset , target , targetoffset , numbytes ) ; }	Writes the content of this string into a memory address, identified by an object and an offset.The target memory address must already been allocated, and have enough space to hold all thebytes in this string.
public byte [ ] getbytes ( ) {	Returns the underline bytes, will be a copy of it if it's part of another array.
public boolean contains ( final utf8string substring ) { if ( substring . numbytes == num_ ) { return bool_ ; } byte first = substring . getbyte ( num_ ) ; for ( int i = num_ ; i <= numbytes - substring . numbytes ; i ++ ) { if ( getbyte ( i ) == first && matchat ( substring , i ) ) { return bool_ ; } } return bool_ ; }	Returns whether this contains `substring` or not.
public utf8string touppercase ( ) { if ( numbytes == num_ ) { return empty_utf8 ; } byte [ ] bytes = new byte [ numbytes ] ; bytes [ num_ ] = ( byte ) character . totitlecase ( getbyte ( num_ ) ) ; for ( int i = num_ ; i < numbytes ; i ++ ) { byte b = getbyte ( i ) ; if ( numbytesforfirstbyte ( b ) != num_ ) {	Returns the upper case of this string.
public utf8string tolowercase ( ) { if ( numbytes == num_ ) { return empty_utf8 ; } byte [ ] bytes = new byte [ numbytes ] ; bytes [ num_ ] = ( byte ) character . totitlecase ( getbyte ( num_ ) ) ; for ( int i = num_ ; i < numbytes ; i ++ ) { byte b = getbyte ( i ) ; if ( numbytesforfirstbyte ( b ) != num_ ) {	Returns the lower case of this string.
public utf8string totitlecase ( ) { if ( numbytes == num_ ) { return empty_utf8 ; } byte [ ] bytes = new byte [ numbytes ] ; for ( int i = num_ ; i < numbytes ; i ++ ) { byte b = getbyte ( i ) ; if ( i == num_ || getbyte ( i - num_ ) == str_ ) { if ( numbytesforfirstbyte ( b ) != num_ ) {	Returns the title case of this string, that could be used as title.
private utf8string copyutf8string ( int start , int end ) { int len = end - start + num_ ; byte [ ] newbytes = new byte [ len ] ; copymemory ( base , offset + start , newbytes , byte_array_offset , len ) ; return utf8string . frombytes ( newbytes ) ; }	Copy the bytes from the current UTF8String, and make a new UTF8String.
public utf8string trim ( utf8string trimstring ) { if ( trimstring != null ) { return trimleft ( trimstring ) . trimright ( trimstring ) ; } else { return null ; } }	Based on the given trim string, trim this string starting from both endsThis method searches for each character in the source string, removes the character if it isfound in the trim string, stops at the first not found.
public utf8string trimleft ( utf8string trimstring ) { if ( trimstring == null ) return null ;	Based on the given trim string, trim this string starting from left endThis method searches each character in the source string starting from the left end, removesthe character if it is in the trim string, stops at the first character which is not in thetrim string, returns the new string.
public utf8string trimright ( utf8string trimstring ) { if ( trimstring == null ) return null ; int charidx = num_ ;	Based on the given trim string, trim this string starting from right endThis method searches each character in the source string starting from the right end,removes the character if it is in the trim string, stops at the first character which is notin the trim string, returns the new string.
private int find ( utf8string str , int start ) { assert ( str . numbytes > num_ ) ; while ( start <= numbytes - str . numbytes ) { if ( bytearraymethods . arrayequals ( base , offset + start , str . base , str . offset , str . numbytes ) ) { return start ; } start += num_ ; } return - num_ ; }	Find the `str` from left to right.
public static utf8string concat ( utf8string ... inputs ) {	Concatenates input strings together into a single string.
public void registerwithshuffleserver ( string host , int port , string execid , executorshuffleinfo executorinfo ) throws ioexception , interruptedexception { checkinit ( ) ; try ( transportclient client = clientfactory . createunmanagedclient ( host , port ) ) { bytebuffer registermessage = new registerexecutor ( appid , execid , executorinfo ) . tobytebuffer ( ) ; client . sendrpcsync ( registermessage , registrationtimeoutms ) ; } }	Registers this executor with an external shuffle server.
@ override public long spill ( long size , memoryconsumer trigger ) throws ioexception { if ( trigger != this ) { if ( readingiterator != null ) { return readingiterator . spill ( ) ; } return num_ ;	Sort and spill the current records in response to memory pressure.
private long getmemoryusage ( ) { long totalpagesize = num_ ; for ( memoryblock page : allocatedpages ) { totalpagesize += page . size ( ) ; } return ( ( inmemsorter == null ) ? num_ : inmemsorter . getmemoryusage ( ) ) + totalpagesize ; }	Return the total memory usage of this sorter, including the data pages and the sorter's pointerarray.
private long freememory ( ) { updatepeakmemoryused ( ) ; long memoryfreed = num_ ; for ( memoryblock block : allocatedpages ) { memoryfreed += block . size ( ) ; freepage ( block ) ; } allocatedpages . clear ( ) ; currentpage = null ; pagecursor = num_ ; return memoryfreed ; }	Free this sorter's data pages.
private void deletespillfiles ( ) { for ( unsafesorterspillwriter spill : spillwriters ) { file file = spill . getfile ( ) ; if ( file != null && file . exists ( ) ) { if ( ! file . delete ( ) ) { logger . error ( str_ , file . getabsolutepath ( ) ) ; } } } }	Deletes any spill files created by this sorter.
private void growpointerarrayifnecessary ( ) throws ioexception { assert ( inmemsorter != null ) ; if ( ! inmemsorter . hasspaceforanotherrecord ( ) ) { long used = inmemsorter . getmemoryusage ( ) ; longarray array ; try {	Checks whether there is enough space to insert an additional record in to the sort pointerarray and grows the array if additional space is required.
private void acquirenewpageifnecessary ( int required ) { if ( currentpage == null || pagecursor + required > currentpage . getbaseoffset ( ) + currentpage . size ( ) ) {	Allocates more memory in order to insert an additional record.
public void insertrecord ( object recordbase , long recordoffset , int length , long prefix , boolean prefixisnull ) throws ioexception { assert ( inmemsorter != null ) ; if ( inmemsorter . numrecords ( ) >= numelementsforspillthreshold ) { logger . info ( str_ + numelementsforspillthreshold ) ; spill ( ) ; } growpointerarrayifnecessary ( ) ; int uaosize = unsafealignedoffset . getuaosize ( ) ;	Write a record to the sorter.
public void merge ( unsafeexternalsorter other ) throws ioexception { other . spill ( ) ; spillwriters . addall ( other . spillwriters ) ;	Merges another UnsafeExternalSorters into this one, the other one will be emptied.
public unsafesorteriterator getiterator ( int startindex ) throws ioexception { if ( spillwriters . isempty ( ) ) { assert ( inmemsorter != null ) ; unsafesorteriterator iter = inmemsorter . getsortediterator ( ) ; moveover ( iter , startindex ) ; return iter ; } else { linkedlist < unsafesorteriterator > queue = new linkedlist < > ( ) ; int i = num_ ; for ( unsafesorterspillwriter spillwriter : spillwriters ) { if ( i + spillwriter . recordsspilled ( ) > startindex ) { unsafesorteriterator iter = spillwriter . getreader ( serializermanager ) ; moveover ( iter , startindex - i ) ; queue . add ( iter ) ; } i += spillwriter . recordsspilled ( ) ; } if ( inmemsorter != null ) { unsafesorteriterator iter = inmemsorter . getsortediterator ( ) ; moveover ( iter , startindex - i ) ; queue . add ( iter ) ; } return new chainediterator ( queue ) ; } }	Returns an iterator starts from startIndex, which will return the rows in the order asinserted.It is the caller's responsibility to call `cleanupResources()`after consuming this iterator.TODO: support forced spilling.
void grow ( int neededsize ) { if ( neededsize < num_ ) { throw new illegalargumentexception ( str_ + neededsize + str_ ) ; } if ( neededsize > array_max - totalsize ( ) ) { throw new illegalargumentexception ( str_ + neededsize + str_ + str_ + array_max ) ; } final int length = totalsize ( ) + neededsize ; if ( buffer . length < length ) {	Grows the buffer by at least neededSize and points the row to the buffer.
public synchronized byte [ ] firsttoken ( ) { if ( saslclient != null && saslclient . hasinitialresponse ( ) ) { try { return saslclient . evaluatechallenge ( new byte [ num_ ] ) ; } catch ( saslexception e ) { throw throwables . propagate ( e ) ; } } else { return new byte [ num_ ] ; } }	Used to initiate SASL handshake with server.
public synchronized byte [ ] response ( byte [ ] token ) { try { return saslclient != null ? saslclient . evaluatechallenge ( token ) : new byte [ num_ ] ; } catch ( saslexception e ) { throw throwables . propagate ( e ) ; } }	Respond to server's SASL token.
@ override public synchronized void dispose ( ) { if ( saslclient != null ) { try { saslclient . dispose ( ) ; } catch ( saslexception e ) {	Disposes of any system resources or security-sensitive information theSaslClient might be using.
@ override public void getmetrics ( metricscollector collector , boolean all ) { metricsrecordbuilder metricsrecordbuilder = collector . addrecord ( str_ ) ; for ( map . entry < string , metric > entry : metricset . getmetrics ( ) . entryset ( ) ) { collectmetric ( metricsrecordbuilder , entry . getkey ( ) , entry . getvalue ( ) ) ; } }	Get metrics from the source.
public static properties tocryptoconf ( string prefix , iterable < map . entry < string , string > > conf ) { properties props = new properties ( ) ; for ( map . entry < string , string > e : conf ) { string key = e . getkey ( ) ; if ( key . startswith ( prefix ) ) { props . setproperty ( commons_crypto_config_prefix + key . substring ( prefix . length ( ) ) , e . getvalue ( ) ) ; } } return props ; }	Extract the commons-crypto configuration embedded in a list of config values.
public boolean [ ] getbooleans ( int rowid , int count ) { boolean [ ] res = new boolean [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getboolean ( rowid + i ) ; } return res ; }	Gets boolean type values from [rowId, rowId + count).
public byte [ ] getbytes ( int rowid , int count ) { byte [ ] res = new byte [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getbyte ( rowid + i ) ; } return res ; }	Gets byte type values from [rowId, rowId + count).
public short [ ] getshorts ( int rowid , int count ) { short [ ] res = new short [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getshort ( rowid + i ) ; } return res ; }	Gets short type values from [rowId, rowId + count).
public int [ ] getints ( int rowid , int count ) { int [ ] res = new int [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getint ( rowid + i ) ; } return res ; }	Gets int type values from [rowId, rowId + count).
public long [ ] getlongs ( int rowid , int count ) { long [ ] res = new long [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getlong ( rowid + i ) ; } return res ; }	Gets long type values from [rowId, rowId + count).
public float [ ] getfloats ( int rowid , int count ) { float [ ] res = new float [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getfloat ( rowid + i ) ; } return res ; }	Gets float type values from [rowId, rowId + count).
public double [ ] getdoubles ( int rowid , int count ) { double [ ] res = new double [ count ] ; for ( int i = num_ ; i < count ; i ++ ) { res [ i ] = getdouble ( rowid + i ) ; } return res ; }	Gets double type values from [rowId, rowId + count).
public tprocessorfactory getauthprocfactory ( thriftcliservice service ) throws loginexception { if ( authtypestr . equalsignorecase ( authtypes . kerberos . getauthname ( ) ) ) { return kerberossaslhelper . getkerberosprocessorfactory ( saslserver , service ) ; } else { return plainsaslhelper . getplainprocessorfactory ( service ) ; } }	Returns the thrift processor factory for HiveServer2 running in binary mode.
public static void loginfromkeytab ( hiveconf hiveconf ) throws ioexception { string principal = hiveconf . getvar ( confvars . hive_server2_kerberos_principal ) ; string keytabfile = hiveconf . getvar ( confvars . hive_server2_kerberos_keytab ) ; if ( principal . isempty ( ) || keytabfile . isempty ( ) ) { throw new ioexception ( str_ ) ; } else { usergroupinformation . loginuserfromkeytab ( securityutil . getserverprincipal ( principal , str_ ) , keytabfile ) ; } }	Perform kerberos login using the hadoop shim API if the configuration is available.
public static usergroupinformation loginfromspnegokeytabandreturnugi ( hiveconf hiveconf ) throws ioexception { string principal = hiveconf . getvar ( confvars . hive_server2_spnego_principal ) ; string keytabfile = hiveconf . getvar ( confvars . hive_server2_spnego_keytab ) ; if ( principal . isempty ( ) || keytabfile . isempty ( ) ) { throw new ioexception ( str_ ) ; } else { return usergroupinformation . loginuserfromkeytabandreturnugi ( securityutil . getserverprincipal ( principal , str_ ) , keytabfile ) ; } }	Perform SPNEGO login using the hadoop shim API if the configuration is available.
public string getdelegationtoken ( string owner , string renewer ) throws hivesqlexception { if ( saslserver == null ) { throw new hivesqlexception ( str_ , str_ ) ; } try { string tokenstr = saslserver . getdelegationtokenwithservice ( owner , renewer , hs2_client_token ) ; if ( tokenstr == null || tokenstr . isempty ( ) ) { throw new hivesqlexception ( str_ + owner , str_ ) ; } return tokenstr ; } catch ( ioexception e ) { throw new hivesqlexception ( str_ + owner , str_ , e ) ; } catch ( interruptedexception e ) { throw new hivesqlexception ( str_ , str_ , e ) ; } }	retrieve delegation token for the given user.
public void canceldelegationtoken ( string delegationtoken ) throws hivesqlexception { if ( saslserver == null ) { throw new hivesqlexception ( str_ , str_ ) ; } try { saslserver . canceldelegationtoken ( delegationtoken ) ; } catch ( ioexception e ) { throw new hivesqlexception ( str_ + delegationtoken , str_ , e ) ; } }	cancel given delegation token.
public static string patterntoregex ( string pattern ) { if ( pattern == null ) { return str_ ; } else { stringbuilder result = new stringbuilder ( pattern . length ( ) ) ; boolean escaped = bool_ ; for ( int i = num_ , len = pattern . length ( ) ; i < len ; i ++ ) { char c = pattern . charat ( i ) ; if ( escaped ) { if ( c != search_string_escape ) { escaped = bool_ ; } result . append ( c ) ; } else { if ( c == search_string_escape ) { escaped = bool_ ; continue ; } else if ( c == str_ ) { result . append ( str_ ) ; } else if ( c == str_ ) { result . append ( str_ ) ; } else { result . append ( character . tolowercase ( c ) ) ; } } } return result . tostring ( ) ; } }	Convert a SQL search pattern into an equivalent Java Regex.
public static void ensurecurrentstate ( service . state state , service . state expectedstate ) { if ( state != expectedstate ) { throw new illegalstateexception ( str_ + str_ + expectedstate + str_ + state ) ; } }	Verify that a service is in a given state.
public static void init ( service service , hiveconf configuration ) { service . state state = service . getservicestate ( ) ; ensurecurrentstate ( state , service . state . notinited ) ; service . init ( configuration ) ; }	Initialize a service.The service state is checked before the operation begins.This process is not thread safe.
public static void start ( service service ) { service . state state = service . getservicestate ( ) ; ensurecurrentstate ( state , service . state . inited ) ; service . start ( ) ; }	Start a service.The service state is checked before the operation begins.This process is not thread safe.
public static void deploy ( service service , hiveconf configuration ) { init ( service , configuration ) ; start ( service ) ; }	Initialize then start a service.The service state is checked before the operation begins.This process is not thread safe.
public static void stop ( service service ) { if ( service != null ) { service . state state = service . getservicestate ( ) ; if ( state == service . state . started ) { service . stop ( ) ; } } }	Stop a service.Do nothing if the service is null or not in a state in which it can be/needs to be stopped.The service state is checked before the operation begins.This process is not thread safe.
private boolean next ( ) throws ioexception { if ( valuesread >= endofpagevaluecount ) { if ( valuesread >= totalvaluecount ) {	Advances to the next value.
void readbatch ( int total , writablecolumnvector column ) throws ioexception { int rowid = num_ ; writablecolumnvector dictionaryids = null ; if ( dictionary != null ) {	Reads `total` values from this columnReader into column.
private schemacolumnconvertnotsupportedexception constructconvertnotsupportedexception ( columndescriptor descriptor , writablecolumnvector column ) { return new schemacolumnconvertnotsupportedexception ( arrays . tostring ( descriptor . getpath ( ) ) , descriptor . getprimitivetype ( ) . getprimitivetypename ( ) . tostring ( ) , column . datatype ( ) . catalogstring ( ) ) ; }	Helper function to construct exception for parquet schema mismatch.
public static eventloopgroup createeventloop ( iomode mode , int numthreads , string threadprefix ) { threadfactory threadfactory = createthreadfactory ( threadprefix ) ; switch ( mode ) { case nio : return new nioeventloopgroup ( numthreads , threadfactory ) ; case epoll : return new epolleventloopgroup ( numthreads , threadfactory ) ; default : throw new illegalargumentexception ( str_ + mode ) ; } }	Creates a Netty EventLoopGroup based on the IOMode.
public static class < ? extends serverchannel > getserverchannelclass ( iomode mode ) { switch ( mode ) { case nio : return nioserversocketchannel . class ; case epoll : return epollserversocketchannel . class ; default : throw new illegalargumentexception ( str_ + mode ) ; } }	Returns the correct ServerSocketChannel class based on IOMode.
public static string getremoteaddress ( channel channel ) { if ( channel != null && channel . remoteaddress ( ) != null ) { return channel . remoteaddress ( ) . tostring ( ) ; } return str_ ; }	Returns the remote address on the channel or "&lt;unknown remote&gt;" if none exists.
public static int defaultnumthreads ( int numusablecores ) { final int availablecores ; if ( numusablecores > num_ ) { availablecores = numusablecores ; } else { availablecores = runtime . getruntime ( ) . availableprocessors ( ) ; } return math . min ( availablecores , max_default_netty_threads ) ; }	Returns the default number of threads for both the Netty client and server thread pools.If numUsableCores is 0, we will use Runtime get an approximate number of available cores.
public static synchronized pooledbytebufallocator getsharedpooledbytebufallocator ( boolean allowdirectbufs , boolean allowcache ) { final int index = allowcache ? num_ : num_ ; if ( _sharedpooledbytebufallocator [ index ] == null ) { _sharedpooledbytebufallocator [ index ] = createpooledbytebufallocator ( allowdirectbufs , allowcache , defaultnumthreads ( num_ ) ) ; } return _sharedpooledbytebufallocator [ index ] ; }	Returns the lazily created shared pooled ByteBuf allocator for the specified allowCacheparameter value.
public static pooledbytebufallocator createpooledbytebufallocator ( boolean allowdirectbufs , boolean allowcache , int numcores ) { if ( numcores == num_ ) { numcores = runtime . getruntime ( ) . availableprocessors ( ) ; } return new pooledbytebufallocator ( allowdirectbufs && platformdependent . directbufferpreferred ( ) , math . min ( pooledbytebufallocator . defaultnumheaparena ( ) , numcores ) , math . min ( pooledbytebufallocator . defaultnumdirectarena ( ) , allowdirectbufs ? numcores : num_ ) , pooledbytebufallocator . defaultpagesize ( ) , pooledbytebufallocator . defaultmaxorder ( ) , allowcache ? pooledbytebufallocator . defaulttinycachesize ( ) : num_ , allowcache ? pooledbytebufallocator . defaultsmallcachesize ( ) : num_ , allowcache ? pooledbytebufallocator . defaultnormalcachesize ( ) : num_ , allowcache ? pooledbytebufallocator . defaultusecacheforallthreads ( ) : bool_ ) ; }	Create a pooled ByteBuf allocator but disables the thread-local cache.
public static string createcookietoken ( string clientusername ) { stringbuffer sb = new stringbuffer ( ) ; sb . append ( cookie_client_user_name ) . append ( cookie_key_value_separator ) . append ( clientusername ) . append ( cookie_attr_separator ) ; sb . append ( cookie_client_rand_number ) . append ( cookie_key_value_separator ) . append ( ( new random ( system . currenttimemillis ( ) ) ) . nextlong ( ) ) ; return sb . tostring ( ) ; }	Creates and returns a HS2 cookie token.
public static string getusernamefromcookietoken ( string tokenstr ) { map < string , string > map = splitcookietoken ( tokenstr ) ; if ( ! map . keyset ( ) . equals ( cookie_attributes ) ) { log . error ( str_ + tokenstr ) ; return null ; } return map . get ( cookie_client_user_name ) ; }	Parses a cookie token to retrieve client user name.
private static map < string , string > splitcookietoken ( string tokenstr ) { map < string , string > map = new hashmap < string , string > ( ) ; stringtokenizer st = new stringtokenizer ( tokenstr , cookie_attr_separator ) ; while ( st . hasmoretokens ( ) ) { string part = st . nexttoken ( ) ; int separator = part . indexof ( cookie_key_value_separator ) ; if ( separator == - num_ ) { log . error ( str_ + tokenstr ) ; return null ; } string key = part . substring ( num_ , separator ) ; string value = part . substring ( separator + num_ ) ; map . put ( key , value ) ; } return map ; }	Splits the cookie token into attributes pairs.
protected void validatefetchorientation ( fetchorientation orientation , enumset < fetchorientation > supportedorientations ) throws hivesqlexception { if ( ! supportedorientations . contains ( orientation ) ) { throw new hivesqlexception ( str_ + orientation . tostring ( ) + str_ , str_ ) ; } }	Verify if the given fetch orientation is part of the supported orientation types.
public static bytebuffer allocatedirectbuffer ( int size ) { try { if ( cleaner_create_method == null ) {	Allocate a DirectByteBuffer, potentially bypassing the JVM's MaxDirectMemorySize limit.
public static void writetomemory ( byte [ ] src , object target , long targetoffset ) { platform . copymemory ( src , platform . byte_array_offset , target , targetoffset , src . length ) ; }	Writes the content of a byte array into a memory address, identified by an object and anoffset.
public static offheapcolumnvector [ ] allocatecolumns ( int capacity , structfield [ ] fields ) { offheapcolumnvector [ ] vectors = new offheapcolumnvector [ fields . length ] ; for ( int i = num_ ; i < fields . length ; i ++ ) { vectors [ i ] = new offheapcolumnvector ( capacity , fields [ i ] . datatype ( ) ) ; } return vectors ; }	Allocates columns to store elements of each field off heap.Capacity is the initial capacity of the vector and it will grow as necessary.
@ override public int putbytearray ( int rowid , byte [ ] value , int offset , int length ) { int result = arraydata ( ) . appendbytes ( length , value , offset ) ; platform . putint ( null , lengthdata + num_ * rowid , length ) ; platform . putint ( null , offsetdata + num_ * rowid , result ) ; return result ; }	APIs dealing with ByteArrays.
@ override protected void reserveinternal ( int newcapacity ) { int oldcapacity = ( nulls == num_ ) ? num_ : capacity ; if ( isarray ( ) || type instanceof maptype ) { this . lengthdata = platform . reallocatememory ( lengthdata , oldcapacity * num_ , newcapacity * num_ ) ; this . offsetdata = platform . reallocatememory ( offsetdata , oldcapacity * num_ , newcapacity * num_ ) ; } else if ( type instanceof bytetype || type instanceof booleantype ) { this . data = platform . reallocatememory ( data , oldcapacity , newcapacity ) ; } else if ( type instanceof shorttype ) { this . data = platform . reallocatememory ( data , oldcapacity * num_ , newcapacity * num_ ) ; } else if ( type instanceof integertype || type instanceof floattype || type instanceof datetype || decimaltype . is32bitdecimaltype ( type ) ) { this . data = platform . reallocatememory ( data , oldcapacity * num_ , newcapacity * num_ ) ; } else if ( type instanceof longtype || type instanceof doubletype || decimaltype . is64bitdecimaltype ( type ) || type instanceof timestamptype ) { this . data = platform . reallocatememory ( data , oldcapacity * num_ , newcapacity * num_ ) ; } else if ( childcolumns != null ) {	Split out the slow path.
private void init ( int bitwidth ) { preconditions . checkargument ( bitwidth >= num_ && bitwidth <= num_ , str_ ) ; this . bitwidth = bitwidth ; this . byteswidth = bytesutils . paddedbytecountfrombits ( bitwidth ) ; this . packer = packer . little_endian . newbytepacker ( bitwidth ) ; }	Initializes the internal state for decoding ints of `bitWidth`.
@ override public void readintegers ( int total , writablecolumnvector c , int rowid ) { int left = total ; while ( left > num_ ) { if ( this . currentcount == num_ ) this . readnextgroup ( ) ; int n = math . min ( left , this . currentcount ) ; switch ( mode ) { case rle : c . putints ( rowid , n , currentvalue ) ; break ; case packed : c . putints ( rowid , n , currentbuffer , currentbufferidx ) ; currentbufferidx += n ; break ; } rowid += n ; left -= n ; currentcount -= n ; } }	Since this is only used to decode dictionary IDs, only decoding integers is supported.
private int readunsignedvarint ( ) throws ioexception { int value = num_ ; int shift = num_ ; int b ; do { b = in . read ( ) ; value |= ( b & num_ ) << shift ; shift += num_ ; } while ( ( b & num_ ) != num_ ) ; return value ; }	Reads the next varint encoded int.
private int readintlittleendianpaddedonbitwidth ( ) throws ioexception { switch ( byteswidth ) { case num_ : return num_ ; case num_ : return in . read ( ) ; case num_ : { int ch2 = in . read ( ) ; int ch1 = in . read ( ) ; return ( ch1 << num_ ) + ch2 ; } case num_ : { int ch3 = in . read ( ) ; int ch2 = in . read ( ) ; int ch1 = in . read ( ) ; return ( ch1 << num_ ) + ( ch2 << num_ ) + ( ch3 << num_ ) ; } case num_ : { return readintlittleendian ( ) ; } } throw new runtimeexception ( str_ ) ; }	Reads the next byteWidth little endian int.
private void readnextgroup ( ) { try { int header = readunsignedvarint ( ) ; this . mode = ( header & num_ ) == num_ ? mode . rle : mode . packed ; switch ( mode ) { case rle : this . currentcount = header > > > num_ ; this . currentvalue = readintlittleendianpaddedonbitwidth ( ) ; return ; case packed : int numgroups = header > > > num_ ; this . currentcount = numgroups * num_ ; if ( this . currentbuffer . length < this . currentcount ) { this . currentbuffer = new int [ this . currentcount ] ; } currentbufferidx = num_ ; int valueindex = num_ ; while ( valueindex < this . currentcount ) {	Reads the next group.
private void changestate ( service . state newstate ) { state = newstate ;	Change to a new state and notify all listeners.This is a private method that is only invoked from synchronized methods,which avoid having to clone the listener list.
public longarray allocatearray ( long size ) { long required = size * num_ ; memoryblock page = taskmemorymanager . allocatepage ( required , this ) ; if ( page == null || page . size ( ) < required ) { throwoom ( page , required ) ; } used += required ; return new longarray ( page ) ; }	Allocates a LongArray of `size`.
protected memoryblock allocatepage ( long required ) { memoryblock page = taskmemorymanager . allocatepage ( math . max ( pagesize , required ) , this ) ; if ( page == null || page . size ( ) < required ) { throwoom ( page , required ) ; } used += page . size ( ) ; return page ; }	Allocate a memory block with at least `required` bytes.
@ override public long transferto ( final writablebytechannel target , final long position ) throws ioexception { preconditions . checkargument ( position == totalbytestransferred , str_ ) ;	This code is more complicated than you would think because we might require multipletransferTo invocations in order to transfer a single MessageWithHeader to avoid busy waiting.The contract is that the caller will ensure position is properly set to the total numberof bytes transferred so far (i.e.
public void pointto ( object baseobject , long baseoffset , int sizeinbytes ) { assert numfields >= num_ : str_ + numfields + str_ ; assert sizeinbytes % num_ == num_ : str_ + sizeinbytes + str_ ; this . baseobject = baseobject ; this . baseoffset = baseoffset ; this . sizeinbytes = sizeinbytes ; }	Update this UnsafeRow to point to different backing data.
@ override public void setdecimal ( int ordinal , decimal value , int precision ) { assertindexisvalid ( ordinal ) ; if ( precision <= decimal . max_long_digits ( ) ) {	Updates the decimal column.Note: In order to support update a decimal with precision > 18, CAN NOT callsetNullAt() for this column.
@ override public unsaferow copy ( ) { unsaferow rowcopy = new unsaferow ( numfields ) ; final byte [ ] rowdatacopy = new byte [ sizeinbytes ] ; platform . copymemory ( baseobject , baseoffset , rowdatacopy , platform . byte_array_offset , sizeinbytes ) ; rowcopy . pointto ( rowdatacopy , platform . byte_array_offset , sizeinbytes ) ; return rowcopy ; }	Copies this row, returning a self-contained UnsafeRow that stores its data in an internalbyte array rather than referencing data stored in a data page.
public static unsaferow createfrombytearray ( int numbytes , int numfields ) { final unsaferow row = new unsaferow ( numfields ) ; row . pointto ( new byte [ numbytes ] , numbytes ) ; return row ; }	Creates an empty UnsafeRow from a byte array with specified numBytes and numFields.The returned row is invalid until we call copyFrom on it.
public void writetostream ( outputstream out , byte [ ] writebuffer ) throws ioexception { if ( baseobject instanceof byte [ ] ) { int offsetinbytearray = ( int ) ( baseoffset - platform . byte_array_offset ) ; out . write ( ( byte [ ] ) baseobject , offsetinbytearray , sizeinbytes ) ; }	Write this UnsafeRow's underlying bytes to the given OutputStream.
@ override public void dobootstrap ( transportclient client , channel channel ) { sparksaslclient saslclient = new sparksaslclient ( appid , secretkeyholder , conf . saslencryption ( ) ) ; try { byte [ ] payload = saslclient . firsttoken ( ) ; while ( ! saslclient . iscomplete ( ) ) { saslmessage msg = new saslmessage ( appid , payload ) ; bytebuf buf = unpooled . buffer ( msg . encodedlength ( ) + ( int ) msg . body ( ) . size ( ) ) ; msg . encode ( buf ) ; buf . writebytes ( msg . body ( ) . niobytebuffer ( ) ) ; bytebuffer response = client . sendrpcsync ( buf . niobuffer ( ) , conf . authrttimeoutms ( ) ) ; payload = saslclient . response ( javautils . buffertoarray ( response ) ) ; } client . setclientid ( appid ) ; if ( conf . saslencryption ( ) ) { if ( ! sparksaslserver . qop_auth_conf . equals ( saslclient . getnegotiatedproperty ( sasl . qop ) ) ) { throw new runtimeexception ( new saslexception ( str_ ) ) ; } saslencryption . addtochannel ( channel , saslclient , conf . maxsaslencryptedblocksize ( ) ) ; saslclient = null ; logger . debug ( str_ , client ) ; } } catch ( ioexception ioe ) { throw new runtimeexception ( ioe ) ; } finally { if ( saslclient != null ) { try {	Performs SASL authentication by sending a token, and then proceeding with the SASLchallenge-response tokens until we either successfully authenticate or throw an exceptiondue to mismatch.
sessionhandle getsessionhandle ( topensessionreq req , topensessionresp res ) throws hivesqlexception , loginexception , ioexception { string username = getusername ( req ) ; string ipaddress = getipaddress ( ) ; tprotocolversion protocol = getminversion ( cliservice . server_version , req . getclient_protocol ( ) ) ; sessionhandle sessionhandle ; if ( cliservice . gethiveconf ( ) . getboolvar ( confvars . hive_server2_enable_doas ) && ( username != null ) ) { string delegationtokenstr = getdelegationtoken ( username ) ; sessionhandle = cliservice . opensessionwithimpersonation ( protocol , username , req . getpassword ( ) , ipaddress , req . getconfiguration ( ) , delegationtokenstr ) ; } else { sessionhandle = cliservice . opensession ( protocol , username , req . getpassword ( ) , ipaddress , req . getconfiguration ( ) ) ; } res . setserverprotocolversion ( protocol ) ; return sessionhandle ; }	Create a session handle.
private string getproxyuser ( string realuser , map < string , string > sessionconf , string ipaddress ) throws hivesqlexception { string proxyuser = null ;	If the proxy user name is provided then check privileges to substitute the user.
public boolean getboolean ( string key , boolean defaultvalue ) { string value = get ( key ) ;	Returns the boolean value to which the specified key is mapped,or defaultValue if there is no mapping for the key.
public double getdouble ( string key , double defaultvalue ) { string value = get ( key ) ; return value == null ? defaultvalue : double . parsedouble ( value ) ; }	Returns the double value to which the specified key is mapped,or defaultValue if there is no mapping for the key.
boolean set ( long index ) { if ( ! get ( index ) ) { data [ ( int ) ( index > > > num_ ) ] |= ( num_ << index ) ; bitcount ++ ; return bool_ ; } return bool_ ; }	Returns true if the bit changed value.
void putall ( bitarray array ) { assert data . length == array . data . length : str_ ; long bitcount = num_ ; for ( int i = num_ ; i < data . length ; i ++ ) { data [ i ] |= array . data [ i ] ; bitcount += long . bitcount ( data [ i ] ) ; } this . bitcount = bitcount ; }	Combines the two BitArrays using bitwise OR.
public rpchandler dobootstrap ( channel channel , rpchandler rpchandler ) { return new saslrpchandler ( conf , channel , rpchandler , secretkeyholder ) ; }	Wrap the given application handler in a SaslRpcHandler that will handle the initial SASLnegotiation.
public shuffleindexrecord getindex ( int reduceid ) { long offset = offsets . get ( reduceid ) ; long nextoffset = offsets . get ( reduceid + num_ ) ; return new shuffleindexrecord ( offset , nextoffset - offset ) ; }	Get index offset for a particular reducer.
private void grow ( int neededsize ) { if ( neededsize > array_max - totalsize ( ) ) { throw new unsupportedoperationexception ( str_ + neededsize + str_ + str_ + array_max ) ; } final int length = totalsize ( ) + neededsize ; if ( buffer . length < length ) { int newlength = length < array_max / num_ ? length * num_ : array_max ; final byte [ ] tmp = new byte [ newlength ] ; platform . copymemory ( buffer , platform . byte_array_offset , tmp , platform . byte_array_offset , totalsize ( ) ) ; buffer = tmp ; } }	Grows the buffer by at least `neededSize`.
public int connectiontimeoutms ( ) { long defaultnetworktimeouts = javautils . timestringassec ( conf . get ( str_ , str_ ) ) ; long defaulttimeoutms = javautils . timestringassec ( conf . get ( spark_network_io_connectiontimeout_key , defaultnetworktimeouts + str_ ) ) * num_ ; return ( int ) defaulttimeoutms ; }	Connect timeout in milliseconds.
list < string > buildjavacommand ( string extraclasspath ) throws ioexception { list < string > cmd = new arraylist < > ( ) ; string [ ] candidatejavahomes = new string [ ] { javahome , childenv . get ( str_ ) , system . getenv ( str_ ) , system . getproperty ( str_ ) } ; for ( string javahome : candidatejavahomes ) { if ( javahome != null ) { cmd . add ( join ( file . separator , javahome , str_ , str_ ) ) ; break ; } }	Builds a list of arguments to run java.This method finds the java executable to use and appends JVM-specific options for running aclass with Spark in the classpath.
private void addtoclasspath ( set < string > cp , string entries ) { if ( isempty ( entries ) ) { return ; } string [ ] split = entries . split ( pattern . quote ( file . pathseparator ) ) ; for ( string entry : split ) { if ( ! isempty ( entry ) ) { if ( new file ( entry ) . isdirectory ( ) && ! entry . endswith ( file . separator ) ) { entry += file . separator ; } cp . add ( entry ) ; } } }	Adds entries to the classpath.
private properties loadpropertiesfile ( ) throws ioexception { properties props = new properties ( ) ; file propsfile ; if ( propertiesfile != null ) { propsfile = new file ( propertiesfile ) ; checkargument ( propsfile . isfile ( ) , str_ , propertiesfile ) ; } else { propsfile = new file ( getconfdir ( ) , default_properties_file ) ; } if ( propsfile . isfile ( ) ) { try ( inputstreamreader isr = new inputstreamreader ( new fileinputstream ( propsfile ) , standardcharsets . utf_8 ) ) { props . load ( isr ) ; for ( map . entry < object , object > e : props . entryset ( ) ) { e . setvalue ( e . getvalue ( ) . tostring ( ) . trim ( ) ) ; } } } return props ; }	Loads the configuration file for the application, if it exists.
@ override public void initialize ( inputsplit inputsplit , taskattemptcontext taskattemptcontext ) throws ioexception { filesplit filesplit = ( filesplit ) inputsplit ; configuration conf = taskattemptcontext . getconfiguration ( ) ; reader reader = orcfile . createreader ( filesplit . getpath ( ) , orcfile . readeroptions ( conf ) . maxlength ( orcconf . max_file_length . getlong ( conf ) ) . filesystem ( filesplit . getpath ( ) . getfilesystem ( conf ) ) ) ; reader . options options = orcinputformat . buildoptions ( conf , reader , filesplit . getstart ( ) , filesplit . getlength ( ) ) ; recordreader = reader . rows ( options ) ; }	Initialize ORC file reader and batch record reader.Please note that `initBatch` is needed to be called after this.
public void initbatch ( typedescription orcschema , structfield [ ] requiredfields , int [ ] requesteddatacolids , int [ ] requestedpartitioncolids , internalrow partitionvalues ) { wrap = new vectorizedrowbatchwrap ( orcschema . createrowbatch ( capacity ) ) ; assert ( ! wrap . batch ( ) . selectedinuse ) ;	Initialize columnar batch by setting required schema and partition information.With this information, this creates ColumnarBatch with the full schema.
private boolean nextbatch ( ) throws ioexception { recordreader . nextbatch ( wrap . batch ( ) ) ; int batchsize = wrap . batch ( ) . size ; if ( batchsize == num_ ) { return bool_ ; } columnarbatch . setnumrows ( batchsize ) ; for ( int i = num_ ; i < requiredfields . length ; i ++ ) { if ( requesteddatacolids [ i ] != - num_ ) { ( ( orccolumnvector ) orcvectorwrappers [ i ] ) . setbatchsize ( batchsize ) ; } } return bool_ ; }	Return true if there exists more data in the next batch.
public static long parsesecondnano ( string secondnano ) throws illegalargumentexception { string [ ] parts = secondnano . split ( str_ ) ; if ( parts . length == num_ ) { return tolongwithrange ( str_ , parts [ num_ ] , long . min_value / micros_per_second , long . max_value / micros_per_second ) * micros_per_second ; } else if ( parts . length == num_ ) { long seconds = parts [ num_ ] . equals ( str_ ) ? num_ : tolongwithrange ( str_ , parts [ num_ ] , long . min_value / micros_per_second , long . max_value / micros_per_second ) ; long nanos = tolongwithrange ( str_ , parts [ num_ ] , num_ , num_ ) ; return seconds * micros_per_second + nanos / num_ ; } else { throw new illegalargumentexception ( str_ ) ; } }	Parse second_nano string in ss.nnnnnnnnn format to microseconds.
public void addtochannel ( channel ch ) throws ioexception { ch . pipeline ( ) . addfirst ( encryption_handler_name , new encryptionhandler ( this ) ) . addfirst ( decryption_handler_name , new decryptionhandler ( this ) ) ; }	Add handlers to channel.
@ override public void close ( ) {	Close all connections in the connection pool, and shutdown the worker thread pool.
@ override public int write ( bytebuffer src ) { int totransfer = math . min ( src . remaining ( ) , data . length - offset ) ; src . get ( data , offset , totransfer ) ; offset += totransfer ; return totransfer ; }	Reads from the given buffer into the internal byte array.
protected synchronized void release ( boolean useraccess ) { sessionstate . detachsession ( ) ; if ( threadwithgarbagecleanup . currentthread ( ) instanceof threadwithgarbagecleanup ) { threadwithgarbagecleanup currentthread = ( threadwithgarbagecleanup ) threadwithgarbagecleanup . currentthread ( ) ; currentthread . cachethreadlocalrawstore ( ) ; } if ( useraccess ) { lastaccesstime = system . currenttimemillis ( ) ; } if ( ophandleset . isempty ( ) ) { lastidletime = system . currenttimemillis ( ) ; } else { lastidletime = num_ ; } }	1. We'll remove the ThreadLocal SessionState as this thread might now serveother requests.2. We'll cache the ThreadLocal RawStore object for this background thread for an orderly cleanupwhen this thread is garbage collected later.
private string getuserfromtoken ( hiveauthfactory authfactory , string tokenstr ) throws hivesqlexception { return authfactory . getuserfromtoken ( tokenstr ) ; }	extract the real user from the given token string.
public void setsessionugi ( string owner ) throws hivesqlexception { if ( owner == null ) { throw new hivesqlexception ( str_ ) ; } if ( usergroupinformation . issecurityenabled ( ) ) { try { sessionugi = usergroupinformation . createproxyuser ( owner , usergroupinformation . getloginuser ( ) ) ; } catch ( ioexception e ) { throw new hivesqlexception ( str_ , e ) ; } } else { sessionugi = usergroupinformation . createremoteuser ( owner ) ; } }	setup appropriate UGI for the session.
@ override public void close ( ) throws hivesqlexception { try { acquire ( bool_ ) ; canceldelegationtoken ( ) ; } finally { try { super . close ( ) ; } finally { try { filesystem . closeallforugi ( sessionugi ) ; } catch ( ioexception ioe ) { throw new hivesqlexception ( str_ + sessionugi , ioe ) ; } } } }	Close the file systems for the session and remove it from the FileSystem cache.Cancel the session's delegation token and close the metastore connection.
private void setdelegationtoken ( string delegationtokenstr ) throws hivesqlexception { this . delegationtokenstr = delegationtokenstr ; if ( delegationtokenstr != null ) { gethiveconf ( ) . set ( str_ , hs2token ) ; try { utils . settokenstr ( sessionugi , delegationtokenstr , hs2token ) ; } catch ( ioexception e ) { throw new hivesqlexception ( str_ , e ) ; } } }	Enable delegation token for the sessionsave the token string and set the token.signature in hive conf.
private void canceldelegationtoken ( ) throws hivesqlexception { if ( delegationtokenstr != null ) { try { hive . get ( gethiveconf ( ) ) . canceldelegationtoken ( delegationtokenstr ) ; } catch ( hiveexception e ) { throw new hivesqlexception ( str_ , e ) ; }	If the session has a delegation token obtained from the metastore, then cancel it.
public void releaseexecutionmemory ( long size , memoryconsumer consumer ) { logger . debug ( str_ , taskattemptid , utils . bytestostring ( size ) , consumer ) ; memorymanager . releaseexecutionmemory ( size , taskattemptid , consumer . getmode ( ) ) ; }	Release N bytes of execution memory for a MemoryConsumer.
public void showmemoryusage ( ) { logger . info ( str_ + taskattemptid ) ; synchronized ( this ) { long memoryaccountedforbyconsumers = num_ ; for ( memoryconsumer c : consumers ) { long totalmemusage = c . getused ( ) ; memoryaccountedforbyconsumers += totalmemusage ; if ( totalmemusage > num_ ) { logger . info ( str_ + c + str_ + utils . bytestostring ( totalmemusage ) ) ; } } long memorynotaccountedfor = memorymanager . getexecutionmemoryusagefortask ( taskattemptid ) - memoryaccountedforbyconsumers ; logger . info ( str_ , memorynotaccountedfor , taskattemptid ) ; logger . info ( str_ , memorymanager . executionmemoryused ( ) , memorymanager . storagememoryused ( ) ) ; } }	Dump the memory usage of all consumers.
public memoryblock allocatepage ( long size , memoryconsumer consumer ) { assert ( consumer != null ) ; assert ( consumer . getmode ( ) == tungstenmemorymode ) ; if ( size > maximum_page_size_bytes ) { throw new toolargepageexception ( size ) ; } long acquired = acquireexecutionmemory ( size , consumer ) ; if ( acquired <= num_ ) { return null ; } final int pagenumber ; synchronized ( this ) { pagenumber = allocatedpages . nextclearbit ( num_ ) ; if ( pagenumber >= page_table_size ) { releaseexecutionmemory ( acquired , consumer ) ; throw new illegalstateexception ( str_ + page_table_size + str_ ) ; } allocatedpages . set ( pagenumber ) ; } memoryblock page = null ; try { page = memorymanager . tungstenmemoryallocator ( ) . allocate ( acquired ) ; } catch ( outofmemoryerror e ) { logger . warn ( str_ , acquired ) ;	Allocate a block of memory that will be tracked in the MemoryManager's page table; this isintended for allocating large blocks of Tungsten memory that will be shared between operators.Returns `null` if there was not enough memory to allocate the page.
public long encodepagenumberandoffset ( memoryblock page , long offsetinpage ) { if ( tungstenmemorymode == memorymode . off_heap ) {	Given a memory page and offset within that page, encode this address into a 64-bit long.This address will remain valid as long as the corresponding page has not been freed.
public long cleanupallallocatedmemory ( ) { synchronized ( this ) { for ( memoryconsumer c : consumers ) { if ( c != null && c . getused ( ) > num_ ) {	Clean up all allocated memory and pages.
public synchronized byte [ ] response ( byte [ ] token ) { try { return saslserver != null ? saslserver . evaluateresponse ( token ) : new byte [ num_ ] ; } catch ( saslexception e ) { throw throwables . propagate ( e ) ; } }	Used to respond to server SASL tokens.
@ override public synchronized void dispose ( ) { if ( saslserver != null ) { try { saslserver . dispose ( ) ; } catch ( saslexception e ) {	Disposes of any system resources or security-sensitive information theSaslServer might be using.
private static string getbase64encodedstring ( string str ) { bytebuf bytebuf = null ; bytebuf encodedbytebuf = null ; try { bytebuf = unpooled . wrappedbuffer ( str . getbytes ( standardcharsets . utf_8 ) ) ; encodedbytebuf = base64 . encode ( bytebuf ) ; return encodedbytebuf . tostring ( standardcharsets . utf_8 ) ; } finally {	Return a Base64-encoded string.
public static long packpointer ( long recordpointer , int partitionid ) { assert ( partitionid <= maximum_partition_id ) ;	Pack a record address and partition id into a single word.
synchronized void dispose ( ) { if ( ! isdisposed ( ) ) {	Mark the handle as disposed, and set it as LOST in case the current state is not final.This method should be called only when there's a reasonable expectation that the communicationwith the child application is not needed anymore, either because the code managing the handlehas said so, or because the child application is finished.
public synchronized string getdelegationtokenfrommetastore ( string owner ) throws hivesqlexception , unsupportedoperationexception , loginexception , ioexception { if ( ! hiveconf . getboolvar ( hiveconf . confvars . metastore_use_thrift_sasl ) || ! hiveconf . getboolvar ( hiveconf . confvars . hive_server2_enable_doas ) ) { throw new unsupportedoperationexception ( str_ ) ; } try { hive . closecurrent ( ) ; return hive . get ( hiveconf ) . getdelegationtoken ( owner , owner ) ; } catch ( hiveexception e ) { if ( e . getcause ( ) instanceof unsupportedoperationexception ) { throw ( unsupportedoperationexception ) e . getcause ( ) ; } else { throw new hivesqlexception ( str_ , e ) ; } } }	obtain delegation token for the give user from metastore.
public integer getdecimaldigits ( ) { switch ( this . type ) { case boolean_type : case tinyint_type : case smallint_type : case int_type : case bigint_type : return num_ ; case float_type : return num_ ; case double_type : return num_ ; case decimal_type : return typequalifiers . getscale ( ) ; case timestamp_type : return num_ ; default : return null ; } }	The number of fractional digits for this type.Null is returned for data types where this is not applicable.
public static < out > iterator < out > collect ( datastream < out > stream ) throws ioexception { typeserializer < out > serializer = stream . gettype ( ) . createserializer ( stream . getexecutionenvironment ( ) . getconfig ( ) ) ; socketstreamiterator < out > iter = new socketstreamiterator < out > ( serializer ) ;	Returns an iterator to iterate over the elements of the DataStream.
public commandline getcommandline ( options commandlineoptions ) throws exception { final list < string > args = new arraylist < > ( ) ; properties . asmap ( ) . foreach ( ( k , v ) -> {	Parses the given command line options from the deployment properties.
public static deploymententry merge ( deploymententry deployment1 , deploymententry deployment2 ) { final map < string , string > mergedproperties = new hashmap < > ( deployment1 . asmap ( ) ) ; mergedproperties . putall ( deployment2 . asmap ( ) ) ; final descriptorproperties properties = new descriptorproperties ( bool_ ) ; properties . putproperties ( mergedproperties ) ; return new deploymententry ( properties ) ; }	Merges two deployments entries.
public static rpcservice createrpcservice ( final configuration configuration , final highavailabilityservices haservices ) throws exception { checknotnull ( configuration ) ; checknotnull ( haservices ) ; final string taskmanageraddress = determinetaskmanagerbindaddress ( configuration , haservices ) ; final string portrangedefinition = configuration . getstring ( taskmanageroptions . rpc_port ) ; return akkarpcserviceutils . createrpcservice ( taskmanageraddress , portrangedefinition , configuration ) ; }	Create a RPC service for the task manager.
long refreshandgettotal ( ) { long total = num_ ; for ( resultsubpartition part : partition . getallpartitions ( ) ) { total += part . unsynchronizedgetnumberofqueuedbuffers ( ) ; } return total ; }	Iterates over all sub-partitions and collects the total number of queued buffers in abest-effort way.
int refreshandgetmin ( ) { int min = integer . max_value ; resultsubpartition [ ] allpartitions = partition . getallpartitions ( ) ; if ( allpartitions . length == num_ ) {	Iterates over all sub-partitions and collects the minimum number of queued buffers in asub-partition in a best-effort way.
int refreshandgetmax ( ) { int max = num_ ; for ( resultsubpartition part : partition . getallpartitions ( ) ) { int size = part . unsynchronizedgetnumberofqueuedbuffers ( ) ; max = math . max ( max , size ) ; } return max ; }	Iterates over all sub-partitions and collects the maximum number of queued buffers in asub-partition in a best-effort way.
float refreshandgetavg ( ) { long total = num_ ; resultsubpartition [ ] allpartitions = partition . getallpartitions ( ) ; for ( resultsubpartition part : allpartitions ) { int size = part . unsynchronizedgetnumberofqueuedbuffers ( ) ; total += size ; } return total / ( float ) allpartitions . length ; }	Iterates over all sub-partitions and collects the average number of queued buffers in asub-partition in a best-effort way.
public synchronized url addfile ( file localfile , string remotefile ) throws ioexception , malformedurlexception { return addpath ( new path ( localfile . touri ( ) ) , new path ( remotefile ) ) ; }	Adds a file to the artifact server.
public synchronized url addpath ( path path , path remotefile ) throws ioexception , malformedurlexception { if ( paths . containskey ( remotefile ) ) { throw new illegalargumentexception ( str_ ) ; } if ( remotefile . isabsolute ( ) ) { throw new illegalargumentexception ( str_ ) ; } url fileurl = new url ( baseurl , remotefile . tostring ( ) ) ; router . addany ( fileurl . getpath ( ) , new virtualfileserverhandler ( path ) ) ; paths . put ( remotefile , fileurl ) ; return fileurl ; }	Adds a path to the artifact server.
public synchronized void stop ( ) throws exception { if ( this . serverchannel != null ) { this . serverchannel . close ( ) . awaituninterruptibly ( ) ; this . serverchannel = null ; } if ( bootstrap != null ) { if ( bootstrap . group ( ) != null ) { bootstrap . group ( ) . shutdowngracefully ( ) ; } bootstrap = null ; } }	Stops the artifact server.
private object invokerpc ( method method , object [ ] args ) throws exception { string methodname = method . getname ( ) ; class < ? > [ ] parametertypes = method . getparametertypes ( ) ; annotation [ ] [ ] parameterannotations = method . getparameterannotations ( ) ; time futuretimeout = extractrpctimeout ( parameterannotations , args , timeout ) ; final rpcinvocation rpcinvocation = createrpcinvocationmessage ( methodname , parametertypes , args ) ; class < ? > returntype = method . getreturntype ( ) ; final object result ; if ( objects . equals ( returntype , void . type ) ) { tell ( rpcinvocation ) ; result = null ; } else {	Invokes a RPC method by sending the RPC invocation details to the rpc endpoint.
protected rpcinvocation createrpcinvocationmessage ( final string methodname , final class < ? > [ ] parametertypes , final object [ ] args ) throws ioexception { final rpcinvocation rpcinvocation ; if ( islocal ) { rpcinvocation = new localrpcinvocation ( methodname , parametertypes , args ) ; } else { try { remoterpcinvocation remoterpcinvocation = new remoterpcinvocation ( methodname , parametertypes , args ) ; if ( remoterpcinvocation . getsize ( ) > maximumframesize ) { throw new ioexception ( str_ ) ; } else { rpcinvocation = remoterpcinvocation ; } } catch ( ioexception e ) { log . warn ( str_ , e ) ; throw e ; } } return rpcinvocation ; }	Create the RpcInvocation message for the given RPC.
protected completablefuture < ? > ask ( object message , time timeout ) { return futureutils . tojava ( patterns . ask ( rpcendpoint , message , timeout . tomilliseconds ( ) ) ) ; }	Sends the message to the RPC endpoint and returns a future containingits response.
public result unregisterreference ( sharedstateregistrykey registrationkey ) { preconditions . checknotnull ( registrationkey ) ; final result result ; final streamstatehandle scheduledstatedeletion ; sharedstateregistry . sharedstateentry entry ; synchronized ( registeredstates ) { entry = registeredstates . get ( registrationkey ) ; preconditions . checkstate ( entry != null , str_ ) ; entry . decreasereferencecount ( ) ;	Releases one reference to the given shared state in the registry.
public void registerall ( iterable < ? extends compositestatehandle > statehandles ) { if ( statehandles == null ) { return ; } synchronized ( registeredstates ) { for ( compositestatehandle statehandle : statehandles ) { statehandle . registersharedstates ( this ) ; } } }	Register given shared states in the registry.
public boolean setcancellerhandle ( scheduledfuture < ? > cancellerhandle ) { synchronized ( lock ) { if ( this . cancellerhandle == null ) { if ( ! discarded ) { this . cancellerhandle = cancellerhandle ; return bool_ ; } else { return bool_ ; } } else { throw new illegalstateexception ( str_ ) ; } } }	Sets the handle for the canceller to this pending checkpoint.
public taskacknowledgeresult acknowledgetask ( executionattemptid executionattemptid , taskstatesnapshot operatorsubtaskstates , checkpointmetrics metrics ) { synchronized ( lock ) { if ( discarded ) { return taskacknowledgeresult . discarded ; } final executionvertex vertex = notyetacknowledgedtasks . remove ( executionattemptid ) ; if ( vertex == null ) { if ( acknowledgedtasks . contains ( executionattemptid ) ) { return taskacknowledgeresult . duplicate ; } else { return taskacknowledgeresult . unknown ; } } else { acknowledgedtasks . add ( executionattemptid ) ; } list < operatorid > operatorids = vertex . getjobvertex ( ) . getoperatorids ( ) ; int subtaskindex = vertex . getparallelsubtaskindex ( ) ; long acktimestamp = system . currenttimemillis ( ) ; long statesize = num_ ; if ( operatorsubtaskstates != null ) { for ( operatorid operatorid : operatorids ) { operatorsubtaskstate operatorsubtaskstate = operatorsubtaskstates . getsubtaskstatebyoperatorid ( operatorid ) ;	Acknowledges the task with the given execution attempt id and the given subtask state.
public void abort ( checkpointfailurereason reason , throwable cause ) { try { checkpointexception exception = new checkpointexception ( reason , cause ) ; oncompletionpromise . completeexceptionally ( exception ) ; reportfailedcheckpoint ( exception ) ; assertabortsubsumedforced ( reason ) ; } finally { dispose ( bool_ ) ; } }	Aborts a checkpoint with reason and cause.
private void reportfailedcheckpoint ( exception cause ) {	Reports a failed checkpoint with the given optional cause.
static typeinformation schematotypeinfo ( typedescription schema ) { switch ( schema . getcategory ( ) ) { case boolean : return basictypeinfo . boolean_type_info ; case byte : return basictypeinfo . byte_type_info ; case short : return basictypeinfo . short_type_info ; case int : return basictypeinfo . int_type_info ; case long : return basictypeinfo . long_type_info ; case float : return basictypeinfo . float_type_info ; case double : return basictypeinfo . double_type_info ; case decimal : return basictypeinfo . big_dec_type_info ; case string : case char : case varchar : return basictypeinfo . string_type_info ; case date : return sqltimetypeinfo . date ; case timestamp : return sqltimetypeinfo . timestamp ; case binary : return primitivearraytypeinfo . byte_primitive_array_type_info ; case struct : list < typedescription > fieldschemas = schema . getchildren ( ) ; typeinformation [ ] fieldtypes = new typeinformation [ fieldschemas . size ( ) ] ; for ( int i = num_ ; i < fieldschemas . size ( ) ; i ++ ) { fieldtypes [ i ] = schematotypeinfo ( fieldschemas . get ( i ) ) ; } string [ ] fieldnames = schema . getfieldnames ( ) . toarray ( new string [ ] { } ) ; return new rowtypeinfo ( fieldtypes , fieldnames ) ; case list : typedescription elementschema = schema . getchildren ( ) . get ( num_ ) ; typeinformation < ? > elementtype = schematotypeinfo ( elementschema ) ;	Converts an ORC schema to a Flink TypeInformation.
static int fillrows ( row [ ] rows , typedescription schema , vectorizedrowbatch batch , int [ ] selectedfields ) { int rowstoread = math . min ( ( int ) batch . count ( ) , rows . length ) ; list < typedescription > fieldtypes = schema . getchildren ( ) ;	Fills an ORC batch into an array of Row.
private static void fillcolumnwithrepeatingvalue ( object [ ] vals , int fieldidx , object repeatingvalue , int childcount ) { if ( fieldidx == - num_ ) {	Sets a repeating value to all objects or row fields of the passed vals array.
public static string lpad ( string base , int len , string pad ) { if ( len < num_ || str_ . equals ( pad ) ) { return null ; } else if ( len == num_ ) { return str_ ; } char [ ] data = new char [ len ] ; char [ ] basechars = base . tochararray ( ) ; char [ ] padchars = pad . tochararray ( ) ;	Returns the string str left-padded with the string pad to a length of len characters.If str is longer than len, the return value is shortened to len characters.
public static string rpad ( string base , int len , string pad ) { if ( len < num_ || str_ . equals ( pad ) ) { return null ; } else if ( len == num_ ) { return str_ ; } char [ ] data = new char [ len ] ; char [ ] basechars = base . tochararray ( ) ; char [ ] padchars = pad . tochararray ( ) ; int pos = num_ ;	Returns the string str right-padded with the string pad to a length of len characters.If str is longer than len, the return value is shortened to len characters.
public static string replace ( string str , string oldstr , string replacement ) { return str . replace ( oldstr , replacement ) ; }	Replaces all the old strings with the replacement string.
public static string regexpreplace ( string str , string regex , string replacement ) { if ( regex . isempty ( ) ) { return str ; } try {	Returns a string resulting from replacing all substrings that match the regularexpression with replacement.
public static string regexpextract ( string str , string regex , int extractindex ) { if ( extractindex < num_ ) { return null ; } try { matcher m = regexp_pattern_cache . get ( regex ) . matcher ( str ) ; if ( m . find ( ) ) { matchresult mr = m . tomatchresult ( ) ; return mr . group ( extractindex ) ; } return null ; } catch ( exception e ) { log . error ( string . format ( str_ , str , regex , extractindex ) , e ) ; return null ; } }	Returns a string extracted with a specified regular expression and a regexmatch group index.
public static string hash ( string algorithm , string str , string charsetname ) { try { byte [ ] digest = messagedigest . getinstance ( algorithm ) . digest ( strtobyteswithcharset ( str , charsetname ) ) ; return encodingutils . hex ( digest ) ; } catch ( nosuchalgorithmexception e ) { throw new illegalargumentexception ( str_ + algorithm , e ) ; } }	Calculate the hash value of a given string.
public static string parseurl ( string urlstr , string parttoextract ) { url url ; try { url = url_cache . get ( urlstr ) ; } catch ( exception e ) { log . error ( str_ + urlstr , e ) ; return null ; } if ( str_ . equals ( parttoextract ) ) { return url . gethost ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getpath ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getquery ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getref ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getprotocol ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getfile ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getauthority ( ) ; } if ( str_ . equals ( parttoextract ) ) { return url . getuserinfo ( ) ; } return null ; }	Parse url and return various components of the URL.If accept any null arguments, return null.
public static string parseurl ( string urlstr , string parttoextract , string key ) { if ( ! str_ . equals ( parttoextract ) ) { return null ; } string query = parseurl ( urlstr , parttoextract ) ; if ( query == null ) { return null ; } pattern p = pattern . compile ( str_ + pattern . quote ( key ) + str_ ) ; matcher m = p . matcher ( query ) ; if ( m . find ( ) ) { return m . group ( num_ ) ; } return null ; }	Parse url and return various parameter of the URL.If accept any null arguments, return null.
public static string hex ( string x ) { return encodingutils . hex ( x . getbytes ( standardcharsets . utf_8 ) ) . touppercase ( ) ; }	Returns the hex string of a string argument.
public static map < string , string > strtomap ( string text , string listdelimiter , string keyvaluedelimiter ) { if ( stringutils . isempty ( text ) ) { return empty_map ; } string [ ] keyvaluepairs = text . split ( listdelimiter ) ; map < string , string > ret = new hashmap < > ( keyvaluepairs . length ) ; for ( string keyvaluepair : keyvaluepairs ) { string [ ] keyvalue = keyvaluepair . split ( keyvaluedelimiter , num_ ) ; if ( keyvalue . length < num_ ) { ret . put ( keyvaluepair , null ) ; } else { ret . put ( keyvalue [ num_ ] , keyvalue [ num_ ] ) ; } } return ret ; }	Creates a map by parsing text.
@ nonnull public consumerrecords < byte [ ] , byte [ ] > pollnext ( ) throws exception { synchronized ( lock ) { while ( next == null && error == null ) { lock . wait ( ) ; } consumerrecords < byte [ ] , byte [ ] > n = next ; if ( n != null ) { next = null ; lock . notifyall ( ) ; return n ; } else { exceptionutils . rethrowexception ( error , error . getmessage ( ) ) ;	Polls the next element from the Handover, possibly blocking until the next element isavailable.
public boolean iscompatiblewith ( deweynumber other ) { if ( length ( ) > other . length ( ) ) {	Checks whether this dewey number is compatible to the other dewey number.
public deweynumber increase ( int times ) { int [ ] newdeweynumber = arrays . copyof ( deweynumber , deweynumber . length ) ; newdeweynumber [ deweynumber . length - num_ ] += times ; return new deweynumber ( newdeweynumber ) ; }	Creates a new dewey number from this such that its last digit is increased by the suppliednumber.
public deweynumber addstage ( ) { int [ ] newdeweynumber = arrays . copyof ( deweynumber , deweynumber . length + num_ ) ; return new deweynumber ( newdeweynumber ) ; }	Creates a new dewey number from this such that a 0 is appended as new last digit.
public static deweynumber fromstring ( final string deweynumberstring ) { string [ ] splits = deweynumberstring . split ( str_ ) ; if ( splits . length == num_ ) { return new deweynumber ( integer . parseint ( deweynumberstring ) ) ; } else { int [ ] deweynumber = new int [ splits . length ] ; for ( int i = num_ ; i < splits . length ; i ++ ) { deweynumber [ i ] = integer . parseint ( splits [ i ] ) ; } return new deweynumber ( deweynumber ) ; } }	Creates a dewey number from a string representation.
public completablefuture < jobdetailsinfo > getjobdetails ( jobid jobid ) { final jobdetailsheaders detailsheaders = jobdetailsheaders . getinstance ( ) ; final jobmessageparameters params = new jobmessageparameters ( ) ; params . jobpathparameter . resolve ( jobid ) ; return sendrequest ( detailsheaders , params ) ; }	Requests the job details.
jobsubmissionresult finalizeexecute ( ) throws programinvocationexception { return client . run ( detachedplan , jarfilestoattach , classpathstoattach , usercodeclassloader , savepointsettings ) ; }	Finishes this Context Environment's execution by explicitly running the plan constructed.
public static void discardstatefuture ( runnablefuture < ? extends stateobject > statefuture ) throws exception { if ( null != statefuture ) { if ( ! statefuture . cancel ( bool_ ) ) { try {	Discards the given state future by first trying to cancel it.
public static < t > t find ( class < t > factoryclass , descriptor descriptor ) { preconditions . checknotnull ( descriptor ) ; return findinternal ( factoryclass , descriptor . toproperties ( ) , optional . empty ( ) ) ; }	Finds a table factory of the given class and descriptor.
public static < t > t find ( class < t > factoryclass , descriptor descriptor , classloader classloader ) { preconditions . checknotnull ( descriptor ) ; preconditions . checknotnull ( classloader ) ; return findinternal ( factoryclass , descriptor . toproperties ( ) , optional . of ( classloader ) ) ; }	Finds a table factory of the given class, descriptor, and classloader.
public static < t > t find ( class < t > factoryclass , map < string , string > propertymap ) { return findinternal ( factoryclass , propertymap , optional . empty ( ) ) ; }	Finds a table factory of the given class and property map.
private static list < tablefactory > discoverfactories ( optional < classloader > classloader ) { try { list < tablefactory > result = new linkedlist < > ( ) ; if ( classloader . ispresent ( ) ) { serviceloader . load ( tablefactory . class , classloader . get ( ) ) . iterator ( ) . foreachremaining ( result :: add ) ; } else { defaultloader . iterator ( ) . foreachremaining ( result :: add ) ; } return result ; } catch ( serviceconfigurationerror e ) { log . error ( str_ , e ) ; throw new tableexception ( str_ , e ) ; } }	Searches for factories using Java service providers.
private static < t > list < tablefactory > filterbyfactoryclass ( class < t > factoryclass , map < string , string > properties , list < tablefactory > foundfactories ) { list < tablefactory > classfactories = foundfactories . stream ( ) . filter ( p -> factoryclass . isassignablefrom ( p . getclass ( ) ) ) . collect ( collectors . tolist ( ) ) ; if ( classfactories . isempty ( ) ) { throw new nomatchingtablefactoryexception ( string . format ( str_ , factoryclass . getcanonicalname ( ) ) , factoryclass , foundfactories , properties ) ; } return classfactories ; }	Filters factories with matching context by factory class.
private static < t > list < tablefactory > filterbycontext ( class < t > factoryclass , map < string , string > properties , list < tablefactory > foundfactories , list < tablefactory > classfactories ) { list < tablefactory > matchingfactories = classfactories . stream ( ) . filter ( factory -> { map < string , string > requestedcontext = normalizecontext ( factory ) ; map < string , string > plaincontext = new hashmap < > ( requestedcontext ) ;	Filters for factories with matching context.
private static map < string , string > normalizecontext ( tablefactory factory ) { map < string , string > requiredcontext = factory . requiredcontext ( ) ; if ( requiredcontext == null ) { throw new tableexception ( string . format ( str_ , factory . getclass ( ) . getname ( ) ) ) ; } return requiredcontext . keyset ( ) . stream ( ) . collect ( collectors . tomap ( key -> key . tolowercase ( ) , key -> requiredcontext . get ( key ) ) ) ; }	Prepares the properties of a context to be used for match operations.
private static < t > t filterbysupportedproperties ( class < t > factoryclass , map < string , string > properties , list < tablefactory > foundfactories , list < tablefactory > classfactories ) { final list < string > plaingivenkeys = new linkedlist < > ( ) ; properties . keyset ( ) . foreach ( k -> {	Filters the matching class factories by supported properties.
private static tuple2 < list < string > , list < string > > normalizesupportedproperties ( tablefactory factory ) { list < string > supportedproperties = factory . supportedproperties ( ) ; if ( supportedproperties == null ) { throw new tableexception ( string . format ( str_ , factory . getclass ( ) . getname ( ) ) ) ; } list < string > supportedkeys = supportedproperties . stream ( ) . map ( p -> p . tolowercase ( ) ) . collect ( collectors . tolist ( ) ) ;	Prepares the supported properties of a factory to be used for match operations.
@ override public void insertorreplacerecord ( t record ) throws ioexception { if ( closed ) { return ; } t match = prober . getmatchfor ( record , reuse ) ; if ( match == null ) { prober . insertafternomatch ( record ) ; } else { prober . updatematch ( record ) ; } }	Searches the hash table for a record with the given key.If it is found, then it is overridden with the specified record.Otherwise, the specified record is inserted.
private void rebuild ( long newnumbucketsegments ) throws ioexception {	Same as above, but the number of bucket segments of the new table can be specified.
public static stringifiedaccumulatorresult [ ] stringifyaccumulatorresults ( map < string , optionalfailure < accumulator < ? , ? > > > accs ) { if ( accs == null || accs . isempty ( ) ) { return new stringifiedaccumulatorresult [ num_ ] ; } else { stringifiedaccumulatorresult [ ] results = new stringifiedaccumulatorresult [ accs . size ( ) ] ; int i = num_ ; for ( map . entry < string , optionalfailure < accumulator < ? , ? > > > entry : accs . entryset ( ) ) { results [ i ++ ] = stringifyaccumulatorresult ( entry . getkey ( ) , entry . getvalue ( ) ) ; } return results ; } }	Flatten a map of accumulator names to Accumulator instances into an array of StringifiedAccumulatorResult values.
public boolean ismatching ( resourceprofile required ) { if ( required == unknown ) { return bool_ ; } if ( cpucores >= required . getcpucores ( ) && heapmemoryinmb >= required . getheapmemoryinmb ( ) && directmemoryinmb >= required . getdirectmemoryinmb ( ) && nativememoryinmb >= required . getnativememoryinmb ( ) && networkmemoryinmb >= required . getnetworkmemoryinmb ( ) ) { for ( map . entry < string , resource > resource : required . extendedresources . entryset ( ) ) { if ( ! extendedresources . containskey ( resource . getkey ( ) ) || ! extendedresources . get ( resource . getkey ( ) ) . getresourceaggregatetype ( ) . equals ( resource . getvalue ( ) . getresourceaggregatetype ( ) ) || extendedresources . get ( resource . getkey ( ) ) . getvalue ( ) < resource . getvalue ( ) . getvalue ( ) ) { return bool_ ; } } return bool_ ; } return bool_ ; }	Check whether required resource profile can be matched.
private void grow ( int mincapacity ) { int oldcapacity = segment . size ( ) ; int newcapacity = oldcapacity + ( oldcapacity > > num_ ) ; if ( newcapacity - mincapacity < num_ ) { newcapacity = mincapacity ; } segment = memorysegmentfactory . wrap ( arrays . copyof ( segment . getarray ( ) , newcapacity ) ) ; aftergrow ( ) ; }	Increases the capacity to ensure that it can hold at least theminimum capacity argument.
public void releasepartitions ( collection < resultpartitionid > partitionids ) { for ( resultpartitionid partitionid : partitionids ) { resultpartitionmanager . releasepartition ( partitionid , null ) ; } }	Batch release intermediate result partitions.
public static restartstrategyconfiguration fixeddelayrestart ( int restartattempts , long delaybetweenattempts ) { return fixeddelayrestart ( restartattempts , time . of ( delaybetweenattempts , timeunit . milliseconds ) ) ; }	Generates a FixedDelayRestartStrategyConfiguration.
public static failureraterestartstrategyconfiguration failureraterestart ( int failurerate , time failureinterval , time delayinterval ) { return new failureraterestartstrategyconfiguration ( failurerate , failureinterval , delayinterval ) ; }	Generates a FailureRateRestartStrategyConfiguration.
private < t > void deployjob ( executioncontext < t > context , jobgraph jobgraph , result < t > result ) {	Deploys a job. Depending on the deployment creates a new job cluster. It saves the cluster id inthe result and blocks until job completion.
void storeinitialhashtable ( ) throws ioexception { if ( spilled ) { return ;	This method stores the initial hash table's contents on disk if hash join needs the memoryfor further partition processing.The initial hash table is rebuild before a new secondary input is opened.For the sake of simplicity we iterate over all in-memory elements and store them in one file.The file is hashed into memory upon opening a new probe input.
protected boolean checknextindexoffset ( ) { if ( this . currentsortindexoffset > this . lastindexentryoffset ) { memorysegment returnsegment = nextmemorysegment ( ) ; if ( returnsegment != null ) { this . currentsortindexsegment = returnsegment ; this . sortindex . add ( this . currentsortindexsegment ) ; this . currentsortindexoffset = num_ ; } else { return bool_ ; } } return bool_ ; }	check if we need request next index memory.
protected void writeindexandnormalizedkey ( baserow record , long curroffset ) {	Write of index and normalizedKey.
@ suppresswarnings ( { str_ , str_ } ) public void collectbuffer ( collector < out > c , int buffersize ) throws ioexception { filebuffer . position ( num_ ) ; while ( filebuffer . position ( ) < buffersize ) { c . collect ( deserializer . deserialize ( ) ) ; } }	Reads a buffer of the given size from the memory-mapped file, and collects all records contained.
@ deprecated public void init ( map < eventid , lockable < v > > events , map < nodeid , lockable < sharedbuffernode > > entries ) throws exception { eventsbuffer . putall ( events ) ; this . entries . putall ( entries ) ; map < long , integer > maxids = events . keyset ( ) . stream ( ) . collect ( collectors . tomap ( eventid :: gettimestamp , eventid :: getid , math :: max ) ) ; eventscount . putall ( maxids ) ; }	Initializes underlying state with given map of events and entries.
public boolean isempty ( ) throws exception { return iterables . isempty ( eventsbuffercache . keyset ( ) ) && iterables . isempty ( eventsbuffer . keys ( ) ) ; }	Checks if there is no elements in the buffer.
void upsertevent ( eventid eventid , lockable < v > event ) { this . eventsbuffercache . put ( eventid , event ) ; }	Inserts or updates an event in cache.
void upsertentry ( nodeid nodeid , lockable < sharedbuffernode > entry ) { this . entrycache . put ( nodeid , entry ) ; }	Inserts or updates a shareBufferNode in cache.
void removeevent ( eventid eventid ) throws exception { this . eventsbuffercache . remove ( eventid ) ; this . eventsbuffer . remove ( eventid ) ; }	Removes an event from cache and state.
void removeentry ( nodeid nodeid ) throws exception { this . entrycache . remove ( nodeid ) ; this . entries . remove ( nodeid ) ; }	Removes a ShareBufferNode from cache and state.
lockable < sharedbuffernode > getentry ( nodeid nodeid ) { return entrycache . computeifabsent ( nodeid , id -> { try { return entries . get ( id ) ; } catch ( exception ex ) { throw new wrappingruntimeexception ( ex ) ; } } ) ; }	It always returns node either from state or cache.
lockable < v > getevent ( eventid eventid ) { return eventsbuffercache . computeifabsent ( eventid , id -> { try { return eventsbuffer . get ( id ) ; } catch ( exception ex ) { throw new wrappingruntimeexception ( ex ) ; } } ) ; }	It always returns event either from state or cache.
void flushcache ( ) throws exception { if ( ! entrycache . isempty ( ) ) { entries . putall ( entrycache ) ; entrycache . clear ( ) ; } if ( ! eventsbuffercache . isempty ( ) ) { eventsbuffer . putall ( eventsbuffercache ) ; eventsbuffercache . clear ( ) ; } }	Flush the event and node from cache to state.
public timewindow cover ( timewindow other ) { return new timewindow ( math . min ( start , other . start ) , math . max ( end , other . end ) ) ; }	Returns the minimal window covers both this window and the given window.
@ override protected void computeoperatorspecificdefaultestimates ( datastatistics statistics ) { this . estimatednumrecords = getpredecessornode ( ) . getestimatednumrecords ( ) ; this . estimatedoutputsize = getpredecessornode ( ) . getestimatedoutputsize ( ) ; }	Computes the estimated outputs for the data sink.
public list < kafkatopicpartition > discoverpartitions ( ) throws wakeupexception , closedexception { if ( ! closed && ! wakeup ) { try { list < kafkatopicpartition > newdiscoveredpartitions ;	Execute a partition discovery attempt for this subtask.This method lets the partition discoverer update what partitions it has discovered so far.
public void shutdown ( jobstatus jobstatus ) throws exception { synchronized ( lock ) { if ( ! shutdown ) { shutdown = bool_ ; log . info ( str_ , job ) ; periodicscheduling = bool_ ; triggerrequestqueued = bool_ ;	Shuts down the checkpoint coordinator.
public completablefuture < completedcheckpoint > triggersavepoint ( final long timestamp , @ nullable final string targetlocation ) { final checkpointproperties properties = checkpointproperties . forsavepoint ( ) ; return triggersavepointinternal ( timestamp , properties , bool_ , targetlocation ) ; }	Triggers a savepoint with the given savepoint directory as a target.
public completablefuture < completedcheckpoint > triggersynchronoussavepoint ( final long timestamp , final boolean advancetoendofeventtime , @ nullable final string targetlocation ) { final checkpointproperties properties = checkpointproperties . forsyncsavepoint ( ) ; return triggersavepointinternal ( timestamp , properties , advancetoendofeventtime , targetlocation ) ; }	Triggers a synchronous savepoint with the given savepoint directory as a target.
public boolean triggercheckpoint ( long timestamp , boolean isperiodic ) { try { triggercheckpoint ( timestamp , checkpointproperties , null , isperiodic , bool_ ) ; return bool_ ; } catch ( checkpointexception e ) { return bool_ ; } }	Triggers a new standard checkpoint and uses the given timestamp as the checkpointtimestamp.
private void completependingcheckpoint ( pendingcheckpoint pendingcheckpoint ) throws checkpointexception { final long checkpointid = pendingcheckpoint . getcheckpointid ( ) ; final completedcheckpoint completedcheckpoint ;	Try to complete the given pending checkpoint.
public void failunacknowledgedpendingcheckpointsfor ( executionattemptid executionattemptid , throwable cause ) { synchronized ( lock ) { iterator < pendingcheckpoint > pendingcheckpointiterator = pendingcheckpoints . values ( ) . iterator ( ) ; while ( pendingcheckpointiterator . hasnext ( ) ) { final pendingcheckpoint pendingcheckpoint = pendingcheckpointiterator . next ( ) ; if ( ! pendingcheckpoint . isacknowledgedby ( executionattemptid ) ) { pendingcheckpointiterator . remove ( ) ; discardcheckpoint ( pendingcheckpoint , cause ) ; } } } }	Fails all pending checkpoints which have not been acknowledged by the given executionattempt id.
private void triggerqueuedrequests ( ) { if ( triggerrequestqueued ) { triggerrequestqueued = bool_ ;	Triggers the queued request, if there is one. NOTE: The caller of this method must hold the lock when invoking the method!.
public boolean restoresavepoint ( string savepointpointer , boolean allownonrestored , map < jobvertexid , executionjobvertex > tasks , classloader userclassloader ) throws exception { preconditions . checknotnull ( savepointpointer , str_ ) ; log . info ( str_ , job , savepointpointer , ( allownonrestored ? str_ : str_ ) ) ; final completedcheckpointstoragelocation checkpointlocation = checkpointstorage . resolvecheckpoint ( savepointpointer ) ;	Restore the state with given savepoint.
public void abortpendingcheckpoints ( checkpointexception exception ) { synchronized ( lock ) { for ( pendingcheckpoint p : pendingcheckpoints . values ( ) ) { p . abort ( exception . getcheckpointfailurereason ( ) ) ; } pendingcheckpoints . clear ( ) ; } }	Aborts all the pending checkpoints due to en exception.
private void discardsubtaskstate ( final jobid jobid , final executionattemptid executionattemptid , final long checkpointid , final taskstatesnapshot subtaskstate ) { if ( subtaskstate != null ) { executor . execute ( new runnable ( ) { @ override public void run ( ) { try { subtaskstate . discardstate ( ) ; } catch ( throwable t2 ) { log . warn ( str_ + str_ , checkpointid , executionattemptid , jobid , t2 ) ; } } } ) ; } }	Discards the given state object asynchronously belonging to the given job, execution attemptid and checkpoint id.
public resourcespec merge ( resourcespec other ) { resourcespec target = new resourcespec ( math . max ( this . cpucores , other . cpucores ) , this . heapmemoryinmb + other . heapmemoryinmb , this . directmemoryinmb + other . directmemoryinmb , this . nativememoryinmb + other . nativememoryinmb , this . statesizeinmb + other . statesizeinmb ) ; target . extendedresources . putall ( extendedresources ) ; for ( resource resource : other . extendedresources . values ( ) ) { target . extendedresources . merge ( resource . getname ( ) , resource , ( v1 , v2 ) -> v1 . merge ( v2 ) ) ; } return target ; }	Used by system internally to merge the other resources of chained operatorswhen generating the job graph or merge the resource consumed by state backend.
public boolean isvalid ( ) { if ( this . cpucores >= num_ && this . heapmemoryinmb >= num_ && this . directmemoryinmb >= num_ && this . nativememoryinmb >= num_ && this . statesizeinmb >= num_ ) { for ( resource resource : extendedresources . values ( ) ) { if ( resource . getvalue ( ) < num_ ) { return bool_ ; } } return bool_ ; } else { return bool_ ; } }	Check whether all the field values are valid.
public void adduniquefield ( fieldset uniquefieldset ) { if ( this . uniquefields == null ) { this . uniquefields = new hashset < fieldset > ( ) ; } this . uniquefields . add ( uniquefieldset ) ; }	Adds a FieldSet to be unique.
public void adduniquefield ( int field ) { if ( this . uniquefields == null ) { this . uniquefields = new hashset < fieldset > ( ) ; } this . uniquefields . add ( new fieldset ( field ) ) ; }	Adds a field as having only unique values.
public void adduniquefields ( set < fieldset > uniquefieldsets ) { if ( this . uniquefields == null ) { this . uniquefields = new hashset < fieldset > ( ) ; } this . uniquefields . addall ( uniquefieldsets ) ; }	Adds multiple FieldSets to be unique.
public static descriptorproperties normalizeyaml ( map < string , object > yamlmap ) { final map < string , string > normalized = new hashmap < > ( ) ; yamlmap . foreach ( ( k , v ) -> normalizeyamlobject ( normalized , k , v ) ) ; final descriptorproperties properties = new descriptorproperties ( bool_ ) ; properties . putproperties ( normalized ) ; return properties ; }	Normalizes key-value properties from Yaml in the normalized format of the Table API.
void retriggersubpartitionrequest ( timer timer , final int subpartitionindex ) { synchronized ( requestlock ) { checkstate ( subpartitionview == null , str_ ) ; timer . schedule ( new timertask ( ) { @ override public void run ( ) { try { requestsubpartition ( subpartitionindex ) ; } catch ( throwable t ) { seterror ( t ) ; } } } , getcurrentbackoff ( ) ) ; } }	Retriggers a subpartition request.
public static string formataddress ( int address ) { int b1 = ( address > > > num_ ) & num_ ; int b2 = ( address > > > num_ ) & num_ ; int b3 = ( address > > > num_ ) & num_ ; int b4 = address & num_ ; return str_ + b1 + str_ + b2 + str_ + b3 + str_ + b4 ; }	Util method to create a string representation of a 32 bit integer representingan IPv4 address.
public pythondatastream from_collection ( iterator < object > iter ) throws exception { return new pythondatastream < > ( env . addsource ( new pythoniteratorfunction ( iter ) , typeextractor . getforclass ( object . class ) ) . map ( new adaptermap < > ( ) ) ) ; }	Creates a python data stream from the given iterator.
public void seek ( long block , long recordinblock ) throws ioexception { list < blockmetadata > blockmetadata = reader . getrowgroups ( ) ; if ( block == - num_ && recordinblock == - num_ ) {	Moves the reading position to the given block and seeks to and reads the given record.
public tuple2 < long , long > getcurrentreadposition ( ) {	Returns the current read position in the split, i.e., the current block andthe number of records that were returned from that block.
public boolean reachend ( ) throws ioexception {	Checks if the record reader returned all records.This method must be called before a record can be returned.
private boolean readnextrecord ( ) throws ioexception { boolean recordfound = bool_ ; while ( ! recordfound ) {	Reads the next record.
public void shutdown ( ) { synchronized ( globallock ) { for ( instance i : allinstances ) { i . removeslotlistener ( ) ; i . cancelandreleaseallslots ( ) ; } allinstances . clear ( ) ; allinstancesbyhost . clear ( ) ; instanceswithavailableresources . clear ( ) ; taskqueue . clear ( ) ; } }	Shuts the scheduler down.
public string format ( description description ) { for ( blockelement blockelement : description . getblocks ( ) ) { blockelement . format ( this ) ; } return finalizeformatting ( ) ; }	Formats the description into a String using format specific tags.
@ override protected shardconsumer createshardconsumer ( integer subscribedshardstateindex , streamshardhandle handle , sequencenumber lastseqnum , shardmetricsreporter shardmetricsreporter ) { return new shardconsumer ( this , subscribedshardstateindex , handle , lastseqnum , dynamodbstreamsproxy . create ( getconsumerconfiguration ( ) ) , shardmetricsreporter ) ; }	Create a new DynamoDB streams shard consumer.
private void opencli ( sessioncontext context , executor executor ) { cliclient cli = null ; try { cli = new cliclient ( context , executor ) ;	Opens the CLI client for executing SQL statements.
public static amazonkinesis createkinesisclient ( properties configprops , clientconfiguration awsclientconfig ) {	Creates an Amazon Kinesis Client.
private static awscredentialsprovider getcredentialsprovider ( final properties configprops , final string configprefix ) { credentialprovider credentialprovidertype ; if ( ! configprops . containskey ( configprefix ) ) { if ( configprops . containskey ( awsconfigconstants . accesskeyid ( configprefix ) ) && configprops . containskey ( awsconfigconstants . secretkey ( configprefix ) ) ) {	If the provider is ASSUME_ROLE, then the credentials for assuming this role are determinedrecursively.
public static boolean isvalidregion ( string region ) { try { regions . fromname ( region . tolowercase ( ) ) ; } catch ( illegalargumentexception e ) { return bool_ ; } return bool_ ; }	Checks whether or not a region ID is valid.
public static long nextpoweroftwo ( long x ) { if ( x == num_ ) { return num_ ; } else { -- x ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; return ( x | x > > num_ ) + num_ ; } }	Return the least power of two greater than or equal to the specified value.
public static int maxfill ( int n , float f ) { return math . min ( ( int ) math . ceil ( ( double ) ( ( float ) n * f ) ) , n - num_ ) ; }	Returns the maximum number of entries that can be filled before rehashing.
@ override public void recover ( ) throws exception { log . info ( str_ ) ;	Gets the latest checkpoint from ZooKeeper and removes all others.
@ override public void addcheckpoint ( final completedcheckpoint checkpoint ) throws exception { checknotnull ( checkpoint , str_ ) ; final string path = checkpointidtopath ( checkpoint . getcheckpointid ( ) ) ;	Synchronously writes the new checkpoints to ZooKeeper and asynchronously removes older ones.
public static long pathtocheckpointid ( string path ) { try { string numberstring ;	Converts a path to the checkpoint id.
private void checkandpropagateasyncerror ( ) throws exception { if ( thrownexception != null ) { string errormessages = str_ ; if ( thrownexception instanceof userrecordfailedexception ) { list < attempt > attempts = ( ( userrecordfailedexception ) thrownexception ) . getresult ( ) . getattempts ( ) ; for ( attempt attempt : attempts ) { if ( attempt . geterrormessage ( ) != null ) { errormessages += attempt . geterrormessage ( ) + str_ ; } } } if ( failonerror ) { throw new runtimeexception ( str_ + errormessages , thrownexception ) ; } else { log . warn ( str_ , thrownexception , errormessages ) ;	Check if there are any asynchronous exceptions.
public static queryablestateconfiguration disabled ( ) { final iterator < integer > proxyports = netutils . getportrangefromstring ( queryablestateoptions . proxy_port_range . defaultvalue ( ) ) ; final iterator < integer > serverports = netutils . getportrangefromstring ( queryablestateoptions . server_port_range . defaultvalue ( ) ) ; return new queryablestateconfiguration ( proxyports , serverports , num_ , num_ , num_ , num_ ) ; }	Gets the configuration describing the queryable state as deactivated.
public void addbroadcastsetforscatterfunction ( string name , dataset < ? > data ) { this . bcvarsscatter . add ( new tuple2 < > ( name , data ) ) ; }	Adds a data set as a broadcast set to the scatter function.
public void addbroadcastsetforgatherfunction ( string name , dataset < ? > data ) { this . bcvarsgather . add ( new tuple2 < > ( name , data ) ) ; }	Adds a data set as a broadcast set to the gather function.
public list < map < string , list < eventid > > > extractpatterns ( final nodeid nodeid , final deweynumber version ) { list < map < string , list < eventid > > > result = new arraylist < > ( ) ;	Returns all elements from the previous relation starting at the given entry.
public map < string , list < v > > materializematch ( map < string , list < eventid > > match ) { map < string , list < v > > materializedmatch = new linkedhashmap < > ( match . size ( ) ) ; for ( map . entry < string , list < eventid > > pattern : match . entryset ( ) ) { list < v > events = new arraylist < > ( pattern . getvalue ( ) . size ( ) ) ; for ( eventid eventid : pattern . getvalue ( ) ) { try { v event = sharedbuffer . getevent ( eventid ) . getelement ( ) ; events . add ( event ) ; } catch ( exception ex ) { throw new wrappingruntimeexception ( ex ) ; } } materializedmatch . put ( pattern . getkey ( ) , events ) ; } return materializedmatch ; }	Extracts the real event from the sharedBuffer with pre-extracted eventId.
public void locknode ( final nodeid node ) { lockable < sharedbuffernode > sharedbuffernode = sharedbuffer . getentry ( node ) ; if ( sharedbuffernode != null ) { sharedbuffernode . lock ( ) ; sharedbuffer . upsertentry ( node , sharedbuffernode ) ; } }	Increases the reference counter for the given entry so that it is notaccidentally removed.
public void releasenode ( final nodeid node ) throws exception { lockable < sharedbuffernode > sharedbuffernode = sharedbuffer . getentry ( node ) ; if ( sharedbuffernode != null ) { if ( sharedbuffernode . release ( ) ) { removenode ( node , sharedbuffernode . getelement ( ) ) ; } else { sharedbuffer . upsertentry ( node , sharedbuffernode ) ; } } }	Decreases the reference counter for the given entry so that it can beremoved once the reference counter reaches 0.
private void lockevent ( eventid eventid ) { lockable < v > eventwrapper = sharedbuffer . getevent ( eventid ) ; checkstate ( eventwrapper != null , str_ , eventid ) ; eventwrapper . lock ( ) ; sharedbuffer . upsertevent ( eventid , eventwrapper ) ; }	Increases the reference counter for the given event so that it is notaccidentally removed.
public void releaseevent ( eventid eventid ) throws exception { lockable < v > eventwrapper = sharedbuffer . getevent ( eventid ) ; if ( eventwrapper != null ) { if ( eventwrapper . release ( ) ) { sharedbuffer . removeevent ( eventid ) ; } else { sharedbuffer . upsertevent ( eventid , eventwrapper ) ; } } }	Decreases the reference counter for the given event so that it can beremoved once the reference counter reaches 0.
protected void stop ( string [ ] args ) throws exception { log . info ( str_ ) ; final options commandoptions = clifrontendparser . getstopcommandoptions ( ) ; final options commandlineoptions = clifrontendparser . mergeoptions ( commandoptions , customcommandlineoptions ) ; final commandline commandline = clifrontendparser . parse ( commandlineoptions , args , bool_ ) ; final stopoptions stopoptions = new stopoptions ( commandline ) ; if ( stopoptions . isprinthelp ( ) ) { clifrontendparser . printhelpforstop ( customcommandlines ) ; return ; } final string [ ] cleanedargs = stopoptions . getargs ( ) ; final string targetdirectory = stopoptions . hassavepointflag ( ) && cleanedargs . length > num_ ? stopoptions . gettargetdirectory ( ) : null ;	Executes the STOP action.
protected void cancel ( string [ ] args ) throws exception { log . info ( str_ ) ; final options commandoptions = clifrontendparser . getcancelcommandoptions ( ) ; final options commandlineoptions = clifrontendparser . mergeoptions ( commandoptions , customcommandlineoptions ) ; final commandline commandline = clifrontendparser . parse ( commandlineoptions , args , bool_ ) ; canceloptions canceloptions = new canceloptions ( commandline ) ;	Executes the CANCEL action.
protected void savepoint ( string [ ] args ) throws exception { log . info ( str_ ) ; final options commandoptions = clifrontendparser . getsavepointcommandoptions ( ) ; final options commandlineoptions = clifrontendparser . mergeoptions ( commandoptions , customcommandlineoptions ) ; final commandline commandline = clifrontendparser . parse ( commandlineoptions , args , bool_ ) ; final savepointoptions savepointoptions = new savepointoptions ( commandline ) ;	Executes the SAVEPOINT action.
private string triggersavepoint ( clusterclient < ? > clusterclient , jobid jobid , string savepointdirectory ) throws flinkexception { logandsysout ( str_ + jobid + str_ ) ; completablefuture < string > savepointpathfuture = clusterclient . triggersavepoint ( jobid , savepointdirectory ) ; logandsysout ( str_ ) ; final string savepointpath ; try { savepointpath = savepointpathfuture . get ( ) ; } catch ( exception e ) { throwable cause = exceptionutils . stripexecutionexception ( e ) ; throw new flinkexception ( str_ + jobid + str_ , cause ) ; } logandsysout ( str_ + savepointpath ) ; logandsysout ( str_ ) ; return savepointpath ; }	Sends a SavepointTriggerMessage to the job manager.
private void disposesavepoint ( clusterclient < ? > clusterclient , string savepointpath ) throws flinkexception { preconditions . checknotnull ( savepointpath , str_ + str_ ) ; logandsysout ( str_ + savepointpath + str_ ) ; final completablefuture < acknowledge > disposefuture = clusterclient . disposesavepoint ( savepointpath ) ; logandsysout ( str_ ) ; try { disposefuture . get ( clienttimeout . tomillis ( ) , timeunit . milliseconds ) ; } catch ( exception e ) { throw new flinkexception ( str_ + savepointpath + str_ , e ) ; } logandsysout ( str_ + savepointpath + str_ ) ; }	Sends a SavepointDisposalRequest to the job manager.
packagedprogram buildprogram ( programoptions options ) throws filenotfoundexception , programinvocationexception { string [ ] programargs = options . getprogramargs ( ) ; string jarfilepath = options . getjarfilepath ( ) ; list < url > classpaths = options . getclasspaths ( ) ; if ( jarfilepath == null ) { throw new illegalargumentexception ( str_ ) ; } file jarfile = new file ( jarfilepath ) ;	Creates a Packaged program from the given command line options.
private static int handleparametrizationexception ( programparametrizationexception e ) { log . error ( str_ , e ) ; system . err . println ( e . getmessage ( ) ) ; return num_ ; }	Displays an optional exception message for incorrect program parametrization.
private static int handleerror ( throwable t ) { log . error ( str_ , t ) ; system . err . println ( ) ; system . err . println ( str_ ) ; system . err . println ( str_ ) ; system . err . println ( ) ; if ( t . getcause ( ) instanceof invalidprogramexception ) { system . err . println ( t . getcause ( ) . getmessage ( ) ) ; stacktraceelement [ ] trace = t . getcause ( ) . getstacktrace ( ) ; for ( stacktraceelement ele : trace ) { system . err . println ( str_ + ele ) ; if ( ele . getmethodname ( ) . equals ( str_ ) ) { break ; } } } else { t . printstacktrace ( ) ; } return num_ ; }	Displays an exception message.
public static void main ( final string [ ] args ) { environmentinformation . logenvironmentinfo ( log , str_ , args ) ;	Submits the job based on the arguments.
static void setjobmanageraddressinconfig ( configuration config , inetsocketaddress address ) { config . setstring ( jobmanageroptions . address , address . gethoststring ( ) ) ; config . setinteger ( jobmanageroptions . port , address . getport ( ) ) ; config . setstring ( restoptions . address , address . gethoststring ( ) ) ; config . setinteger ( restoptions . port , address . getport ( ) ) ; }	Writes the given job manager address to the associated configuration object.
public customcommandline < ? > getactivecustomcommandline ( commandline commandline ) { for ( customcommandline < ? > cli : customcommandlines ) { if ( cli . isactive ( commandline ) ) { return cli ; } } throw new illegalstateexception ( str_ ) ; }	Gets the custom command-line for the arguments.
private static customcommandline < ? > loadcustomcommandline ( string classname , object ... params ) throws illegalaccessexception , invocationtargetexception , instantiationexception , classnotfoundexception , nosuchmethodexception { class < ? extends customcommandline > customcliclass = class . forname ( classname ) . assubclass ( customcommandline . class ) ;	Loads a class from the classpath that implements the CustomCommandLine interface.
private static jobvertexbackpressureinfo . vertexbackpressurelevel getbackpressurelevel ( double backpressureratio ) { if ( backpressureratio <= num_ ) { return jobvertexbackpressureinfo . vertexbackpressurelevel . ok ; } else if ( backpressureratio <= num_ ) { return jobvertexbackpressureinfo . vertexbackpressurelevel . low ; } else { return jobvertexbackpressureinfo . vertexbackpressurelevel . high ; } }	Returns the back pressure level as a String.
public boolean schemaequals ( object obj ) { return equals ( obj ) && arrays . equals ( fieldnames , ( ( rowtypeinfo ) obj ) . fieldnames ) ; }	Tests whether an other object describes the same, schema-equivalent row information.
@ override public void discardstate ( ) throws exception { filesystem fs = getfilesystem ( ) ; fs . delete ( filepath , bool_ ) ; }	Discard the state by deleting the file that stores the state.
public final void setnewvertexvalue ( vv newvalue ) { if ( setnewvertexvaluecalled ) { throw new illegalstateexception ( str_ ) ; } setnewvertexvaluecalled = bool_ ; outvertex . f1 = newvalue ; out . collect ( either . left ( outvertex ) ) ; }	Sets the new value of this vertex.
public void setnewvertexvalue ( vv newvalue ) { if ( setnewvertexvaluecalled ) { throw new illegalstateexception ( str_ ) ; } setnewvertexvaluecalled = bool_ ; if ( isoptdegrees ( ) ) { outvalwithdegrees . f1 . f0 = newvalue ; outwithdegrees . collect ( outvalwithdegrees ) ; } else { outval . setvalue ( newvalue ) ; out . collect ( outval ) ; } }	Sets the new value of this vertex.
private static path validatepath ( path path ) { final uri uri = path . touri ( ) ; final string scheme = uri . getscheme ( ) ; final string pathpart = uri . getpath ( ) ;	Checks the validity of the path's scheme and path.
public void transferallstatedatatodirectory ( incrementalremotekeyedstatehandle restorestatehandle , path dest , closeableregistry closeableregistry ) throws exception { final map < statehandleid , streamstatehandle > sstfiles = restorestatehandle . getsharedstate ( ) ; final map < statehandleid , streamstatehandle > miscfiles = restorestatehandle . getprivatestate ( ) ; downloaddataforallstatehandles ( sstfiles , dest , closeableregistry ) ; downloaddataforallstatehandles ( miscfiles , dest , closeableregistry ) ; }	Transfer all state data to the target directory using specified number of threads.
private void downloaddataforstatehandle ( path restorefilepath , streamstatehandle remotefilehandle , closeableregistry closeableregistry ) throws ioexception { fsdatainputstream inputstream = null ; fsdataoutputstream outputstream = null ; try { filesystem restorefilesystem = restorefilepath . getfilesystem ( ) ; inputstream = remotefilehandle . openinputstream ( ) ; closeableregistry . registercloseable ( inputstream ) ; outputstream = restorefilesystem . create ( restorefilepath , filesystem . writemode . overwrite ) ; closeableregistry . registercloseable ( outputstream ) ; byte [ ] buffer = new byte [ num_ * num_ ] ; while ( bool_ ) { int numbytes = inputstream . read ( buffer ) ; if ( numbytes == - num_ ) { break ; } outputstream . write ( buffer , num_ , numbytes ) ; } } finally { if ( closeableregistry . unregistercloseable ( inputstream ) ) { inputstream . close ( ) ; } if ( closeableregistry . unregistercloseable ( outputstream ) ) { outputstream . close ( ) ; } } }	Copies the file from a single state handle to the given path.
public static < out > void checkcollection ( collection < out > elements , class < out > viewedas ) { for ( out elem : elements ) { if ( elem == null ) { throw new illegalargumentexception ( str_ ) ; } if ( ! viewedas . isassignablefrom ( elem . getclass ( ) ) ) { throw new illegalargumentexception ( str_ + viewedas . getcanonicalname ( ) ) ; } } }	Verifies that all elements in the collection are non-null, and are of the given class, ora subclass thereof.
public void initializecache ( object key ) throws exception { this . sortedwindows = cachedsortedwindows . get ( key ) ; if ( sortedwindows == null ) { this . sortedwindows = new treeset < > ( ) ; iterator < map . entry < w , w > > keyvalues = mapping . iterator ( ) ; if ( keyvalues != null ) { while ( keyvalues . hasnext ( ) ) { map . entry < w , w > keyvalue = keyvalues . next ( ) ; this . sortedwindows . add ( keyvalue . getkey ( ) ) ; } } cachedsortedwindows . put ( key , sortedwindows ) ; } }	Set current key context of this window set. Notes: {.
public final boolean isresolved ( ) { return getpathparameters ( ) . stream ( ) . filter ( messageparameter :: ismandatory ) . allmatch ( messageparameter :: isresolved ) && getqueryparameters ( ) . stream ( ) . filter ( messageparameter :: ismandatory ) . allmatch ( messageparameter :: isresolved ) ; }	Returns whether all mandatory parameters have been resolved.
public static database createhivedatabase ( string dbname , catalogdatabase db ) { map < string , string > props = db . getproperties ( ) ; return new database ( dbname , db . getdescription ( ) . ispresent ( ) ? db . getdescription ( ) . get ( ) : null , null , props ) ; }	Creates a Hive database from CatalogDatabase.
private static int indexofname ( list < unresolvedreferenceexpression > inputfieldreferences , string targetname ) { int i ; for ( i = num_ ; i < inputfieldreferences . size ( ) ; ++ i ) { if ( inputfieldreferences . get ( i ) . getname ( ) . equals ( targetname ) ) { break ; } } return i == inputfieldreferences . size ( ) ? - num_ : i ; }	Find the index of targetName in the list.
private static boolean checkbegin ( binarystring pattern , memorysegment [ ] segments , int start , int len ) { int lensub = pattern . getsizeinbytes ( ) ; return len >= lensub && segmentsutil . equals ( pattern . getsegments ( ) , num_ , segments , start , lensub ) ; }	Matches the beginning of each string to a pattern.
private static int indexmiddle ( binarystring pattern , memorysegment [ ] segments , int start , int len ) { return segmentsutil . find ( segments , start , len , pattern . getsegments ( ) , pattern . getoffset ( ) , pattern . getsizeinbytes ( ) ) ; }	Matches the middle of each string to its pattern.
public < c extends rpcgateway > c getselfgateway ( class < c > selfgatewaytype ) { if ( selfgatewaytype . isinstance ( rpcserver ) ) { @ suppresswarnings ( str_ ) c selfgateway = ( ( c ) rpcserver ) ; return selfgateway ; } else { throw new runtimeexception ( str_ + selfgatewaytype + str_ ) ; } }	Returns a self gateway of the specified type which can be used to issue asynchronouscalls against the RpcEndpoint.
@ internal public static void closesafetynetandguardedresourcesforthread ( ) { safetynetcloseableregistry registry = registries . get ( ) ; if ( null != registry ) { registries . remove ( ) ; ioutils . closequietly ( registry ) ; } }	Closes the safety net for a thread.
public void addheuristicnetworkcost ( double cost ) { if ( cost <= num_ ) { throw new illegalargumentexception ( str_ ) ; } this . heuristicnetworkcost += cost ;	Adds the heuristic costs for network to the current heuristic network costsfor this Costs object.
public void addheuristicdiskcost ( double cost ) { if ( cost <= num_ ) { throw new illegalargumentexception ( str_ ) ; } this . heuristicdiskcost += cost ;	Adds the heuristic costs for disk to the current heuristic disk costsfor this Costs object.
public void addheuristiccpucost ( double cost ) { if ( cost <= num_ ) { throw new illegalargumentexception ( str_ ) ; } this . heuristiccpucost += cost ;	Adds the given heuristic CPU cost to the current heuristic CPU cost for this Costs object.
public void subtractcosts ( costs other ) { if ( this . networkcost != unknown && other . networkcost != unknown ) { this . networkcost -= other . networkcost ; if ( this . networkcost < num_ ) { throw new illegalargumentexception ( str_ ) ; } } if ( this . diskcost != unknown && other . diskcost != unknown ) { this . diskcost -= other . diskcost ; if ( this . diskcost < num_ ) { throw new illegalargumentexception ( str_ ) ; } } if ( this . cpucost != unknown && other . cpucost != unknown ) { this . cpucost -= other . cpucost ; if ( this . cpucost < num_ ) { throw new illegalargumentexception ( str_ ) ; } }	Subtracts the given costs from these costs.
public joinoperator < i1 , i2 , out > withpartitioner ( partitioner < ? > partitioner ) { if ( partitioner != null ) { keys1 . validatecustompartitioner ( partitioner , null ) ; keys2 . validatecustompartitioner ( partitioner , null ) ; } this . custompartitioner = getinput1 ( ) . clean ( partitioner ) ; return this ; }	Sets a custom partitioner for this join.
public binaryrow append ( lookupinfo info , binaryrow value ) throws ioexception { try { if ( numelements >= growththreshold ) { growandrehash ( ) ;	Append an value into the hash map's record area.
public void reset ( ) { int numbuckets = bucketsegments . size ( ) * numbucketspersegment ; this . log2numbuckets = mathutils . log2strict ( numbuckets ) ; this . numbucketsmask = ( num_ << mathutils . log2strict ( numbuckets ) ) - num_ ; this . numbucketsmask2 = ( num_ << mathutils . log2strict ( numbuckets > > num_ ) ) - num_ ; this . growththreshold = ( int ) ( numbuckets * load_factor ) ;	reset the map's record and bucket area's memory segments for reusing.
static tuple2 < path , localresource > setuplocalresource ( filesystem fs , string appid , path localsrcpath , path homedir , string relativetargetpath ) throws ioexception { file localfile = new file ( localsrcpath . touri ( ) . getpath ( ) ) ; if ( localfile . isdirectory ( ) ) { throw new illegalargumentexception ( str_ + localsrcpath ) ; }	Copy a local file to a remote file system.
private static localresource registerlocalresource ( path remotersrcpath , long resourcesize , long resourcemodificationtime ) { localresource localresource = records . newrecord ( localresource . class ) ; localresource . setresource ( converterutils . getyarnurlfromuri ( remotersrcpath . touri ( ) ) ) ; localresource . setsize ( resourcesize ) ; localresource . settimestamp ( resourcemodificationtime ) ; localresource . settype ( localresourcetype . file ) ; localresource . setvisibility ( localresourcevisibility . application ) ; return localresource ; }	Creates a YARN resource for the remote object at the given location.
private static void obtaintokenforhbase ( credentials credentials , configuration conf ) throws ioexception { if ( usergroupinformation . issecurityenabled ( ) ) { log . info ( str_ ) ; try {	Obtain Kerberos security token for HBase.
public static map < string , string > getenvironmentvariables ( string envprefix , org . apache . flink . configuration . configuration flinkconfiguration ) { map < string , string > result = new hashmap < > ( ) ; for ( map . entry < string , string > entry : flinkconfiguration . tomap ( ) . entryset ( ) ) { if ( entry . getkey ( ) . startswith ( envprefix ) && entry . getkey ( ) . length ( ) > envprefix . length ( ) ) {	Method to extract environment variables from the flinkConfiguration based on the given prefix String.
static void require ( boolean condition , string message , object ... values ) { if ( ! condition ) { throw new runtimeexception ( string . format ( message , values ) ) ; } }	Validates a condition, throwing a RuntimeException if the condition is violated.
public queryscopeinfo getqueryservicemetricinfo ( characterfilter filter ) { if ( queryservicescopeinfo == null ) { queryservicescopeinfo = createqueryservicemetricinfo ( filter ) ; } return queryservicescopeinfo ; }	Returns the metric query service scope for this group.
protected void addmetric ( string name , metric metric ) { if ( metric == null ) { log . warn ( str_ , name ) ; return ; }	Adds the given metric to the group and registers it at the registry, if the groupis not yet closed, and if no metric with the same name has been registered before.
private static calendar valueascalendar ( object value ) { date date = ( date ) value ; calendar cal = calendar . getinstance ( ) ; cal . settime ( date ) ; return cal ; }	Convert a Date value to a Calendar.
public static boolean isfunctionoftype ( expression expr , functiondefinition . type type ) { return expr instanceof callexpression && ( ( callexpression ) expr ) . getfunctiondefinition ( ) . gettype ( ) == type ; }	Checks if the expression is a function call of given type.
private static string striphostname ( final string originalhostname ) {	Looks for a domain suffix in a FQDN and strips it if present.
private void onbarrier ( int channelindex ) throws ioexception { if ( ! blockedchannels [ channelindex ] ) { blockedchannels [ channelindex ] = bool_ ; numbarriersreceived ++ ; if ( log . isdebugenabled ( ) ) { log . debug ( str_ , inputgate . getowningtaskname ( ) , channelindex ) ; } } else { throw new ioexception ( str_ + channelindex ) ; } }	Blocks the given channel index, from which a barrier has been received.
private void releaseblocksandresetbarriers ( ) throws ioexception { log . debug ( str_ , inputgate . getowningtaskname ( ) ) ; for ( int i = num_ ; i < blockedchannels . length ; i ++ ) { blockedchannels [ i ] = bool_ ; } if ( currentbuffered == null ) {	Releases the blocks on all channels and resets the barrier count.Makes sure the just written data is the next to be consumed.
public static void initdefaultsfromconfiguration ( configuration configuration ) { final boolean overwrite = configuration . getboolean ( coreoptions . filesytem_default_override ) ; default_write_mode = overwrite ? writemode . overwrite : writemode . no_overwrite ; final boolean alwayscreatedirectory = configuration . getboolean ( coreoptions . filesystem_output_always_create_directory ) ; default_output_directory_mode = alwayscreatedirectory ? outputdirectorymode . always : outputdirectorymode . paronly ; }	Initialize defaults for output format.
@ override public void initializeglobal ( int parallelism ) throws ioexception { final path path = getoutputfilepath ( ) ; final filesystem fs = path . getfilesystem ( ) ;	Initialization of the distributed file system if it is used.
public static < t extends throwable > optional < t > findthrowable ( throwable throwable , class < t > searchtype ) { if ( throwable == null || searchtype == null ) { return optional . empty ( ) ; } throwable t = throwable ; while ( t != null ) { if ( searchtype . isassignablefrom ( t . getclass ( ) ) ) { return optional . of ( searchtype . cast ( t ) ) ; } else { t = t . getcause ( ) ; } } return optional . empty ( ) ; }	Checks whether a throwable chain contains a specific type of exception and returns it.
public static optional < throwable > findthrowable ( throwable throwable , predicate < throwable > predicate ) { if ( throwable == null || predicate == null ) { return optional . empty ( ) ; } throwable t = throwable ; while ( t != null ) { if ( predicate . test ( t ) ) { return optional . of ( t ) ; } else { t = t . getcause ( ) ; } } return optional . empty ( ) ; }	Checks whether a throwable chain contains an exception matching a predicate and returns it.
public static optional < throwable > findthrowablewithmessage ( throwable throwable , string searchmessage ) { if ( throwable == null || searchmessage == null ) { return optional . empty ( ) ; } throwable t = throwable ; while ( t != null ) { if ( t . getmessage ( ) != null && t . getmessage ( ) . contains ( searchmessage ) ) { return optional . of ( t ) ; } else { t = t . getcause ( ) ; } } return optional . empty ( ) ; }	Checks whether a throwable chain contains a specific error message and returns the corresponding throwable.
public static int optimalnumofbits ( long inputentries , double fpp ) { int numbits = ( int ) ( - inputentries * math . log ( fpp ) / ( math . log ( num_ ) * math . log ( num_ ) ) ) ; return numbits ; }	Compute optimal bits number with given input entries and expected false positive probability.
static int optimalnumofhashfunctions ( long expectentries , long bitsize ) { return math . max ( num_ , ( int ) math . round ( ( double ) bitsize / expectentries * math . log ( num_ ) ) ) ; }	compute the optimal hash function number with given input entries and bits size, which wouldmake the false positive probability lowest.
@ suppresswarnings ( str_ ) public list < recordwriter < serializationdelegate < t > > > getwriters ( ) { return collections . unmodifiablelist ( arrays . aslist ( this . writers ) ) ; }	List of writers that are associated with this output collector.
@ override public boolean tryassignpayload ( payload payload ) { preconditions . checknotnull ( payload ) ;	Atomically sets the executed vertex, if no vertex has been assigned to this slot so far.
public static scopeformats fromconfig ( configuration config ) { string jmformat = config . getstring ( metricoptions . scope_naming_jm ) ; string jmjobformat = config . getstring ( metricoptions . scope_naming_jm_job ) ; string tmformat = config . getstring ( metricoptions . scope_naming_tm ) ; string tmjobformat = config . getstring ( metricoptions . scope_naming_tm_job ) ; string taskformat = config . getstring ( metricoptions . scope_naming_task ) ; string operatorformat = config . getstring ( metricoptions . scope_naming_operator ) ; return new scopeformats ( jmformat , jmjobformat , tmformat , tmjobformat , taskformat , operatorformat ) ; }	Creates the scope formats as defined in the given configuration.
private static void initdefaultsfromconfiguration ( configuration configuration ) { final long to = configuration . getlong ( configconstants . fs_stream_opening_timeout_key , configconstants . default_fs_stream_opening_timeout ) ; if ( to < num_ ) { log . error ( str_ + to + str_ + configconstants . default_fs_stream_opening_timeout ) ; default_opening_timeout = configconstants . default_fs_stream_opening_timeout ; } else if ( to == num_ ) { default_opening_timeout = num_ ;	Initialize defaults for input format.
public path [ ] getfilepaths ( ) { if ( supportsmultipaths ( ) ) { if ( this . filepaths == null ) { return new path [ num_ ] ; } return this . filepaths ; } else { if ( this . filepath == null ) { return new path [ num_ ] ; } return new path [ ] { filepath } ; } }	Returns the paths of all files to be read by the FileInputFormat.
private long addfilesindir ( path path , list < filestatus > files , boolean logexcludedfiles ) throws ioexception { final filesystem fs = path . getfilesystem ( ) ; long length = num_ ; for ( filestatus dir : fs . liststatus ( path ) ) { if ( dir . isdir ( ) ) { if ( acceptfile ( dir ) && enumeratenestedfiles ) { length += addfilesindir ( dir . getpath ( ) , files , logexcludedfiles ) ; } else { if ( logexcludedfiles && log . isdebugenabled ( ) ) { log . debug ( str_ + dir . getpath ( ) . tostring ( ) + str_ ) ; } } } else { if ( acceptfile ( dir ) ) { files . add ( dir ) ; length += dir . getlen ( ) ; testforunsplittable ( dir ) ; } else { if ( logexcludedfiles && log . isdebugenabled ( ) ) { log . debug ( str_ + dir . getpath ( ) . tostring ( ) + str_ ) ; } } } } return length ; }	Enumerate all files in the directory and recursive if enumerateNestedFiles is true.
public synchronized void addopenchannels ( list < fileiochannel > toopen ) { checkargument ( ! closed ) ; for ( fileiochannel channel : toopen ) { openchannels . add ( channel ) ; channels . remove ( channel . getchannelid ( ) ) ; } }	Open File channels.
public void open ( context < k , w > ctx ) throws exception { this . ctx = ctx ; this . windowassigner . open ( ctx ) ; }	Initialization method for the function.
public singleoutputstreamoperator < t > sum ( int positiontosum ) { return aggregate ( new sumaggregator < > ( positiontosum , input . gettype ( ) , input . getexecutionconfig ( ) ) ) ; }	Applies an aggregation that sums every window of the data stream at thegiven position.
public singleoutputstreamoperator < t > sum ( string field ) { return aggregate ( new sumaggregator < > ( field , input . gettype ( ) , input . getexecutionconfig ( ) ) ) ; }	Applies an aggregation that sums every window of the pojo data stream atthe given field for every window.
public singleoutputstreamoperator < t > min ( int positiontomin ) { return aggregate ( new comparableaggregator < > ( positiontomin , input . gettype ( ) , aggregationfunction . aggregationtype . min , input . getexecutionconfig ( ) ) ) ; }	Applies an aggregation that that gives the minimum value of every windowof the data stream at the given position.
public singleoutputstreamoperator < t > min ( string field ) { return aggregate ( new comparableaggregator < > ( field , input . gettype ( ) , aggregationfunction . aggregationtype . min , bool_ , input . getexecutionconfig ( ) ) ) ; }	Applies an aggregation that that gives the minimum value of the pojo datastream at the given field expression for every window. A field expression is either the name of a public field or a getter method withparentheses of the {.
public singleoutputstreamoperator < t > max ( int positiontomax ) { return aggregate ( new comparableaggregator < > ( positiontomax , input . gettype ( ) , aggregationfunction . aggregationtype . max , input . getexecutionconfig ( ) ) ) ; }	Applies an aggregation that gives the maximum value of every window ofthe data stream at the given position.
public sortedgrouping < t > withpartitioner ( partitioner < ? > partitioner ) { preconditions . checknotnull ( partitioner ) ; getkeys ( ) . validatecustompartitioner ( partitioner , null ) ; this . custompartitioner = partitioner ; return this ; }	Uses a custom partitioner for the grouping.
public static byte [ ] encodeutf8 ( string str ) { byte [ ] bytes = allocatereusebytes ( str . length ( ) * max_bytes_per_char ) ; int len = encodeutf8 ( str , bytes ) ; return arrays . copyof ( bytes , len ) ; }	This method must have the same result with JDK's String.getBytes.
public methodlessrouter < t > addroute ( string pathpattern , t target ) { pathpattern p = new pathpattern ( pathpattern ) ; if ( routes . containskey ( p ) ) { return this ; } routes . put ( p , target ) ; return this ; }	This method does nothing if the path pattern has already been added.A path pattern can only point to one target.
public boolean anymatched ( string [ ] requestpathtokens ) { map < string , string > pathparams = new hashmap < > ( ) ; for ( pathpattern pattern : routes . keyset ( ) ) { if ( pattern . match ( requestpathtokens , pathparams ) ) { return bool_ ; }	Checks if there's any matching route.
private void initialize ( string scheme , string authority , string path ) { try { this . uri = new uri ( scheme , authority , normalizepath ( path ) , null , null ) . normalize ( ) ; } catch ( urisyntaxexception e ) { throw new illegalargumentexception ( e ) ; } }	Initializes a path object given the scheme, authority and path string.
public boolean isabsolute ( ) { final int start = haswindowsdrive ( uri . getpath ( ) , bool_ ) ? num_ : num_ ; return uri . getpath ( ) . startswith ( separator , start ) ; }	Checks if the directory of this path is absolute.
public int depth ( ) { string path = uri . getpath ( ) ; int depth = num_ ; int slash = path . length ( ) == num_ && path . charat ( num_ ) == str_ ? - num_ : num_ ; while ( slash != - num_ ) { depth ++ ; slash = path . indexof ( separator , slash + num_ ) ; } return depth ; }	Returns the number of elements in this path.
public avro recordclass ( class < ? extends specificrecord > recordclass ) { preconditions . checknotnull ( recordclass ) ; this . recordclass = recordclass ; return this ; }	Sets the class of the Avro specific record.
public static void readfully ( final inputstream in , final byte [ ] buf , int off , final int len ) throws ioexception { int toread = len ; while ( toread > num_ ) { final int ret = in . read ( buf , off , toread ) ; if ( ret < num_ ) { throw new ioexception ( str_ ) ; } toread -= ret ; off += ret ; } }	Reads len bytes in a loop.
private static string getalgorithmslisting ( ) { strbuilder strbuilder = new strbuilder ( ) ; strbuilder . appendnewline ( ) . appendln ( str_ ) . appendnewline ( ) . appendln ( str_ ) ; for ( driver algorithm : driverfactory ) { strbuilder . append ( str_ ) . appendfixedwidthpadright ( algorithm . getname ( ) , num_ , str_ ) . append ( algorithm . getshortdescription ( ) ) . appendnewline ( ) ; } return strbuilder . tostring ( ) ; }	List available algorithms. This is displayed to the user when no validalgorithm is given in the program parameterization.
private static string getalgorithmusage ( string algorithmname ) { strbuilder strbuilder = new strbuilder ( ) ; driver algorithm = driverfactory . get ( algorithmname ) ; strbuilder . appendnewline ( ) . appendnewline ( ) . appendln ( algorithm . getlongdescription ( ) ) . appendnewline ( ) . append ( str_ ) . append ( algorithmname ) . append ( str_ ) . appendnewline ( ) . appendnewline ( ) . appendln ( str_ ) ; for ( input input : inputfactory ) { strbuilder . append ( str_ ) . append ( input . getname ( ) ) . append ( str_ ) . appendln ( input . getusage ( ) ) ; } string algorithmparameterization = algorithm . getusage ( ) ; if ( algorithmparameterization . length ( ) > num_ ) { strbuilder . appendnewline ( ) . appendln ( str_ ) . append ( str_ ) . appendln ( algorithm . getusage ( ) ) ; } strbuilder . appendnewline ( ) . appendln ( str_ ) ; for ( output output : outputfactory ) { strbuilder . append ( str_ ) . append ( output . getname ( ) ) . append ( str_ ) . appendln ( output . getusage ( ) ) ; } return strbuilder . appendnewline ( ) . tostring ( ) ; }	Display the usage for the given algorithm.
private void execute ( ) throws exception { if ( result == null ) { env . execute ( executionname ) ; } else { output . write ( executionname . tostring ( ) , system . out , result ) ; } system . out . println ( ) ; algorithm . printanalytics ( system . out ) ; if ( jobdetailspath . getvalue ( ) != null ) { writejobdetails ( env , jobdetailspath . getvalue ( ) ) ; } }	Execute the Flink job.
protected void startthreads ( ) { if ( this . readthread != null ) { this . readthread . start ( ) ; } if ( this . sortthread != null ) { this . sortthread . start ( ) ; } if ( this . spillthread != null ) { this . spillthread . start ( ) ; } }	Starts all the threads that are used by this sort-merger.
protected final void setresultiteratorexception ( ioexception ioex ) { synchronized ( this . iteratorlock ) { if ( this . iteratorexception == null ) { this . iteratorexception = ioex ; this . iteratorlock . notifyall ( ) ; } } }	Reports an exception to all threads that are waiting for the result iterator.
protected static < t > circularelement < t > endmarker ( ) { @ suppresswarnings ( str_ ) circularelement < t > c = ( circularelement < t > ) eof_marker ; return c ; }	Gets the element that is passed as marker for the end of data.
protected static < t > circularelement < t > spillingmarker ( ) { @ suppresswarnings ( str_ ) circularelement < t > c = ( circularelement < t > ) spilling_marker ; return c ; }	Gets the element that is passed as marker for signal beginning of spilling.
@ override public void createresource ( ) throws exception { cluster = builder . getcluster ( ) ; session = cluster . connect ( ) ; session . execute ( string . format ( str_ , keyspace ) ) ; session . execute ( string . format ( str_ , keyspace , table ) ) ; try { session . close ( ) ; } catch ( exception e ) { log . error ( str_ , e ) ; } try { cluster . close ( ) ; } catch ( exception e ) { log . error ( str_ , e ) ; } }	Generates the necessary tables to store information.
public void jardir ( file dirorfile2jar , file destjar ) throws ioexception { if ( dirorfile2jar == null || destjar == null ) { throw new illegalargumentexception ( ) ; } mdestjarname = destjar . getcanonicalpath ( ) ; fileoutputstream fout = new fileoutputstream ( destjar ) ; jaroutputstream jout = new jaroutputstream ( fout ) ;	Jars a given directory or single file into a JarOutputStream.
public void unjardir ( file jarfile , file destdir ) throws ioexception { bufferedoutputstream dest = null ; fileinputstream fis = new fileinputstream ( jarfile ) ; unjar ( fis , destdir ) ; }	Unjars a given jar file into a given directory.
public void unjar ( inputstream in , file destdir ) throws ioexception { bufferedoutputstream dest = null ; jarinputstream jis = new jarinputstream ( in ) ; jarentry entry ; while ( ( entry = jis . getnextjarentry ( ) ) != null ) { if ( entry . isdirectory ( ) ) { file dir = new file ( destdir , entry . getname ( ) ) ; dir . mkdir ( ) ; if ( entry . gettime ( ) != - num_ ) { dir . setlastmodified ( entry . gettime ( ) ) ; } continue ; } int count ; byte [ ] data = new byte [ buffer_size ] ; file destfile = new file ( destdir , entry . getname ( ) ) ; if ( mverbose ) { system . out . println ( str_ + destfile + str_ + entry . getname ( ) ) ; } fileoutputstream fos = new fileoutputstream ( destfile ) ; dest = new bufferedoutputstream ( fos , buffer_size ) ; try { while ( ( count = jis . read ( data , num_ , buffer_size ) ) != - num_ ) { dest . write ( data , num_ , count ) ; } dest . flush ( ) ; } finally { dest . close ( ) ; } if ( entry . gettime ( ) != - num_ ) { destfile . setlastmodified ( entry . gettime ( ) ) ; } } jis . close ( ) ; }	Given an InputStream on a jar file, unjars the contents into the givendirectory.
private boolean ensurebatch ( ) throws ioexception { if ( nextrow >= rowsinbatch ) {	Checks if there is at least one row left in the batch to return.If no more row are available, it reads another batch of rows.
public map < string , optionalfailure < object > > getaccumulators ( jobid jobid ) throws exception { return getaccumulators ( jobid , classloader . getsystemclassloader ( ) ) ; }	Requests and returns the accumulators for the given job identifier.
private static optimizedplan getoptimizedplan ( optimizer compiler , jobwithjars prog , int parallelism ) throws compilerexception , programinvocationexception { return getoptimizedplan ( compiler , prog . getplan ( ) , parallelism ) ; }	Creates the optimized plan for a given program, using this client's compiler.
public static string generateruntimename ( class < ? > clazz , string [ ] fields ) { return tableconnectorutils . generateruntimename ( clazz , fields ) ; }	Returns the table connector name used for log and web UI.
public channelfuture requestsubpartition ( final resultpartitionid partitionid , final int subpartitionindex , final remoteinputchannel inputchannel , int delayms ) throws ioexception { checknotclosed ( ) ; log . debug ( str_ , subpartitionindex , partitionid , delayms ) ; clienthandler . addinputchannel ( inputchannel ) ; final partitionrequest request = new partitionrequest ( partitionid , subpartitionindex , inputchannel . getinputchannelid ( ) , inputchannel . getinitialcredit ( ) ) ; final channelfuturelistener listener = new channelfuturelistener ( ) { @ override public void operationcomplete ( channelfuture future ) throws exception { if ( ! future . issuccess ( ) ) { clienthandler . removeinputchannel ( inputchannel ) ; socketaddress remoteaddr = future . channel ( ) . remoteaddress ( ) ; inputchannel . onerror ( new localtransportexception ( string . format ( str_ , remoteaddr ) , future . channel ( ) . localaddress ( ) , future . cause ( ) ) ) ; } } } ; if ( delayms == num_ ) { channelfuture f = tcpchannel . writeandflush ( request ) ; f . addlistener ( listener ) ; return f ; } else { final channelfuture [ ] f = new channelfuture [ num_ ] ; tcpchannel . eventloop ( ) . schedule ( new runnable ( ) { @ override public void run ( ) { f [ num_ ] = tcpchannel . writeandflush ( request ) ; f [ num_ ] . addlistener ( listener ) ; } } , delayms , timeunit . milliseconds ) ; return f [ num_ ] ; } }	Requests a remote intermediate result partition queue.
public void selectfields ( string [ ] fieldnames ) { checknotnull ( fieldnames , str_ ) ; this . fieldnames = fieldnames ; rowtypeinfo rowtypeinfo = ( rowtypeinfo ) parquetschemaconverter . fromparquettype ( expectedfileschema ) ; typeinformation [ ] selectfieldtypes = new typeinformation [ fieldnames . length ] ; for ( int i = num_ ; i < fieldnames . length ; i ++ ) { try { selectfieldtypes [ i ] = rowtypeinfo . gettypeat ( fieldnames [ i ] ) ; } catch ( indexoutofboundsexception e ) { throw new illegalargumentexception ( string . format ( str_ + str_ , fieldnames [ i ] ) , e ) ; } } this . fieldtypes = selectfieldtypes ; }	Configures the fields to be read and returned by the ParquetInputFormat.
private messagetype getreadschema ( messagetype fileschema , path filepath ) { rowtypeinfo filetypeinfo = ( rowtypeinfo ) parquetschemaconverter . fromparquettype ( fileschema ) ; list < type > types = new arraylist < > ( ) ; for ( int i = num_ ; i < fieldnames . length ; ++ i ) { string readfieldname = fieldnames [ i ] ; typeinformation < ? > readfieldtype = fieldtypes [ i ] ; if ( filetypeinfo . getfieldindex ( readfieldname ) < num_ ) { if ( ! skipwrongschemafilesplit ) { throw new illegalargumentexception ( str_ + readfieldname + str_ + str_ + filepath + str_ ) ; } else { this . skipthissplit = bool_ ; return fileschema ; } } if ( ! readfieldtype . equals ( filetypeinfo . gettypeat ( readfieldname ) ) ) { if ( ! skipwrongschemafilesplit ) { throw new illegalargumentexception ( str_ + readfieldtype + str_ + readfieldname + str_ + filetypeinfo . gettypeat ( readfieldname ) + str_ + filepath + str_ ) ; } else { this . skipthissplit = bool_ ; return fileschema ; } } types . add ( fileschema . gettype ( readfieldname ) ) ; } return new messagetype ( fileschema . getname ( ) , types ) ; }	Generates and returns the read schema based on the projected fields for a given file.
private long calexpirationtime ( long operatortime , long relativesize ) { if ( operatortime < long . max_value ) { return operatortime - relativesize - allowedlateness - num_ ; } else {	Calculate the expiration time with the given operator time and relative window size.
private void registercleanuptimer ( context ctx , long rowtime , boolean leftrow ) throws ioexception { if ( leftrow ) { long cleanuptime = rowtime + leftrelativesize + mincleanupinterval + allowedlateness + num_ ; registertimer ( ctx , cleanuptime ) ; righttimerstate . update ( cleanuptime ) ; } else { long cleanuptime = rowtime + rightrelativesize + mincleanupinterval + allowedlateness + num_ ; registertimer ( ctx , cleanuptime ) ; lefttimerstate . update ( cleanuptime ) ; } }	Register a timer for cleaning up rows in a specified time.
private void removeexpiredrows ( collector < baserow > collector , long expirationtime , mapstate < long , list < tuple2 < baserow , boolean > > > rowcache , valuestate < long > timerstate , ontimercontext ctx , boolean removeleft ) throws exception { iterator < map . entry < long , list < tuple2 < baserow , boolean > > > > iterator = rowcache . iterator ( ) ; long earliesttimestamp = - num_ ;	Remove the expired rows.
public < t > dynamicresult < t > createresult ( environment env , tableschema schema , executionconfig config ) { final rowtypeinfo outputtype = new rowtypeinfo ( schema . getfieldtypes ( ) , schema . getfieldnames ( ) ) ; if ( env . getexecution ( ) . isstreamingexecution ( ) ) {	Creates a result. Might start threads or opens sockets so every created result must be closed.
@ override public void lazydestroy ( ) {	Destroy is called after the produce or consume phase of a task finishes.
public static < kt , kb , vvt , vvb , ev > bipartitegraph < kt , kb , vvt , vvb , ev > fromdataset ( dataset < vertex < kt , vvt > > topvertices , dataset < vertex < kb , vvb > > bottomvertices , dataset < bipartiteedge < kt , kb , ev > > edges , executionenvironment context ) { return new bipartitegraph < > ( topvertices , bottomvertices , edges , context ) ; }	Create bipartite graph from datasets.
public graph < kt , vvt , tuple2 < ev , ev > > projectiontopsimple ( ) { dataset < edge < kt , tuple2 < ev , ev > > > newedges = edges . join ( edges ) . where ( num_ ) . equalto ( num_ ) . with ( new projectiontopsimple < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( topvertices , newedges , context ) ; }	Convert a bipartite graph into an undirected graph that contains only top vertices.
public graph < kb , vvb , tuple2 < ev , ev > > projectionbottomsimple ( ) { dataset < edge < kb , tuple2 < ev , ev > > > newedges = edges . join ( edges ) . where ( num_ ) . equalto ( num_ ) . with ( new projectionbottomsimple < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( bottomvertices , newedges , context ) ; }	Convert a bipartite graph into an undirected graph that contains only bottom vertices.
public graph < kt , vvt , projection < kb , vvb , vvt , ev > > projectiontopfull ( ) { dataset < tuple5 < kt , kb , ev , vvt , vvb > > edgeswithvertices = joinedgewithvertices ( ) ; dataset < edge < kt , projection < kb , vvb , vvt , ev > > > newedges = edgeswithvertices . join ( edgeswithvertices ) . where ( num_ ) . equalto ( num_ ) . with ( new projectiontopfull < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( topvertices , newedges , context ) ; }	Convert a bipartite graph into a graph that contains only top vertices.
public graph < kb , vvb , projection < kt , vvt , vvb , ev > > projectionbottomfull ( ) { dataset < tuple5 < kt , kb , ev , vvt , vvb > > edgeswithvertices = joinedgewithvertices ( ) ; dataset < edge < kb , projection < kt , vvt , vvb , ev > > > newedges = edgeswithvertices . join ( edgeswithvertices ) . where ( num_ ) . equalto ( num_ ) . with ( new projectionbottomfull < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( bottomvertices , newedges , context ) ; }	Convert a bipartite graph into a graph that contains only bottom vertices.
@ override public jobexecutionresult execute ( string jobname ) throws exception {	Executes the JobGraph of the on a mini cluster of CLusterUtil with a userspecified name.
public static kvstateservice fromconfiguration ( taskmanagerservicesconfiguration taskmanagerservicesconfiguration ) { kvstateregistry kvstateregistry = new kvstateregistry ( ) ; queryablestateconfiguration qsconfig = taskmanagerservicesconfiguration . getqueryablestateconfig ( ) ; kvstateclientproxy kvclientproxy = null ; kvstateserver kvstateserver = null ; if ( qsconfig != null ) { int numproxyservernetworkthreads = qsconfig . numproxyserverthreads ( ) == num_ ? taskmanagerservicesconfiguration . getnumberofslots ( ) : qsconfig . numproxyserverthreads ( ) ; int numproxyserverquerythreads = qsconfig . numproxyquerythreads ( ) == num_ ? taskmanagerservicesconfiguration . getnumberofslots ( ) : qsconfig . numproxyquerythreads ( ) ; kvclientproxy = queryablestateutils . createkvstateclientproxy ( taskmanagerservicesconfiguration . gettaskmanageraddress ( ) , qsconfig . getproxyportrange ( ) , numproxyservernetworkthreads , numproxyserverquerythreads , new disabledkvstaterequeststats ( ) ) ; int numstateservernetworkthreads = qsconfig . numstateserverthreads ( ) == num_ ? taskmanagerservicesconfiguration . getnumberofslots ( ) : qsconfig . numstateserverthreads ( ) ; int numstateserverquerythreads = qsconfig . numstatequerythreads ( ) == num_ ? taskmanagerservicesconfiguration . getnumberofslots ( ) : qsconfig . numstatequerythreads ( ) ; kvstateserver = queryablestateutils . createkvstateserver ( taskmanagerservicesconfiguration . gettaskmanageraddress ( ) , qsconfig . getstateserverportrange ( ) , numstateservernetworkthreads , numstateserverquerythreads , kvstateregistry , new disabledkvstaterequeststats ( ) ) ; } return new kvstateservice ( kvstateregistry , kvstateserver , kvclientproxy ) ; }	Creates and returns the KvState service.
public compensatedsum add ( compensatedsum other ) { double correctedsum = other . value ( ) + ( delta + other . delta ( ) ) ; double updatedvalue = value + correctedsum ; double updateddelta = correctedsum - ( updatedvalue - value ) ; return new compensatedsum ( updatedvalue , updateddelta ) ; }	Increments the Kahan sum by adding two sums, and updating the correction term for reducing numeric errors.
public sortpartitionoperator < t > sortpartition ( int field , order order ) { if ( usekeyselector ) { throw new invalidprogramexception ( str_ ) ; } ensuresortablekey ( field ) ; keys . add ( new keys . expressionkeys < > ( field , gettype ( ) ) ) ; orders . add ( order ) ; return this ; }	Appends an additional sort order with the specified field in the specified order to thelocal partition sorting of the DataSet.
public option < long > getnumberofallocatedbytes ( ) throws nosuchfieldexception , illegalaccessexception { if ( directarenas != null ) { long numchunks = num_ ; for ( object arena : directarenas ) { numchunks += getnumberofallocatedchunks ( arena , str_ ) ; numchunks += getnumberofallocatedchunks ( arena , str_ ) ; numchunks += getnumberofallocatedchunks ( arena , str_ ) ; numchunks += getnumberofallocatedchunks ( arena , str_ ) ; numchunks += getnumberofallocatedchunks ( arena , str_ ) ; numchunks += getnumberofallocatedchunks ( arena , str_ ) ; } long allocatedbytes = numchunks * chunksize ; return option . apply ( allocatedbytes ) ; } else { return option . empty ( ) ; } }	Returns the number of currently allocated bytes.
private long getnumberofallocatedchunks ( object arena , string chunklistfieldname ) throws nosuchfieldexception , illegalaccessexception {	Returns the number of allocated bytes of the given arena and chunk list.
private void validatekeytypes ( int [ ] keyfieldindices ) { final typeinformation < ? > [ ] types = getfieldtypes ( ) ; for ( int keyfieldindex : keyfieldindices ) { final typeinformation < ? > type = types [ keyfieldindex ] ; if ( ! typecheckutils . issimplestringrepresentation ( type ) ) { throw new validationexception ( str_ + str_ + type ) ; } } }	Validate the types that are used for conversion to string.
protected void addpathrecursively ( final file sourcepath , final path targetpath , final containerspecification env ) throws ioexception { final java . nio . file . path sourceroot = sourcepath . topath ( ) . getparent ( ) ; files . walkfiletree ( sourcepath . topath ( ) , new simplefilevisitor < java . nio . file . path > ( ) { @ override public filevisitresult visitfile ( java . nio . file . path file , basicfileattributes attrs ) throws ioexception { java . nio . file . path relativepath = sourceroot . relativize ( file ) ; containerspecification . artifact . builder artifact = containerspecification . artifact . newbuilder ( ) . setsource ( new path ( file . touri ( ) ) ) . setdest ( new path ( targetpath , relativepath . tostring ( ) ) ) . setexecutable ( files . isexecutable ( file ) ) . setcachable ( bool_ ) . setextract ( bool_ ) ; env . getartifacts ( ) . add ( artifact . build ( ) ) ; return super . visitfile ( file , attrs ) ; } } ) ; }	Add a path recursively to the container specification.If the path is a directory, the directory itself (not just its contents) is added to the target path.The execute bit is preserved; permissions aren't.
public void subscribetoevent ( resultpartitionid partitionid , eventlistener < taskevent > eventlistener , class < ? extends taskevent > eventtype ) { checknotnull ( partitionid ) ; checknotnull ( eventlistener ) ; checknotnull ( eventtype ) ; taskeventhandler taskeventhandler ; synchronized ( registeredhandlers ) { taskeventhandler = registeredhandlers . get ( partitionid ) ; } if ( taskeventhandler == null ) { throw new illegalstateexception ( str_ + partitionid + str_ ) ; } taskeventhandler . subscribe ( eventlistener , eventtype ) ; }	Subscribes a listener to this dispatcher for events on a partition.
public static pyobject adapt ( object o ) { if ( o instanceof pyobject ) { return ( pyobject ) o ; } return py . java2py ( o ) ; }	Convert java object to its corresponding PyObject representation.
public static void reset ( final collection < mastertriggerrestorehook < ? > > hooks , final logger log ) throws flinkexception { for ( mastertriggerrestorehook < ? > hook : hooks ) { final string id = hook . getidentifier ( ) ; try { hook . reset ( ) ; } catch ( throwable t ) { exceptionutils . rethrowiffatalerrororoom ( t ) ; throw new flinkexception ( str_ + id + str_ , t ) ; } } }	Resets the master hooks.
public static void close ( final collection < mastertriggerrestorehook < ? > > hooks , final logger log ) throws flinkexception { for ( mastertriggerrestorehook < ? > hook : hooks ) { try { hook . close ( ) ; } catch ( throwable t ) { log . warn ( str_ + hook . getidentifier ( ) + str_ , t ) ; } } }	Closes the master hooks.
public static list < masterstate > triggermasterhooks ( collection < mastertriggerrestorehook < ? > > hooks , long checkpointid , long timestamp , executor executor , time timeout ) throws flinkexception { final arraylist < masterstate > states = new arraylist < > ( hooks . size ( ) ) ; for ( mastertriggerrestorehook < ? > hook : hooks ) { masterstate state = triggerhook ( hook , checkpointid , timestamp , executor , timeout ) ; if ( state != null ) { states . add ( state ) ; } } states . trimtosize ( ) ; return states ; }	Triggers all given master hooks and returns state objects for each hook thatproduced a state.
public static < t > mastertriggerrestorehook < t > wraphook ( mastertriggerrestorehook < t > hook , classloader userclassloader ) { return new wrappedmasterhook < > ( hook , userclassloader ) ; }	Wraps a hook such that the user-code classloader is applied when the hook is invoked.
@ suppresswarnings ( str_ ) public static < x > x deserializefunction ( runtimecontext context , byte [ ] serfun ) throws flinkexception { if ( ! jythoninitialized ) {	Deserialize the given python function.
public static void initandexecpythonscript ( pythonenvironmentfactory factory , java . nio . file . path scriptdirectory , string scriptname , string [ ] args ) { string [ ] fullargs = new string [ args . length + num_ ] ; fullargs [ num_ ] = scriptdirectory . resolve ( scriptname ) . tostring ( ) ; system . arraycopy ( args , num_ , fullargs , num_ , args . length ) ; pythoninterpreter pythoninterpreter = initpythoninterpreter ( fullargs , scriptdirectory . touri ( ) . getpath ( ) , scriptname ) ; pythoninterpreter . set ( str_ , factory ) ; pythoninterpreter . exec ( scriptname + str_ ) ; }	Initializes the Jython interpreter and executes a python script.
private static void setrequiredproperties ( properties zkprops ) {	Sets required properties to reasonable defaults and logs it.
public static string generateruntimename ( class < ? > clazz , string [ ] fields ) { string classname = clazz . getsimplename ( ) ; if ( null == fields ) { return classname + str_ ; } else { return classname + str_ + string . join ( str_ , fields ) + str_ ; } }	Returns the table connector name used for logging and web UI.
public mesosconfiguration withframeworkinfo ( protos . frameworkinfo . builder frameworkinfo ) { return new mesosconfiguration ( masterurl , frameworkinfo , credential ) ; }	Revise the configuration with updated framework info.
public set < string > roles ( ) { return frameworkinfo . hasrole ( ) && ! str_ . equals ( frameworkinfo . getrole ( ) ) ? collections . singleton ( frameworkinfo . getrole ( ) ) : collections . emptyset ( ) ; }	Gets the roles associated with the framework.
public schedulerdriver createdriver ( scheduler scheduler , boolean implicitacknowledgements ) { mesosschedulerdriver schedulerdriver ; if ( this . credential ( ) . isdefined ( ) ) { schedulerdriver = new mesosschedulerdriver ( scheduler , frameworkinfo . build ( ) , this . masterurl ( ) , implicitacknowledgements , this . credential ( ) . get ( ) . build ( ) ) ; } else { schedulerdriver = new mesosschedulerdriver ( scheduler , frameworkinfo . build ( ) , this . masterurl ( ) , implicitacknowledgements ) ; } return schedulerdriver ; }	Create the Mesos scheduler driver based on this configuration.
public static thread addshutdownhook ( final autocloseable service , final string servicename , final logger logger ) { checknotnull ( service ) ; checknotnull ( logger ) ; final thread shutdownhook = new thread ( ( ) -> { try { service . close ( ) ; } catch ( throwable t ) { logger . error ( str_ , servicename , t ) ; } } , servicename + str_ ) ; return addshutdownhookthread ( shutdownhook , servicename , logger ) ? shutdownhook : null ; }	Adds a shutdown hook to the JVM and returns the Thread, which has been registered.
public static boolean addshutdownhookthread ( final thread shutdownhook , final string servicename , final logger logger ) { checknotnull ( shutdownhook ) ; checknotnull ( logger ) ; try {	Adds a shutdown hook to the JVM.
public static void removeshutdownhook ( final thread shutdownhook , final string servicename , final logger logger ) {	Removes a shutdown hook from the JVM.
public void start ( final string initialowneraddress , final rpcservice initialrpcservice , final highavailabilityservices initialhighavailabilityservices , final jobleaderlistener initialjobleaderlistener ) { if ( jobleaderservice . state . created != state ) { throw new illegalstateexception ( str_ ) ; } else { log . info ( str_ ) ; this . owneraddress = preconditions . checknotnull ( initialowneraddress ) ; this . rpcservice = preconditions . checknotnull ( initialrpcservice ) ; this . highavailabilityservices = preconditions . checknotnull ( initialhighavailabilityservices ) ; this . jobleaderlistener = preconditions . checknotnull ( initialjobleaderlistener ) ; state = jobleaderservice . state . started ; } }	Start the job leader service with the given services.
public void stop ( ) throws exception { log . info ( str_ ) ; if ( jobleaderservice . state . started == state ) { for ( tuple2 < leaderretrievalservice , jobleaderservice . jobmanagerleaderlistener > leaderretrievalserviceentry : jobleaderservices . values ( ) ) { leaderretrievalservice leaderretrievalservice = leaderretrievalserviceentry . f0 ; jobleaderservice . jobmanagerleaderlistener jobmanagerleaderlistener = leaderretrievalserviceentry . f1 ; jobmanagerleaderlistener . stop ( ) ; leaderretrievalservice . stop ( ) ; } jobleaderservices . clear ( ) ; } state = jobleaderservice . state . stopped ; }	Stop the job leader services.
public void removejob ( jobid jobid ) throws exception { preconditions . checkstate ( jobleaderservice . state . started == state , str_ ) ; tuple2 < leaderretrievalservice , jobleaderservice . jobmanagerleaderlistener > entry = jobleaderservices . remove ( jobid ) ; if ( entry != null ) { log . info ( str_ , jobid ) ; leaderretrievalservice leaderretrievalservice = entry . f0 ; jobleaderservice . jobmanagerleaderlistener jobmanagerleaderlistener = entry . f1 ; leaderretrievalservice . stop ( ) ; jobmanagerleaderlistener . stop ( ) ; } }	Remove the given job from being monitored by the job leader service.
public void addjob ( final jobid jobid , final string defaulttargetaddress ) throws exception { preconditions . checkstate ( jobleaderservice . state . started == state , str_ ) ; log . info ( str_ , jobid ) ; final leaderretrievalservice leaderretrievalservice = highavailabilityservices . getjobmanagerleaderretriever ( jobid , defaulttargetaddress ) ; jobleaderservice . jobmanagerleaderlistener jobmanagerleaderlistener = new jobmanagerleaderlistener ( jobid ) ; final tuple2 < leaderretrievalservice , jobmanagerleaderlistener > oldentry = jobleaderservices . put ( jobid , tuple2 . of ( leaderretrievalservice , jobmanagerleaderlistener ) ) ; if ( oldentry != null ) { oldentry . f0 . stop ( ) ; oldentry . f1 . stop ( ) ; } leaderretrievalservice . start ( jobmanagerleaderlistener ) ; }	Add the given job to be monitored.
public void reconnect ( final jobid jobid ) { preconditions . checknotnull ( jobid , str_ ) ; final tuple2 < leaderretrievalservice , jobmanagerleaderlistener > jobleaderservice = jobleaderservices . get ( jobid ) ; if ( jobleaderservice != null ) { jobleaderservice . f1 . reconnect ( ) ; } else { log . info ( str_ , jobid ) ; } }	Triggers reconnection to the last known leader of the given job.
@ visiblefortesting public boolean containsjob ( jobid jobid ) { preconditions . checkstate ( jobleaderservice . state . started == state , str_ ) ; return jobleaderservices . containskey ( jobid ) ; }	Check whether the service monitors the given job.
private void savehandleinstate ( final long checkpointid , final long timestamp ) throws exception {	Called when a checkpoint barrier arrives.
public statistics columnstats ( string columnname , columnstats columnstats ) { map < string , string > map = normalizecolumnstats ( columnstats ) ; this . columnstats . put ( columnname , map ) ; return this ; }	Sets statistics for a column.
public statistics columndistinctcount ( string columnname , long ndv ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( distinct_count , string . valueof ( ndv ) ) ; return this ; }	Sets the number of distinct values statistic for the given column.
public statistics columnnullcount ( string columnname , long nullcount ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( null_count , string . valueof ( nullcount ) ) ; return this ; }	Sets the number of null values statistic for the given column.
public statistics columnavglength ( string columnname , double avglen ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( avg_length , string . valueof ( avglen ) ) ; return this ; }	Sets the average length statistic for the given column.
public statistics columnmaxlength ( string columnname , integer maxlen ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( max_length , string . valueof ( maxlen ) ) ; return this ; }	Sets the maximum length statistic for the given column.
public statistics columnmaxvalue ( string columnname , number max ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( max_value , string . valueof ( max ) ) ; return this ; }	Sets the maximum value statistic for the given column.
public statistics columnminvalue ( string columnname , number min ) { this . columnstats . computeifabsent ( columnname , column -> new hashmap < > ( ) ) . put ( min_value , string . valueof ( min ) ) ; return this ; }	Sets the minimum value statistic for the given column.
@ override public int size ( ) { if ( allelementsincache ) { return orderedcache . size ( ) ; } else { int count = num_ ; try ( final rocksbytesiterator iterator = orderedbytesiterator ( ) ) { while ( iterator . hasnext ( ) ) { iterator . next ( ) ; ++ count ; } } return count ; } }	This implementation comes at a relatively high cost per invocation.
private void generateallfailoverregion ( list < executionjobvertex > newjobverticestopological ) { final identityhashmap < executionvertex , arraylist < executionvertex > > vertextoregion = new identityhashmap < > ( ) ;	Generate all the FailoverRegion from the new added job vertexes.
@ override public void reset ( ) { this . cursor = fixedsize ; for ( int i = num_ ; i < nullbitssizeinbytes ; i += num_ ) { segment . putlong ( i , num_ ) ; } this . segment . putint ( num_ , numelements ) ; }	First, reset.
private static inetaddress findaddressusingstrategy ( addressdetectionstate strategy , inetsocketaddress targetaddress , boolean logging ) throws ioexception {	Try to find a local address which allows as to connect to the targetAddress using the givenstrategy.
@ override public void add ( bufferorevent boe ) throws ioexception { try { bytebuffer contents ; if ( boe . isbuffer ( ) ) { buffer buf = boe . getbuffer ( ) ; contents = buf . getniobufferreadable ( ) ; } else { contents = eventserializer . toserializedevent ( boe . getevent ( ) ) ; } headbuffer . clear ( ) ; headbuffer . putint ( boe . getchannelindex ( ) ) ; headbuffer . putint ( contents . remaining ( ) ) ; headbuffer . put ( ( byte ) ( boe . isbuffer ( ) ? num_ : num_ ) ) ; headbuffer . flip ( ) ; byteswritten += ( headbuffer . remaining ( ) + contents . remaining ( ) ) ; fileutils . writecompletely ( currentchannel , headbuffer ) ; fileutils . writecompletely ( currentchannel , contents ) ; } finally { if ( boe . isbuffer ( ) ) { boe . getbuffer ( ) . recyclebuffer ( ) ; } } }	Adds a buffer or event to the sequence of spilled buffers and events.
public static baserowkeyselector getbaserowselector ( int [ ] keyfields , baserowtypeinfo rowtype ) { if ( keyfields . length > num_ ) { internaltype [ ] inputfieldtypes = rowtype . getinternaltypes ( ) ; string [ ] inputfieldnames = rowtype . getfieldnames ( ) ; internaltype [ ] keyfieldtypes = new internaltype [ keyfields . length ] ; string [ ] keyfieldnames = new string [ keyfields . length ] ; for ( int i = num_ ; i < keyfields . length ; ++ i ) { keyfieldtypes [ i ] = inputfieldtypes [ keyfields [ i ] ] ; keyfieldnames [ i ] = inputfieldnames [ keyfields [ i ] ] ; } rowtype returntype = new rowtype ( keyfieldtypes , keyfieldnames ) ; rowtype inputtype = new rowtype ( inputfieldtypes , rowtype . getfieldnames ( ) ) ; generatedprojection generatedprojection = projectioncodegenerator . generateprojection ( codegeneratorcontext . apply ( new tableconfig ( ) ) , str_ , inputtype , returntype , keyfields ) ; baserowtypeinfo keyrowtype = returntype . totypeinfo ( ) ;	Create a BaseRowKeySelector to extract keys from DataStream which type is BaseRowTypeInfo.
public void close ( ) { synchronized ( this ) { if ( this . closed ) { return ; } this . closed = bool_ ; } this . numrecordsinbuffer = num_ ; this . numrecordsreturned = num_ ;	This method closes the iterator and releases all resources.
private map < path , filestatus > listeligiblefiles ( filesystem filesystem , path path ) throws ioexception { final filestatus [ ] statuses ; try { statuses = filesystem . liststatus ( path ) ; } catch ( ioexception e ) {	Returns the paths of the files not yet processed.
private timewindow mergewindow ( timewindow curwindow , timewindow other , collection < timewindow > mergedwindow ) { if ( curwindow . intersects ( other ) ) { mergedwindow . add ( other ) ; return curwindow . cover ( other ) ; } else { return curwindow ; } }	Merge curWindow and other, return a new window which covers curWindow and otherif they are overlapped.
protected configuration applycommandlineoptionstoconfiguration ( commandline commandline ) throws flinkexception { final configuration resultingconfiguration = new configuration ( configuration ) ; if ( commandline . hasoption ( addressoption . getopt ( ) ) ) { string addresswithport = commandline . getoptionvalue ( addressoption . getopt ( ) ) ; inetsocketaddress jobmanageraddress = clientutils . parsehostportaddress ( addresswithport ) ; setjobmanageraddressinconfig ( resultingconfiguration , jobmanageraddress ) ; } if ( commandline . hasoption ( zookeepernamespaceoption . getopt ( ) ) ) { string zknamespace = commandline . getoptionvalue ( zookeepernamespaceoption . getopt ( ) ) ; resultingconfiguration . setstring ( highavailabilityoptions . ha_cluster_id , zknamespace ) ; } return resultingconfiguration ; }	Override configuration settings by specified command line options.
private string getinternal ( string key ) { preconditions . checkargument ( configuredoptions . containskey ( key ) , str_ + key + str_ ) ; return configuredoptions . get ( key ) ; }	Returns the value in string format with the given key.
protected boolean increasebackoff ( ) {	Increases the current backoff and returns whether the operation was successful.
public static final boolean delimiternext ( byte [ ] bytes , int startpos , byte [ ] delim ) { for ( int pos = num_ ; pos < delim . length ; pos ++ ) {	Checks if the delimiter starts at the given start position of the byte array.Attention: This method assumes that enough characters follow the start position for the delimiter check!.
public static final boolean endswithdelimiter ( byte [ ] bytes , int endpos , byte [ ] delim ) { if ( endpos < delim . length - num_ ) { return bool_ ; } for ( int pos = num_ ; pos < delim . length ; ++ pos ) { if ( delim [ pos ] != bytes [ endpos - delim . length + num_ + pos ] ) { return bool_ ; } } return bool_ ; }	Checks if the given bytes ends with the delimiter at the given end position.
protected final int nextstringendpos ( byte [ ] bytes , int startpos , int limit , byte [ ] delimiter ) { int endpos = startpos ; final int delimlimit = limit - delimiter . length + num_ ; while ( endpos < limit ) { if ( endpos < delimlimit && delimiternext ( bytes , endpos , delimiter ) ) { break ; } endpos ++ ; } if ( endpos == startpos ) { seterrorstate ( parseerrorstate . empty_column ) ; return - num_ ; } return endpos ; }	Returns the end position of a string.
protected static final int nextstringlength ( byte [ ] bytes , int startpos , int length , char delimiter ) { if ( length <= num_ ) { throw new illegalargumentexception ( str_ ) ; } int limitedlength = num_ ; final byte delbyte = ( byte ) delimiter ; while ( limitedlength < length && bytes [ startpos + limitedlength ] != delbyte ) { limitedlength ++ ; } return limitedlength ; }	Returns the length of a string.
public static < t > class < fieldparser < t > > getparserfortype ( class < t > type ) { class < ? extends fieldparser < ? > > parser = parsers . get ( type ) ; if ( parser == null ) { return null ; } else { @ suppresswarnings ( str_ ) class < fieldparser < t > > typedparser = ( class < fieldparser < t > > ) parser ; return typedparser ; } }	Gets the parser for the type specified by the given class.
protected void reportallelementkeygroups ( ) { preconditions . checkstate ( partitioningsource . length >= numberofelements ) ; for ( int i = num_ ; i < numberofelements ; ++ i ) { int keygroup = keygrouprangeassignment . assigntokeygroup ( keyextractorfunction . extractkeyfromelement ( partitioningsource [ i ] ) , totalkeygroups ) ; reportkeygroupofelementatindex ( i , keygroup ) ; } }	This method iterates over the input data and reports the key-group for each element.
protected void reportkeygroupofelementatindex ( int index , int keygroup ) { final int keygroupindex = keygroup - firstkeygroup ; elementkeygroups [ index ] = keygroupindex ; ++ counterhistogram [ keygroupindex ] ; }	This method reports in the bookkeeping data that the element at the given index belongs to the given key-group.
@ override public void open ( runtimecontext runtimecontext ) { this . runtimecontext = runtimecontext ; localratebytespersecond = globalratebytespersecond / runtimecontext . getnumberofparallelsubtasks ( ) ; this . ratelimiter = ratelimiter . create ( localratebytespersecond ) ; }	Creates a rate limiter with the runtime context provided.
protected static void validatezookeeperconfig ( properties props ) { if ( props . getproperty ( str_ ) == null ) { throw new illegalargumentexception ( str_ ) ; } if ( props . getproperty ( consumerconfig . group_id_config ) == null ) { throw new illegalargumentexception ( str_ + consumerconfig . group_id_config + str_ ) ; } try {	Validate the ZK configuration, checking for required parameters.
private static void validateautooffsetresetvalue ( properties config ) { final string val = config . getproperty ( consumerconfig . auto_offset_reset_config , str_ ) ; if ( ! ( val . equals ( str_ ) || val . equals ( str_ ) || val . equals ( str_ ) || val . equals ( str_ ) ) ) {	Check for invalid "auto.offset.reset" values.
public boolean iscanceledorfailed ( ) { return executionstate == executionstate . canceling || executionstate == executionstate . canceled || executionstate == executionstate . failed ; }	Checks whether the task has failed, is canceled, or is being canceled at the moment.
private void releasenetworkresources ( ) { log . debug ( str_ , tasknamewithsubtask , getexecutionstate ( ) ) ; for ( resultpartition partition : producedpartitions ) { taskeventdispatcher . unregisterpartition ( partition . getpartitionid ( ) ) ; if ( iscanceledorfailed ( ) ) { partition . fail ( getfailurecause ( ) ) ; } } closenetworkresources ( ) ; }	Releases network resources before task exits.
private boolean transitionstate ( executionstate currentstate , executionstate newstate , throwable cause ) { if ( state_updater . compareandset ( this , currentstate , newstate ) ) { if ( cause == null ) { log . info ( str_ , tasknamewithsubtask , executionid , currentstate , newstate ) ; } else { log . info ( str_ , tasknamewithsubtask , executionid , currentstate , newstate , cause ) ; } return bool_ ; } else { return bool_ ; } }	Try to transition the execution state from the current state to the new state.
public void triggercheckpointbarrier ( final long checkpointid , final long checkpointtimestamp , final checkpointoptions checkpointoptions , final boolean advancetoendofeventtime ) { final abstractinvokable invokable = this . invokable ; final checkpointmetadata checkpointmetadata = new checkpointmetadata ( checkpointid , checkpointtimestamp ) ; if ( executionstate == executionstate . running && invokable != null ) {	Calls the invokable to trigger a checkpoint.
private void executeasynccallrunnable ( runnable runnable , string callname , boolean blocking ) {	Utility method to dispatch an asynchronous call on the invokable.
public static < k , v > mergeresult < k , v > mergerightintoleft ( linkedoptionalmap < k , v > left , linkedoptionalmap < k , v > right ) { linkedoptionalmap < k , v > merged = new linkedoptionalmap < > ( left ) ; merged . putall ( right ) ; return new mergeresult < > ( merged , isleftprefixofright ( left , right ) ) ; }	Tries to merges the keys and the values of .
public set < string > absentkeysorvalues ( ) { return underlyingmap . entryset ( ) . stream ( ) . filter ( linkedoptionalmap :: keyorvalueisabsent ) . map ( entry :: getkey ) . collect ( collectors . tocollection ( linkedhashset :: new ) ) ; }	Returns the key names of any keys or values that are absent.
public boolean hasabsentkeysorvalues ( ) { for ( entry < string , keyvalue < k , v > > entry : underlyingmap . entryset ( ) ) { if ( keyorvalueisabsent ( entry ) ) { return bool_ ; } } return bool_ ; }	Checks whether there are entries with absent keys or values.
public void adddiscoveredpartitions ( list < kafkatopicpartition > newpartitions ) throws ioexception , classnotfoundexception { list < kafkatopicpartitionstate < kph > > newpartitionstates = createpartitionstateholders ( newpartitions , kafkatopicpartitionstatesentinel . earliest_offset , timestampwatermarkmode , watermarksperiodic , watermarkspunctuated , usercodeclassloader ) ; if ( usemetrics ) { registeroffsetmetrics ( consumermetricgroup , newpartitionstates ) ; } for ( kafkatopicpartitionstate < kph > newpartitionstate : newpartitionstates ) {	Adds a list of newly discovered partitions to the fetcher for consuming. This method creates the partition state holder for each new partition, using{.
public hashmap < kafkatopicpartition , long > snapshotcurrentstate ( ) {	Takes a snapshot of the partition offsets.
protected void emitrecord ( t record , kafkatopicpartitionstate < kph > partitionstate , long offset ) throws exception { if ( record != null ) { if ( timestampwatermarkmode == no_timestamps_watermarks ) {	Emits a record without attaching an existing timestamp to it.
protected void emitrecordwithtimestamp ( t record , kafkatopicpartitionstate < kph > partitionstate , long offset , long timestamp ) throws exception { if ( record != null ) { if ( timestampwatermarkmode == no_timestamps_watermarks ) {	Emits a record attaching a timestamp to it.
private void emitrecordwithtimestampandperiodicwatermark ( t record , kafkatopicpartitionstate < kph > partitionstate , long offset , long kafkaeventtimestamp ) { @ suppresswarnings ( str_ ) final kafkatopicpartitionstatewithperiodicwatermarks < t , kph > withwatermarksstate = ( kafkatopicpartitionstatewithperiodicwatermarks < t , kph > ) partitionstate ;	Record emission, if a timestamp will be attached from an assigner that isalso a periodic watermark generator.
private void emitrecordwithtimestampandpunctuatedwatermark ( t record , kafkatopicpartitionstate < kph > partitionstate , long offset , long kafkaeventtimestamp ) { @ suppresswarnings ( str_ ) final kafkatopicpartitionstatewithpunctuatedwatermarks < t , kph > withwatermarksstate = ( kafkatopicpartitionstatewithpunctuatedwatermarks < t , kph > ) partitionstate ;	Record emission, if a timestamp will be attached from an assigner that isalso a punctuated watermark generator.
private void updateminpunctuatedwatermark ( watermark nextwatermark ) { if ( nextwatermark . gettimestamp ( ) > maxwatermarksofar ) { long newmin = long . max_value ; for ( kafkatopicpartitionstate < ? > state : subscribedpartitionstates ) { @ suppresswarnings ( str_ ) final kafkatopicpartitionstatewithpunctuatedwatermarks < t , kph > withwatermarksstate = ( kafkatopicpartitionstatewithpunctuatedwatermarks < t , kph > ) state ; newmin = math . min ( newmin , withwatermarksstate . getcurrentpartitionwatermark ( ) ) ; }	Checks whether a new per-partition watermark is also a new cross-partition watermark.
public elasticsearch host ( string hostname , int port , string protocol ) { final host host = new host ( preconditions . checknotnull ( hostname ) , port , preconditions . checknotnull ( protocol ) ) ; hosts . add ( host ) ; return this ; }	Adds an Elasticsearch host to connect to.
public elasticsearch failurehandlercustom ( class < ? extends actionrequestfailurehandler > failurehandlerclass ) { internalproperties . putstring ( connector_failure_handler , elasticsearchvalidator . connector_failure_handler_value_custom ) ; internalproperties . putclass ( connector_failure_handler_class , failurehandlerclass ) ; return this ; }	Configures a failure handling strategy in case a request to Elasticsearch fails. This strategy allows for custom failure handling using a {.
public elasticsearch bulkflushmaxsize ( string maxsize ) { internalproperties . putmemorysize ( connector_bulk_flush_max_size , memorysize . parse ( maxsize , memorysize . memoryunit . bytes ) ) ; return this ; }	Configures how to buffer elements before sending them in bulk to the cluster for efficiency. Sets the maximum size of buffered actions per bulk request (using the syntax of {.
public set < string > generateidstoabort ( ) { set < string > idstoabort = new hashset < > ( ) ; for ( int i = num_ ; i < safescaledownfactor ; i ++ ) { idstoabort . addall ( generateidstouse ( i * poolsize * totalnumberofsubtasks ) ) ; } return idstoabort ; }	If we have to abort previous transactional id in case of restart after a failure BEFORE first checkpointcompleted, we don't know what was the parallelism used in previous attempt.
@ override public void registertablesource ( string name ) { preconditions . checknotnull ( name ) ; tablesource < ? > tablesource = tablefactoryutil . findandcreatetablesource ( this ) ; tableenv . registertablesource ( name , tablesource ) ; }	Searches for the specified table source, configures it accordingly, and registers it asa table under the given name.
@ override public void registertablesink ( string name ) { preconditions . checknotnull ( name ) ; tablesink < ? > tablesink = tablefactoryutil . findandcreatetablesink ( this ) ; tableenv . registertablesink ( name , tablesink ) ; }	Searches for the specified table sink, configures it accordingly, and registers it asa table under the given name.
@ override public d withformat ( formatdescriptor format ) { formatdescriptor = optional . of ( preconditions . checknotnull ( format ) ) ; return ( d ) this ; }	Specifies the format that defines how to read data from a connector.
@ override public d withschema ( schema schema ) { schemadescriptor = optional . of ( preconditions . checknotnull ( schema ) ) ; return ( d ) this ; }	Specifies the resulting table schema.
private list < map < streamstatehandle , operatorstatehandle > > initmergemaplist ( list < list < operatorstatehandle > > parallelsubtaskstates ) { int parallelism = parallelsubtaskstates . size ( ) ; final list < map < streamstatehandle , operatorstatehandle > > mergemaplist = new arraylist < > ( parallelism ) ; for ( list < operatorstatehandle > previousparallelsubtaskstate : parallelsubtaskstates ) { mergemaplist . add ( previousparallelsubtaskstate . stream ( ) . collect ( collectors . tomap ( operatorstatehandle :: getdelegatestatehandle , function . identity ( ) ) ) ) ; } return mergemaplist ; }	Init the the list of StreamStateHandle -> OperatorStateHandle map with given parallelSubtaskStates when parallelism not changed.
private map < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > collectunionstates ( list < list < operatorstatehandle > > parallelsubtaskstates ) { map < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > unionstates = new hashmap < > ( parallelsubtaskstates . size ( ) ) ; for ( list < operatorstatehandle > subtaskstate : parallelsubtaskstates ) { for ( operatorstatehandle operatorstatehandle : subtaskstate ) { if ( operatorstatehandle == null ) { continue ; } final set < map . entry < string , operatorstatehandle . statemetainfo > > partitionoffsetentries = operatorstatehandle . getstatenametopartitionoffsets ( ) . entryset ( ) ; partitionoffsetentries . stream ( ) . filter ( entry -> entry . getvalue ( ) . getdistributionmode ( ) . equals ( operatorstatehandle . mode . union ) ) . foreach ( entry -> { list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > statelocations = unionstates . computeifabsent ( entry . getkey ( ) , k -> new arraylist < > ( parallelsubtaskstates . size ( ) * partitionoffsetentries . size ( ) ) ) ; statelocations . add ( tuple2 . of ( operatorstatehandle . getdelegatestatehandle ( ) , entry . getvalue ( ) ) ) ; } ) ; } } return unionstates ; }	Collect union states from given parallelSubtaskStates.
@ suppresswarnings ( str_ ) private groupbystatenameresults groupbystatemode ( list < list < operatorstatehandle > > previousparallelsubtaskstates ) {	Group by the different named states.
private list < map < streamstatehandle , operatorstatehandle > > repartition ( groupbystatenameresults nametostatebymode , int newparallelism ) {	Repartition all named states.
private void repartitionsplitstate ( map < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > nametodistributestate , int newparallelism , list < map < streamstatehandle , operatorstatehandle > > mergemaplist ) { int startparallelop = num_ ;	Repartition SPLIT_DISTRIBUTE state.
private void repartitionunionstate ( map < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > unionstate , list < map < streamstatehandle , operatorstatehandle > > mergemaplist ) { for ( map < streamstatehandle , operatorstatehandle > mergemap : mergemaplist ) { for ( map . entry < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > e : unionstate . entryset ( ) ) { for ( tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > handlewithmetainfo : e . getvalue ( ) ) { operatorstatehandle operatorstatehandle = mergemap . get ( handlewithmetainfo . f0 ) ; if ( operatorstatehandle == null ) { operatorstatehandle = new operatorstreamstatehandle ( new hashmap < > ( unionstate . size ( ) ) , handlewithmetainfo . f0 ) ; mergemap . put ( handlewithmetainfo . f0 , operatorstatehandle ) ; } operatorstatehandle . getstatenametopartitionoffsets ( ) . put ( e . getkey ( ) , handlewithmetainfo . f1 ) ; } } } }	Repartition UNION state.
private void repartitionbroadcaststate ( map < string , list < tuple2 < streamstatehandle , operatorstatehandle . statemetainfo > > > broadcaststate , list < map < streamstatehandle , operatorstatehandle > > mergemaplist ) { int newparallelism = mergemaplist . size ( ) ; for ( int i = num_ ; i < newparallelism ; ++ i ) { final map < streamstatehandle , operatorstatehandle > mergemap = mergemaplist . get ( i ) ;	Repartition BROADCAST state.
private int binarysearch ( t record ) { int low = num_ ; int high = this . boundaries . length - num_ ; typecomparator . extractkeys ( record , keys , num_ ) ; while ( low <= high ) { final int mid = ( low + high ) > > > num_ ; final int result = comparekeys ( flatcomparators , keys , this . boundaries [ mid ] ) ; if ( result > num_ ) { low = mid + num_ ; } else if ( result < num_ ) { high = mid - num_ ; } else { return mid ; } }	Search the range index of input record.
public void serializetopageswithoutlength ( binaryrow record , abstractpagedoutputview out ) throws ioexception { int remainsize = record . getsizeinbytes ( ) ; int posinsegofrecord = record . getoffset ( ) ; int segmentsize = record . getsegments ( ) [ num_ ] . size ( ) ; for ( memorysegment segofrecord : record . getsegments ( ) ) { int nwrite = math . min ( segmentsize - posinsegofrecord , remainsize ) ; assert nwrite > num_ ; out . write ( segofrecord , posinsegofrecord , nwrite ) ;	Serialize row to pages without row length.
public void copyfrompagestoview ( abstractpagedinputview source , dataoutputview target ) throws ioexception { checkskipreadforfixlengthpart ( source ) ; int length = source . readint ( ) ; target . writeint ( length ) ; target . write ( source , length ) ; }	Copy a binaryRow which stored in paged input view to output view.
public void setdriverkeyinfo ( fieldlist keys , int id ) { this . setdriverkeyinfo ( keys , gettruearray ( keys . size ( ) ) , id ) ; }	Sets the key field indexes for the specified driver comparator.
public void setdriverkeyinfo ( fieldlist keys , boolean [ ] sortorder , int id ) { if ( id < num_ || id >= driverkeys . length ) { throw new compilerexception ( str_ + super . getdriverstrategy ( ) . getnumrequiredcomparators ( ) + str_ ) ; } this . driverkeys [ id ] = keys ; this . driversortorders [ id ] = sortorder ; }	Sets the key field information for the specified driver comparator.
private void addcontender ( embeddedleaderelectionservice service , leadercontender contender ) { synchronized ( lock ) { checkstate ( ! shutdown , str_ ) ; checkstate ( ! service . running , str_ ) ; try { if ( ! allleadercontenders . add ( service ) ) { throw new illegalstateexception ( str_ ) ; } service . contender = contender ; service . running = bool_ ; updateleader ( ) . whencomplete ( ( avoid , throwable ) -> { if ( throwable != null ) { fatalerror ( throwable ) ; } } ) ; } catch ( throwable t ) { fatalerror ( t ) ; } } }	Callback from leader contenders when they start their service.
private void removecontender ( embeddedleaderelectionservice service ) { synchronized ( lock ) {	Callback from leader contenders when they stop their service.
private void confirmleader ( final embeddedleaderelectionservice service , final uuid leadersessionid ) { synchronized ( lock ) {	Callback from leader contenders when they confirm a leader grant.
private static collection < string > getavailablemetrics ( collection < ? extends metricstore . componentmetricstore > stores ) { set < string > uniquemetrics = new hashset < > ( num_ ) ; for ( metricstore . componentmetricstore store : stores ) { uniquemetrics . addall ( store . metrics . keyset ( ) ) ; } return uniquemetrics ; }	Returns a JSON string containing a list of all available metrics in the given stores.
private aggregatedmetricsresponsebody getaggregatedmetricvalues ( collection < ? extends metricstore . componentmetricstore > stores , list < string > requestedmetrics , metricaccumulatorfactory requestedaggregationsfactories ) { collection < aggregatedmetric > aggregatedmetrics = new arraylist < > ( requestedmetrics . size ( ) ) ; for ( string requestedmetric : requestedmetrics ) { final collection < double > values = new arraylist < > ( stores . size ( ) ) ; try { for ( metricstore . componentmetricstore store : stores ) { string stringvalue = store . metrics . get ( requestedmetric ) ; if ( stringvalue != null ) { values . add ( double . valueof ( stringvalue ) ) ; } } } catch ( numberformatexception nfe ) { log . warn ( str_ , requestedmetric , nfe ) ;	Extracts and aggregates all requested metrics from the given metric stores, and maps the result to a JSON string.
private static void setdeserializer ( properties props ) { final string desername = bytearraydeserializer . class . getname ( ) ; object keydeser = props . get ( consumerconfig . key_deserializer_class_config ) ; object valdeser = props . get ( consumerconfig . value_deserializer_class_config ) ; if ( keydeser != null && ! keydeser . equals ( desername ) ) { log . warn ( str_ , consumerconfig . key_deserializer_class_config ) ; } if ( valdeser != null && ! valdeser . equals ( desername ) ) { log . warn ( str_ , consumerconfig . value_deserializer_class_config ) ; } props . put ( consumerconfig . key_deserializer_class_config , desername ) ; props . put ( consumerconfig . value_deserializer_class_config , desername ) ; }	Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.
public void persist ( ) throws exception { if ( ! mapping . equals ( initialmapping ) ) { state . clear ( ) ; for ( map . entry < w , w > window : mapping . entryset ( ) ) { state . add ( new tuple2 < > ( window . getkey ( ) , window . getvalue ( ) ) ) ; } } }	Persist the updated mapping to the given state if the mapping changed sinceinitialization.
private org . apache . hadoop . conf . configuration loadhadoopconfigfromflink ( ) { org . apache . hadoop . conf . configuration hadoopconfig = new org . apache . hadoop . conf . configuration ( ) ; for ( string key : flinkconfig . keyset ( ) ) { for ( string prefix : flinkconfigprefixes ) { if ( key . startswith ( prefix ) ) { string newkey = hadoopconfigprefix + key . substring ( prefix . length ( ) ) ; string newvalue = fixhadoopconfig ( key , flinkconfig . getstring ( key , null ) ) ; hadoopconfig . set ( newkey , newvalue ) ; log . debug ( str_ , key , newkey ) ; } } } return hadoopconfig ; }	add additional config entries from the Flink config to the Hadoop config.
private static boolean waituntilleaseisrevoked ( final filesystem fs , final path path ) throws ioexception { preconditions . checkstate ( fs instanceof distributedfilesystem ) ; final distributedfilesystem dfs = ( distributedfilesystem ) fs ; dfs . recoverlease ( path ) ; final deadline deadline = deadline . now ( ) . plus ( duration . ofmillis ( lease_timeout ) ) ; final stopwatch sw = new stopwatch ( ) ; sw . start ( ) ; boolean isclosed = dfs . isfileclosed ( path ) ; while ( ! isclosed && deadline . hastimeleft ( ) ) { try { thread . sleep ( num_ ) ; } catch ( interruptedexception e1 ) { throw new ioexception ( str_ , e1 ) ; } isclosed = dfs . isfileclosed ( path ) ; } return isclosed ; }	Called when resuming execution after a failure and waits until the leaseof the file we are resuming is free.
@ override public completablefuture < void > onstop ( ) { log . info ( str_ , getaddress ( ) ) ; throwable throwable = null ; if ( resourcemanagerconnection != null ) { resourcemanagerconnection . close ( ) ; } for ( jobmanagerconnection jobmanagerconnection : jobmanagerconnections . values ( ) ) { try { disassociatefromjobmanager ( jobmanagerconnection , new flinkexception ( str_ ) ) ; } catch ( throwable t ) { throwable = exceptionutils . firstorsuppressed ( t , throwable ) ; } } jobmanagerheartbeatmanager . stop ( ) ; resourcemanagerheartbeatmanager . stop ( ) ; try { stoptaskexecutorservices ( ) ; } catch ( exception e ) { throwable = exceptionutils . firstorsuppressed ( e , throwable ) ; } if ( throwable != null ) { return futureutils . completedexceptionally ( new flinkexception ( str_ , throwable ) ) ; } else { log . info ( str_ , getaddress ( ) ) ; return completablefuture . completedfuture ( null ) ; } }	Called to shut down the TaskManager.
public optional < operatorbackpressurestats > getoperatorbackpressurestats ( executionjobvertex vertex ) { synchronized ( lock ) { final operatorbackpressurestats stats = operatorstatscache . getifpresent ( vertex ) ; if ( stats == null || backpressurestatsrefreshinterval <= system . currenttimemillis ( ) - stats . getendtimestamp ( ) ) { triggerstacktracesampleinternal ( vertex ) ; } return optional . ofnullable ( stats ) ; } }	Returns back pressure statistics for a operator.
private boolean triggerstacktracesampleinternal ( final executionjobvertex vertex ) { assert ( thread . holdslock ( lock ) ) ; if ( shutdown ) { return bool_ ; } if ( ! pendingstats . contains ( vertex ) && ! vertex . getgraph ( ) . getstate ( ) . isgloballyterminalstate ( ) ) { executor executor = vertex . getgraph ( ) . getfutureexecutor ( ) ;	Triggers a stack trace sample for a operator to gather the back pressurestatistics.
private static string [ ] getcldblocations ( string authority ) throws ioexception {	Retrieves the CLDB locations for the given MapR cluster name.
@ suppresswarnings ( str_ ) @ publicevolving public static < x > primitivearraytypeinfo < x > getinfofor ( class < x > type ) { if ( ! type . isarray ( ) ) { throw new invalidtypesexception ( str_ ) ; }	Tries to get the PrimitiveArrayTypeInfo for an array.
static void adjustautocommitconfig ( properties properties , offsetcommitmode offsetcommitmode ) { if ( offsetcommitmode == offsetcommitmode . on_checkpoints || offsetcommitmode == offsetcommitmode . disabled ) { properties . setproperty ( consumerconfig . enable_auto_commit_config , str_ ) ; } }	Make sure that auto commit is disabled when our offset commit mode is ON_CHECKPOINTS.This overwrites whatever setting the user configured in the properties.
protected flinkkafkaconsumerbase < t > setstartfromtimestamp ( long startupoffsetstimestamp ) { checkargument ( startupoffsetstimestamp >= num_ , str_ ) ; long currenttimestamp = system . currenttimemillis ( ) ; checkargument ( startupoffsetstimestamp <= currenttimestamp , str_ , startupoffsetstimestamp , currenttimestamp ) ; this . startupmode = startupmode . timestamp ; this . startupoffsetstimestamp = startupoffsetstimestamp ; this . specificstartupoffsets = null ; return this ; }	Version-specific subclasses which can expose the functionality should override and allow public access.
@ visiblefortesting public sharedstateregistrykey createsharedstateregistrykeyfromfilename ( statehandleid shid ) { return new sharedstateregistrykey ( string . valueof ( backendidentifier ) + str_ + keygrouprange , shid ) ; }	Create a unique key to register one of our shared state handles.
public static < l , r > either < l , r > left ( l value ) { return new left < l , r > ( value ) ; }	Create a Left value of Either.
public static < l , r > either < l , r > right ( r value ) { return new right < l , r > ( value ) ; }	Create a Right value of Either.
public throwable unwrap ( ) { throwable cause = getcause ( ) ; return ( cause instanceof wrappingruntimeexception ) ? ( ( wrappingruntimeexception ) cause ) . unwrap ( ) : cause ; }	Recursively unwraps this WrappingRuntimeException and its causes, getting the firstnon wrapping exception.
private kryo getkryoinstance ( ) { try {	Returns the Chill Kryo Serializer which is implicitly added to the classpath via flink-runtime.Falls back to the default Kryo serializer if it can't be found.
private static linkedhashmap < string , kryoregistration > buildkryoregistrations ( class < ? > serializedtype , linkedhashset < class < ? > > registeredtypes , linkedhashmap < class < ? > , class < ? extends serializer < ? > > > registeredtypeswithserializerclasses , linkedhashmap < class < ? > , executionconfig . serializableserializer < ? > > registeredtypeswithserializers ) { final linkedhashmap < string , kryoregistration > kryoregistrations = new linkedhashmap < > ( ) ; kryoregistrations . put ( serializedtype . getname ( ) , new kryoregistration ( serializedtype ) ) ; for ( class < ? > registeredtype : checknotnull ( registeredtypes ) ) { kryoregistrations . put ( registeredtype . getname ( ) , new kryoregistration ( registeredtype ) ) ; } for ( map . entry < class < ? > , class < ? extends serializer < ? > > > registeredtypewithserializerclassentry : checknotnull ( registeredtypeswithserializerclasses ) . entryset ( ) ) { kryoregistrations . put ( registeredtypewithserializerclassentry . getkey ( ) . getname ( ) , new kryoregistration ( registeredtypewithserializerclassentry . getkey ( ) , registeredtypewithserializerclassentry . getvalue ( ) ) ) ; } for ( map . entry < class < ? > , executionconfig . serializableserializer < ? > > registeredtypewithserializerentry : checknotnull ( registeredtypeswithserializers ) . entryset ( ) ) { kryoregistrations . put ( registeredtypewithserializerentry . getkey ( ) . getname ( ) , new kryoregistration ( registeredtypewithserializerentry . getkey ( ) , registeredtypewithserializerentry . getvalue ( ) ) ) ; }	Utility method that takes lists of registered types and their serializers, and resolvethem into a single list such that the result will resemble the final registrationresult in Kryo.
@ suppresswarnings ( str_ ) public < k , vv , ev > graph < k , vv , ev > types ( class < k > vertexkey , class < vv > vertexvalue , class < ev > edgevalue ) { if ( edgereader == null ) { throw new runtimeexception ( str_ ) ; } dataset < tuple3 < k , k , ev > > edges = edgereader . types ( vertexkey , vertexkey , edgevalue ) ;	Creates a Graph from CSV input with vertex values and edge values.The vertex values are specified through a vertices input file or a user-defined map function.
public < k , ev > graph < k , nullvalue , ev > edgetypes ( class < k > vertexkey , class < ev > edgevalue ) { if ( edgereader == null ) { throw new runtimeexception ( str_ ) ; } dataset < tuple3 < k , k , ev > > edges = edgereader . types ( vertexkey , vertexkey , edgevalue ) . name ( graphcsvreader . class . getname ( ) ) ; return graph . fromtupledataset ( edges , executioncontext ) ; }	Creates a Graph from CSV input with edge values, but without vertex values.
public < k > graph < k , nullvalue , nullvalue > keytype ( class < k > vertexkey ) { if ( edgereader == null ) { throw new runtimeexception ( str_ ) ; } dataset < edge < k , nullvalue > > edges = edgereader . types ( vertexkey , vertexkey ) . name ( graphcsvreader . class . getname ( ) ) . map ( new tuple2toedgemap < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( edges , executioncontext ) ; }	Creates a Graph from CSV input without vertex values or edge values.
@ suppresswarnings ( { str_ , str_ } ) public < k , vv > graph < k , vv , nullvalue > vertextypes ( class < k > vertexkey , class < vv > vertexvalue ) { if ( edgereader == null ) { throw new runtimeexception ( str_ ) ; } dataset < edge < k , nullvalue > > edges = edgereader . types ( vertexkey , vertexkey ) . name ( graphcsvreader . class . getname ( ) ) . map ( new tuple2toedgemap < > ( ) ) . name ( str_ ) ;	Creates a Graph from CSV input without edge values.The vertex values are specified through a vertices input file or a user-defined map function.If no vertices input file is provided, the vertex IDs are automatically created from the edgesinput file.
public static void mergehadoopconf ( jobconf jobconf ) {	Merge HadoopConfiguration into JobConf.
@ suppresswarnings ( str_ ) public completablefuture < stacktracesample > triggerstacktracesample ( executionvertex [ ] taskstosample , int numsamples , time delaybetweensamples , int maxstacktracedepth ) { checknotnull ( taskstosample , str_ ) ; checkargument ( taskstosample . length >= num_ , str_ ) ; checkargument ( numsamples >= num_ , str_ ) ; checkargument ( maxstacktracedepth >= num_ , str_ ) ;	Triggers a stack trace sample to all tasks.
public void cancelstacktracesample ( int sampleid , throwable cause ) { synchronized ( lock ) { if ( isshutdown ) { return ; } pendingstacktracesample sample = pendingsamples . remove ( sampleid ) ; if ( sample != null ) { if ( cause != null ) { log . info ( str_ + sampleid , cause ) ; } else { log . info ( str_ , sampleid ) ; } sample . discard ( cause ) ; rememberrecentsampleid ( sampleid ) ; } } }	Cancels a pending sample.
public void shutdown ( ) { synchronized ( lock ) { if ( ! isshutdown ) { log . info ( str_ ) ; for ( pendingstacktracesample pending : pendingsamples . values ( ) ) { pending . discard ( new runtimeexception ( str_ ) ) ; } pendingsamples . clear ( ) ; isshutdown = bool_ ; } } }	Shuts down the coordinator.
public void collectstacktraces ( int sampleid , executionattemptid executionid , list < stacktraceelement [ ] > stacktraces ) { synchronized ( lock ) { if ( isshutdown ) { return ; } if ( log . isdebugenabled ( ) ) { log . debug ( str_ , sampleid , executionid ) ; } pendingstacktracesample pending = pendingsamples . get ( sampleid ) ; if ( pending != null ) { pending . collectstacktraces ( executionid , stacktraces ) ;	Collects stack traces of a task.
public < out > datastreamsource < out > fromcollection ( collection < out > data , typeinformation < out > typeinfo ) { preconditions . checknotnull ( data , str_ ) ;	Creates a data stream from the given non-empty collection.
private < out > datastreamsource < out > fromparallelcollection ( splittableiterator < out > iterator , typeinformation < out > typeinfo , string operatorname ) { return addsource ( new fromsplittableiteratorfunction < > ( iterator ) , operatorname , typeinfo ) ; }	private helper for passing different names.
public static < t > dataset < longvalue > count ( dataset < t > input ) { return input . map ( new mapto < > ( new longvalue ( num_ ) ) ) . returns ( long_value_type_info ) . name ( str_ ) . reduce ( new addlongvalue ( ) ) . name ( str_ ) ; }	Count the number of elements in a DataSet.
public static void install ( securityconfiguration config ) throws exception {	Installs a process-wide security configuration.
private static void writeheader ( final bytebuf buf , final messagetype messagetype ) { buf . writeint ( version ) ; buf . writeint ( messagetype . ordinal ( ) ) ; }	Helper for serializing the header.
private static bytebuf writepayload ( final bytebufallocator alloc , final long requestid , final messagetype messagetype , final byte [ ] payload ) { final int framelength = header_length + request_id_size + payload . length ; final bytebuf buf = alloc . iobuffer ( framelength + integer . bytes ) ; buf . writeint ( framelength ) ; writeheader ( buf , messagetype ) ; buf . writelong ( requestid ) ; buf . writebytes ( payload ) ; return buf ; }	Helper for serializing the messages.
byte [ ] [ ] getfamilykeys ( ) { charset c = charset . forname ( charset ) ; byte [ ] [ ] familykeys = new byte [ this . familymap . size ( ) ] [ ] ; int i = num_ ; for ( string name : this . familymap . keyset ( ) ) { familykeys [ i ++ ] = name . getbytes ( c ) ; } return familykeys ; }	Returns the HBase identifiers of all registered column families.
string [ ] getqualifiernames ( string family ) { map < string , typeinformation < ? > > qualifiermap = familymap . get ( family ) ; if ( qualifiermap == null ) { throw new illegalargumentexception ( str_ + family + str_ ) ; } string [ ] qualifiernames = new string [ qualifiermap . size ( ) ] ; int i = num_ ; for ( string qualifier : qualifiermap . keyset ( ) ) { qualifiernames [ i ] = qualifier ; i ++ ; } return qualifiernames ; }	Returns the names of all registered column qualifiers of a specific column family.
byte [ ] [ ] getqualifierkeys ( string family ) { map < string , typeinformation < ? > > qualifiermap = familymap . get ( family ) ; if ( qualifiermap == null ) { throw new illegalargumentexception ( str_ + family + str_ ) ; } charset c = charset . forname ( charset ) ; byte [ ] [ ] qualifierkeys = new byte [ qualifiermap . size ( ) ] [ ] ; int i = num_ ; for ( string name : qualifiermap . keyset ( ) ) { qualifierkeys [ i ++ ] = name . getbytes ( c ) ; } return qualifierkeys ; }	Returns the HBase identifiers of all registered column qualifiers for a specific column family.
typeinformation < ? > [ ] getqualifiertypes ( string family ) { map < string , typeinformation < ? > > qualifiermap = familymap . get ( family ) ; if ( qualifiermap == null ) { throw new illegalargumentexception ( str_ + family + str_ ) ; } typeinformation < ? > [ ] typeinformation = new typeinformation [ qualifiermap . size ( ) ] ; int i = num_ ; for ( typeinformation < ? > typeinfo : qualifiermap . values ( ) ) { typeinformation [ i ] = typeinfo ; i ++ ; } return typeinformation ; }	Returns the types of all registered column qualifiers of a specific column family.
@ publicevolving public string getstring ( configoption < string > configoption , string overridedefault ) { object o = getrawvaluefromoption ( configoption ) ; return o == null ? overridedefault : o . tostring ( ) ; }	Returns the value associated with the given config option as a string.If no value is mapped under any key of the option, it returns the specifieddefault instead of the option's default value.
@ publicevolving public int getinteger ( configoption < integer > configoption ) { object o = getvalueordefaultfromoption ( configoption ) ; return converttoint ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as an integer.
@ publicevolving public int getinteger ( configoption < integer > configoption , int overridedefault ) { object o = getrawvaluefromoption ( configoption ) ; if ( o == null ) { return overridedefault ; } return converttoint ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as an integer.If no value is mapped under any key of the option, it returns the specifieddefault instead of the option's default value.
@ publicevolving public long getlong ( configoption < long > configoption ) { object o = getvalueordefaultfromoption ( configoption ) ; return converttolong ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as a long integer.
@ publicevolving public long getlong ( configoption < long > configoption , long overridedefault ) { object o = getrawvaluefromoption ( configoption ) ; if ( o == null ) { return overridedefault ; } return converttolong ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as a long integer.If no value is mapped under any key of the option, it returns the specifieddefault instead of the option's default value.
@ publicevolving public boolean getboolean ( configoption < boolean > configoption ) { object o = getvalueordefaultfromoption ( configoption ) ; return converttoboolean ( o ) ; }	Returns the value associated with the given config option as a boolean.
@ publicevolving public boolean getboolean ( configoption < boolean > configoption , boolean overridedefault ) { object o = getrawvaluefromoption ( configoption ) ; if ( o == null ) { return overridedefault ; } return converttoboolean ( o ) ; }	Returns the value associated with the given config option as a boolean.If no value is mapped under any key of the option, it returns the specifieddefault instead of the option's default value.
@ publicevolving public float getfloat ( configoption < float > configoption ) { object o = getvalueordefaultfromoption ( configoption ) ; return converttofloat ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as a float.
@ publicevolving public float getfloat ( configoption < float > configoption , float overridedefault ) { object o = getrawvaluefromoption ( configoption ) ; if ( o == null ) { return overridedefault ; } return converttofloat ( o , configoption . defaultvalue ( ) ) ; }	Returns the value associated with the given config option as a float.If no value is mapped under any key of the option, it returns the specifieddefault instead of the option's default value.
@ publicevolving public string getvalue ( configoption < ? > configoption ) { object o = getvalueordefaultfromoption ( configoption ) ; return o == null ? null : o . tostring ( ) ; }	Returns the value associated with the given config option as a string.
@ publicevolving public < t extends enum < t > > t getenum ( final class < t > enumclass , final configoption < string > configoption ) { checknotnull ( enumclass , str_ ) ; checknotnull ( configoption , str_ ) ; final string configvalue = getstring ( configoption ) ; try { return enum . valueof ( enumclass , configvalue . touppercase ( locale . root ) ) ; } catch ( final illegalargumentexception | nullpointerexception e ) { final string errormessage = string . format ( str_ , configoption . key ( ) , arrays . tostring ( enumclass . getenumconstants ( ) ) , configvalue ) ; throw new illegalargumentexception ( errormessage , e ) ; } }	Returns the value associated with the given config option as an enum.
public void addall ( configuration other , string prefix ) { final stringbuilder bld = new stringbuilder ( ) ; bld . append ( prefix ) ; final int pl = bld . length ( ) ; synchronized ( this . confdata ) { synchronized ( other . confdata ) { for ( map . entry < string , object > entry : other . confdata . entryset ( ) ) { bld . setlength ( pl ) ; bld . append ( entry . getkey ( ) ) ; this . confdata . put ( bld . tostring ( ) , entry . getvalue ( ) ) ; } } } }	Adds all entries from the given configuration into this configuration.
@ publicevolving public boolean contains ( configoption < ? > configoption ) { synchronized ( this . confdata ) {	Checks whether there is an entry for the given config option.
public < t > boolean removeconfig ( configoption < t > configoption ) { synchronized ( this . confdata ) {	Removes given config option from the configuration.
@ override public void uploadpart ( refcountedfsoutputstream file ) throws ioexception {	Adds a part to the uploads without any size limitations.
@ override public s3recoverable snapshotandgetrecoverable ( @ nullable final refcountedfsoutputstream incompletepartfile ) throws ioexception { final string incompletepartobjectname = safelyuploadsmallpart ( incompletepartfile ) ;	Creates a snapshot of this MultiPartUpload, from which the upload can be resumed. Data buffered locally which is less than{.
public connectedstreams < in1 , in2 > keyby ( int keyposition1 , int keyposition2 ) { return new connectedstreams < > ( this . environment , inputstream1 . keyby ( keyposition1 ) , inputstream2 . keyby ( keyposition2 ) ) ; }	KeyBy operation for connected data stream.
public connectedstreams < in1 , in2 > keyby ( int [ ] keypositions1 , int [ ] keypositions2 ) { return new connectedstreams < > ( environment , inputstream1 . keyby ( keypositions1 ) , inputstream2 . keyby ( keypositions2 ) ) ; }	KeyBy operation for connected data stream.
public connectedstreams < in1 , in2 > keyby ( keyselector < in1 , ? > keyselector1 , keyselector < in2 , ? > keyselector2 ) { return new connectedstreams < > ( environment , inputstream1 . keyby ( keyselector1 ) , inputstream2 . keyby ( keyselector2 ) ) ; }	KeyBy operation for connected data stream.
public < key > connectedstreams < in1 , in2 > keyby ( keyselector < in1 , key > keyselector1 , keyselector < in2 , key > keyselector2 , typeinformation < key > keytype ) { return new connectedstreams < > ( environment , inputstream1 . keyby ( keyselector1 , keytype ) , inputstream2 . keyby ( keyselector2 , keytype ) ) ; }	KeyBy operation for connected data stream.
public list < memorysegment > close ( ) throws ioexception {	Closes this OutputView, closing the underlying writer and returning all memory segments.
public typeserializer < uk > getkeyserializer ( ) { final typeserializer < map < uk , uv > > rawserializer = getserializer ( ) ; if ( ! ( rawserializer instanceof mapserializer ) ) { throw new illegalstateexception ( str_ ) ; } return ( ( mapserializer < uk , uv > ) rawserializer ) . getkeyserializer ( ) ; }	Gets the serializer for the keys in the state.
protected boolean iselementlate ( streamrecord < in > element ) { return ( windowassigner . iseventtime ( ) ) && ( element . gettimestamp ( ) + allowedlateness <= internaltimerservice . currentwatermark ( ) ) ; }	Decide if a record is currently late, based on current watermark and allowed lateness.
protected void deletecleanuptimer ( w window ) { long cleanuptime = cleanuptime ( window ) ; if ( cleanuptime == long . max_value ) {	Deletes the cleanup timer set for the contents of the provided window.
public rowtime watermarksperiodicbounded ( long delay ) { internalproperties . putstring ( rowtime_watermarks_type , rowtime_watermarks_type_value_periodic_bounded ) ; internalproperties . putlong ( rowtime_watermarks_delay , delay ) ; return this ; }	Sets a built-in watermark strategy for rowtime attributes which are out-of-order by a boundedtime interval.
public map < string , accumulator < ? , ? > > deserializeuseraccumulators ( classloader classloader ) throws ioexception , classnotfoundexception { return useraccumulators . deserializevalue ( classloader ) ; }	Gets the user-defined accumulators values.
public void reset ( ) { nextwindow = null ; watermark = long . min_value ; triggerwindowstartindex = num_ ; emptywindowtriggered = bool_ ; resetbuffer ( ) ; }	Reset for next group.
public boolean hastriggerwindow ( ) { skipemptywindow ( ) ; preconditions . checkstate ( watermark == long . min_value || nextwindow != null , str_ ) ; return nextwindow != null && nextwindow . getend ( ) <= watermark ; }	Check if there are windows could be triggered according to the current watermark.
@ override public void usereventtriggered ( channelhandlercontext ctx , object msg ) throws exception { if ( msg instanceof remoteinputchannel ) { boolean triggerwrite = inputchannelswithcredit . isempty ( ) ; inputchannelswithcredit . add ( ( remoteinputchannel ) msg ) ; if ( triggerwrite ) { writeandflushnextmessageifpossible ( ctx . channel ( ) ) ; } } else { ctx . fireusereventtriggered ( msg ) ; } }	Triggered by notifying credit available in the client handler pipeline.
private void writeandflushnextmessageifpossible ( channel channel ) { if ( channelerror . get ( ) != null || ! channel . iswritable ( ) ) { return ; } while ( bool_ ) { remoteinputchannel inputchannel = inputchannelswithcredit . poll ( ) ;	Tries to write&flush unannounced credits for the next input channel in queue.
public list < kafkatopicpartitionleader > getpartitionleadersfortopics ( list < string > topics ) { list < kafkatopicpartitionleader > partitions = new linkedlist < > ( ) ; retryloop : for ( int retry = num_ ; retry < numretries ; retry ++ ) { brokersloop : for ( int arridx = num_ ; arridx < seedbrokeraddresses . length ; arridx ++ ) { log . info ( str_ , seedbrokeraddresses [ currentcontactseedbrokerindex ] , retry , numretries ) ; try {	Send request to Kafka to get partitions for topics.
private void usenextaddressasnewcontactseedbroker ( ) { if ( ++ currentcontactseedbrokerindex == seedbrokeraddresses . length ) { currentcontactseedbrokerindex = num_ ; } url newcontacturl = netutils . getcorrecthostnameport ( seedbrokeraddresses [ currentcontactseedbrokerindex ] ) ; this . consumer = new simpleconsumer ( newcontacturl . gethost ( ) , newcontacturl . getport ( ) , sotimeout , buffersize , dummyclientid ) ; }	Re-establish broker connection using the next available seed broker address.
private static node brokertonode ( broker broker ) { return new node ( broker . id ( ) , broker . host ( ) , broker . port ( ) ) ; }	Turn a broker instance into a node instance.
private static void validateseedbrokers ( string [ ] seedbrokers , exception exception ) { if ( ! ( exception instanceof closedchannelexception ) ) { return ; } int unknownhosts = num_ ; for ( string broker : seedbrokers ) { url brokerurl = netutils . getcorrecthostnameport ( broker . trim ( ) ) ; try { inetaddress . getbyname ( brokerurl . gethost ( ) ) ; } catch ( unknownhostexception e ) { unknownhosts ++ ; } }	Validate that at least one seed broker is valid in case of aClosedChannelException.
public static void maxnormalizedkey ( memorysegment target , int offset , int numbytes ) {	Max unsigned byte is -1.
public static void putdecimalnormalizedkey ( decimal record , memorysegment target , int offset , int len ) { assert record . getprecision ( ) <= decimal . max_compact_precision ; putlongnormalizedkey ( record . tounscaledlong ( ) , target , offset , len ) ; }	Just support the compact precision decimal.
public static void mergehadoopconf ( configuration hadoopconfig ) {	Merge HadoopConfiguration into Configuration.
public tablestats copy ( ) { tablestats copy = new tablestats ( this . rowcount ) ; for ( map . entry < string , columnstats > entry : this . colstats . entryset ( ) ) { copy . colstats . put ( entry . getkey ( ) , entry . getvalue ( ) . copy ( ) ) ; } return copy ; }	Create a deep copy of "this" instance.
private static linkedhashset < class < ? > > getregisteredsubclassesfromexecutionconfig ( class < ? > basepojoclass , executionconfig executionconfig ) { linkedhashset < class < ? > > subclassesinregistrationorder = new linkedhashset < > ( executionconfig . getregisteredpojotypes ( ) . size ( ) ) ; for ( class < ? > registeredclass : executionconfig . getregisteredpojotypes ( ) ) { if ( registeredclass . equals ( basepojoclass ) ) { continue ; } if ( ! basepojoclass . isassignablefrom ( registeredclass ) ) { continue ; } subclassesinregistrationorder . add ( registeredclass ) ; } return subclassesinregistrationorder ; }	Extracts the subclasses of the base POJO class registered in the execution config.
private static linkedhashmap < class < ? > , integer > createregisteredsubclasstags ( linkedhashset < class < ? > > registeredsubclasses ) { final linkedhashmap < class < ? > , integer > classtotag = new linkedhashmap < > ( ) ; int id = num_ ; for ( class < ? > registeredclass : registeredsubclasses ) { classtotag . put ( registeredclass , id ) ; id ++ ; } return classtotag ; }	Builds map of registered subclasses to their class tags.Class tags will be integers starting from 0, assigned incrementally with the order of provided subclasses.
private static typeserializer < ? > [ ] createregisteredsubclassserializers ( linkedhashset < class < ? > > registeredsubclasses , executionconfig executionconfig ) { final typeserializer < ? > [ ] subclassserializers = new typeserializer [ registeredsubclasses . size ( ) ] ; int i = num_ ; for ( class < ? > registeredclass : registeredsubclasses ) { subclassserializers [ i ] = typeextractor . createtypeinfo ( registeredclass ) . createserializer ( executionconfig ) ; i ++ ; } return subclassserializers ; }	Creates an array of serializers for provided list of registered subclasses.Order of returned serializers will correspond to order of provided subclasses.
typeserializer < ? > getsubclassserializer ( class < ? > subclass ) { typeserializer < ? > result = subclassserializercache . get ( subclass ) ; if ( result == null ) { result = createsubclassserializer ( subclass ) ; subclassserializercache . put ( subclass , result ) ; } return result ; }	Fetches cached serializer for a non-registered subclass;also creates the serializer if it doesn't exist yet.This method is also exposed to package-private accessfor testing purposes.
private static < t > pojoserializersnapshot < t > buildsnapshot ( class < t > pojotype , linkedhashmap < class < ? > , integer > registeredsubclassestotags , typeserializer < ? > [ ] registeredsubclassserializers , field [ ] fields , typeserializer < ? > [ ] fieldserializers , map < class < ? > , typeserializer < ? > > nonregisteredsubclassserializercache ) { final linkedhashmap < class < ? > , typeserializer < ? > > subclassregistry = new linkedhashmap < > ( registeredsubclassestotags . size ( ) ) ; for ( map . entry < class < ? > , integer > entry : registeredsubclassestotags . entryset ( ) ) { subclassregistry . put ( entry . getkey ( ) , registeredsubclassserializers [ entry . getvalue ( ) ] ) ; } return new pojoserializersnapshot < > ( pojotype , fields , fieldserializers , subclassregistry , nonregisteredsubclassserializercache ) ; }	Build and return a snapshot of the serializer's parameters and currently cached serializers.
public static < t > class < t > compile ( classloader cl , string name , string code ) { tuple2 < classloader , string > cachekey = tuple2 . of ( cl , name ) ; class < ? > clazz = compiled_cache . getifpresent ( cachekey ) ; if ( clazz == null ) { clazz = docompile ( cl , name , code ) ; compiled_cache . put ( cachekey , clazz ) ; }	Compiles a generated code to a Class.
private static string addlinenumber ( string code ) { string [ ] lines = code . split ( str_ ) ; stringbuilder builder = new stringbuilder ( ) ; for ( int i = num_ ; i < lines . length ; i ++ ) { builder . append ( str_ ) . append ( i + num_ ) . append ( str_ ) . append ( lines [ i ] ) . append ( str_ ) ; } return builder . tostring ( ) ; }	To output more information when an error occurs.Generally, when cook fails, it shows which line is wrong.
protected final void addcloseableinternal ( closeable closeable , t metadata ) { synchronized ( getsynchronizationlock ( ) ) { closeabletoref . put ( closeable , metadata ) ; } }	Adds a mapping to the registry map, respecting locking.
private void bufferrows1 ( ) throws ioexception { binaryrow copy = key1 . copy ( ) ; buffer1 . reset ( ) ; do { buffer1 . add ( row1 ) ; } while ( nextrow1 ( ) && keycomparator . compare ( key1 , copy ) == num_ ) ; buffer1 . complete ( ) ; }	Buffer rows from iterator1 with same key.
private void bufferrows2 ( ) throws ioexception { binaryrow copy = key2 . copy ( ) ; buffer2 . reset ( ) ; do { buffer2 . add ( row2 ) ; } while ( nextrow2 ( ) && keycomparator . compare ( key2 , copy ) == num_ ) ; buffer2 . complete ( ) ; }	Buffer rows from iterator2 with same key.
public static < t > typeserializerschemacompatibility < t > compatiblewithreconfiguredserializer ( typeserializer < t > reconfiguredserializer ) { return new typeserializerschemacompatibility < > ( type . compatible_with_reconfigured_serializer , preconditions . checknotnull ( reconfiguredserializer ) ) ; }	Returns a result that indicates a reconfigured version of the new serializer is compatible, and should beused instead of the original new serializer.
public static checkpointproperties forcheckpoint ( checkpointretentionpolicy policy ) { switch ( policy ) { case never_retain_after_termination : return checkpoint_never_retained ; case retain_on_failure : return checkpoint_retained_on_failure ; case retain_on_cancellation : return checkpoint_retained_on_cancellation ; default : throw new illegalargumentexception ( str_ + policy ) ; } }	Creates the checkpoint properties for a checkpoint.
public longparameter setminimumvalue ( long minimumvalue ) { if ( hasmaximumvalue ) { util . checkparameter ( minimumvalue <= maximumvalue , str_ + minimumvalue + str_ + maximumvalue + str_ ) ; } this . hasminimumvalue = bool_ ; this . minimumvalue = minimumvalue ; return this ; }	Set the minimum value.
public longparameter setmaximumvalue ( long maximumvalue ) { if ( hasminimumvalue ) { util . checkparameter ( maximumvalue >= minimumvalue , str_ + maximumvalue + str_ + minimumvalue + str_ ) ; } this . hasmaximumvalue = bool_ ; this . maximumvalue = maximumvalue ; return this ; }	Set the maximum value.
protected void cleanfile ( string path ) { try { printwriter writer ; writer = new printwriter ( path ) ; writer . print ( str_ ) ; writer . close ( ) ; } catch ( filenotfoundexception e ) { throw new runtimeexception ( str_ + e . getmessage ( ) , e ) ; } }	Creates target file if it does not exist, cleans it if it exists.
@ override public iterator < map . entry < k , v > > iterator ( ) { return collections . unmodifiableset ( state . entryset ( ) ) . iterator ( ) ; }	Iterates over all the mappings in the state.
public static void sendnotmodified ( channelhandlercontext ctx ) { fullhttpresponse response = new defaultfullhttpresponse ( http_1_1 , not_modified ) ; setdateheader ( response ) ;	Send the "304 Not Modified" response.
public static void setcontenttypeheader ( httpresponse response , file file ) { string mimetype = mimetypes . getmimetypeforfilename ( file . getname ( ) ) ; string mimefinal = mimetype != null ? mimetype : mimetypes . getdefaultmimetype ( ) ; response . headers ( ) . set ( content_type , mimefinal ) ; }	Sets the content type header for the HTTP Response.
public void adddatasink ( genericdatasinkbase < ? > sink ) { checknotnull ( sink , str_ ) ; if ( ! this . sinks . contains ( sink ) ) { this . sinks . add ( sink ) ; } }	Adds a data sink to the set of sinks in this program.
@ override public void accept ( visitor < operator < ? > > visitor ) { for ( genericdatasinkbase < ? > sink : this . sinks ) { sink . accept ( visitor ) ; } }	Traverses the job depth first from all data sinks on towards the sources.
public static int caloperatorparallelism ( double rowcount , configuration tableconf ) { int maxparallelism = getoperatormaxparallelism ( tableconf ) ; int minparallelism = getoperatorminparallelism ( tableconf ) ; int resultparallelism = ( int ) ( rowcount / getrowcountperpartition ( tableconf ) ) ; return math . max ( math . min ( resultparallelism , maxparallelism ) , minparallelism ) ; }	Calculates operator parallelism based on rowcount of the operator.
public checkpointstatssnapshot createsnapshot ( ) { checkpointstatssnapshot snapshot = latestsnapshot ;	Creates a new snapshot of the available stats.
pendingcheckpointstats reportpendingcheckpoint ( long checkpointid , long triggertimestamp , checkpointproperties props ) { concurrenthashmap < jobvertexid , taskstatestats > taskstatestats = createemptytaskstatestatsmap ( ) ; pendingcheckpointstats pending = new pendingcheckpointstats ( checkpointid , triggertimestamp , props , totalsubtaskcount , taskstatestats , new pendingcheckpointstatscallback ( ) ) ; statsreadwritelock . lock ( ) ; try { counts . incrementinprogresscheckpoints ( ) ; history . addinprogresscheckpoint ( pending ) ; dirty = bool_ ; } finally { statsreadwritelock . unlock ( ) ; } return pending ; }	Creates a new pending checkpoint tracker.
void reportrestoredcheckpoint ( restoredcheckpointstats restored ) { checknotnull ( restored , str_ ) ; statsreadwritelock . lock ( ) ; try { counts . incrementrestoredcheckpoints ( ) ; latestrestoredcheckpoint = restored ; dirty = bool_ ; } finally { statsreadwritelock . unlock ( ) ; } }	Callback when a checkpoint is restored.
private void reportcompletedcheckpoint ( completedcheckpointstats completed ) { statsreadwritelock . lock ( ) ; try { latestcompletedcheckpoint = completed ; counts . incrementcompletedcheckpoints ( ) ; history . replacependingcheckpointbyid ( completed ) ; summary . updatesummary ( completed ) ; dirty = bool_ ; } finally { statsreadwritelock . unlock ( ) ; } }	Callback when a checkpoint completes.
private void reportfailedcheckpoint ( failedcheckpointstats failed ) { statsreadwritelock . lock ( ) ; try { counts . incrementfailedcheckpoints ( ) ; history . replacependingcheckpointbyid ( failed ) ; dirty = bool_ ; } finally { statsreadwritelock . unlock ( ) ; } }	Callback when a checkpoint fails.
private void registermetrics ( metricgroup metricgroup ) { metricgroup . gauge ( number_of_checkpoints_metric , new checkpointscounter ( ) ) ; metricgroup . gauge ( number_of_in_progress_checkpoints_metric , new inprogresscheckpointscounter ( ) ) ; metricgroup . gauge ( number_of_completed_checkpoints_metric , new completedcheckpointscounter ( ) ) ; metricgroup . gauge ( number_of_failed_checkpoints_metric , new failedcheckpointscounter ( ) ) ; metricgroup . gauge ( latest_restored_checkpoint_timestamp_metric , new latestrestoredcheckpointtimestampgauge ( ) ) ; metricgroup . gauge ( latest_completed_checkpoint_size_metric , new latestcompletedcheckpointsizegauge ( ) ) ; metricgroup . gauge ( latest_completed_checkpoint_duration_metric , new latestcompletedcheckpointdurationgauge ( ) ) ; metricgroup . gauge ( latest_completed_checkpoint_alignment_buffered_metric , new latestcompletedcheckpointalignmentbufferedgauge ( ) ) ; metricgroup . gauge ( latest_completed_checkpoint_external_path_metric , new latestcompletedcheckpointexternalpathgauge ( ) ) ; }	Register the exposed metrics.
@ override public void configure ( configuration parameters ) { super . configure ( parameters ) ;	Configures this input format by reading the path to the file from the configuration and the string thatdefines the record delimiter.
private boolean fillbuffer ( int offset ) throws ioexception { int maxreadlength = this . readbuffer . length - offset ;	Fills the read buffer with bytes read from the file starting from an offset.
@ override public void set ( final iterator < tuple2 < key , value > > iterator ) { this . iterator = iterator ; if ( this . hasnext ( ) ) { final tuple2 < key , value > tuple = iterator . next ( ) ; this . curkey = keyserializer . copy ( tuple . f0 ) ; this . firstvalue = tuple . f1 ; this . atfirst = bool_ ; } else { this . atfirst = bool_ ; } }	Set the Flink iterator to wrap.
private static void fix ( indexedsortable s , int pn , int po , int rn , int ro ) { if ( s . compare ( pn , po , rn , ro ) > num_ ) { s . swap ( pn , po , rn , ro ) ; } }	Fix the records into sorted order, swapping when the first record isgreater than the second record.
public static < w extends window > afterfirstelementperiodic < w > every ( duration time ) { return new afterfirstelementperiodic < > ( time . tomillis ( ) ) ; }	Creates a trigger that fires by a certain interval after reception of the first element.
@ override public void invoke ( in value ) throws exception { byte [ ] msg = schema . serialize ( value ) ; try { outputstream . write ( msg ) ; if ( autoflush ) { outputstream . flush ( ) ; } } catch ( ioexception e ) {	Called when new data arrives to the sink, and forwards it to Socket.
boolean reportsubtaskstats ( jobvertexid jobvertexid , subtaskstatestats subtask ) { taskstatestats taskstatestats = taskstats . get ( jobvertexid ) ; if ( taskstatestats != null && taskstatestats . reportsubtaskstats ( subtask ) ) { currentnumacknowledgedsubtasks ++ ; latestacknowledgedsubtask = subtask ; currentstatesize += subtask . getstatesize ( ) ; long alignmentbuffered = subtask . getalignmentbuffered ( ) ; if ( alignmentbuffered > num_ ) { currentalignmentbuffered += alignmentbuffered ; } return bool_ ; } else { return bool_ ; } }	Reports statistics for a single subtask.
completedcheckpointstats . discardcallback reportcompletedcheckpoint ( string externalpointer ) { completedcheckpointstats completed = new completedcheckpointstats ( checkpointid , triggertimestamp , props , numberofsubtasks , new hashmap < > ( taskstats ) , currentnumacknowledgedsubtasks , currentstatesize , currentalignmentbuffered , latestacknowledgedsubtask , externalpointer ) ; trackercallback . reportcompletedcheckpoint ( completed ) ; return completed . getdiscardcallback ( ) ; }	Reports a successfully completed pending checkpoint.
public void setbroadcastinputs ( map < operator < ? > , optimizernode > operatortonode , executionmode defaultexchangemode ) {	This function connects the operators that produce the broadcast inputs to this operator.
public void setparallelism ( int parallelism ) { if ( parallelism < num_ && parallelism != executionconfig . parallelism_default ) { throw new illegalargumentexception ( str_ + parallelism + str_ ) ; } this . parallelism = parallelism ; }	Sets the parallelism for this optimizer node.The parallelism denotes how many parallel instances of the operator will bespawned during the execution.
public void computeunionofinterestingpropertiesfromsuccessors ( ) { list < dagconnection > conns = getoutgoingconnections ( ) ; if ( conns . size ( ) == num_ ) {	Computes all the interesting properties that are relevant to this node.
protected boolean arebranchcompatible ( plannode plan1 , plannode plan2 ) { if ( plan1 == null || plan2 == null ) { throw new nullpointerexception ( ) ; }	Checks whether to candidate plans for the sub-plan of this node are comparable.
public < i , o > heartbeatmanager < i , o > createheartbeatmanager ( resourceid resourceid , heartbeatlistener < i , o > heartbeatlistener , scheduledexecutor scheduledexecutor , logger log ) { return new heartbeatmanagerimpl < > ( heartbeattimeout , resourceid , heartbeatlistener , scheduledexecutor , scheduledexecutor , log ) ; }	Creates a heartbeat manager which does not actively send heartbeats.
public < i , o > heartbeatmanager < i , o > createheartbeatmanagersender ( resourceid resourceid , heartbeatlistener < i , o > heartbeatlistener , scheduledexecutor scheduledexecutor , logger log ) { return new heartbeatmanagersenderimpl < > ( heartbeatinterval , heartbeattimeout , resourceid , heartbeatlistener , scheduledexecutor , scheduledexecutor , log ) ; }	Creates a heartbeat manager which actively sends heartbeats to monitoring targets.
protected long adjustrunloopfrequency ( long processingstarttimenanos , long processingendtimenanos ) throws interruptedexception { long endtimenanos = processingendtimenanos ; if ( fetchintervalmillis != num_ ) { long processingtimenanos = processingendtimenanos - processingstarttimenanos ; long sleeptimemillis = fetchintervalmillis - ( processingtimenanos / num_ ) ; if ( sleeptimemillis > num_ ) { thread . sleep ( sleeptimemillis ) ; endtimenanos = system . nanotime ( ) ; shardmetricsreporter . setsleeptimemillis ( sleeptimemillis ) ; } } return endtimenanos ; }	Adjusts loop timing to match target frequency if specified.
private int adaptrecordstoread ( long runlooptimenanos , int numrecords , long recordbatchsizebytes , int maxnumberofrecordsperfetch ) { if ( useadaptivereads && numrecords != num_ && runlooptimenanos != num_ ) { long averagerecordsizebytes = recordbatchsizebytes / numrecords ;	Calculates how many records to read each time through the loop based on a target throughputand the measured frequenecy of the loop.
public class < ? extends abstractinvokable > getinvokableclass ( classloader cl ) { if ( cl == null ) { throw new nullpointerexception ( str_ ) ; } if ( invokableclassname == null ) { return null ; } try { return class . forname ( invokableclassname , bool_ , cl ) . assubclass ( abstractinvokable . class ) ; } catch ( classnotfoundexception e ) { throw new runtimeexception ( str_ , e ) ; } catch ( classcastexception e ) { throw new runtimeexception ( str_ + abstractinvokable . class . getname ( ) , e ) ; } }	Returns the invokable class which represents the task of this vertex.
public void setresources ( resourcespec minresources , resourcespec preferredresources ) { this . minresources = checknotnull ( minresources ) ; this . preferredresources = checknotnull ( preferredresources ) ; }	Sets the minimum and preferred resources for the task.
public void setslotsharinggroup ( slotsharinggroup grp ) { if ( this . slotsharinggroup != null ) { this . slotsharinggroup . removevertexfromgroup ( id ) ; } this . slotsharinggroup = grp ; if ( grp != null ) { grp . addvertextogroup ( id ) ; } }	Associates this vertex with a slot sharing group for scheduling.
private void ensurecapacity ( int mincapacity ) { long currentcapacity = data . length ; if ( mincapacity <= currentcapacity ) { return ; }	If the size of the array is insufficient to hold the given capacity thencopy the array into a new, larger array.
private void unregisterjobfromhighavailability ( ) { try { runningjobsregistry . setjobfinished ( jobgraph . getjobid ( ) ) ; } catch ( throwable t ) { log . error ( str_ + str_ , jobgraph . getname ( ) , jobgraph . getjobid ( ) , t ) ; } }	Marks this runner's job as not running.
private void failover ( long globalmodversionoffailover ) { if ( ! executiongraph . getrestartstrategy ( ) . canrestart ( ) ) { executiongraph . failglobal ( new flinkexception ( str_ ) ) ; } else { jobstatus curstatus = this . state ; if ( curstatus . equals ( jobstatus . running ) ) { cancel ( globalmodversionoffailover ) ; } else if ( curstatus . equals ( jobstatus . canceled ) ) { reset ( globalmodversionoffailover ) ; } else { log . info ( str_ , id , state ) ; } } }	Notice the region to failover,.
private void cancel ( final long globalmodversionoffailover ) { executiongraph . getjobmastermainthreadexecutor ( ) . assertrunninginmainthread ( ) ; while ( bool_ ) { jobstatus curstatus = this . state ; if ( curstatus . equals ( jobstatus . running ) ) { if ( transitionstate ( curstatus , jobstatus . cancelling ) ) { createterminationfutureoverallconnectedvertexes ( ) . thenaccept ( ( nullptr ) -> allverticesinterminalstate ( globalmodversionoffailover ) ) ; break ; } } else { log . info ( str_ , id , state ) ; break ; } } }	cancel all executions in this sub graph.
private void reset ( long globalmodversionoffailover ) { try {	reset all executions in this sub graph.
private void restart ( long globalmodversionoffailover ) { try { if ( transitionstate ( jobstatus . created , jobstatus . running ) ) {	restart all executions in this sub graph.
public static long getmanagedmemorysize ( configuration configuration ) { long managedmemorysize ; string managedmemorysizedefaultval = taskmanageroptions . managed_memory_size . defaultvalue ( ) ; if ( ! configuration . getstring ( taskmanageroptions . managed_memory_size ) . equals ( managedmemorysizedefaultval ) ) { try { managedmemorysize = memorysize . parse ( configuration . getstring ( taskmanageroptions . managed_memory_size ) , mega_bytes ) . getmebibytes ( ) ; } catch ( illegalargumentexception e ) { throw new illegalconfigurationexception ( str_ + taskmanageroptions . managed_memory_size . key ( ) , e ) ; } } else { managedmemorysize = long . valueof ( managedmemorysizedefaultval ) ; } checkconfigparameter ( configuration . getstring ( taskmanageroptions . managed_memory_size ) . equals ( taskmanageroptions . managed_memory_size . defaultvalue ( ) ) || managedmemorysize > num_ , managedmemorysize , taskmanageroptions . managed_memory_size . key ( ) , str_ + str_ ) ; return managedmemorysize ; }	Parses the configuration to get the managed memory size and validates the value.
public static float getmanagedmemoryfraction ( configuration configuration ) { float managedmemoryfraction = configuration . getfloat ( taskmanageroptions . managed_memory_fraction ) ; checkconfigparameter ( managedmemoryfraction > num_ && managedmemoryfraction < num_ , managedmemoryfraction , taskmanageroptions . managed_memory_fraction . key ( ) , str_ ) ; return managedmemoryfraction ; }	Parses the configuration to get the fraction of managed memory and validates the value.
public static memorytype getmemorytype ( configuration configuration ) {	Parses the configuration to get the type of memory.
public static int getslot ( configuration configuration ) { int slots = configuration . getinteger ( taskmanageroptions . num_task_slots , num_ ) ;	Parses the configuration to get the number of slots and validates the value.
public static void checkconfigparameter ( boolean condition , object parameter , string name , string errormessage ) throws illegalconfigurationexception { if ( ! condition ) { throw new illegalconfigurationexception ( str_ + name + str_ + parameter + str_ + errormessage ) ; } }	Validates a condition for a config parameter and displays a standard exception, if thethe condition does not hold.
public static yarnhighavailabilityservices forsinglejobappmaster ( configuration flinkconfig , org . apache . hadoop . conf . configuration hadoopconfig ) throws ioexception { checknotnull ( flinkconfig , str_ ) ; checknotnull ( hadoopconfig , str_ ) ; final highavailabilitymode mode = highavailabilitymode . fromconfig ( flinkconfig ) ; switch ( mode ) { case none : return new yarnintranonhamasterservices ( flinkconfig , hadoopconfig ) ; case zookeeper : throw new unsupportedoperationexception ( str_ ) ; default : throw new illegalconfigurationexception ( str_ + mode ) ; } }	Creates the high-availability services for a single-job Flink YARN application, to beused in the Application Master that runs both ResourceManager and JobManager.
public static yarnhighavailabilityservices foryarntaskmanager ( configuration flinkconfig , org . apache . hadoop . conf . configuration hadoopconfig ) throws ioexception { checknotnull ( flinkconfig , str_ ) ; checknotnull ( hadoopconfig , str_ ) ; final highavailabilitymode mode = highavailabilitymode . fromconfig ( flinkconfig ) ; switch ( mode ) { case none : return new yarnpreconfiguredmasternonhaservices ( flinkconfig , hadoopconfig , highavailabilityservicesutils . addressresolution . try_address_resolution ) ; case zookeeper : throw new unsupportedoperationexception ( str_ ) ; default : throw new illegalconfigurationexception ( str_ + mode ) ; } }	Creates the high-availability services for the TaskManagers participating ina Flink YARN application.
@ override public list < memorysegment > close ( ) throws ioexception { if ( this . closed ) { throw new illegalstateexception ( str_ ) ; } this . closed = bool_ ;	Closes this InputView, closing the underlying reader and returning all memory segments.
protected void sendreadrequest ( memorysegment seg ) throws ioexception { if ( this . numrequestsremaining != num_ ) { this . reader . readblock ( seg ) ; if ( this . numrequestsremaining != - num_ ) { this . numrequestsremaining -- ; } } else {	Sends a new read requests, if further requests remain.
public static < t > typeinformation < t > of ( class < t > typeclass ) { try { return typeextractor . createtypeinfo ( typeclass ) ; } catch ( invalidtypesexception e ) { throw new flinkruntimeexception ( str_ + str_ + str_ + str_ ) ; } }	Creates a TypeInformation for the type described by the given class.
public static int calculatefixlengthpartsize ( internaltype type ) { if ( type . equals ( internaltypes . boolean ) ) { return num_ ; } else if ( type . equals ( internaltypes . byte ) ) { return num_ ; } else if ( type . equals ( internaltypes . short ) ) { return num_ ; } else if ( type . equals ( internaltypes . int ) ) { return num_ ; } else if ( type . equals ( internaltypes . float ) ) { return num_ ; } else if ( type . equals ( internaltypes . char ) ) { return num_ ; } else if ( type . equals ( internaltypes . date ) ) { return num_ ; } else if ( type . equals ( internaltypes . time ) ) { return num_ ; } else {	It store real value when type is primitive.It store the length and offset of variable-length part when type is string, map, etc.
public collection < completablefuture < taskmanagerlocation > > getpreferredlocationsbasedonstate ( ) { taskmanagerlocation priorlocation ; if ( currentexecution . gettaskrestore ( ) != null && ( priorlocation = getlatestpriorlocation ( ) ) != null ) { return collections . singleton ( completablefuture . completedfuture ( priorlocation ) ) ; } else { return null ; } }	Gets the preferred location to execute the current task execution attempt, based on the statethat the execution attempt will resume.
void scheduleorupdateconsumers ( resultpartitionid partitionid ) { final execution execution = currentexecution ;	Schedules or updates the consumer tasks of the result partition with the given ID.
boolean checkinputdependencyconstraints ( ) { if ( getinputdependencyconstraint ( ) == inputdependencyconstraint . any ) {	Check whether the InputDependencyConstraint is satisfied for this vertex.
boolean isinputconsumable ( int inputnumber ) { return arrays . stream ( inputedges [ inputnumber ] ) . map ( executionedge :: getsource ) . anymatch ( intermediateresultpartition :: isconsumable ) ; }	Get whether an input of the vertex is consumable.An input is consumable when when any partition in it is consumable.Note that a BLOCKING result partition is only consumable when all partitions in the result are FINISHED.
void notifystatetransition ( execution execution , executionstate newstate , throwable error ) {	Simply forward this notification.
private static void getcontainedgenerictypes ( compositetype < ? > typeinfo , list < generictypeinfo < ? > > target ) { for ( int i = num_ ; i < typeinfo . getarity ( ) ; i ++ ) { typeinformation < ? > type = typeinfo . gettypeat ( i ) ; if ( type instanceof compositetype ) { getcontainedgenerictypes ( ( compositetype < ? > ) type , target ) ; } else if ( type instanceof generictypeinfo ) { if ( ! target . contains ( type ) ) { target . add ( ( generictypeinfo < ? > ) type ) ; } } } }	Returns all GenericTypeInfos contained in a composite type.
@ override public refcountedfile apply ( file file ) throws ioexception { final file directory = tempdirectories [ nextindex ( ) ] ; while ( bool_ ) { try { if ( file == null ) { final file newfile = new file ( directory , str_ + uuid . randomuuid ( ) ) ; final outputstream out = files . newoutputstream ( newfile . topath ( ) , standardopenoption . create_new ) ; return refcountedfile . newfile ( newfile , out ) ; } else { final outputstream out = files . newoutputstream ( file . topath ( ) , standardopenoption . append ) ; return refcountedfile . restoredfile ( file , out , file . length ( ) ) ; } } catch ( filealreadyexistsexception ignored ) {	Gets the next temp file and stream to temp file.This creates the temp file atomically, making sure no previous file is overwritten.
protected boolean registerallrequestsprocessedlistener ( notificationlistener listener ) throws ioexception { checknotnull ( listener ) ; synchronized ( listenerlock ) { if ( allrequestsprocessedlistener == null ) {	Registers a listener to be notified when all outstanding requests have been processed.
@ override public dataset < vertex < k , vv > > createresult ( ) { if ( this . initialvertices == null ) { throw new illegalstateexception ( str_ ) ; }	Creates the operator that represents this scatter-gather graph computation.
private cogroupoperator < ? , ? , tuple2 < k , message > > buildscatterfunctionverticeswithdegrees ( deltaiteration < vertex < k , tuple3 < vv , longvalue , longvalue > > , vertex < k , tuple3 < vv , longvalue , longvalue > > > iteration , typeinformation < tuple2 < k , message > > messagetypeinfo , int wherearg , int equaltoarg , dataset < longvalue > numberofvertices ) {	Method that builds the scatter function using a coGroup operator for a vertexcontaining degree information.It afterwards configures the function with a custom name and broadcast variables.
private dataset < vertex < k , vv > > createresultsimplevertex ( edgedirection messagingdirection , typeinformation < tuple2 < k , message > > messagetypeinfo , dataset < longvalue > numberofvertices ) { dataset < tuple2 < k , message > > messages ; typeinformation < vertex < k , vv > > vertextypes = initialvertices . gettype ( ) ; final deltaiteration < vertex < k , vv > , vertex < k , vv > > iteration = initialvertices . iteratedelta ( initialvertices , this . maximumnumberofiterations , num_ ) ; setupiteration ( iteration ) ; switch ( messagingdirection ) { case in : messages = buildscatterfunction ( iteration , messagetypeinfo , num_ , num_ , numberofvertices ) ; break ; case out : messages = buildscatterfunction ( iteration , messagetypeinfo , num_ , num_ , numberofvertices ) ; break ; case all : messages = buildscatterfunction ( iteration , messagetypeinfo , num_ , num_ , numberofvertices ) . union ( buildscatterfunction ( iteration , messagetypeinfo , num_ , num_ , numberofvertices ) ) ; break ; default : throw new illegalargumentexception ( str_ ) ; } gatherudf < k , vv , message > updateudf = new gatherudfsimplevv < > ( gatherfunction , vertextypes ) ;	Creates the operator that represents this scatter-gather graph computation for a simple vertex.
public o setparallelism ( int parallelism ) { preconditions . checkargument ( parallelism > num_ || parallelism == executionconfig . parallelism_default , str_ ) ; this . parallelism = parallelism ; @ suppresswarnings ( str_ ) o returntype = ( o ) this ; return returntype ; }	Sets the parallelism for this operator.The parallelism must be 1 or more.
private o setresources ( resourcespec minresources , resourcespec preferredresources ) { preconditions . checknotnull ( minresources , str_ ) ; preconditions . checknotnull ( preferredresources , str_ ) ; preconditions . checkargument ( minresources . isvalid ( ) && preferredresources . isvalid ( ) && minresources . lessthanorequal ( preferredresources ) , str_ ) ; this . minresources = minresources ; this . preferredresources = preferredresources ; @ suppresswarnings ( str_ ) o returntype = ( o ) this ; return returntype ; }	Sets the minimum and preferred resources for this operator.
private o setresources ( resourcespec resources ) { preconditions . checknotnull ( resources , str_ ) ; preconditions . checkargument ( resources . isvalid ( ) , str_ ) ; this . minresources = resources ; this . preferredresources = resources ; @ suppresswarnings ( str_ ) o returntype = ( o ) this ; return returntype ; }	Sets the resources for this operator.
public graphalgorithmwrappingbase < k , vv , ev , r > setparallelism ( int parallelism ) { preconditions . checkargument ( parallelism > num_ || parallelism == parallelism_default , str_ ) ; this . parallelism = parallelism ; return this ; }	Set the parallelism for this algorithm's operators.
public int getnumberofavailableslotsforgroup ( abstractid groupid ) { synchronized ( lock ) { map < resourceid , list < sharedslot > > available = availableslotsperjid . get ( groupid ) ; if ( available != null ) { set < sharedslot > set = new hashset < sharedslot > ( ) ; for ( list < sharedslot > list : available . values ( ) ) { for ( sharedslot slot : list ) { set . add ( slot ) ; } } return set . size ( ) ; } else {	Gets the number of shared slots into which the given group can place subtasks ornested task groups.
void releasesimpleslot ( simpleslot simpleslot ) { synchronized ( lock ) {	Releases the simple slot from the assignment group.
public int [ ] toarray ( ) { int [ ] a = new int [ this . collection . size ( ) ] ; int i = num_ ; for ( int col : this . collection ) { a [ i ++ ] = col ; } return a ; }	Transforms the field set into an array of field IDs.
public adamicadar < k , vv , ev > setminimumscore ( float score ) { preconditions . checkargument ( score >= num_ , str_ ) ; this . minimumscore = score ; return this ; }	Filter out Adamic-Adar scores less than the given minimum.
public adamicadar < k , vv , ev > setminimumratio ( float ratio ) { preconditions . checkargument ( ratio >= num_ , str_ ) ; this . minimumratio = ratio ; return this ; }	Filter out Adamic-Adar scores less than the given ratio times the average score.
public schema schema ( tableschema schema ) { tableschema . clear ( ) ; lastfield = null ; for ( int i = num_ ; i < schema . getfieldcount ( ) ; i ++ ) { field ( schema . getfieldname ( i ) . get ( ) , schema . getfieldtype ( i ) . get ( ) ) ; } return this ; }	Sets the schema with field names and the types.
public schema field ( string fieldname , typeinformation < ? > fieldtype ) { field ( fieldname , typestringutils . writetypeinfo ( fieldtype ) ) ; return this ; }	Adds a field with the field name and the type information.
public schema field ( string fieldname , string fieldtype ) { if ( tableschema . containskey ( fieldname ) ) { throw new validationexception ( str_ ) ; } linkedhashmap < string , string > fieldproperties = new linkedhashmap < > ( ) ; fieldproperties . put ( schema_type , fieldtype ) ; tableschema . put ( fieldname , fieldproperties ) ; lastfield = fieldname ; return this ; }	Adds a field with the field name and the type string.
public schema from ( string originfieldname ) { if ( lastfield == null ) { throw new validationexception ( str_ ) ; } tableschema . get ( lastfield ) . put ( schema_from , originfieldname ) ; lastfield = null ; return this ; }	Specifies the origin of the previously defined field.
public schema proctime ( ) { if ( lastfield == null ) { throw new validationexception ( str_ ) ; } tableschema . get ( lastfield ) . put ( schema_proctime , str_ ) ; lastfield = null ; return this ; }	Specifies the previously defined field as a processing-time attribute.
public schema rowtime ( rowtime rowtime ) { if ( lastfield == null ) { throw new validationexception ( str_ ) ; } tableschema . get ( lastfield ) . putall ( rowtime . toproperties ( ) ) ; lastfield = null ; return this ; }	Specifies the previously defined field as an event-time attribute.
public void oncomplete ( final consumer < streamelementqueueentry < t > > completefunction , executor executor ) { final streamelementqueueentry < t > thisreference = this ; getfuture ( ) . whencompleteasync (	Register the given complete function to be called once this queue entry has been completed.
public static string formatsystemproperties ( configuration jvmargs ) { stringbuilder sb = new stringbuilder ( ) ; for ( map . entry < string , string > entry : jvmargs . tomap ( ) . entryset ( ) ) { if ( sb . length ( ) > num_ ) { sb . append ( str_ ) ; } boolean quoted = entry . getvalue ( ) . contains ( str_ ) ; if ( quoted ) { sb . append ( str_ ) ; } sb . append ( str_ ) . append ( entry . getkey ( ) ) . append ( str_ ) . append ( entry . getvalue ( ) ) ; if ( quoted ) { sb . append ( str_ ) ; } } return sb . tostring ( ) ; }	Format the system properties as a shell-compatible command-line argument.
public void registertimeout ( final k key , final long delay , final timeunit unit ) { preconditions . checkstate ( timeoutlistener != null , str_ + getclass ( ) . getsimplename ( ) + str_ ) ; if ( timeouts . containskey ( key ) ) { unregistertimeout ( key ) ; } timeouts . put ( key , new timeout < > ( timeoutlistener , key , delay , unit , scheduledexecutorservice ) ) ; }	Register a timeout for the given key which shall occur in the given delay.
public void unregistertimeout ( k key ) { timeout < k > timeout = timeouts . remove ( key ) ; if ( timeout != null ) { timeout . cancel ( ) ; } }	Unregister the timeout for the given key.
protected void unregisteralltimeouts ( ) { for ( timeout < k > timeout : timeouts . values ( ) ) { timeout . cancel ( ) ; } timeouts . clear ( ) ; }	Unregister all timeouts.
public static memorysegment allocateunpooledoffheapmemory ( int size , object owner ) { bytebuffer memory = bytebuffer . allocatedirect ( size ) ; return wrappooledoffheapmemory ( memory , owner ) ; }	Allocates some unpooled off-heap memory and creates a new memory segment thatrepresents that memory.
@ override public void writeblock ( buffer buffer ) throws ioexception { try {	Writes the given block asynchronously.
public void setnumfields ( final int numfields ) { final int oldnumfields = this . numfields ;	Sets the number of fields in the record.
public void makespace ( int numfields ) { final int oldnumfields = this . numfields ;	Reserves space for at least the given number of fields in the internal arrays.
public boolean getfieldinto ( int fieldnum , value target ) {	Gets the field at the given position.
public boolean getfieldsinto ( int [ ] positions , value [ ] targets ) { for ( int i = num_ ; i < positions . length ; i ++ ) { if ( ! getfieldinto ( positions [ i ] , targets [ i ] ) ) { return bool_ ; } } return bool_ ; }	Gets the fields at the given positions into an array.If at any position a field is null, then this method returns false.All fields that have been successfully read until the failing read are correctly contained in the record.All other fields are not set.
public void updatebinaryrepresenation ( ) {	Updates the binary representation of the data, such that it reflects the state of the currentlystored fields.
public static < k , vv , ev , message > vertexcentriciteration < k , vv , ev , message > withedges ( dataset < edge < k , ev > > edgeswithvalue , computefunction < k , vv , ev , message > cf , int maximumnumberofiterations ) { return new vertexcentriciteration < > ( cf , edgeswithvalue , null , maximumnumberofiterations ) ; }	Creates a new vertex-centric iteration operator.
private void setupiteration ( deltaiteration < ? , ? > iteration ) {	Helper method which sets up an iteration with the given vertex value.
private static list < string > gettopics ( list < kafkatopicpartitionstate < topicandpartition > > partitions ) { hashset < string > uniquetopics = new hashset < > ( ) ; for ( kafkatopicpartitionstate < topicandpartition > fp : partitions ) { uniquetopics . add ( fp . gettopic ( ) ) ; } return new arraylist < > ( uniquetopics ) ; }	Returns a list of unique topics from for the given partitions.
private static map < node , list < kafkatopicpartitionstate < topicandpartition > > > findleaderforpartitions ( list < kafkatopicpartitionstate < topicandpartition > > partitionstoassign , properties kafkaproperties ) throws exception { if ( partitionstoassign . isempty ( ) ) { throw new illegalargumentexception ( str_ ) ; } log . info ( str_ , partitionstoassign ) ;	Find leaders for the partitions.
public static void validateawsconfiguration ( properties config ) { if ( config . containskey ( awsconfigconstants . aws_credentials_provider ) ) { string credentialsprovidertype = config . getproperty ( awsconfigconstants . aws_credentials_provider ) ;	Validate configuration properties related to Amazon AWS service.
public static string getmemoryusagestatsasstring ( memorymxbean memorymxbean ) { memoryusage heap = memorymxbean . getheapmemoryusage ( ) ; memoryusage nonheap = memorymxbean . getnonheapmemoryusage ( ) ; long heapused = heap . getused ( ) > > num_ ; long heapcommitted = heap . getcommitted ( ) > > num_ ; long heapmax = heap . getmax ( ) > > num_ ; long nonheapused = nonheap . getused ( ) > > num_ ; long nonheapcommitted = nonheap . getcommitted ( ) > > num_ ; long nonheapmax = nonheap . getmax ( ) > > num_ ; return string . format ( str_ + str_ , heapused , heapcommitted , heapmax , nonheapused , nonheapcommitted , nonheapmax ) ; }	Gets the memory footprint of the JVM in a string representation.
public static string getmemorypoolstatsasstring ( list < memorypoolmxbean > poolbeans ) { stringbuilder bld = new stringbuilder ( str_ ) ; int count = num_ ; for ( memorypoolmxbean bean : poolbeans ) { if ( bean . gettype ( ) == memorytype . non_heap ) { if ( count > num_ ) { bld . append ( str_ ) ; } count ++ ; memoryusage usage = bean . getusage ( ) ; long used = usage . getused ( ) > > num_ ; long committed = usage . getcommitted ( ) > > num_ ; long max = usage . getmax ( ) > > num_ ; bld . append ( str_ ) . append ( bean . getname ( ) ) . append ( str_ ) ; bld . append ( used ) . append ( str_ ) . append ( committed ) . append ( str_ ) . append ( max ) ; bld . append ( str_ ) ; } } return bld . tostring ( ) ; }	Gets the memory pool statistics from the JVM.
public static string getgarbagecollectorstatsasstring ( list < garbagecollectormxbean > gcmxbeans ) { stringbuilder bld = new stringbuilder ( str_ ) ; for ( garbagecollectormxbean bean : gcmxbeans ) { bld . append ( str_ ) . append ( bean . getname ( ) ) . append ( str_ ) . append ( bean . getcollectiontime ( ) ) ; bld . append ( str_ ) . append ( bean . getcollectioncount ( ) ) . append ( str_ ) ; bld . append ( str_ ) ; } if ( ! gcmxbeans . isempty ( ) ) { bld . setlength ( bld . length ( ) - num_ ) ; } return bld . tostring ( ) ; }	Gets the garbage collection statistics from the JVM.
public < t extends comparable < t > > graph < t , nullvalue , nullvalue > simplify ( graph < t , nullvalue , nullvalue > graph , int parallelism ) throws exception { switch ( value ) { case directed : graph = graph . run ( new org . apache . flink . graph . asm . simple . directed . simplify < t , nullvalue , nullvalue > ( ) . setparallelism ( parallelism ) ) ; break ; case undirected : graph = graph . run ( new org . apache . flink . graph . asm . simple . undirected . simplify < t , nullvalue , nullvalue > ( bool_ ) . setparallelism ( parallelism ) ) ; break ; case undirected_clip_and_flip : graph = graph . run ( new org . apache . flink . graph . asm . simple . undirected . simplify < t , nullvalue , nullvalue > ( bool_ ) . setparallelism ( parallelism ) ) ; break ; } return graph ; }	Simplify the given graph based on the configured value.
public iterator < t > sampleincoordinator ( iterator < intermediatesampledata < t > > input ) { if ( numsamples == num_ ) { return emptyiterable ; }	Sample algorithm for the second phase.
@ override public iterator < t > sample ( iterator < t > input ) { return sampleincoordinator ( sampleinpartition ( input ) ) ; }	Combine the first phase and second phase in sequence, implemented for test purpose only.
public static fixeddelayrestartstrategyfactory createfactory ( configuration configuration ) throws exception { int maxattempts = configuration . getinteger ( configconstants . restart_strategy_fixed_delay_attempts , num_ ) ; string delaystring = configuration . getstring ( configconstants . restart_strategy_fixed_delay_delay ) ; long delay ; try { delay = duration . apply ( delaystring ) . tomillis ( ) ; } catch ( numberformatexception nfe ) { throw new exception ( str_ + configconstants . restart_strategy_fixed_delay_delay + str_ + delaystring + str_ ) ; } return new fixeddelayrestartstrategyfactory ( maxattempts , delay ) ; }	Creates a FixedDelayRestartStrategy from the given Configuration.
public static boolean isinsssp ( final edge < long , double > edgetoberemoved , dataset < edge < long , double > > edgesinsssp ) throws exception { return edgesinsssp . filter ( new filterfunction < edge < long , double > > ( ) { @ override public boolean filter ( edge < long , double > edge ) throws exception { return edge . equals ( edgetoberemoved ) ; } } ) . count ( ) > num_ ; }	Function that verifies whether the edge to be removed is part of the SSSP or not.If it is, the src vertex will be invalidated.
public boolean markactive ( ) { if ( taskslotstate . allocated == state || taskslotstate . active == state ) { state = taskslotstate . active ; return bool_ ; } else { return bool_ ; } }	Mark this slot as active.
public boolean markfree ( ) { if ( isempty ( ) ) { state = taskslotstate . free ; this . jobid = null ; this . allocationid = null ; return bool_ ; } else { return bool_ ; } }	Mark the slot as free.
public slotoffer generateslotoffer ( ) { preconditions . checkstate ( taskslotstate . active == state || taskslotstate . allocated == state , str_ ) ; preconditions . checkstate ( allocationid != null , str_ ) ; return new slotoffer ( allocationid , index , resourceprofile ) ; }	Generate the slot offer from this TaskSlot.
@ override public rocksdbstatebackend configure ( configuration config , classloader classloader ) { return new rocksdbstatebackend ( this , config , classloader ) ; }	Creates a copy of this state backend that uses the values defined in the configurationfor fields where that were not yet specified in this state backend.
public string [ ] getdbstoragepaths ( ) { if ( localrocksdbdirectories == null ) { return null ; } else { string [ ] paths = new string [ localrocksdbdirectories . length ] ; for ( int i = num_ ; i < paths . length ; i ++ ) { paths [ i ] = localrocksdbdirectories [ i ] . tostring ( ) ; } return paths ; } }	Gets the configured local DB storage paths, or null, if none were configured.
public void assignexclusivesegments ( networkbufferpool networkbufferpool , int networkbuffersperchannel ) throws ioexception { checkstate ( this . iscreditbased , str_ ) ; checkstate ( this . networkbufferpool == null , str_ + str_ ) ; this . networkbufferpool = checknotnull ( networkbufferpool ) ; this . networkbuffersperchannel = networkbuffersperchannel ; synchronized ( requestlock ) { for ( inputchannel inputchannel : inputchannels . values ( ) ) { if ( inputchannel instanceof remoteinputchannel ) { ( ( remoteinputchannel ) inputchannel ) . assignexclusivesegments ( networkbufferpool . requestmemorysegments ( networkbuffersperchannel ) ) ; } } } }	Assign the exclusive buffers to all remote input channels directly for credit-based mode.
public void retriggerpartitionrequest ( intermediateresultpartitionid partitionid ) throws ioexception , interruptedexception { synchronized ( requestlock ) { if ( ! isreleased ) { final inputchannel ch = inputchannels . get ( partitionid ) ; checknotnull ( ch , str_ + partitionid ) ; log . debug ( str_ , owningtaskname , ch . partitionid , consumedsubpartitionindex ) ; if ( ch . getclass ( ) == remoteinputchannel . class ) { final remoteinputchannel rch = ( remoteinputchannel ) ch ; rch . retriggersubpartitionrequest ( consumedsubpartitionindex ) ; } else if ( ch . getclass ( ) == localinputchannel . class ) { final localinputchannel ich = ( localinputchannel ) ch ; if ( retriggerlocalrequesttimer == null ) { retriggerlocalrequesttimer = new timer ( bool_ ) ; } ich . retriggersubpartitionrequest ( retriggerlocalrequesttimer , consumedsubpartitionindex ) ; } else { throw new illegalstateexception ( str_ + ch . getclass ( ) ) ; } } } }	Retriggers a partition request.
public static singleinputgate create ( string owningtaskname , jobid jobid , inputgatedeploymentdescriptor igdd , networkenvironment networkenvironment , taskeventpublisher taskeventpublisher , taskactions taskactions , inputchannelmetrics metrics , counter numbytesincounter ) { final intermediatedatasetid consumedresultid = checknotnull ( igdd . getconsumedresultid ( ) ) ; final resultpartitiontype consumedpartitiontype = checknotnull ( igdd . getconsumedpartitiontype ( ) ) ; final int consumedsubpartitionindex = igdd . getconsumedsubpartitionindex ( ) ; checkargument ( consumedsubpartitionindex >= num_ ) ; final inputchanneldeploymentdescriptor [ ] icdd = checknotnull ( igdd . getinputchanneldeploymentdescriptors ( ) ) ; final networkenvironmentconfiguration networkconfig = networkenvironment . getconfiguration ( ) ; final singleinputgate inputgate = new singleinputgate ( owningtaskname , jobid , consumedresultid , consumedpartitiontype , consumedsubpartitionindex , icdd . length , taskactions , numbytesincounter , networkconfig . iscreditbased ( ) ) ;	Creates an input gate and all of its input channels.
public static int getavailableport ( ) { for ( int i = num_ ; i < num_ ; i ++ ) { try ( serversocket serversocket = new serversocket ( num_ ) ) { int port = serversocket . getlocalport ( ) ; if ( port != num_ ) { return port ; } } catch ( ioexception ignored ) { } } throw new runtimeexception ( str_ ) ; }	Find a non-occupied port.
public static string unresolvedhosttonormalizedstring ( string host ) {	Returns an address in a normalized format for Akka.When an IPv6 address is specified, it normalizes the IPv6 address to avoidcomplications with the exact URL match policy of Akka.
public static string ipaddresstourlstring ( inetaddress address ) { if ( address == null ) { throw new nullpointerexception ( str_ ) ; } else if ( address instanceof inet4address ) { return address . gethostaddress ( ) ; } else if ( address instanceof inet6address ) { return getipv6urlrepresentation ( ( inet6address ) address ) ; } else { throw new illegalargumentexception ( str_ + address ) ; } }	Encodes an IP address properly as a URL string.
public static string socketaddresstourlstring ( inetsocketaddress address ) { if ( address . isunresolved ( ) ) { throw new illegalargumentexception ( str_ + address . gethoststring ( ) ) ; } return ipaddressandporttourlstring ( address . getaddress ( ) , address . getport ( ) ) ; }	Encodes an IP address and port to be included in URL.
public static string hostandporttourlstring ( string host , int port ) throws unknownhostexception { return ipaddressandporttourlstring ( inetaddress . getbyname ( host ) , port ) ; }	Normalizes and encodes a hostname and port to be included in URL.In particular, this method makes sure that IPv6 address literals have the properformatting to be included in URLs.
private static string getipv6urlrepresentation ( byte [ ] addressbytes ) {	Creates a compressed URL style representation of an Inet6Address.
public static iterator < integer > getportrangefromstring ( string rangedefinition ) throws numberformatexception { final string [ ] ranges = rangedefinition . trim ( ) . split ( str_ ) ; unioniterator < integer > iterators = new unioniterator < > ( ) ; for ( string rawrange : ranges ) { iterator < integer > rangeiterator ; string range = rawrange . trim ( ) ; int dashidx = range . indexof ( str_ ) ; if ( dashidx == - num_ ) {	Returns an iterator over available ports defined by the range definition.
public static serversocket createsocketfromports ( iterator < integer > portsiterator , socketfactory factory ) { while ( portsiterator . hasnext ( ) ) { int port = portsiterator . next ( ) ; log . debug ( str_ , port ) ; try { return factory . createsocket ( port ) ; } catch ( ioexception | illegalargumentexception e ) { if ( log . isdebugenabled ( ) ) { log . debug ( str_ , e ) ; } else { log . info ( str_ , port , e . getmessage ( ) ) ; } } } return null ; }	Tries to allocate a socket from the given sets of ports.
public void setrangepartitioned ( ordering ordering , datadistribution distribution ) { if ( ordering == null ) { throw new nullpointerexception ( ) ; } this . partitioning = partitioningproperty . range_partitioned ; this . ordering = ordering ; this . partitioningfields = ordering . getinvolvedindexes ( ) ; this . distribution = distribution ; }	Set the parameters for range partition.
public static < k , vv , ev > graph < k , vv , ev > fromcollection ( collection < vertex < k , vv > > vertices , collection < edge < k , ev > > edges , executionenvironment context ) { return fromdataset ( context . fromcollection ( vertices ) , context . fromcollection ( edges ) , context ) ; }	Creates a graph from a Collection of vertices and a Collection of edges.
public static < k , ev > graph < k , nullvalue , ev > fromcollection ( collection < edge < k , ev > > edges , executionenvironment context ) { return fromdataset ( context . fromcollection ( edges ) , context ) ; }	Creates a graph from a Collection of edges.Vertices are created automatically and their values are set toNullValue.
public static < k , vv , ev > graph < k , vv , ev > fromcollection ( collection < edge < k , ev > > edges , final mapfunction < k , vv > vertexvalueinitializer , executionenvironment context ) { return fromdataset ( context . fromcollection ( edges ) , vertexvalueinitializer , context ) ; }	Creates a graph from a Collection of edges.Vertices are created automatically and their values are setby applying the provided map function to the vertex IDs.
public static < k , vv , ev > graph < k , vv , ev > fromdataset ( dataset < vertex < k , vv > > vertices , dataset < edge < k , ev > > edges , executionenvironment context ) { return new graph < > ( vertices , edges , context ) ; }	Creates a graph from a DataSet of vertices and a DataSet of edges.
public static < k , ev > graph < k , nullvalue , ev > fromdataset ( dataset < edge < k , ev > > edges , executionenvironment context ) { dataset < vertex < k , nullvalue > > vertices = edges . flatmap ( new emitsrcandtarget < > ( ) ) . name ( str_ ) . distinct ( ) . name ( str_ ) ; return new graph < > ( vertices , edges , context ) ; }	Creates a graph from a DataSet of edges.Vertices are created automatically and their values are set toNullValue.
public static < k , vv , ev > graph < k , vv , ev > fromdataset ( dataset < edge < k , ev > > edges , final mapfunction < k , vv > vertexvalueinitializer , executionenvironment context ) { typeinformation < k > keytype = ( ( tupletypeinfo < ? > ) edges . gettype ( ) ) . gettypeat ( num_ ) ; typeinformation < vv > valuetype = typeextractor . createtypeinfo ( mapfunction . class , vertexvalueinitializer . getclass ( ) , num_ , keytype , null ) ; @ suppresswarnings ( { str_ , str_ } ) typeinformation < vertex < k , vv > > returntype = ( typeinformation < vertex < k , vv > > ) new tupletypeinfo ( vertex . class , keytype , valuetype ) ; dataset < vertex < k , vv > > vertices = edges . flatmap ( new emitsrcandtargetastuple1 < > ( ) ) . name ( str_ ) . distinct ( ) . name ( str_ ) . map ( new mapfunction < tuple1 < k > , vertex < k , vv > > ( ) { private vertex < k , vv > output = new vertex < > ( ) ; public vertex < k , vv > map ( tuple1 < k > value ) throws exception { output . f0 = value . f0 ; output . f1 = vertexvalueinitializer . map ( value . f0 ) ; return output ; } } ) . returns ( returntype ) . withforwardedfields ( str_ ) . name ( str_ ) ; return new graph < > ( vertices , edges , context ) ; }	Creates a graph from a DataSet of edges.Vertices are created automatically and their values are setby applying the provided map function to the vertex IDs.
public static < k , vv , ev > graph < k , vv , ev > fromtupledataset ( dataset < tuple2 < k , vv > > vertices , dataset < tuple3 < k , k , ev > > edges , executionenvironment context ) { dataset < vertex < k , vv > > vertexdataset = vertices . map ( new tuple2tovertexmap < > ( ) ) . name ( str_ ) ; dataset < edge < k , ev > > edgedataset = edges . map ( new tuple3toedgemap < > ( ) ) . name ( str_ ) ; return fromdataset ( vertexdataset , edgedataset , context ) ; }	Creates a graph from a DataSet of Tuple2 objects for vertices andTuple3 objects for edges.
public static < k > graph < k , nullvalue , nullvalue > fromtuple2dataset ( dataset < tuple2 < k , k > > edges , executionenvironment context ) { dataset < edge < k , nullvalue > > edgedataset = edges . map ( new tuple2toedgemap < > ( ) ) . name ( str_ ) ; return fromdataset ( edgedataset , context ) ; }	Creates a graph from a DataSet of Tuple2 objects for edges.Each Tuple2 will become one Edge, where the source ID will be the first field of the Tuple2and the target ID will be the second field of the Tuple2.
public static graphcsvreader fromcsvreader ( string verticespath , string edgespath , executionenvironment context ) { return new graphcsvreader ( verticespath , edgespath , context ) ; }	Creates a Graph from a CSV file of vertices and a CSV file of edges.
public dataset < triplet < k , vv , ev > > gettriplets ( ) { return this . getvertices ( ) . join ( this . getedges ( ) ) . where ( num_ ) . equalto ( num_ ) . with ( new projectedgewithsrcvalue < > ( ) ) . name ( str_ ) . join ( this . getvertices ( ) ) . where ( num_ ) . equalto ( num_ ) . with ( new projectedgewithvertexvalues < > ( ) ) . name ( str_ ) ; }	This method allows access to the graph's edge values along with its source and target vertex values.
public graph < k , vv , ev > filteronvertices ( filterfunction < vertex < k , vv > > vertexfilter ) { dataset < vertex < k , vv > > filteredvertices = this . vertices . filter ( vertexfilter ) ; dataset < edge < k , ev > > remainingedges = this . edges . join ( filteredvertices ) . where ( num_ ) . equalto ( num_ ) . with ( new projectedge < > ( ) ) . join ( filteredvertices ) . where ( num_ ) . equalto ( num_ ) . with ( new projectedge < > ( ) ) . name ( str_ ) ; return new graph < > ( filteredvertices , remainingedges , this . context ) ; }	Apply a filtering function to the graph and return a sub-graph thatsatisfies the predicates only for the vertices.
public graph < k , vv , ev > filteronedges ( filterfunction < edge < k , ev > > edgefilter ) { dataset < edge < k , ev > > filterededges = this . edges . filter ( edgefilter ) . name ( str_ ) ; return new graph < > ( this . vertices , filterededges , this . context ) ; }	Apply a filtering function to the graph and return a sub-graph thatsatisfies the predicates only for the edges.
public dataset < tuple2 < k , longvalue > > outdegrees ( ) { return vertices . cogroup ( edges ) . where ( num_ ) . equalto ( num_ ) . with ( new countneighborscogroup < > ( ) ) . name ( str_ ) ; }	Return the out-degree of all vertices in the graph.
public dataset < tuple2 < k , longvalue > > getdegrees ( ) { return outdegrees ( ) . union ( indegrees ( ) ) . name ( str_ ) . groupby ( num_ ) . sum ( num_ ) . name ( str_ ) ; }	Return the degree of all vertices in the graph.
public graph < k , vv , ev > getundirected ( ) { dataset < edge < k , ev > > undirectededges = edges . flatmap ( new regularandreversededgesmap < > ( ) ) . name ( str_ ) ; return new graph < > ( vertices , undirectededges , this . context ) ; }	This operation adds all inverse-direction edges to the graph.
public < t > dataset < t > groupreduceonedges ( edgesfunctionwithvertexvalue < k , vv , ev , t > edgesfunction , edgedirection direction ) throws illegalargumentexception { switch ( direction ) { case in : return vertices . cogroup ( edges ) . where ( num_ ) . equalto ( num_ ) . with ( new applycogroupfunction < > ( edgesfunction ) ) . name ( str_ ) ; case out : return vertices . cogroup ( edges ) . where ( num_ ) . equalto ( num_ ) . with ( new applycogroupfunction < > ( edgesfunction ) ) . name ( str_ ) ; case all : return vertices . cogroup ( edges . flatmap ( new emitoneedgepernode < > ( ) ) . name ( str_ ) ) . where ( num_ ) . equalto ( num_ ) . with ( new applycogroupfunctiononalledges < > ( edgesfunction ) ) . name ( str_ ) ; default : throw new illegalargumentexception ( str_ ) ; } }	Groups by vertex and computes a GroupReduce transformation over the edge values of each vertex.The edgesFunction applied on the edges has access to both the id and the valueof the grouping vertex.
public graph < k , vv , ev > reverse ( ) throws unsupportedoperationexception { dataset < edge < k , ev > > reversededges = edges . map ( new reverseedgesmap < > ( ) ) . name ( str_ ) ; return new graph < > ( vertices , reversededges , this . context ) ; }	Reverse the direction of the edges in the graph.
public graph < k , vv , ev > addvertex ( final vertex < k , vv > vertex ) { list < vertex < k , vv > > newvertex = new arraylist < > ( ) ; newvertex . add ( vertex ) ; return addvertices ( newvertex ) ; }	Adds the input vertex to the graph.
public graph < k , vv , ev > addvertices ( list < vertex < k , vv > > verticestoadd ) {	Adds the list of vertices, passed as input, to the graph.If the vertices already exist in the graph, they will not be added once more.
public graph < k , vv , ev > addedge ( vertex < k , vv > source , vertex < k , vv > target , ev edgevalue ) { graph < k , vv , ev > partialgraph = fromcollection ( arrays . aslist ( source , target ) , collections . singletonlist ( new edge < > ( source . f0 , target . f0 , edgevalue ) ) , this . context ) ; return this . union ( partialgraph ) ; }	Adds the given edge to the graph.
public graph < k , vv , ev > addedges ( list < edge < k , ev > > newedges ) { dataset < edge < k , ev > > newedgesdataset = this . context . fromcollection ( newedges ) ; dataset < edge < k , ev > > validnewedges = this . getvertices ( ) . join ( newedgesdataset ) . where ( num_ ) . equalto ( num_ ) . with ( new joinverticeswithedgesonsrc < > ( ) ) . name ( str_ ) . join ( this . getvertices ( ) ) . where ( num_ ) . equalto ( num_ ) . with ( new joinwithverticesontrg < > ( ) ) . name ( str_ ) ; return graph . fromdataset ( this . vertices , this . edges . union ( validnewedges ) , this . context ) ; }	Adds the given list edges to the graph.
public graph < k , vv , ev > removevertex ( vertex < k , vv > vertex ) { list < vertex < k , vv > > vertextoberemoved = new arraylist < > ( ) ; vertextoberemoved . add ( vertex ) ; return removevertices ( vertextoberemoved ) ; }	Removes the given vertex and its edges from the graph.
public graph < k , vv , ev > removeedge ( edge < k , ev > edge ) { dataset < edge < k , ev > > newedges = getedges ( ) . filter ( new edgeremovaledgefilter < > ( edge ) ) . name ( str_ ) ; return new graph < > ( this . vertices , newedges , this . context ) ; }	Removes all edges that match the given edge from the graph.
public graph < k , vv , ev > removeedges ( list < edge < k , ev > > edgestoberemoved ) { dataset < edge < k , ev > > newedges = getedges ( ) . cogroup ( this . context . fromcollection ( edgestoberemoved ) ) . where ( num_ , num_ ) . equalto ( num_ , num_ ) . with ( new edgeremovalcogroup < > ( ) ) . name ( str_ ) ; return new graph < > ( this . vertices , newedges , context ) ; }	Removes all the edges that match the edges in the given data set from the graph.
public graph < k , vv , ev > union ( graph < k , vv , ev > graph ) { dataset < vertex < k , vv > > unionedvertices = graph . getvertices ( ) . union ( this . getvertices ( ) ) . name ( str_ ) . distinct ( ) . name ( str_ ) ; dataset < edge < k , ev > > unionededges = graph . getedges ( ) . union ( this . getedges ( ) ) . name ( str_ ) ; return new graph < > ( unionedvertices , unionededges , this . context ) ; }	Performs union on the vertices and edges sets of the input graphsremoving duplicate vertices but maintaining duplicate edges.
private dataset < edge < k , ev > > getdistinctedgeintersection ( dataset < edge < k , ev > > edges ) { return this . getedges ( ) . join ( edges ) . where ( num_ , num_ , num_ ) . equalto ( num_ , num_ , num_ ) . with ( new joinfunction < edge < k , ev > , edge < k , ev > , edge < k , ev > > ( ) { @ override public edge < k , ev > join ( edge < k , ev > first , edge < k , ev > second ) throws exception { return first ; } } ) . withforwardedfieldsfirst ( str_ ) . name ( str_ ) . distinct ( ) . name ( str_ ) ; }	Computes the intersection between the edge set and the given edge set.
private dataset < edge < k , ev > > getpairwiseedgeintersection ( dataset < edge < k , ev > > edges ) { return this . getedges ( ) . cogroup ( edges ) . where ( num_ , num_ , num_ ) . equalto ( num_ , num_ , num_ ) . with ( new matchingedgereducer < > ( ) ) . name ( str_ ) ; }	Computes the intersection between the edge set and the given edge set.
public < m > graph < k , vv , ev > runscattergatheriteration ( scatterfunction < k , vv , m , ev > scatterfunction , org . apache . flink . graph . spargel . gatherfunction < k , vv , m > gatherfunction , int maximumnumberofiterations ) { return this . runscattergatheriteration ( scatterfunction , gatherfunction , maximumnumberofiterations , null ) ; }	Runs a ScatterGather iteration on the graph.No configuration options are provided.
public < m > graph < k , vv , ev > runscattergatheriteration ( scatterfunction < k , vv , m , ev > scatterfunction , org . apache . flink . graph . spargel . gatherfunction < k , vv , m > gatherfunction , int maximumnumberofiterations , scattergatherconfiguration parameters ) { scattergatheriteration < k , vv , m , ev > iteration = scattergatheriteration . withedges ( edges , scatterfunction , gatherfunction , maximumnumberofiterations ) ; iteration . configure ( parameters ) ; dataset < vertex < k , vv > > newvertices = this . getvertices ( ) . runoperation ( iteration ) ; return new graph < > ( newvertices , this . edges , this . context ) ; }	Runs a ScatterGather iteration on the graph with configuration options.
public < m > graph < k , vv , ev > rungathersumapplyiteration ( org . apache . flink . graph . gsa . gatherfunction < vv , ev , m > gatherfunction , sumfunction < vv , ev , m > sumfunction , applyfunction < k , vv , m > applyfunction , int maximumnumberofiterations ) { return this . rungathersumapplyiteration ( gatherfunction , sumfunction , applyfunction , maximumnumberofiterations , null ) ; }	Runs a Gather-Sum-Apply iteration on the graph.No configuration options are provided.
public < m > graph < k , vv , ev > rungathersumapplyiteration ( org . apache . flink . graph . gsa . gatherfunction < vv , ev , m > gatherfunction , sumfunction < vv , ev , m > sumfunction , applyfunction < k , vv , m > applyfunction , int maximumnumberofiterations , gsaconfiguration parameters ) { gathersumapplyiteration < k , vv , ev , m > iteration = gathersumapplyiteration . withedges ( edges , gatherfunction , sumfunction , applyfunction , maximumnumberofiterations ) ; iteration . configure ( parameters ) ; dataset < vertex < k , vv > > newvertices = vertices . runoperation ( iteration ) ; return new graph < > ( newvertices , this . edges , this . context ) ; }	Runs a Gather-Sum-Apply iteration on the graph with configuration options.
public static long totimestamp ( string datestr , string format , timezone tz ) { simpledateformat formatter = formatter_cache . get ( format ) ; formatter . settimezone ( tz ) ; try { return formatter . parse ( datestr ) . gettime ( ) ; } catch ( parseexception e ) { return null ; } }	Parse date time string to timestamp based on the given time zone and format.Returns null if parsing failed.
public static long totimestamptz ( string datestr , string format , string tzstr ) { timezone tz = timezone_cache . get ( tzstr ) ; return totimestamp ( datestr , format , tz ) ; }	Parse date time string to timestamp based on the given time zone string and format.Returns null if parsing failed.
public static int strtodate ( string datestr , string fromformat ) {	Returns the epoch days since 1970-01-01.
public static string dateformat ( long ts , string format , timezone tz ) { simpledateformat formatter = formatter_cache . get ( format ) ; formatter . settimezone ( tz ) ; date datetime = new date ( ts ) ; return formatter . format ( datetime ) ; }	Format a timestamp as specific.
public static string dateformat ( string datestr , string fromformat , string toformat , timezone tz ) { simpledateformat fromformatter = formatter_cache . get ( fromformat ) ; fromformatter . settimezone ( tz ) ; simpledateformat toformatter = formatter_cache . get ( toformat ) ; toformatter . settimezone ( tz ) ; try { return toformatter . format ( fromformatter . parse ( datestr ) ) ; } catch ( parseexception e ) { log . error ( str_ + datestr + str_ + fromformat + str_ + toformat + str_ , e ) ; return null ; } }	Format a string datetime as specific.
public static string converttz ( string datestr , string format , string tzfrom , string tzto ) { return dateformattz ( totimestamptz ( datestr , format , tzfrom ) , tzto ) ; }	Convert datetime string from a time zone to another time zone.
public static string timestamptostring ( long ts , int precision , timezone tz ) { int p = ( precision <= num_ && precision >= num_ ) ? precision : num_ ; string format = default_datetime_formats [ p ] ; return dateformat ( ts , format , tz ) ; }	Convert a timestamp to string.
private static int getmillis ( string datestr ) { int length = datestr . length ( ) ; if ( length == num_ ) {	Returns the milli second part of the datetime.
public static long timestampceil ( timeunitrange range , long ts , timezone tz ) {	Keep the algorithm consistent with Calcite DateTimeUtils.julianDateFloor, but herewe take time zone into account.
@ override public boolean validate ( graph < k , vv , ev > graph ) throws exception { dataset < tuple1 < k > > edgeids = graph . getedges ( ) . flatmap ( new mapedgeids < > ( ) ) . distinct ( ) ; dataset < k > invalidids = graph . getvertices ( ) . cogroup ( edgeids ) . where ( num_ ) . equalto ( num_ ) . with ( new groupinvalidids < > ( ) ) . first ( num_ ) ; return invalidids . map ( new ktotuplemap < > ( ) ) . count ( ) == num_ ; }	Checks that the edge set input contains valid vertex Ids, i.e.
public hcatinputformatbase < t > getfields ( string ... fields ) throws ioexception {	Specifies the fields which are returned by the InputFormat and their order.
static byte [ ] readbinaryfieldfromsegments ( memorysegment [ ] segments , int baseoffset , int fieldoffset , long variablepartoffsetandlen ) { long mark = variablepartoffsetandlen & highest_first_bit ; if ( mark == num_ ) { final int suboffset = ( int ) ( variablepartoffsetandlen > > num_ ) ; final int len = ( int ) variablepartoffsetandlen ; return segmentsutil . copytobytes ( segments , baseoffset + suboffset , len ) ; } else { int len = ( int ) ( ( variablepartoffsetandlen & highest_second_to_eighth_bit ) > > > num_ ) ; if ( segmentsutil . little_endian ) { return segmentsutil . copytobytes ( segments , fieldoffset , len ) ; } else {	Get binary, if len less than 8, will be include in variablePartOffsetAndLen.
static binarystring readbinarystringfieldfromsegments ( memorysegment [ ] segments , int baseoffset , int fieldoffset , long variablepartoffsetandlen ) { long mark = variablepartoffsetandlen & highest_first_bit ; if ( mark == num_ ) { final int suboffset = ( int ) ( variablepartoffsetandlen > > num_ ) ; final int len = ( int ) variablepartoffsetandlen ; return new binarystring ( segments , baseoffset + suboffset , len ) ; } else { int len = ( int ) ( ( variablepartoffsetandlen & highest_second_to_eighth_bit ) > > > num_ ) ; if ( segmentsutil . little_endian ) { return new binarystring ( segments , fieldoffset , len ) ; } else {	Get binary string, if len less than 8, will be include in variablePartOffsetAndLen.
public static string getversion ( ) { string version = environmentinformation . class . getpackage ( ) . getimplementationversion ( ) ; return version != null ? version : unknown ; }	Returns the version of the code as String.
public static string gethadoopuser ( ) { try { class < ? > ugiclass = class . forname ( str_ , bool_ , environmentinformation . class . getclassloader ( ) ) ; method currentusermethod = ugiclass . getmethod ( str_ ) ; method shortusernamemethod = ugiclass . getmethod ( str_ ) ; object ugi = currentusermethod . invoke ( null ) ; return ( string ) shortusernamemethod . invoke ( ugi ) ; } catch ( classnotfoundexception e ) { return str_ ; } catch ( linkageerror e ) {	Gets the name of the user that is running the JVM.
public static long getmaxjvmheapmemory ( ) { final long maxmemory = runtime . getruntime ( ) . maxmemory ( ) ; if ( maxmemory != long . max_value ) {	The maximum JVM heap size, in bytes.
public json schema ( typeinformation < row > schematype ) { preconditions . checknotnull ( schematype ) ; this . schema = typestringutils . writetypeinfo ( schematype ) ; this . jsonschema = null ; this . deriveschema = null ; return this ; }	Sets the schema using type information.
@ override public void open ( ) { synchronized ( statelock ) { if ( ! closed ) { throw new illegalstateexception ( str_ ) ; } closed = bool_ ; }	Initialize the hash table.
@ override public void close ( ) {	Closes the hash table.
private long getsize ( ) { long numsegments = num_ ; numsegments += this . availablememory . size ( ) ; numsegments += this . buckets . length ; for ( inmemorypartition < t > p : this . partitions ) { numsegments += p . getblockcount ( ) ; numsegments += p . numoverflowsegments ; } numsegments += this . compactionmemory . getblockcount ( ) ; return numsegments * this . segmentsize ; }	Size of all memory segments owned by this hash table.
private long getpartitionsize ( ) { long numsegments = num_ ; for ( inmemorypartition < t > p : this . partitions ) { numsegments += p . getblockcount ( ) ; } return numsegments * this . segmentsize ; }	Size of all memory segments owned by the partitions of this hash table excluding the compaction partition.
private void trydeleteemptyparentznodes ( ) throws exception {	Tries to delete empty parent znodes. IMPORTANT: This method can be removed once all supported ZooKeeper versionssupport the container {.
@ visiblefortesting public int numkeyvaluestateentries ( object namespace ) { int sum = num_ ; for ( statetable < ? , ? , ? > state : registeredkvstates . values ( ) ) { sum += state . sizeofnamespace ( namespace ) ; } return sum ; }	Returns the total number of state entries across all keys for the given namespace.
static void skipserializedstates ( datainputview in ) throws ioexception { typeserializer < string > nameserializer = stringserializer . instance ; typeserializer < state . statetype > statetypeserializer = new enumserializer < > ( state . statetype . class ) ; typeserializer < statetransitionaction > actionserializer = new enumserializer < > ( statetransitionaction . class ) ; final int noofstates = in . readint ( ) ; for ( int i = num_ ; i < noofstates ; i ++ ) { nameserializer . deserialize ( in ) ; statetypeserializer . deserialize ( in ) ; } for ( int i = num_ ; i < noofstates ; i ++ ) { string srcname = nameserializer . deserialize ( in ) ; int nooftransitions = in . readint ( ) ; for ( int j = num_ ; j < nooftransitions ; j ++ ) { string src = nameserializer . deserialize ( in ) ; preconditions . checkstate ( src . equals ( srcname ) , str_ + srcname + str_ + src + str_ ) ; nameserializer . deserialize ( in ) ; actionserializer . deserialize ( in ) ; try { skipcondition ( in ) ; } catch ( classnotfoundexception e ) { e . printstacktrace ( ) ; } } } }	Skips bytes corresponding to serialized states.
public static boolean isinfixedlengthpart ( internaltype type ) { if ( type instanceof decimaltype ) { return ( ( decimaltype ) type ) . precision ( ) <= decimaltype . max_compact_precision ; } else { return mutable_field_types . contains ( type ) ; } }	If it is a fixed-length field, we can call this BinaryRow's setXX method for in-place updates.If it is variable-length field, can't use this method, because the underlying data is stored continuously.
public boolean anynull ( ) {	The bit is 1 when the field is null.
private static < r extends jarrequestbody , m extends messageparameters > list < string > getprogramargs ( handlerrequest < r , m > request , logger log ) throws resthandlerexception { jarrequestbody requestbody = request . getrequestbody ( ) ; @ suppresswarnings ( str_ ) list < string > programargs = tokenizearguments ( fromrequestbodyorqueryparameter ( emptytonull ( requestbody . getprogramarguments ( ) ) , ( ) -> getqueryparameter ( request , programargsqueryparameter . class ) , null , log ) ) ; list < string > programargslist = fromrequestbodyorqueryparameter ( requestbody . getprogramargumentslist ( ) , ( ) -> request . getqueryparameter ( programargqueryparameter . class ) , null , log ) ; if ( ! programargslist . isempty ( ) ) { if ( ! programargs . isempty ( ) ) { throw new resthandlerexception ( str_ , httpresponsestatus . bad_request ) ; } return programargslist ; } else { return programargs ; } }	Parse program arguments in jar run or plan request.
@ visiblefortesting static list < string > tokenizearguments ( @ nullable final string args ) { if ( args == null ) { return collections . emptylist ( ) ; } final matcher matcher = arguments_tokenize_pattern . matcher ( args ) ; final list < string > tokens = new arraylist < > ( ) ; while ( matcher . find ( ) ) { tokens . add ( matcher . group ( ) . trim ( ) . replace ( str_ , str_ ) . replace ( str_ , str_ ) ) ; } return tokens ; }	Takes program arguments as a single string, and splits them into a list of string.
public map < string , optionalfailure < accumulator < ? , ? > > > aggregateuseraccumulators ( ) { map < string , optionalfailure < accumulator < ? , ? > > > useraccumulators = new hashmap < > ( ) ; for ( executionvertex vertex : getallexecutionvertices ( ) ) { map < string , accumulator < ? , ? > > next = vertex . getcurrentexecutionattempt ( ) . getuseraccumulators ( ) ; if ( next != null ) { accumulatorhelper . mergeinto ( useraccumulators , next ) ; } } return useraccumulators ; }	Merges all accumulator results from the tasks previously executed in the Executions.
@ override public map < string , serializedvalue < optionalfailure < object > > > getaccumulatorsserialized ( ) { return aggregateuseraccumulators ( ) . entryset ( ) . stream ( ) . collect ( collectors . tomap ( map . entry :: getkey , entry -> serializeaccumulator ( entry . getkey ( ) , entry . getvalue ( ) ) ) ) ; }	Gets a serialized accumulator map.
@ override public stringifiedaccumulatorresult [ ] getaccumulatorresultsstringified ( ) { map < string , optionalfailure < accumulator < ? , ? > > > accumulatormap = aggregateuseraccumulators ( ) ; return stringifiedaccumulatorresult . stringifyaccumulatorresults ( accumulatormap ) ; }	Returns the a stringified version of the user-defined accumulators.
public void suspend ( throwable suspensioncause ) { assertrunninginjobmastermainthread ( ) ; if ( state . isterminalstate ( ) ) {	Suspends the current ExecutionGraph. The JobStatus will be directly set to {.
public void failglobal ( throwable t ) { assertrunninginjobmastermainthread ( ) ; while ( bool_ ) { jobstatus current = state ;	Fails the execution graph globally.
public boolean updatestate ( taskexecutionstate state ) { assertrunninginjobmastermainthread ( ) ; final execution attempt = currentexecutions . get ( state . getid ( ) ) ; if ( attempt != null ) { try { map < string , accumulator < ? , ? > > accumulators ; switch ( state . getexecutionstate ( ) ) { case running : return attempt . switchtorunning ( ) ; case finished :	Updates the state of one of the ExecutionVertex's Execution attempts.If the new status if "FINISHED", this also updates the accumulators.
private map < string , accumulator < ? , ? > > deserializeaccumulators ( taskexecutionstate state ) { accumulatorsnapshot serializedaccumulators = state . getaccumulators ( ) ; if ( serializedaccumulators != null ) { try { return serializedaccumulators . deserializeuseraccumulators ( userclassloader ) ; } catch ( throwable t ) {	Deserializes accumulators from a task state update. This method never throws an exception!.
public void scheduleorupdateconsumers ( resultpartitionid partitionid ) throws executiongraphexception { assertrunninginjobmastermainthread ( ) ; final execution execution = currentexecutions . get ( partitionid . getproducerid ( ) ) ; if ( execution == null ) { throw new executiongraphexception ( str_ + partitionid . getpartitionid ( ) + str_ ) ; } else if ( execution . getvertex ( ) == null ) { throw new executiongraphexception ( str_ + partitionid . getpartitionid ( ) + str_ ) ; } else { execution . getvertex ( ) . scheduleorupdateconsumers ( partitionid ) ; } }	Schedule or updates consumers of the given result partition.
public void updateaccumulators ( accumulatorsnapshot accumulatorsnapshot ) { map < string , accumulator < ? , ? > > useraccumulators ; try { useraccumulators = accumulatorsnapshot . deserializeuseraccumulators ( userclassloader ) ; executionattemptid execid = accumulatorsnapshot . getexecutionattemptid ( ) ; execution execution = currentexecutions . get ( execid ) ; if ( execution != null ) { execution . setaccumulators ( useraccumulators ) ; } else { log . debug ( str_ , execid ) ; } } catch ( exception e ) { log . error ( str_ , getjobid ( ) , e ) ; } }	Updates the accumulators during the runtime of a job.
private set < allocationid > computeallpriorallocationids ( ) { hashset < allocationid > allpreviousallocationids = new hashset < > ( getnumberofexecutionjobvertices ( ) ) ; for ( executionvertex executionvertex : getallexecutionvertices ( ) ) { allocationid latestpriorallocation = executionvertex . getlatestpriorallocation ( ) ; if ( latestpriorallocation != null ) { allpreviousallocationids . add ( latestpriorallocation ) ; } } return allpreviousallocationids ; }	Computes and returns a set with the prior allocation ids from all execution vertices in the graph.
public static void clean ( object func , boolean checkserializable ) { if ( func == null ) { return ; } final class < ? > cls = func . getclass ( ) ;	Tries to clean the closure of the given object, if the object is a non-static innerclass.
public static < t > void applytoallwhilesuppressingexceptions ( iterable < t > inputs , throwingconsumer < t , ? extends exception > throwingconsumer ) throws exception { if ( inputs != null && throwingconsumer != null ) { exception exception = null ; for ( t input : inputs ) { if ( input != null ) { try { throwingconsumer . accept ( input ) ; } catch ( exception ex ) { exception = exceptionutils . firstorsuppressed ( ex , exception ) ; } } } if ( exception != null ) { throw exception ; } } }	This method supplies all elements from the input to the consumer.
private executorservice createqueryexecutor ( ) { threadfactory threadfactory = new threadfactorybuilder ( ) . setdaemon ( bool_ ) . setnameformat ( str_ + getservername ( ) + str_ ) . build ( ) ; return executors . newfixedthreadpool ( numquerythreads , threadfactory ) ; }	Creates a thread pool for the query execution.
private boolean attempttobind ( final int port ) throws throwable { log . debug ( str_ , servername , port ) ; this . queryexecutor = createqueryexecutor ( ) ; this . handler = initializehandler ( ) ; final nettybufferpool bufferpool = new nettybufferpool ( numeventloopthreads ) ; final threadfactory threadfactory = new threadfactorybuilder ( ) . setdaemon ( bool_ ) . setnameformat ( str_ + servername + str_ ) . build ( ) ; final nioeventloopgroup niogroup = new nioeventloopgroup ( numeventloopthreads , threadfactory ) ; this . bootstrap = new serverbootstrap ( ) . localaddress ( bindaddress , port ) . group ( niogroup ) . channel ( nioserversocketchannel . class ) . option ( channeloption . allocator , bufferpool ) . childoption ( channeloption . allocator , bufferpool ) . childhandler ( new serverchannelinitializer < > ( handler ) ) ; final int defaulthighwatermark = num_ * num_ ;	Tries to start the server at the provided port. This, in conjunction with {.
public static metricqueryservice createmetricqueryservice ( rpcservice rpcservice , resourceid resourceid , long maximumframesize ) { string endpointid = resourceid == null ? metric_query_service_name : metric_query_service_name + str_ + resourceid . getresourceidstring ( ) ; return new metricqueryservice ( rpcservice , endpointid , maximumframesize ) ; }	Starts the MetricQueryService actor in the given actor system.
public int size ( ) { int ret = anymethodrouter . size ( ) ; for ( methodlessrouter < t > router : routers . values ( ) ) { ret += router . size ( ) ; } return ret ; }	Returns the number of routes in this router.
public router < t > addroute ( httpmethod method , string pathpattern , t target ) { getmethodlessrouter ( method ) . addroute ( pathpattern , target ) ; return this ; }	Add route. A path pattern can only point to one target. This method does nothing if the patternhas already been added.
public set < httpmethod > allowedmethods ( string uri ) { querystringdecoder decoder = new querystringdecoder ( uri ) ; string [ ] tokens = pathpattern . removeslashesatbothends ( decoder . path ( ) ) . split ( str_ ) ; if ( anymethodrouter . anymatched ( tokens ) ) { return allallowedmethods ( ) ; } set < httpmethod > ret = new hashset < httpmethod > ( routers . size ( ) ) ; for ( map . entry < httpmethod , methodlessrouter < t > > entry : routers . entryset ( ) ) { methodlessrouter < t > router = entry . getvalue ( ) ; if ( router . anymatched ( tokens ) ) { httpmethod method = entry . getkey ( ) ; ret . add ( method ) ; } } return ret ; }	Returns allowed methods for a specific URI. For {.
@ publicevolving public queryablestatestream < key , t > asqueryablestate ( string queryablestatename ) { valuestatedescriptor < t > valuestatedescriptor = new valuestatedescriptor < t > ( uuid . randomuuid ( ) . tostring ( ) , gettype ( ) ) ; return asqueryablestate ( queryablestatename , valuestatedescriptor ) ; }	Publishes the keyed stream as queryable ValueState instance.
@ publicevolving public queryablestatestream < key , t > asqueryablestate ( string queryablestatename , valuestatedescriptor < t > statedescriptor ) { transform ( str_ + queryablestatename , gettype ( ) , new queryablevaluestateoperator < > ( queryablestatename , statedescriptor ) ) ; statedescriptor . initializeserializerunlessset ( getexecutionconfig ( ) ) ; return new queryablestatestream < > ( queryablestatename , statedescriptor , getkeytype ( ) . createserializer ( getexecutionconfig ( ) ) ) ; }	Publishes the keyed stream as a queryable ValueState instance.
@ publicevolving @ deprecated public < acc > queryablestatestream < key , acc > asqueryablestate ( string queryablestatename , foldingstatedescriptor < t , acc > statedescriptor ) { transform ( str_ + queryablestatename , gettype ( ) , new queryableappendingstateoperator < > ( queryablestatename , statedescriptor ) ) ; statedescriptor . initializeserializerunlessset ( getexecutionconfig ( ) ) ; return new queryablestatestream < > ( queryablestatename , statedescriptor , getkeytype ( ) . createserializer ( getexecutionconfig ( ) ) ) ; }	Publishes the keyed stream as a queryable FoldingState instance.
@ publicevolving public queryablestatestream < key , t > asqueryablestate ( string queryablestatename , reducingstatedescriptor < t > statedescriptor ) { transform ( str_ + queryablestatename , gettype ( ) , new queryableappendingstateoperator < > ( queryablestatename , statedescriptor ) ) ; statedescriptor . initializeserializerunlessset ( getexecutionconfig ( ) ) ; return new queryablestatestream < > ( queryablestatename , statedescriptor , getkeytype ( ) . createserializer ( getexecutionconfig ( ) ) ) ; }	Publishes the keyed stream as a queryable ReducingState instance.
public static environment parse ( url url ) throws ioexception { try { return new configutil . lowercaseyamlmapper ( ) . readvalue ( url , environment . class ) ; } catch ( jsonmappingexception e ) { throw new sqlclientexception ( str_ + e . getmessage ( ) ) ; } }	Parses an environment file from an URL.
public static environment parse ( string content ) throws ioexception { try { return new configutil . lowercaseyamlmapper ( ) . readvalue ( content , environment . class ) ; } catch ( jsonmappingexception e ) { throw new sqlclientexception ( str_ + e . getmessage ( ) ) ; } }	Parses an environment file from an String.
public static environment merge ( environment env1 , environment env2 ) { final environment mergedenv = new environment ( ) ;	Merges two environments. The properties of the first environment might be overwritten by the second one.
void add ( long value ) { if ( value >= num_ ) { if ( count > num_ ) { min = math . min ( min , value ) ; max = math . max ( max , value ) ; } else { min = value ; max = value ; } count ++ ; sum += value ; } }	Adds the value to the stats if it is >= 0.
public void clear ( ) { final int arrayoffset = getheadelementindex ( ) ; arrays . fill ( queue , arrayoffset , arrayoffset + size , null ) ; size = num_ ; }	Clears the queue.
private void setmapforkeygroup ( int keygroupid , map < n , map < k , s > > map ) { try { state [ indextooffset ( keygroupid ) ] = map ; } catch ( arrayindexoutofboundsexception e ) { throw new illegalargumentexception ( str_ + keygroupid + str_ + str_ + keygroupoffset + str_ + ( keygroupoffset + state . length ) + str_ ) ; } }	Sets the given map for the given key-group.
public void randomemit ( t record ) throws ioexception , interruptedexception { emit ( record , rng . nextint ( numberofchannels ) ) ; }	This is used to send LatencyMarks to a random target channel.
private void notifyflusherexception ( throwable t ) { if ( flusherexception == null ) { log . error ( str_ , t ) ; flusherexception = t ; } }	Notifies the writer that the output flusher thread encountered an exception.
private void handlerpcinvocation ( rpcinvocation rpcinvocation ) { method rpcmethod = null ; try { string methodname = rpcinvocation . getmethodname ( ) ; class < ? > [ ] parametertypes = rpcinvocation . getparametertypes ( ) ; rpcmethod = lookuprpcmethod ( methodname , parametertypes ) ; } catch ( classnotfoundexception e ) { log . error ( str_ , e ) ; rpcconnectionexception rpcexception = new rpcconnectionexception ( str_ , e ) ; getsender ( ) . tell ( new status . failure ( rpcexception ) , getself ( ) ) ; } catch ( ioexception e ) { log . error ( str_ , e ) ; rpcconnectionexception rpcexception = new rpcconnectionexception ( str_ , e ) ; getsender ( ) . tell ( new status . failure ( rpcexception ) , getself ( ) ) ; } catch ( final nosuchmethodexception e ) { log . error ( str_ , e ) ; rpcconnectionexception rpcexception = new rpcconnectionexception ( str_ , e ) ; getsender ( ) . tell ( new status . failure ( rpcexception ) , getself ( ) ) ; } if ( rpcmethod != null ) { try {	Handle rpc invocations by looking up the rpc method on the rpc endpoint and calling thismethod with the provided method arguments.
protected void senderrorifsender ( throwable throwable ) { if ( ! getsender ( ) . equals ( actorref . nosender ( ) ) ) { getsender ( ) . tell ( new status . failure ( throwable ) , getself ( ) ) ; } }	Send throwable to sender if the sender is specified.
private void stop ( rpcendpointterminationresult rpcendpointterminationresult ) { if ( rpcendpointstopped . compareandset ( bool_ , bool_ ) ) { this . rpcendpointterminationresult = rpcendpointterminationresult ; getcontext ( ) . stop ( getself ( ) ) ; } }	Stop the actor immediately.
private static void printcustomclioptions ( collection < customcommandline < ? > > customcommandlines , helpformatter formatter , boolean runoptions ) {	Prints custom cli options.
public static void deletefileordirectory ( file file ) throws ioexception { checknotnull ( file , str_ ) ; guardifwindows ( fileutils :: deletefileordirectoryinternal , file ) ; }	Removes the given file or directory recursively.
public static void deletedirectory ( file directory ) throws ioexception { checknotnull ( directory , str_ ) ; guardifwindows ( fileutils :: deletedirectoryinternal , directory ) ; }	Deletes the given directory recursively.
public static void cleandirectory ( file directory ) throws ioexception { checknotnull ( directory , str_ ) ; guardifwindows ( fileutils :: cleandirectoryinternal , directory ) ; }	Removes all files contained within a directory, without removing the directory itself.
public static void copy ( path sourcepath , path targetpath , boolean executable ) throws ioexception {	Copies all files from source to target and sets executable flag.
public void releasepayload ( throwable cause ) { final payload payload = payloadreference . get ( ) ; if ( payload != null ) { payload . release ( cause ) ; payloadreference . set ( null ) ; } }	Triggers the release of the assigned payload.
public static protos . environment . variable variable ( string name , string value ) { checknotnull ( name ) ; return protos . environment . variable . newbuilder ( ) . setname ( name ) . setvalue ( value ) . build ( ) ; }	Construct a Mesos environment variable.
public static list < protos . resource > resources ( protos . resource ... resources ) { checknotnull ( resources ) ; return arrays . aslist ( resources ) ; }	Construct a list of resources.
public static protos . resource scalar ( string name , string role , double value ) { checknotnull ( name ) ; checknotnull ( role ) ; checknotnull ( value ) ; return protos . resource . newbuilder ( ) . setname ( name ) . settype ( protos . value . type . scalar ) . setscalar ( protos . value . scalar . newbuilder ( ) . setvalue ( value ) ) . setrole ( role ) . build ( ) ; }	Construct a scalar resource.
public static protos . value . range range ( long begin , long end ) { return protos . value . range . newbuilder ( ) . setbegin ( begin ) . setend ( end ) . build ( ) ; }	Construct a range value.
public static protos . resource ranges ( string name , string role , protos . value . range ... ranges ) { checknotnull ( name ) ; checknotnull ( role ) ; checknotnull ( ranges ) ; return protos . resource . newbuilder ( ) . setname ( name ) . settype ( protos . value . type . ranges ) . setranges ( protos . value . ranges . newbuilder ( ) . addallrange ( arrays . aslist ( ranges ) ) . build ( ) ) . setrole ( role ) . build ( ) ; }	Construct a range resource.
public static longstream rangevalues ( collection < protos . resource > resources ) { checknotnull ( resources ) ; return resources . stream ( ) . filter ( protos . resource :: hasranges ) . flatmap ( r -> r . getranges ( ) . getrangelist ( ) . stream ( ) ) . flatmaptolong ( utils :: rangevalues ) ; }	Gets a stream of values from a collection of range resources.
public static longstream rangevalues ( protos . value . range range ) { checknotnull ( range ) ; return longstream . rangeclosed ( range . getbegin ( ) , range . getend ( ) ) ; }	Gets a stream of values from a range.
public optional < typeinformation < ? > > getfieldtype ( int fieldindex ) { if ( fieldindex < num_ || fieldindex >= fieldtypes . length ) { return optional . empty ( ) ; } return optional . of ( fieldtypes [ fieldindex ] ) ; }	Returns the specified type information for the given field index.
public optional < typeinformation < ? > > getfieldtype ( string fieldname ) { if ( fieldnametoindex . containskey ( fieldname ) ) { return optional . of ( fieldtypes [ fieldnametoindex . get ( fieldname ) ] ) ; } return optional . empty ( ) ; }	Returns the specified type information for the given field name.
public optional < string > getfieldname ( int fieldindex ) { if ( fieldindex < num_ || fieldindex >= fieldnames . length ) { return optional . empty ( ) ; } return optional . of ( fieldnames [ fieldindex ] ) ; }	Returns the specified name for the given field index.
public void deploy ( ) throws jobexception { assertrunninginjobmastermainthread ( ) ; final logicalslot slot = assignedresource ; checknotnull ( slot , str_ ) ;	Deploys the execution to the previously assigned resource.
public completablefuture < stacktracesampleresponse > requeststacktracesample ( int sampleid , int numsamples , time delaybetweensamples , int maxstacktracedepth , time timeout ) { final logicalslot slot = assignedresource ; if ( slot != null ) { final taskmanagergateway taskmanagergateway = slot . gettaskmanagergateway ( ) ; return taskmanagergateway . requeststacktracesample ( attemptid , sampleid , numsamples , delaybetweensamples , maxstacktracedepth , timeout ) ; } else { return futureutils . completedexceptionally ( new exception ( str_ ) ) ; } }	Request a stack trace sample from the task of this execution.
public void notifycheckpointcomplete ( long checkpointid , long timestamp ) { final logicalslot slot = assignedresource ; if ( slot != null ) { final taskmanagergateway taskmanagergateway = slot . gettaskmanagergateway ( ) ; taskmanagergateway . notifycheckpointcomplete ( attemptid , getvertex ( ) . getjobid ( ) , checkpointid , timestamp ) ; } else { log . debug ( str_ + str_ ) ; } }	Notify the task of this execution about a completed checkpoint.
private void sendcancelrpccall ( int numberretries ) { final logicalslot slot = assignedresource ; if ( slot != null ) { final taskmanagergateway taskmanagergateway = slot . gettaskmanagergateway ( ) ; final componentmainthreadexecutor jobmastermainthreadexecutor = getvertex ( ) . getexecutiongraph ( ) . getjobmastermainthreadexecutor ( ) ; completablefuture < acknowledge > cancelresultfuture = futureutils . retry ( ( ) -> taskmanagergateway . canceltask ( attemptid , rpctimeout ) , numberretries , jobmastermainthreadexecutor ) ; cancelresultfuture . whencomplete ( ( ack , failure ) -> { if ( failure != null ) { fail ( new exception ( str_ , failure ) ) ; } } ) ; } }	This method sends a CancelTask message to the instance of the assigned slot.
private void sendupdatepartitioninforpccall ( final iterable < partitioninfo > partitioninfos ) { final logicalslot slot = assignedresource ; if ( slot != null ) { final taskmanagergateway taskmanagergateway = slot . gettaskmanagergateway ( ) ; final taskmanagerlocation taskmanagerlocation = slot . gettaskmanagerlocation ( ) ; completablefuture < acknowledge > updatepartitionsresultfuture = taskmanagergateway . updatepartitions ( attemptid , partitioninfos , rpctimeout ) ; updatepartitionsresultfuture . whencompleteasync ( ( ack , failure ) -> {	Update the partition infos on the assigned resource.
@ visiblefortesting public completablefuture < collection < taskmanagerlocation > > calculatepreferredlocations ( locationpreferenceconstraint locationpreferenceconstraint ) { final collection < completablefuture < taskmanagerlocation > > preferredlocationfutures = getvertex ( ) . getpreferredlocations ( ) ; final completablefuture < collection < taskmanagerlocation > > preferredlocationsfuture ; switch ( locationpreferenceconstraint ) { case all : preferredlocationsfuture = futureutils . combineall ( preferredlocationfutures ) ; break ; case any : final arraylist < taskmanagerlocation > completedtaskmanagerlocations = new arraylist < > ( preferredlocationfutures . size ( ) ) ; for ( completablefuture < taskmanagerlocation > preferredlocationfuture : preferredlocationfutures ) { if ( preferredlocationfuture . isdone ( ) && ! preferredlocationfuture . iscompletedexceptionally ( ) ) { final taskmanagerlocation taskmanagerlocation = preferredlocationfuture . getnow ( null ) ; if ( taskmanagerlocation == null ) { throw new flinkruntimeexception ( str_ ) ; } completedtaskmanagerlocations . add ( taskmanagerlocation ) ; } } preferredlocationsfuture = completablefuture . completedfuture ( completedtaskmanagerlocations ) ; break ; default : throw new runtimeexception ( str_ + locationpreferenceconstraint + str_ ) ; } return preferredlocationsfuture ; }	Calculates the preferred locations based on the location preference constraint.
public static < t > void writeversionandserialize ( simpleversionedserializer < t > serializer , t datum , dataoutputview out ) throws ioexception { checknotnull ( serializer , str_ ) ; checknotnull ( datum , str_ ) ; checknotnull ( out , str_ ) ; final byte [ ] data = serializer . serialize ( datum ) ; out . writeint ( serializer . getversion ( ) ) ; out . writeint ( data . length ) ; out . write ( data ) ; }	Serializes the version and datum into a stream. Data serialized via this method can be deserialized via{.
public static < t > t readversionanddeserialize ( simpleversionedserializer < t > serializer , datainputview in ) throws ioexception { checknotnull ( serializer , str_ ) ; checknotnull ( in , str_ ) ; final int version = in . readint ( ) ; final int length = in . readint ( ) ; final byte [ ] data = new byte [ length ] ; in . readfully ( data ) ; return serializer . deserialize ( version , data ) ; }	Deserializes the version and datum from a stream. This method deserializes data serialized via{.
public boolean cleanup ( ) throws ioexception { return ! state . compareandset ( state . ongoing , state . deleted ) || filesystem . delete ( directory , bool_ ) ; }	Calling this method will attempt delete the underlying snapshot directory recursively, if the state is"ongoing".
private boolean shouldroll ( ) throws ioexception { boolean shouldroll = bool_ ; int subtaskindex = getruntimecontext ( ) . getindexofthissubtask ( ) ; if ( ! iswriteropen ) { shouldroll = bool_ ; log . debug ( str_ , subtaskindex ) ; } if ( bucketer . shouldstartnewbucket ( new path ( basepath ) , currentbucketdirectory ) ) { shouldroll = bool_ ; log . debug ( str_ , subtaskindex , bucketer ) ;	Determines whether we should change the bucket file we are writing to. This will roll if no file was created yet, if the file size is larger than the specified sizeor if the {.
private void opennewpartfile ( ) throws exception { closecurrentpartfile ( ) ; path newbucketdirectory = bucketer . getnextbucketpath ( new path ( basepath ) ) ; if ( ! newbucketdirectory . equals ( currentbucketdirectory ) ) { currentbucketdirectory = newbucketdirectory ; try { if ( fs . mkdirs ( currentbucketdirectory ) ) { log . debug ( str_ , currentbucketdirectory ) ; } } catch ( ioexception e ) { throw new runtimeexception ( str_ , e ) ; } } int subtaskindex = getruntimecontext ( ) . getindexofthissubtask ( ) ; currentpartpath = new path ( currentbucketdirectory , partprefix + str_ + subtaskindex + str_ + partcounter ) ;	Opens a new part file. This closes the old bucket file and retrieves a new bucket path from the {.
private void closecurrentpartfile ( ) throws exception { if ( iswriteropen ) { writer . close ( ) ; iswriteropen = bool_ ; } if ( currentpartpath != null ) { path inprogresspath = getinprogresspathfor ( currentpartpath ) ; path pendingpath = getpendingpathfor ( currentpartpath ) ; fs . rename ( inprogresspath , pendingpath ) ; log . debug ( str_ , inprogresspath , pendingpath ) ; this . bucketstate . pendingfiles . add ( currentpartpath . tostring ( ) ) ; } }	Closes the current part file.
public gridgraph adddimension ( long size , boolean wrapendpoints ) { preconditions . checkargument ( size >= num_ , str_ ) ; vertexcount = math . multiplyexact ( vertexcount , size ) ;	Required configuration for each dimension of the graph.
public < t > typeserializer < t > getrestorednestedserializer ( int pos ) { checkargument ( pos < nestedsnapshots . length ) ; @ suppresswarnings ( str_ ) typeserializersnapshot < t > snapshot = ( typeserializersnapshot < t > ) nestedsnapshots [ pos ] ; return snapshot . restoreserializer ( ) ; }	Creates the restore serializer from the pos-th config snapshot.
@ deprecated public < t > typeserializerschemacompatibility < t > resolvecompatibilitywithnested ( typeserializerschemacompatibility < ? > outercompatibility , typeserializer < ? > ... newnestedserializers ) { checkargument ( newnestedserializers . length == nestedsnapshots . length , str_ ) ;	Resolves the compatibility of the nested serializer snapshots with the nestedserializers of the new outer serializer.
public final void writenestedserializersnapshots ( dataoutputview out ) throws ioexception { out . writeint ( magic_number ) ; out . writeint ( version ) ; out . writeint ( nestedsnapshots . length ) ; for ( typeserializersnapshot < ? > snap : nestedsnapshots ) { typeserializersnapshot . writeversionedsnapshot ( out , snap ) ; } }	Writes the composite snapshot of all the contained serializers.
public static nestedserializerssnapshotdelegate readnestedserializersnapshots ( datainputview in , classloader cl ) throws ioexception { final int magicnumber = in . readint ( ) ; if ( magicnumber != magic_number ) { throw new ioexception ( string . format ( str_ , magic_number , magicnumber ) ) ; } final int version = in . readint ( ) ; if ( version != version ) { throw new ioexception ( str_ + version ) ; } final int numsnapshots = in . readint ( ) ; final typeserializersnapshot < ? > [ ] nestedsnapshots = new typeserializersnapshot < ? > [ numsnapshots ] ; for ( int i = num_ ; i < numsnapshots ; i ++ ) { nestedsnapshots [ i ] = typeserializersnapshot . readversionedsnapshot ( in , cl ) ; } return new nestedserializerssnapshotdelegate ( nestedsnapshots ) ; }	Reads the composite snapshot of all the contained serializers.
@ suppresswarnings ( str_ ) private static < e > typeserializerschemacompatibility < e > resolvecompatibility ( typeserializer < ? > serializer , typeserializersnapshot < ? > snapshot ) { typeserializer < e > typedserializer = ( typeserializer < e > ) serializer ; typeserializersnapshot < e > typedsnapshot = ( typeserializersnapshot < e > ) snapshot ; return typedsnapshot . resolveschemacompatibility ( typedserializer ) ; }	Utility method to conjure up a new scope for the generic parameters.
public void setcustomendpointinitializer ( endpointinitializer initializer ) { objects . requirenonnull ( initializer , str_ ) ; closurecleaner . ensureserializable ( initializer ) ; this . initializer = initializer ; }	Set a custom endpoint initializer.
void unregisteroutputstream ( outstream stream ) { lock . lock ( ) ; try {	Atomically removes the given output stream from the set of currently open output streams,and signals that new stream can now be opened.
void unregisterinputstream ( instream stream ) { lock . lock ( ) ; try {	Atomically removes the given input stream from the set of currently open input streams,and signals that new stream can now be opened.
public void setmaxparallelism ( int maxparallelism ) { preconditions . checkargument ( maxparallelism > num_ && maxparallelism <= streamgraphgenerator . upper_bound_max_parallelism , str_ + streamgraphgenerator . upper_bound_max_parallelism + str_ + maxparallelism ) ; this . maxparallelism = maxparallelism ; }	Sets the maximum parallelism for this stream transformation.
public static boolean validateclassloadable ( classnotfoundexception cnfe , classloader cl ) { try { string classname = cnfe . getmessage ( ) ; class . forname ( classname , bool_ , cl ) ; return bool_ ; } catch ( classnotfoundexception e ) { return bool_ ; } catch ( exception e ) { return bool_ ; } }	Checks, whether the class that was not found in the given exception, can be resolved throughthe given class loader.
private mapping extractprojectsandmapping ( aggregate aggregate , relnode input , relbuilder relbuilder ) {	Extract projects from the Aggregate and return the index mapping between the new projectsand it's input.
private immutablebitset . builder getinputfieldused ( aggregate aggregate , relnode input ) {	Compute which input fields are used by the aggregate.
public static containeredtaskmanagerparameters create ( configuration config , long containermemorymb , int numslots ) {	Computes the parameters to be used to start a TaskManager Java process.
@ internal public static set < annotation > readsingleforwardannotations ( class < ? > udfclass ) { forwardedfields forwardedfields = udfclass . getannotation ( forwardedfields . class ) ; nonforwardedfields nonforwardedfields = udfclass . getannotation ( nonforwardedfields . class ) ; readfields readset = udfclass . getannotation ( readfields . class ) ; set < annotation > annotations = new hashset < annotation > ( ) ; if ( forwardedfields != null ) { annotations . add ( forwardedfields ) ; } if ( nonforwardedfields != null ) { if ( ! annotations . isempty ( ) ) { throw new invalidprogramexception ( str_ + forwardedfields . class . getsimplename ( ) + str_ + nonforwardedfields . class . getsimplename ( ) + str_ ) ; } annotations . add ( nonforwardedfields ) ; } if ( readset != null ) { annotations . add ( readset ) ; } return ! annotations . isempty ( ) ? annotations : null ; }	Reads the annotations of a user defined function with one input and returns semantic properties according to the forwarded fields annotated.
@ internal public static set < annotation > readdualforwardannotations ( class < ? > udfclass ) {	Reads the annotations of a user defined function with two inputs and returns semantic properties according to the forwarded fields annotated.
public static binarystring blankstring ( int length ) { byte [ ] spaces = new byte [ length ] ; arrays . fill ( spaces , ( byte ) str_ ) ; return frombytes ( spaces ) ; }	Creates an BinaryString that contains `length` spaces.
private int comparemultisegments ( binarystring other ) { if ( sizeinbytes == num_ || other . sizeinbytes == num_ ) { return sizeinbytes - other . sizeinbytes ; } int len = math . min ( sizeinbytes , other . sizeinbytes ) ; memorysegment seg1 = segments [ num_ ] ; memorysegment seg2 = other . segments [ num_ ] ; int segmentsize = segments [ num_ ] . size ( ) ; int othersegmentsize = other . segments [ num_ ] . size ( ) ; int sizeoffirst1 = segmentsize - offset ; int sizeoffirst2 = othersegmentsize - other . offset ; int varsegindex1 = num_ ; int varsegindex2 = num_ ;	Find the boundaries of segments, and then compare MemorySegment.
public static binarystring concat ( iterable < binarystring > inputs ) {	Concatenates input strings together into a single string.
public boolean contains ( final binarystring substring ) { ensurematerialized ( ) ; substring . ensurematerialized ( ) ; if ( substring . sizeinbytes == num_ ) { return bool_ ; } int find = segmentsutil . find ( segments , offset , sizeinbytes , substring . segments , substring . offset , substring . sizeinbytes ) ; return find != - num_ ; }	Returns whether this contains `substring` or not.Same to like '%substring%'.
public boolean endswith ( final binarystring suffix ) { ensurematerialized ( ) ; suffix . ensurematerialized ( ) ; return matchat ( suffix , sizeinbytes - suffix . sizeinbytes ) ; }	Same to like '%suffix'.
public binarystring trim ( binarystring trimstr ) { if ( trimstr == null ) { return null ; } return trimleft ( trimstr ) . trimright ( trimstr ) ; }	Walk each character of current string from both ends, remove the character if itis in trim string.Return the new substring which both ends trim characters have been removed.
public binarystring trimleft ( binarystring trimstr ) { ensurematerialized ( ) ; if ( trimstr == null ) { return null ; } trimstr . ensurematerialized ( ) ; if ( trimstr . isspacestring ( ) ) { return trimleft ( ) ; } if ( infirstsegment ( ) ) { int searchidx = num_ ; while ( searchidx < this . sizeinbytes ) { int charbytes = numbytesforfirstbyte ( getbyteonesegment ( searchidx ) ) ; binarystring currentchar = copybinarystringinoneseg ( searchidx , searchidx + charbytes - num_ ) ;	Walk each character of current string from left end, remove the character if itis in trim string.
public binarystring trimright ( binarystring trimstr ) { ensurematerialized ( ) ; if ( trimstr == null ) { return null ; } trimstr . ensurematerialized ( ) ; if ( trimstr . isspacestring ( ) ) { return trimright ( ) ; } if ( infirstsegment ( ) ) { int charidx = num_ ; int byteidx = num_ ;	Walk each character of current string from right end, remove the character if itis in trim string.
public int indexof ( binarystring substr , int start ) { ensurematerialized ( ) ; substr . ensurematerialized ( ) ; if ( substr . sizeinbytes == num_ ) { return num_ ; } if ( infirstsegment ( ) ) {	Returns the position of the first occurence of substr in current string starting from givenposition.
public binarystring reverse ( ) { ensurematerialized ( ) ; if ( infirstsegment ( ) ) { byte [ ] result = new byte [ this . sizeinbytes ] ;	Reverse each character in current string.
public long tolong ( ) { ensurematerialized ( ) ; if ( sizeinbytes == num_ ) { return null ; } int size = segments [ num_ ] . size ( ) ; segmentandoffset segmentandoffset = startsegmentandoffset ( size ) ; int totaloffset = num_ ; byte b = segmentandoffset . value ( ) ; final boolean negative = b == str_ ; if ( negative || b == str_ ) { segmentandoffset . nextbyte ( size ) ; totaloffset ++ ; if ( sizeinbytes == num_ ) { return null ; } } long result = num_ ; final byte separator = str_ ; final int radix = num_ ; final long stopvalue = long . min_value / radix ; while ( totaloffset < this . sizeinbytes ) { b = segmentandoffset . value ( ) ; totaloffset ++ ; segmentandoffset . nextbyte ( size ) ; if ( b == separator ) {	Parses this BinaryString to Long.
public binarystring touppercase ( ) { if ( javaobject != null ) { return touppercaseslow ( ) ; } if ( sizeinbytes == num_ ) { return empty_utf8 ; } int size = segments [ num_ ] . size ( ) ; segmentandoffset segmentandoffset = startsegmentandoffset ( size ) ; byte [ ] bytes = new byte [ sizeinbytes ] ; bytes [ num_ ] = ( byte ) character . totitlecase ( segmentandoffset . value ( ) ) ; for ( int i = num_ ; i < sizeinbytes ; i ++ ) { byte b = segmentandoffset . value ( ) ; if ( numbytesforfirstbyte ( b ) != num_ ) {	Returns the upper case of this string.
public binarystring tolowercase ( ) { if ( javaobject != null ) { return tolowercaseslow ( ) ; } if ( sizeinbytes == num_ ) { return empty_utf8 ; } int size = segments [ num_ ] . size ( ) ; segmentandoffset segmentandoffset = startsegmentandoffset ( size ) ; byte [ ] bytes = new byte [ sizeinbytes ] ; bytes [ num_ ] = ( byte ) character . totitlecase ( segmentandoffset . value ( ) ) ; for ( int i = num_ ; i < sizeinbytes ; i ++ ) { byte b = segmentandoffset . value ( ) ; if ( numbytesforfirstbyte ( b ) != num_ ) {	Returns the lower case of this string.
public boolean tobooleansql ( ) { if ( true_strings . contains ( tolowercase ( ) ) ) { return bool_ ; } else if ( false_strings . contains ( tolowercase ( ) ) ) { return bool_ ; } else { return null ; } }	Decide boolean representation of a string.
public singleoutputstreamoperator < t > setparallelism ( int parallelism ) { preconditions . checkargument ( canbeparallel ( ) || parallelism == num_ , str_ ) ; transformation . setparallelism ( parallelism ) ; return this ; }	Sets the parallelism for this operator.
@ publicevolving public singleoutputstreamoperator < t > setmaxparallelism ( int maxparallelism ) { preconditions . checkargument ( maxparallelism > num_ , str_ ) ; preconditions . checkargument ( canbeparallel ( ) || maxparallelism == num_ , str_ ) ; transformation . setmaxparallelism ( maxparallelism ) ; return this ; }	Sets the maximum parallelism of this operator.
private singleoutputstreamoperator < t > setresources ( resourcespec resources ) { preconditions . checknotnull ( resources , str_ ) ; preconditions . checkargument ( resources . isvalid ( ) , str_ ) ; transformation . setresources ( resources , resources ) ; return this ; }	Sets the resources for this operator, the minimum and preferred resources are the same by default.
@ publicevolving public singleoutputstreamoperator < t > forcenonparallel ( ) { transformation . setparallelism ( num_ ) ; transformation . setmaxparallelism ( num_ ) ; nonparallel = bool_ ; return this ; }	Sets the parallelism and maximum parallelism of this operator to one.And mark this operator cannot set a non-1 degree of parallelism.
int finalizebuildphase ( iomanager ioaccess , fileiochannel . enumerator probechannelenumerator ) throws ioexception { this . finalbufferlimit = this . buildsidewritebuffer . getcurrentpositioninsegment ( ) ; this . partitionbuffers = this . buildsidewritebuffer . close ( ) ; if ( ! isinmemory ( ) ) {	After build phase.
public void reporterror ( throwable t ) {	Sets the exception and interrupts the target thread,if no other exception has occurred so far.
private void emitwindowresult ( w window ) throws exception { baserow aggresult = windowfunction . getwindowaggregationresult ( window ) ; if ( sendretraction ) { previousstate . setcurrentnamespace ( window ) ; baserow previousaggresult = previousstate . value ( ) ;	Emits the window result of the given window.
private void registercleanuptimer ( w window ) { long cleanuptime = cleanuptime ( window ) ; if ( cleanuptime == long . max_value ) {	Registers a timer to cleanup the content of the window.
public datasink < t > setparallelism ( int parallelism ) { preconditions . checkargument ( parallelism > num_ || parallelism == executionconfig . parallelism_default , str_ ) ; this . parallelism = parallelism ; return this ; }	Sets the parallelism for this data sink.The degree must be 1 or more.
private datasink < t > setresources ( resourcespec minresources , resourcespec preferredresources ) { preconditions . checknotnull ( minresources , str_ ) ; preconditions . checknotnull ( preferredresources , str_ ) ; preconditions . checkargument ( minresources . isvalid ( ) && preferredresources . isvalid ( ) && minresources . lessthanorequal ( preferredresources ) , str_ ) ; this . minresources = minresources ; this . preferredresources = preferredresources ; return this ; }	Sets the minimum and preferred resources for this data sink.
private datasink < t > setresources ( resourcespec resources ) { preconditions . checknotnull ( resources , str_ ) ; preconditions . checkargument ( resources . isvalid ( ) , str_ ) ; this . minresources = resources ; this . preferredresources = resources ; return this ; }	Sets the resources for this data sink, and the minimum and preferred resources are the same by default.
void restorepartitionbuffers ( iomanager iomanager , list < memorysegment > availablememory ) throws ioexception { final bulkblockchannelreader reader = iomanager . createbulkblockchannelreader ( this . initialbuildsidechannel , availablememory , this . initialpartitionbufferscount ) ; reader . close ( ) ; final list < memorysegment > partitionbuffersfromdisk = reader . getfullsegments ( ) ; this . partitionbuffers = ( memorysegment [ ] ) partitionbuffersfromdisk . toarray ( new memorysegment [ partitionbuffersfromdisk . size ( ) ] ) ; this . overflowsegments = new memorysegment [ num_ ] ; this . numoverflowsegments = num_ ; this . nextoverflowbucket = num_ ; this . isrestored = bool_ ; }	This method is called every time a multi-match hash map is opened again for a new probe input.
public option add ( string name ) throws requiredparametersexception { if ( ! this . data . containskey ( name ) ) { option option = new option ( name ) ; this . data . put ( name , option ) ; return option ; } else { throw new requiredparametersexception ( str_ + name + str_ ) ; } }	Add a parameter based on its name.
private void checkandapplydefaultvalue ( option o , map < string , string > data ) throws requiredparametersexception { if ( hasnodefaultvalueandnovaluepassedonalternativename ( o , data ) ) { throw new requiredparametersexception ( str_ + o . getname ( ) ) ; } }	else throw an exception.
private boolean hasnodefaultvalueandnovaluepassedonalternativename ( option o , map < string , string > data ) throws requiredparametersexception { if ( o . hasalt ( ) && data . containskey ( o . getalt ( ) ) ) { data . put ( o . getname ( ) , data . get ( o . getalt ( ) ) ) ; } else { if ( o . hasdefaultvalue ( ) ) { data . put ( o . getname ( ) , o . getdefaultvalue ( ) ) ; if ( o . hasalt ( ) ) { data . put ( o . getalt ( ) , o . getdefaultvalue ( ) ) ; } } else { return bool_ ; } } return bool_ ; }	else return true to indicate parameter is 'really' missing.
public string gethelp ( ) { stringbuilder sb = new stringbuilder ( data . size ( ) * help_text_length_per_param ) ; sb . append ( str_ ) ; sb . append ( help_text_line_delimiter ) ; for ( option o : data . values ( ) ) { sb . append ( this . helptext ( o ) ) ; } sb . append ( help_text_line_delimiter ) ; return sb . tostring ( ) ; }	Build a help text for the defined parameters. The format of the help text will be:Required Parameters:\t -:shortName:, --:name: \t :helpText: \t default: :defaultValue: \t choices: :choices: \n.
public jaccardindex < k , vv , ev > setgroupsize ( int groupsize ) { preconditions . checkargument ( groupsize > num_ , str_ ) ; this . groupsize = groupsize ; return this ; }	Override the default group size for the quadratic expansion of neighborpairs.
public jaccardindex < k , vv , ev > setminimumscore ( int numerator , int denominator ) { preconditions . checkargument ( numerator >= num_ , str_ ) ; preconditions . checkargument ( denominator > num_ , str_ ) ; preconditions . checkargument ( numerator <= denominator , str_ ) ; this . unboundedscores = bool_ ; this . minimumscorenumerator = numerator ; this . minimumscoredenominator = denominator ; return this ; }	Filter out Jaccard Index scores less than the given minimum fraction.
public jaccardindex < k , vv , ev > setmaximumscore ( int numerator , int denominator ) { preconditions . checkargument ( numerator >= num_ , str_ ) ; preconditions . checkargument ( denominator > num_ , str_ ) ; preconditions . checkargument ( numerator <= denominator , str_ ) ; this . unboundedscores = bool_ ; this . maximumscorenumerator = numerator ; this . maximumscoredenominator = denominator ; return this ; }	Filter out Jaccard Index scores greater than the given maximum fraction.
public dataset < st > closewith ( dataset < st > solutionsetdelta , dataset < wt > newworkset ) { return new deltaiterationresultset < st , wt > ( initialsolutionset . getexecutionenvironment ( ) , initialsolutionset . gettype ( ) , initialworkset . gettype ( ) , this , solutionsetdelta , newworkset , keys , maxiterations ) ; }	Closes the delta iteration.
public deltaiteration < st , wt > parallelism ( int parallelism ) { preconditions . checkargument ( parallelism > num_ || parallelism == executionconfig . parallelism_default , str_ ) ; this . parallelism = parallelism ; return this ; }	Sets the parallelism for the iteration.
private deltaiteration < st , wt > setresources ( resourcespec minresources , resourcespec preferredresources ) { preconditions . checknotnull ( minresources , str_ ) ; preconditions . checknotnull ( preferredresources , str_ ) ; preconditions . checkargument ( minresources . isvalid ( ) && preferredresources . isvalid ( ) && minresources . lessthanorequal ( preferredresources ) , str_ ) ; this . minresources = minresources ; this . preferredresources = preferredresources ; return this ; }	Sets the minimum and preferred resources for the iteration.
private deltaiteration < st , wt > setresources ( resourcespec resources ) { preconditions . checknotnull ( resources , str_ ) ; preconditions . checkargument ( resources . isvalid ( ) , str_ ) ; this . minresources = resources ; this . preferredresources = resources ; return this ; }	Sets the resources for the iteration, and the minimum and preferred resources are the same by default.The lower and upper resource limits will be considered in dynamic resource resize feature for future plan.
private static void requestandsetspecifictimeoffsetsfromkafka ( simpleconsumer consumer , list < kafkatopicpartitionstate < topicandpartition > > partitions , long whichtime ) throws ioexception { map < topicandpartition , partitionoffsetrequestinfo > requestinfo = new hashmap < > ( ) ; for ( kafkatopicpartitionstate < topicandpartition > part : partitions ) { requestinfo . put ( part . getkafkapartitionhandle ( ) , new partitionoffsetrequestinfo ( whichtime , num_ ) ) ; } requestandsetoffsetsfromkafka ( consumer , partitions , requestinfo ) ; }	Request offsets before a specific time for a set of partitions, via a Kafka consumer.
private static void requestandsetoffsetsfromkafka ( simpleconsumer consumer , list < kafkatopicpartitionstate < topicandpartition > > partitionstates , map < topicandpartition , partitionoffsetrequestinfo > partitiontorequestinfo ) throws ioexception { int retries = num_ ; offsetresponse response ; while ( bool_ ) { kafka . javaapi . offsetrequest request = new kafka . javaapi . offsetrequest ( partitiontorequestinfo , kafka . api . offsetrequest . currentversion ( ) , consumer . clientid ( ) ) ; response = consumer . getoffsetsbefore ( request ) ; if ( response . haserror ( ) ) { stringbuilder exception = new stringbuilder ( ) ; for ( kafkatopicpartitionstate < topicandpartition > part : partitionstates ) { short code ; if ( ( code = response . errorcode ( part . gettopic ( ) , part . getpartition ( ) ) ) != errormapping . noerror ( ) ) { exception . append ( str_ ) . append ( part . gettopic ( ) ) . append ( str_ ) . append ( part . getpartition ( ) ) . append ( str_ ) . append ( exceptionutils . stringifyexception ( errormapping . exceptionfor ( code ) ) ) ; } } if ( ++ retries >= num_ ) { throw new ioexception ( str_ + partitionstates + str_ + exception . tostring ( ) ) ; } else { log . warn ( str_ , exception ) ; } } else { break ;	Request offsets from Kafka with a specified set of partition's offset request information.The returned offsets are used to set the internal partition states.
public static < t > completablefuture < t > retry ( final supplier < completablefuture < t > > operation , final int retries , final executor executor ) { final completablefuture < t > resultfuture = new completablefuture < > ( ) ; retryoperation ( resultfuture , operation , retries , executor ) ; return resultfuture ; }	Retry the given operation the given number of times in case of a failure.
private static < t > void retryoperation ( final completablefuture < t > resultfuture , final supplier < completablefuture < t > > operation , final int retries , final executor executor ) { if ( ! resultfuture . isdone ( ) ) { final completablefuture < t > operationfuture = operation . get ( ) ; operationfuture . whencompleteasync ( ( t , throwable ) -> { if ( throwable != null ) { if ( throwable instanceof cancellationexception ) { resultfuture . completeexceptionally ( new retryexception ( str_ , throwable ) ) ; } else { if ( retries > num_ ) { retryoperation ( resultfuture , operation , retries - num_ , executor ) ; } else { resultfuture . completeexceptionally ( new retryexception ( str_ + str_ , throwable ) ) ; } } } else { resultfuture . complete ( t ) ; } } , executor ) ; resultfuture . whencomplete ( ( t , throwable ) -> operationfuture . cancel ( bool_ ) ) ; } }	Helper method which retries the provided operation in case of a failure.
public static < t > completablefuture < t > retrysuccessfulwithdelay ( final supplier < completablefuture < t > > operation , final time retrydelay , final deadline deadline , final predicate < t > acceptancepredicate , final scheduledexecutor scheduledexecutor ) { final completablefuture < t > resultfuture = new completablefuture < > ( ) ; retrysuccessfuloperationwithdelay ( resultfuture , operation , retrydelay , deadline , acceptancepredicate , scheduledexecutor ) ; return resultfuture ; }	Retry the given operation with the given delay in between successful completions where theresult does not match a given predicate.
public static completablefuture < void > composeafterwards ( completablefuture < ? > future , supplier < completablefuture < ? > > composedaction ) { final completablefuture < void > resultfuture = new completablefuture < > ( ) ; future . whencomplete ( ( object outerignored , throwable outerthrowable ) -> { final completablefuture < ? > composedactionfuture = composedaction . get ( ) ; composedactionfuture . whencomplete ( ( object innerignored , throwable innerthrowable ) -> { if ( innerthrowable != null ) { resultfuture . completeexceptionally ( exceptionutils . firstorsuppressed ( innerthrowable , outerthrowable ) ) ; } else if ( outerthrowable != null ) { resultfuture . completeexceptionally ( outerthrowable ) ; } else { resultfuture . complete ( null ) ; } } ) ; } ) ; return resultfuture ; }	Run the given asynchronous action after the completion of the given future.
public static void main ( string [ ] args ) throws exception { final kafkacollector [ ] collectors = new kafkacollector [ num_partitions ] ;	Entry point to the kafka data producer.
@ override public void suspend ( ) { componentmainthreadexecutor . assertrunninginmainthread ( ) ; log . info ( str_ ) ;	Suspends this pool, meaning it has lost its authority to accept and distribute slots.
@ nullable private pendingrequest removependingrequest ( slotrequestid requestid ) { pendingrequest result = waitingforresourcemanager . remove ( requestid ) ; if ( result != null ) {	Checks whether there exists a pending request with the given slot request id and removes itfrom the internal data structures.
private void tryfulfillslotrequestormakeavailable ( allocatedslot allocatedslot ) { preconditions . checkstate ( ! allocatedslot . isused ( ) , str_ ) ; final pendingrequest pendingrequest = pollmatchingpendingrequest ( allocatedslot ) ; if ( pendingrequest != null ) { log . debug ( str_ , pendingrequest . getslotrequestid ( ) , allocatedslot . getallocationid ( ) ) ; allocatedslots . add ( pendingrequest . getslotrequestid ( ) , allocatedslot ) ; pendingrequest . getallocatedslotfuture ( ) . complete ( allocatedslot ) ; } else { log . debug ( str_ , allocatedslot . getallocationid ( ) ) ; availableslots . add ( allocatedslot , clock . relativetimemillis ( ) ) ; } }	Tries to fulfill with the given allocated slot a pending slot request or add theallocated slot to the set of available slots if no matching request is available.
@ override public optional < resourceid > failallocation ( final allocationid allocationid , final exception cause ) { componentmainthreadexecutor . assertrunninginmainthread ( ) ; final pendingrequest pendingrequest = pendingrequests . removekeyb ( allocationid ) ; if ( pendingrequest != null ) {	Fail the specified allocation and release the corresponding slot if we have one.This may triggered by JobManager when some slot allocation failed with rpcTimeout.Or this could be triggered by TaskManager, when it finds out something went wrong with the slot,and decided to take it back.
@ override public boolean registertaskmanager ( final resourceid resourceid ) { componentmainthreadexecutor . assertrunninginmainthread ( ) ; log . debug ( str_ , resourceid ) ; return registeredtaskmanagers . add ( resourceid ) ; }	Register TaskManager to this pool, only those slots come from registered TaskManager will be considered valid.Also it provides a way for us to keep "dead" or "abnormal" TaskManagers out of this pool.
@ override public boolean releasetaskmanager ( final resourceid resourceid , final exception cause ) { componentmainthreadexecutor . assertrunninginmainthread ( ) ; if ( registeredtaskmanagers . remove ( resourceid ) ) { releasetaskmanagerinternal ( resourceid , cause ) ; return bool_ ; } else { return bool_ ; } }	Unregister TaskManager from this pool, all the related slots will be released and tasks be canceled.
private void checkidleslot ( ) {	Check the available slots, release the slot that is idle for a long time.
private void clear ( ) { availableslots . clear ( ) ; allocatedslots . clear ( ) ; pendingrequests . clear ( ) ; waitingforresourcemanager . clear ( ) ; registeredtaskmanagers . clear ( ) ; }	Clear the internal state of the SlotPool.
public void startqueryservice ( rpcservice rpcservice , resourceid resourceid ) { synchronized ( lock ) { preconditions . checkstate ( ! isshutdown ( ) , str_ ) ; try { metricqueryservicerpcservice = rpcservice ; queryservice = metricqueryservice . createmetricqueryservice ( rpcservice , resourceid , maximumframesize ) ; queryservice . start ( ) ; } catch ( exception e ) { log . warn ( str_ , e ) ; } } }	Initializes the MetricQueryService.
public static taskmanagerservices fromconfiguration ( taskmanagerservicesconfiguration taskmanagerservicesconfiguration , taskmanagermetricgroup taskmanagermetricgroup , resourceid resourceid , executor taskioexecutor , long freeheapmemorywithdefrag , long maxjvmheapmemory ) throws exception {	Creates and returns the task manager services.
public static externalcatalog findandcreateexternalcatalog ( descriptor descriptor ) { map < string , string > properties = descriptor . toproperties ( ) ; return tablefactoryservice . find ( externalcatalogfactory . class , properties ) . createexternalcatalog ( properties ) ; }	Returns an external catalog.
public static < t > tablesource < t > findandcreatetablesource ( descriptor descriptor ) { map < string , string > properties = descriptor . toproperties ( ) ; tablesource tablesource ; try { tablesource = tablefactoryservice . find ( tablesourcefactory . class , properties ) . createtablesource ( properties ) ; } catch ( throwable t ) { throw new tableexception ( str_ , t ) ; } return tablesource ; }	Returns a table source matching the descriptor.
public static < t > tablesink < t > findandcreatetablesink ( descriptor descriptor ) { map < string , string > properties = descriptor . toproperties ( ) ; tablesink tablesink ; try { tablesink = tablefactoryservice . find ( tablesinkfactory . class , properties ) . createtablesink ( properties ) ; } catch ( throwable t ) { throw new tableexception ( str_ , t ) ; } return tablesink ; }	Returns a table sink matching the descriptor.
public < t > void setbroadcastvariables ( map < string , operator < t > > inputs ) { this . broadcastinputs . clear ( ) ; this . broadcastinputs . putall ( inputs ) ; }	Clears all previous broadcast inputs and binds the given inputs asbroadcast variables of this operator.
protected static < u > class < u > [ ] asarray ( class < u > clazz ) { @ suppresswarnings ( str_ ) class < u > [ ] array = new class [ ] { clazz } ; return array ; }	Generic utility function that wraps a single class object into an array of that class type.
protected static < u > class < u > [ ] emptyclassarray ( ) { @ suppresswarnings ( str_ ) class < u > [ ] array = new class [ num_ ] ; return array ; }	Generic utility function that returns an empty class array.
@ override public void update ( ) { synchronized ( this ) { long currenttime = system . currenttimemillis ( ) ; if ( currenttime - lastupdatetime > updateinterval ) { lastupdatetime = currenttime ; fetchmetrics ( ) ; } } }	This method can be used to signal this MetricFetcher that the metrics are still in use and should be updated.
private void retrieveandquerymetrics ( string queryserviceaddress ) { log . debug ( str_ , queryserviceaddress ) ; final completablefuture < metricqueryservicegateway > queryservicegatewayfuture = queryserviceretriever . retrieveservice ( queryserviceaddress ) ; queryservicegatewayfuture . whencompleteasync ( ( metricqueryservicegateway queryservicegateway , throwable t ) -> { if ( t != null ) { log . debug ( str_ , t ) ; } else { querymetrics ( queryservicegateway ) ; } } , executor ) ; }	Retrieves and queries the specified QueryServiceGateway.
private void querymetrics ( final metricqueryservicegateway queryservicegateway ) { log . debug ( str_ , queryservicegateway . getaddress ( ) ) ; queryservicegateway . querymetrics ( timeout ) . whencompleteasync ( ( metricdumpserialization . metricserializationresult result , throwable t ) -> { if ( t != null ) { log . debug ( str_ , t ) ; } else { metrics . addall ( deserializer . deserialize ( result ) ) ; } } , executor ) ; }	Query the metrics from the given QueryServiceGateway.
public static reloptcluster create ( reloptplanner planner , rexbuilder rexbuilder ) { return new reloptcluster ( planner , rexbuilder . gettypefactory ( ) , rexbuilder , new atomicinteger ( num_ ) , new hashmap < string , relnode > ( ) ) ; }	Creates a cluster.
@ override public expression getvalueexpression ( ) { return ifthenelse ( equalto ( count , literal ( num_ ) ) , nullof ( getresulttype ( ) ) , div ( sum , count ) ) ; }	If all input are nulls, count will be 0 and we will get null after the division.
private void closecurrentpartfile ( bucketstate < t > bucketstate ) throws exception { if ( bucketstate . iswriteropen ) { bucketstate . writer . close ( ) ; bucketstate . iswriteropen = bool_ ; } if ( bucketstate . currentfile != null ) { path currentpartpath = new path ( bucketstate . currentfile ) ; path inprogresspath = getinprogresspathfor ( currentpartpath ) ; path pendingpath = getpendingpathfor ( currentpartpath ) ; fs . rename ( inprogresspath , pendingpath ) ; log . debug ( str_ , inprogresspath , pendingpath ) ; bucketstate . pendingfiles . add ( currentpartpath . tostring ( ) ) ; bucketstate . currentfile = null ; } }	Closes the current part file and moves it from the in-progress state to the pending state.
public void tryadd ( abstractcheckpointstats checkpoint ) {	Try to add the checkpoint to the cache.
public < r > r wrapclassloader ( supplier < r > supplier ) { try ( temporaryclassloadercontext tmpcl = new temporaryclassloadercontext ( classloader ) ) { return supplier . get ( ) ; } }	Executes the given supplier using the execution context's classloader as thread classloader.
@ override public void open ( configuration config ) throws ioexception { streamer . open ( ) ; streamer . sendbroadcastvariables ( config ) ; }	Opens this function.
public accumulatorsnapshot getsnapshot ( ) { try { return new accumulatorsnapshot ( jobid , taskid , useraccumulators ) ; } catch ( throwable e ) { log . warn ( str_ , e ) ; return null ; } }	Creates a snapshot of this accumulator registry.
public void registerkvstate ( keygrouprange keygrouprange , string registrationname , internalkvstate < ? , ? , ? > kvstate ) { kvstateid kvstateid = registry . registerkvstate ( jobid , jobvertexid , keygrouprange , registrationname , kvstate ) ; registeredkvstates . add ( new kvstateinfo ( keygrouprange , registrationname , kvstateid ) ) ; }	Registers the KvState instance at the KvStateRegistry.
public void unregisterall ( ) { for ( kvstateinfo kvstate : registeredkvstates ) { registry . unregisterkvstate ( jobid , jobvertexid , kvstate . keygrouprange , kvstate . registrationname , kvstate . kvstateid ) ; } }	Unregisters all registered KvState instances from the KvStateRegistry.
public configoption < t > withfallbackkeys ( string ... fallbackkeys ) { final stream < fallbackkey > newfallbackkeys = arrays . stream ( fallbackkeys ) . map ( fallbackkey :: createfallbackkey ) ; final stream < fallbackkey > currentalternativekeys = arrays . stream ( this . fallbackkeys ) ;	Creates a new config option, using this option's key and default value, andadding the given fallback keys. When obtaining a value from the configuration via {.
public configoption < t > withdeprecatedkeys ( string ... deprecatedkeys ) { final stream < fallbackkey > newdeprecatedkeys = arrays . stream ( deprecatedkeys ) . map ( fallbackkey :: createdeprecatedkey ) ; final stream < fallbackkey > currentalternativekeys = arrays . stream ( this . fallbackkeys ) ;	Creates a new config option, using this option's key and default value, andadding the given deprecated keys. When obtaining a value from the configuration via {.
public iterable < fallbackkey > fallbackkeys ( ) { return ( fallbackkeys == empty ) ? collections . emptylist ( ) : arrays . aslist ( fallbackkeys ) ; }	Gets the fallback keys, in the order to be checked.
public static boolean hashdfsdelegationtoken ( ) throws exception { usergroupinformation loginuser = usergroupinformation . getcurrentuser ( ) ; collection < token < ? extends tokenidentifier > > usrtok = loginuser . gettokens ( ) ; for ( token < ? extends tokenidentifier > token : usrtok ) { if ( token . getkind ( ) . equals ( hdfs_delegation_token_kind ) ) { return bool_ ; } } return bool_ ; }	Indicates whether the current user has an HDFS delegation token.
public static boolean isminhadoopversion ( int major , int minor ) throws flinkruntimeexception { string versionstring = versioninfo . getversion ( ) ; string [ ] versionparts = versionstring . split ( str_ ) ; if ( versionparts . length < num_ ) { throw new flinkruntimeexception ( str_ + versionstring ) ; } int maj = integer . parseint ( versionparts [ num_ ] ) ; int min = integer . parseint ( versionparts [ num_ ] ) ; return maj > major || ( maj == major && min >= minor ) ; }	Checks if the Hadoop dependency is at least of the given version.
public static < t extends specificrecordbase > parquetwriterfactory < t > forspecificrecord ( class < t > type ) { final string schemastring = specificdata . get ( ) . getschema ( type ) . tostring ( ) ; final parquetbuilder < t > builder = ( out ) -> createavroparquetwriter ( schemastring , specificdata . get ( ) , out ) ; return new parquetwriterfactory < > ( builder ) ; }	Creates a ParquetWriterFactory for an Avro specific type.
public static parquetwriterfactory < genericrecord > forgenericrecord ( schema schema ) { final string schemastring = schema . tostring ( ) ; final parquetbuilder < genericrecord > builder = ( out ) -> createavroparquetwriter ( schemastring , genericdata . get ( ) , out ) ; return new parquetwriterfactory < > ( builder ) ; }	Creates a ParquetWriterFactory that accepts and writes Avro generic types.The Parquet writers will use the given schema to build and write the columnar data.
public static < t > parquetwriterfactory < t > forreflectrecord ( class < t > type ) { final string schemastring = reflectdata . get ( ) . getschema ( type ) . tostring ( ) ; final parquetbuilder < t > builder = ( out ) -> createavroparquetwriter ( schemastring , reflectdata . get ( ) , out ) ; return new parquetwriterfactory < > ( builder ) ; }	Creates a ParquetWriterFactory for the given type.
@ override public option < protos . frameworkid > getframeworkid ( ) throws exception { synchronized ( startstoplock ) { verifyisrunning ( ) ; option < protos . frameworkid > frameworkid ; byte [ ] value = frameworkidinzookeeper . getvalue ( ) ; if ( value . length == num_ ) { frameworkid = option . empty ( ) ; } else { frameworkid = option . apply ( protos . frameworkid . newbuilder ( ) . setvalue ( new string ( value , configconstants . default_charset ) ) . build ( ) ) ; } return frameworkid ; } }	Get the persisted framework ID.
@ override public void setframeworkid ( option < protos . frameworkid > frameworkid ) throws exception { synchronized ( startstoplock ) { verifyisrunning ( ) ; byte [ ] value = frameworkid . isdefined ( ) ? frameworkid . get ( ) . getvalue ( ) . getbytes ( configconstants . default_charset ) : new byte [ num_ ] ; frameworkidinzookeeper . setvalue ( value ) ; } }	Update the persisted framework ID.
@ override public protos . taskid newtaskid ( ) throws exception { synchronized ( startstoplock ) { verifyisrunning ( ) ; int nextcount ; boolean success ; do { zookeeperversionedvalue < integer > count = totaltaskcountinzookeeper . getversionedvalue ( ) ; nextcount = count . getvalue ( ) + num_ ; success = totaltaskcountinzookeeper . trysetcount ( count , nextcount ) ; } while ( ! success ) ; protos . taskid taskid = protos . taskid . newbuilder ( ) . setvalue ( taskid_format . format ( nextcount ) ) . build ( ) ; return taskid ; } }	Generates a new task ID.
public void shutdown ( ) {	Shuts the memory manager down, trying to release all the memory it managed.
public void release ( memorysegment segment ) {	Tries to release the memory for the specified segment.
public void release ( collection < memorysegment > segments ) { if ( segments == null ) { return ; }	Tries to release many memory segments together.
public void releaseall ( object owner ) { if ( owner == null ) { return ; }	Releases all memory segments for the given owner.
public list < fieldreferenceexpression > getallinputfields ( ) { return fieldreferences . stream ( ) . flatmap ( input -> input . values ( ) . stream ( ) ) . collect ( tolist ( ) ) ; }	Gives all fields of underlying inputs in order of those inputs and order of fields within input.
public csv schema ( typeinformation < row > schematype ) { preconditions . checknotnull ( schematype ) ; internalproperties . putstring ( format_schema , typestringutils . writetypeinfo ( schematype ) ) ; return this ; }	Sets the format schema with field names and the types.
public static void main ( string [ ] args ) throws exception { configuration globalconfig = globalconfiguration . loadconfiguration ( ) ; pythonplanbinder binder = new pythonplanbinder ( globalconfig ) ; try { binder . runplan ( args ) ; } catch ( exception e ) { system . out . println ( str_ + e . getmessage ( ) ) ; log . error ( str_ , e ) ; } }	Entry point for the execution of a python plan.
public < v , a extends serializable > void addaccumulator ( string name , accumulator < v , a > accumulator ) { getruntimecontext ( ) . addaccumulator ( id + separator + name , accumulator ) ; }	Adds an accumulator by prepending the given name with a random string.
static void processlastrow ( baserow currentrow , boolean generateretraction , valuestate < baserow > state , collector < baserow > out ) throws exception {	Processes element to deduplicate on keys, sends current element as last row, retracts previous element ifneeded.
static void processfirstrow ( baserow currentrow , valuestate < boolean > state , collector < baserow > out ) throws exception {	Processes element to deduplicate on keys, sends current element if it is first row.
@ override public iterator < t > sample ( final iterator < t > input ) { if ( fraction == num_ ) { return emptyiterable ; } return new samplediterator < t > ( ) { t current = null ; @ override public boolean hasnext ( ) { if ( current == null ) { current = getnextsampledelement ( ) ; } return current != null ; } @ override public t next ( ) { if ( current == null ) { return getnextsampledelement ( ) ; } else { t result = current ; current = null ; return result ; } } private t getnextsampledelement ( ) { if ( fraction <= threshold ) { double rand = random . nextdouble ( ) ; double u = math . max ( rand , epsilon ) ; int gap = ( int ) ( math . log ( u ) / math . log ( num_ - fraction ) ) ; int elementcount = num_ ; if ( input . hasnext ( ) ) { t element = input . next ( ) ; while ( input . hasnext ( ) && elementcount < gap ) { element = input . next ( ) ; elementcount ++ ; } if ( elementcount < gap ) { return null ; } else { return element ; } } else { return null ; } } else { while ( input . hasnext ( ) ) { t element = input . next ( ) ; if ( random . nextdouble ( ) <= fraction ) { return element ; } } return null ; } } } ; }	Sample the input elements, for each input element, take a Bernoulli trail for sampling.
public static < t > byte [ ] serializevalue ( t value , typeserializer < t > serializer ) throws ioexception { if ( value != null ) {	Serializes the value with the given serializer.
public static < t > t deserializevalue ( byte [ ] serializedvalue , typeserializer < t > serializer ) throws ioexception { if ( serializedvalue == null ) { return null ; } else { final datainputdeserializer deser = new datainputdeserializer ( serializedvalue , num_ , serializedvalue . length ) ; final t value = serializer . deserialize ( deser ) ; if ( deser . available ( ) > num_ ) { throw new ioexception ( str_ + str_ + str_ ) ; } return value ; } }	Deserializes the value with the given serializer.
public static < t > list < t > deserializelist ( byte [ ] serializedvalue , typeserializer < t > serializer ) throws ioexception { if ( serializedvalue != null ) { final datainputdeserializer in = new datainputdeserializer ( serializedvalue , num_ , serializedvalue . length ) ; try { final list < t > result = new arraylist < > ( ) ; while ( in . available ( ) > num_ ) { result . add ( serializer . deserialize ( in ) ) ;	Deserializes all values with the given serializer.
public static < uk , uv > byte [ ] serializemap ( iterable < map . entry < uk , uv > > entries , typeserializer < uk > keyserializer , typeserializer < uv > valueserializer ) throws ioexception { if ( entries != null ) {	Serializes all values of the Iterable with the given serializer.
public static < uk , uv > map < uk , uv > deserializemap ( byte [ ] serializedvalue , typeserializer < uk > keyserializer , typeserializer < uv > valueserializer ) throws ioexception { if ( serializedvalue != null ) { datainputdeserializer in = new datainputdeserializer ( serializedvalue , num_ , serializedvalue . length ) ; map < uk , uv > result = new hashmap < > ( ) ; while ( in . available ( ) > num_ ) { uk key = keyserializer . deserialize ( in ) ; boolean isnull = in . readboolean ( ) ; uv value = isnull ? null : valueserializer . deserialize ( in ) ; result . put ( key , value ) ; } return result ; } else { return null ; } }	Deserializes all kv pairs with the given serializer.
protected void seekinput ( memorysegment segment , int positioninsegment , int limitinsegment ) { this . currentsegment = segment ; this . positioninsegment = positioninsegment ; this . limitinsegment = limitinsegment ; }	Sets the internal state of the view such that the next bytes will be read from the given memory segment,starting at the given position.
public void setshardassigner ( kinesisshardassigner shardassigner ) { this . shardassigner = checknotnull ( shardassigner , str_ ) ; closurecleaner . clean ( shardassigner , bool_ ) ; }	Provide a custom assigner to influence how shards are distributed over subtasks.
protected kinesisdatafetcher < t > createfetcher ( list < string > streams , sourcefunction . sourcecontext < t > sourcecontext , runtimecontext runtimecontext , properties configprops , kinesisdeserializationschema < t > deserializationschema ) { return new kinesisdatafetcher < > ( streams , sourcecontext , runtimecontext , configprops , deserializationschema , shardassigner , periodicwatermarkassigner ) ; }	This method is exposed for tests that need to mock the KinesisDataFetcher in the consumer.
public static void openchainedtasks ( list < chaineddriver < ? , ? > > tasks , abstractinvokable parent ) throws exception {	Opens all chained tasks, in the order as they are stored in the array.
public static void closechainedtasks ( list < chaineddriver < ? , ? > > tasks , abstractinvokable parent ) throws exception { for ( int i = num_ ; i < tasks . size ( ) ; i ++ ) { final chaineddriver < ? , ? > task = tasks . get ( i ) ; task . closetask ( ) ; if ( log . isdebugenabled ( ) ) { log . debug ( constructlogstring ( str_ , task . gettaskname ( ) , parent ) ) ; } } }	Closes all chained tasks, in the order as they are stored in the array.
public static < t > t instantiateusercode ( taskconfig config , classloader cl , class < ? super t > superclass ) { try { t stub = config . < t > getstubwrapper ( cl ) . getusercodeobject ( superclass , cl ) ;	Instantiates a user code class from is definition in the task configuration.The class is instantiated without arguments using the null-ary constructor.
@ publicevolving public void setresources ( resourcespec minresources , resourcespec preferredresources ) { this . minresources = minresources ; this . preferredresources = preferredresources ; }	Sets the minimum and preferred resources for this contract instance.
protected void runasyncwithoutfencing ( runnable runnable ) { if ( rpcserver instanceof fencedmainthreadexecutable ) { ( ( fencedmainthreadexecutable ) rpcserver ) . runasyncwithoutfencing ( runnable ) ; } else { throw new runtimeexception ( str_ ) ; } }	Run the given runnable in the main thread of the RpcEndpoint without checking the fencingtoken.
protected < v > completablefuture < v > callasyncwithoutfencing ( callable < v > callable , time timeout ) { if ( rpcserver instanceof fencedmainthreadexecutable ) { return ( ( fencedmainthreadexecutable ) rpcserver ) . callasyncwithoutfencing ( callable , timeout ) ; } else { throw new runtimeexception ( str_ ) ; } }	Run the given callable in the main thread of the RpcEndpoint without checking the fencingtoken.
static filesystemkind getkindforscheme ( string scheme ) { scheme = scheme . tolowercase ( locale . us ) ; if ( scheme . startswith ( str_ ) || scheme . startswith ( str_ ) || scheme . startswith ( str_ ) ) {	Gets the kind of the file system from its scheme.
void updatesummary ( completedcheckpointstats completed ) { statesize . add ( completed . getstatesize ( ) ) ; duration . add ( completed . getendtoendduration ( ) ) ; alignmentbuffered . add ( completed . getalignmentbuffered ( ) ) ; }	Updates the summary with the given completed checkpoint.
private int getpartitioningfanoutnoestimates ( ) { return math . max ( num_ , findsmallerprime ( ( int ) math . min ( buildrowcount * avgrecordlen / ( num_ * segmentsize ) , max_num_partitions ) ) ) ; }	Gets the number of partitions to be used for an initial hash-table.
public void freecurrent ( ) { int beforereleasenum = availablememory . size ( ) ; memmanager . release ( availablememory ) ; allocatedfloatingnum -= ( beforereleasenum - availablememory . size ( ) ) ; }	Free the memory not used.
public static void adddeprecations ( deprecationdelta [ ] deltas ) { deprecationcontext prev , next ; do { prev = deprecationcontext . get ( ) ; next = new deprecationcontext ( prev , deltas ) ; } while ( ! deprecationcontext . compareandset ( prev , next ) ) ; }	Adds a set of deprecated keys to the global deprecations.This method is lockless.
public void setdeprecatedproperties ( ) { deprecationcontext deprecations = deprecationcontext . get ( ) ; properties props = getprops ( ) ; properties overlay = getoverlay ( ) ; for ( map . entry < string , deprecatedkeyinfo > entry : deprecations . getdeprecatedkeymap ( ) . entryset ( ) ) { string depkey = entry . getkey ( ) ; if ( ! overlay . contains ( depkey ) ) { for ( string newkey : entry . getvalue ( ) . newkeys ) { string val = overlay . getproperty ( newkey ) ; if ( val != null ) { props . setproperty ( depkey , val ) ; overlay . setproperty ( depkey , val ) ; break ; } } } } }	Sets all deprecated properties that are not currently set but have acorresponding new property that is set.
public static synchronized void reloadexistingconfigurations ( ) { if ( log . isdebugenabled ( ) ) { log . debug ( str_ + registry . keyset ( ) . size ( ) + str_ ) ; } for ( configuration conf : registry . keyset ( ) ) { conf . reloadconfiguration ( ) ; } }	Reload existing configuration instances.
public double getstoragesize ( string name , string defaultvalue , storageunit targetunit ) { preconditions . checkstate ( isnotblank ( name ) , str_ ) ; string vstring = get ( name ) ; if ( isblank ( vstring ) ) { vstring = defaultvalue ; }	Gets the Storage Size from the config, or returns the defaultValue.
public void setstoragesize ( string name , double value , storageunit unit ) { set ( name , value + unit . getshortname ( ) ) ; }	Sets Storage Size for the specified key.
private double convertstorageunit ( double value , storageunit sourceunit , storageunit targetunit ) { double bytevalue = sourceunit . tobytes ( value ) ; return targetunit . frombytes ( bytevalue ) ; }	convert the value from one storage unit to another.
public integerranges getrange ( string name , string defaultvalue ) { return new integerranges ( get ( name , defaultvalue ) ) ; }	Parse the given attribute as a set of integer ranges.
public char [ ] getpassword ( string name ) throws ioexception { char [ ] pass = null ; pass = getpasswordfromcredentialproviders ( name ) ; if ( pass == null ) { pass = getpasswordfromconfig ( name ) ; } return pass ; }	Get the value for a known password configuration element.In order to enable the elimination of clear text passwords in config,this method attempts to resolve the property name as an alias throughthe CredentialProvider API and conditionally fallsback to config.
private credentialentry getcredentialentry ( credentialprovider provider , string name ) throws ioexception { credentialentry entry = provider . getcredentialentry ( name ) ; if ( entry != null ) { return entry ; }	Get the credential entry by name from a credential provider.Handle key deprecation.
public class < ? > getclassbynameornull ( string name ) { map < string , weakreference < class < ? > > > map ; synchronized ( cache_classes ) { map = cache_classes . get ( classloader ) ; if ( map == null ) { map = collections . synchronizedmap ( new weakhashmap < string , weakreference < class < ? > > > ( ) ) ; cache_classes . put ( classloader , map ) ; } } class < ? > clazz = null ; weakreference < class < ? > > ref = map . get ( name ) ; if ( ref != null ) { clazz = ref . get ( ) ; } if ( clazz == null ) { try { clazz = class . forname ( name , bool_ , classloader ) ; } catch ( classnotfoundexception e ) {	Load a class by name, returning null rather than throwing an exceptionif it couldn't be loaded.
public set < string > getfinalparameters ( ) { set < string > setfinalparams = collections . newsetfrommap ( new concurrenthashmap < string , boolean > ( ) ) ; setfinalparams . addall ( finalparameters ) ; return setfinalparams ; }	Get the set of parameters marked final.
private void checkforoverride ( properties properties , string name , string attr , string value ) { string propertyvalue = properties . getproperty ( attr ) ; if ( propertyvalue != null && ! propertyvalue . equals ( value ) ) { log . warn ( name + str_ + attr + str_ ) ; } }	Print a warning if a property with a given name already exists with adifferent value.
public static boolean haswarneddeprecation ( string name ) { deprecationcontext deprecations = deprecationcontext . get ( ) ; if ( deprecations . getdeprecatedkeymap ( ) . containskey ( name ) ) { if ( deprecations . getdeprecatedkeymap ( ) . get ( name ) . accessed . get ( ) ) { return bool_ ; } } return bool_ ; }	Returns whether or not a deprecated name has been warned. If the name is notdeprecated then always return false.
public void putbuildrow ( baserow row ) throws ioexception { final int hashcode = hash ( this . buildsideprojection . apply ( row ) . hashcode ( ) , num_ ) ;	Put a build side row to hash table.
public void endbuild ( ) throws ioexception {	End build phase.
public boolean tryprobe ( baserow record ) throws ioexception { if ( ! this . probeiterator . hassource ( ) ) {	Find matched build side rows for a probe row.
public boolean isproperlyshutdown ( ) { for ( file path : paths ) { if ( path != null && path . exists ( ) ) { return bool_ ; } } return bool_ ; }	Utility method to check whether the IO manager has been properly shut down.For this base implementation, this means that all files have been removed.
public void deletechannel ( fileiochannel . id channel ) throws ioexception { if ( channel != null ) { if ( channel . getpathfile ( ) . exists ( ) && ! channel . getpathfile ( ) . delete ( ) ) { log . warn ( str_ , channel . getpath ( ) ) ; } } }	Deletes the file underlying the given channel.
public static string bytetohexstring ( final byte [ ] bytes , final int start , final int end ) { if ( bytes == null ) { throw new illegalargumentexception ( str_ ) ; } int length = end - start ; char [ ] out = new char [ length * num_ ] ; for ( int i = start , j = num_ ; i < end ; i ++ ) { out [ j ++ ] = hex_chars [ ( num_ & bytes [ i ] ) > > > num_ ] ; out [ j ++ ] = hex_chars [ num_ & bytes [ i ] ] ; } return new string ( out ) ; }	Given an array of bytes it will convert the bytes to a hex stringrepresentation of the bytes.
public static string generaterandomalphanumericstring ( random rnd , int length ) { checknotnull ( rnd ) ; checkargument ( length >= num_ ) ; stringbuilder buffer = new stringbuilder ( length ) ; for ( int i = num_ ; i < length ; i ++ ) { buffer . append ( nextalphanumericchar ( rnd ) ) ; } return buffer . tostring ( ) ; }	Creates a random alphanumeric string of given length.
public void startthreads ( ) { if ( this . sortthread != null ) { this . sortthread . start ( ) ; } if ( this . spillthread != null ) { this . spillthread . start ( ) ; } if ( this . mergethread != null ) { this . mergethread . start ( ) ; } }	Starts all the threads that are used by this sorter.
@ override public void dispose ( ) { ioutils . closequietly ( cancelstreamregistry ) ; if ( kvstateregistry != null ) { kvstateregistry . unregisterall ( ) ; } lastname = null ; laststate = null ; keyvaluestatesbyname . clear ( ) ; }	Closes the state backend, releasing all internal resources, but does not delete any persistentcheckpoint data.
@ suppresswarnings ( str_ ) public static < t > t stripproxy ( @ nullable final wrappingproxy < t > wrappingproxy ) { if ( wrappingproxy == null ) { return null ; } t delegate = wrappingproxy . getwrappeddelegate ( ) ; int numproxiesstripped = num_ ; while ( delegate instanceof wrappingproxy ) { throwifsafetynetexceeded ( ++ numproxiesstripped ) ; delegate = ( ( wrappingproxy < t > ) delegate ) . getwrappeddelegate ( ) ; } return delegate ; }	Expects a proxy, and returns the unproxied delegate.
@ override public void close ( ) { ioutils . closequietly ( defaultcolumnfamilyhandle ) ; ioutils . closequietly ( nativemetricmonitor ) ; ioutils . closequietly ( db ) ;	Necessary clean up iff restore operation failed.
public static boolean isrestsslenabled ( configuration sslconfig ) { @ suppresswarnings ( str_ ) final boolean fallbackflag = sslconfig . getboolean ( securityoptions . ssl_enabled ) ; return sslconfig . getboolean ( securityoptions . ssl_rest_enabled , fallbackflag ) ; }	Checks whether SSL for the external REST endpoint is enabled.
public static boolean isrestsslauthenticationenabled ( configuration sslconfig ) { checknotnull ( sslconfig , str_ ) ; return isrestsslenabled ( sslconfig ) && sslconfig . getboolean ( securityoptions . ssl_rest_authentication_enabled ) ; }	Checks whether mutual SSL authentication for the external REST endpoint is enabled.
public static serversocketfactory createsslserversocketfactory ( configuration config ) throws exception { sslcontext sslcontext = createinternalsslcontext ( config ) ; if ( sslcontext == null ) { throw new illegalconfigurationexception ( str_ ) ; } string [ ] protocols = getenabledprotocols ( config ) ; string [ ] ciphersuites = getenabledciphersuites ( config ) ; sslserversocketfactory factory = sslcontext . getserversocketfactory ( ) ; return new configuringsslserversocketfactory ( factory , protocols , ciphersuites ) ; }	Creates a factory for SSL Server Sockets from the given configuration.SSL Server Sockets are always part of internal communication.
public static socketfactory createsslclientsocketfactory ( configuration config ) throws exception { sslcontext sslcontext = createinternalsslcontext ( config ) ; if ( sslcontext == null ) { throw new illegalconfigurationexception ( str_ ) ; } return sslcontext . getsocketfactory ( ) ; }	Creates a factory for SSL Client Sockets from the given configuration.SSL Client Sockets are always part of internal communication.
public static sslhandlerfactory createinternalserversslenginefactory ( final configuration config ) throws exception { sslcontext sslcontext = createinternalsslcontext ( config ) ; if ( sslcontext == null ) { throw new illegalconfigurationexception ( str_ ) ; } return new sslhandlerfactory ( sslcontext , getenabledprotocols ( config ) , getenabledciphersuites ( config ) , bool_ , bool_ , config . getinteger ( securityoptions . ssl_internal_handshake_timeout ) , config . getinteger ( securityoptions . ssl_internal_close_notify_flush_timeout ) ) ; }	Creates a SSLEngineFactory to be used by internal communication server endpoints.
@ nullable public static sslcontext createrestserversslcontext ( configuration config ) throws exception { final restsslcontextconfigmode configmode ; if ( isrestsslauthenticationenabled ( config ) ) { configmode = restsslcontextconfigmode . mutual ; } else { configmode = restsslcontextconfigmode . server ; } return createrestsslcontext ( config , configmode ) ; }	Creates an SSL context for the external REST endpoint server.
@ nullable public static sslcontext createrestclientsslcontext ( configuration config ) throws exception { final restsslcontextconfigmode configmode ; if ( isrestsslauthenticationenabled ( config ) ) { configmode = restsslcontextconfigmode . mutual ; } else { configmode = restsslcontextconfigmode . client ; } return createrestsslcontext ( config , configmode ) ; }	Creates an SSL context for clients against the external REST endpoint.
@ nonnull public final typeserializer < t > previousschemaserializer ( ) { if ( cachedrestoredserializer != null ) { return cachedrestoredserializer ; } if ( previousserializersnapshot == null ) { throw new unsupportedoperationexception ( str_ ) ; } this . cachedrestoredserializer = previousserializersnapshot . restoreserializer ( ) ; return cachedrestoredserializer ; }	Gets the serializer that recognizes the previous serialization schema of the state.This is the serializer that should be used for restoring the state, i.e.
@ override public completablefuture < acknowledge > deregisterapplication ( final applicationstatus finalstatus , @ nullable final string diagnostics ) { log . info ( str_ , finalstatus , diagnostics ) ; try { internalderegisterapplication ( finalstatus , diagnostics ) ; } catch ( resourcemanagerexception e ) { log . warn ( str_ , e ) ; } return completablefuture . completedfuture ( acknowledge . get ( ) ) ; }	Cleanup application and shut down cluster.
private registrationresponse registerjobmasterinternal ( final jobmastergateway jobmastergateway , jobid jobid , string jobmanageraddress , resourceid jobmanagerresourceid ) { if ( jobmanagerregistrations . containskey ( jobid ) ) { jobmanagerregistration oldjobmanagerregistration = jobmanagerregistrations . get ( jobid ) ; if ( objects . equals ( oldjobmanagerregistration . getjobmasterid ( ) , jobmastergateway . getfencingtoken ( ) ) ) {	Registers a new JobMaster.
private registrationresponse registertaskexecutorinternal ( taskexecutorgateway taskexecutorgateway , string taskexecutoraddress , resourceid taskexecutorresourceid , int dataport , hardwaredescription hardwaredescription ) { workerregistration < workertype > oldregistration = taskexecutors . remove ( taskexecutorresourceid ) ; if ( oldregistration != null ) {	Registers a new TaskExecutor.
protected void closejobmanagerconnection ( jobid jobid , exception cause ) { jobmanagerregistration jobmanagerregistration = jobmanagerregistrations . remove ( jobid ) ; if ( jobmanagerregistration != null ) { final resourceid jobmanagerresourceid = jobmanagerregistration . getjobmanagerresourceid ( ) ; final jobmastergateway jobmastergateway = jobmanagerregistration . getjobmanagergateway ( ) ; final jobmasterid jobmasterid = jobmanagerregistration . getjobmasterid ( ) ; log . info ( str_ , jobmasterid , jobmastergateway . getaddress ( ) , jobid ) ; jobmanagerheartbeatmanager . unmonitortarget ( jobmanagerresourceid ) ; jmresourceidregistrations . remove ( jobmanagerresourceid ) ;	This method should be called by the framework once it detects that a currently registeredjob manager has failed.
protected void closetaskmanagerconnection ( final resourceid resourceid , final exception cause ) { taskmanagerheartbeatmanager . unmonitortarget ( resourceid ) ; workerregistration < workertype > workerregistration = taskexecutors . remove ( resourceid ) ; if ( workerregistration != null ) { log . info ( str_ , resourceid , cause . getmessage ( ) ) ;	This method should be called by the framework once it detects that a currently registeredtask executor has failed.
protected void onfatalerror ( throwable t ) { try { log . error ( str_ , t ) ; } catch ( throwable ignored ) { }	Notifies the ResourceManager that a fatal error has occurred and it cannot proceed.
public void notifykvstateregistered ( jobvertexid jobvertexid , keygrouprange keygrouprange , string registrationname , kvstateid kvstateid , inetsocketaddress kvstateserveraddress ) { kvstatelocation location = lookuptable . get ( registrationname ) ; if ( location == null ) {	Notifies the registry about a registered KvState instance.
public void notifykvstateunregistered ( jobvertexid jobvertexid , keygrouprange keygrouprange , string registrationname ) { kvstatelocation location = lookuptable . get ( registrationname ) ; if ( location != null ) {	Notifies the registry about an unregistered KvState instance.
private static void extractintersectingstate ( collection < keyedstatehandle > originalsubtaskstatehandles , keygrouprange rangetoextract , list < keyedstatehandle > extractedstatecollector ) { for ( keyedstatehandle keyedstatehandle : originalsubtaskstatehandles ) { if ( keyedstatehandle != null ) { keyedstatehandle intersectedkeyedstatehandle = keyedstatehandle . getintersection ( rangetoextract ) ; if ( intersectedkeyedstatehandle != null ) { extractedstatecollector . add ( intersectedkeyedstatehandle ) ; } } } }	Extracts certain key group ranges from the given state handles and adds them to the collector.
private static void checkparallelismpreconditions ( operatorstate operatorstate , executionjobvertex executionjobvertex ) {	Verifies conditions in regards to parallelism and maxParallelism that must be met when restoring state.
private static void checkstatemappingcompleteness ( boolean allownonrestoredstate , map < operatorid , operatorstate > operatorstates , map < jobvertexid , executionjobvertex > tasks ) { set < operatorid > alloperatorids = new hashset < > ( ) ; for ( executionjobvertex executionjobvertex : tasks . values ( ) ) { alloperatorids . addall ( executionjobvertex . getoperatorids ( ) ) ; } for ( map . entry < operatorid , operatorstate > operatorgroupstateentry : operatorstates . entryset ( ) ) { operatorstate operatorstate = operatorgroupstateentry . getvalue ( ) ;	Verifies that all operator states can be mapped to an execution job vertex.
public void shutdownandwait ( ) { try { client . shutdown ( ) . get ( ) ; log . info ( str_ ) ; } catch ( exception e ) { log . warn ( str_ , e ) ; } }	Shuts down the client and waits until shutdown is completed.
private completablefuture < kvstateresponse > getkvstate ( final jobid jobid , final string queryablestatename , final int keyhashcode , final byte [ ] serializedkeyandnamespace ) { log . debug ( str_ , remoteaddress ) ; try { kvstaterequest request = new kvstaterequest ( jobid , queryablestatename , keyhashcode , serializedkeyandnamespace ) ; return client . sendrequest ( remoteaddress , request ) ; } catch ( exception e ) { log . error ( str_ , e ) ; return futureutils . getfailedfuture ( e ) ; } }	Returns a future holding the serialized request result.
public typeserializer < t > getelementserializer ( ) {	Gets the serializer for the elements contained in the list.
public static void main ( string [ ] args ) { environmentinformation . logenvironmentinfo ( log , str_ , args ) ; signalhandler . register ( log ) ; jvmshutdownsafeguard . installasshutdownhook ( log ) ; run ( args ) ; }	The entry point for the YARN task executor runner.
@ override public void returnlogicalslot ( logicalslot logicalslot ) { checknotnull ( logicalslot ) ; checkargument ( logicalslot instanceof slot ) ; final slot slot = ( ( slot ) logicalslot ) ; checkargument ( ! slot . isalive ( ) , str_ ) ; checkargument ( slot . getowner ( ) == this , str_ ) ; if ( slot . markreleased ( ) ) { log . debug ( str_ , slot ) ; synchronized ( instancelock ) { if ( isdead ) { return ; } if ( this . allocatedslots . remove ( slot ) ) { this . availableslots . add ( slot . getslotnumber ( ) ) ; if ( this . slotavailabilitylistener != null ) { this . slotavailabilitylistener . newslotavailable ( this ) ; } } else { throw new illegalargumentexception ( str_ ) ; } } } }	Returns a slot that has been allocated from this instance.
public void close ( ) throws ioexception { throwable throwable = null ; try { socket . close ( ) ; sender . close ( ) ; receiver . close ( ) ; } catch ( throwable t ) { throwable = t ; } try { destroyprocess ( process ) ; } catch ( throwable t ) { throwable = exceptionutils . firstorsuppressed ( t , throwable ) ; } shutdownhookutil . removeshutdownhook ( shutdownthread , getclass ( ) . getsimplename ( ) , log ) ; exceptionutils . tryrethrowioexception ( throwable ) ; }	Closes this streamer.
public final void sendbroadcastvariables ( configuration config ) throws ioexception { try { int broadcastcount = config . getinteger ( planbinder_config_bcvar_count , num_ ) ; string [ ] names = new string [ broadcastcount ] ; for ( int x = num_ ; x < names . length ; x ++ ) { names [ x ] = config . getstring ( planbinder_config_bcvar_name_prefix + x , null ) ; } out . write ( new intserializer ( ) . serializewithouttypeinfo ( broadcastcount ) ) ; stringserializer stringserializer = new stringserializer ( ) ; for ( string name : names ) { iterator < byte [ ] > bcv = function . getruntimecontext ( ) . < byte [ ] > getbroadcastvariable ( name ) . iterator ( ) ; out . write ( stringserializer . serializewithouttypeinfo ( name ) ) ; while ( bcv . hasnext ( ) ) { out . writebyte ( num_ ) ; out . write ( bcv . next ( ) ) ; } out . writebyte ( num_ ) ; } } catch ( sockettimeoutexception ignored ) { throw new runtimeexception ( str_ + function . getruntimecontext ( ) . gettaskname ( ) + str_ + msg ) ; } }	Sends all broadcast-variables encoded in the configuration to the external process.
protected static path getcheckpointdirectoryforjob ( path basecheckpointpath , jobid jobid ) { return new path ( basecheckpointpath , jobid . tostring ( ) ) ; }	Builds directory into which a specific job checkpoints, meaning the directory inside whichit creates the checkpoint-specific subdirectories.
public static checkpointstoragelocationreference encodepathasreference ( path path ) { byte [ ] refbytes = path . tostring ( ) . getbytes ( standardcharsets . utf_8 ) ; byte [ ] bytes = new byte [ reference_magic_number . length + refbytes . length ] ; system . arraycopy ( reference_magic_number , num_ , bytes , num_ , reference_magic_number . length ) ; system . arraycopy ( refbytes , num_ , bytes , reference_magic_number . length , refbytes . length ) ; return new checkpointstoragelocationreference ( bytes ) ; }	Encodes the given path as a reference in bytes.
@ suppresswarnings ( str_ ) public t newinstance ( classloader classloader ) { try { return ( t ) compile ( classloader ) . getconstructor ( object [ ] . class )	Create a new instance of this generated class.
private void restorewithoutrescaling ( keyedstatehandle keyedstatehandle ) throws exception { if ( keyedstatehandle instanceof incrementalremotekeyedstatehandle ) { incrementalremotekeyedstatehandle incrementalremotekeyedstatehandle = ( incrementalremotekeyedstatehandle ) keyedstatehandle ; restorepreviousincrementalfilesstatus ( incrementalremotekeyedstatehandle ) ; restorefromremotestate ( incrementalremotekeyedstatehandle ) ; } else if ( keyedstatehandle instanceof incrementallocalkeyedstatehandle ) { incrementallocalkeyedstatehandle incrementallocalkeyedstatehandle = ( incrementallocalkeyedstatehandle ) keyedstatehandle ; restorepreviousincrementalfilesstatus ( incrementallocalkeyedstatehandle ) ; restorefromlocalstate ( incrementallocalkeyedstatehandle ) ; } else { throw new backendbuildingexception ( str_ + str_ + incrementalremotekeyedstatehandle . class + str_ + incrementallocalkeyedstatehandle . class + str_ + keyedstatehandle . getclass ( ) ) ; } }	Recovery from a single remote incremental state without rescaling.
private void restorewithrescaling ( collection < keyedstatehandle > restorestatehandles ) throws exception {	Recovery from multi incremental states with rescaling.
private keyedbackendserializationproxy < k > readmetadata ( streamstatehandle metastatehandle ) throws exception { fsdatainputstream inputstream = null ; try { inputstream = metastatehandle . openinputstream ( ) ; cancelstreamregistry . registercloseable ( inputstream ) ; datainputview in = new datainputviewstreamwrapper ( inputstream ) ; return readmetadata ( in ) ; } finally { if ( cancelstreamregistry . unregistercloseable ( inputstream ) ) { inputstream . close ( ) ; } } }	Reads Flink's state meta data file from the state handle.
private static void deleterange ( rocksdb db , list < columnfamilyhandle > columnfamilyhandles , byte [ ] beginkeybytes , byte [ ] endkeybytes ) throws rocksdbexception { for ( columnfamilyhandle columnfamilyhandle : columnfamilyhandles ) { try ( rocksiteratorwrapper iteratorwrapper = rocksdboperationutils . getrocksiterator ( db , columnfamilyhandle ) ; rocksdbwritebatchwrapper writebatchwrapper = new rocksdbwritebatchwrapper ( db ) ) { iteratorwrapper . seek ( beginkeybytes ) ; while ( iteratorwrapper . isvalid ( ) ) { final byte [ ] currentkey = iteratorwrapper . key ( ) ; if ( beforetheprefixbytes ( currentkey , endkeybytes ) ) { writebatchwrapper . remove ( columnfamilyhandle , currentkey ) ; } else { break ; } iteratorwrapper . next ( ) ; } } } }	Delete the record falls into [beginKeyBytes, endKeyBytes) of the db.
public doubleparameter setdefaultvalue ( double defaultvalue ) { super . setdefaultvalue ( defaultvalue ) ; if ( hasminimumvalue ) { if ( minimumvalueinclusive ) { util . checkparameter ( defaultvalue >= minimumvalue , str_ + defaultvalue + str_ + minimumvalue + str_ ) ; } else { util . checkparameter ( defaultvalue > minimumvalue , str_ + defaultvalue + str_ + minimumvalue + str_ ) ; } } if ( hasmaximumvalue ) { if ( maximumvalueinclusive ) { util . checkparameter ( defaultvalue <= maximumvalue , str_ + defaultvalue + str_ + maximumvalue + str_ ) ; } else { util . checkparameter ( defaultvalue < maximumvalue , str_ + defaultvalue + str_ + maximumvalue + str_ ) ; } } return this ; }	Set the default value.
public doubleparameter setminimumvalue ( double minimumvalue , boolean inclusive ) { if ( hasdefaultvalue ) { if ( inclusive ) { util . checkparameter ( minimumvalue <= defaultvalue , str_ + minimumvalue + str_ + defaultvalue + str_ ) ; } else { util . checkparameter ( minimumvalue < defaultvalue , str_ + minimumvalue + str_ + defaultvalue + str_ ) ; } } else if ( hasmaximumvalue ) { if ( inclusive && maximumvalueinclusive ) { util . checkparameter ( minimumvalue <= maximumvalue , str_ + minimumvalue + str_ + maximumvalue + str_ ) ; } else { util . checkparameter ( minimumvalue < maximumvalue , str_ + minimumvalue + str_ + maximumvalue + str_ ) ; } } this . hasminimumvalue = bool_ ; this . minimumvalue = minimumvalue ; this . minimumvalueinclusive = inclusive ; return this ; }	Set the minimum value.
public doubleparameter setmaximumvalue ( double maximumvalue , boolean inclusive ) { if ( hasdefaultvalue ) { if ( inclusive ) { util . checkparameter ( maximumvalue >= defaultvalue , str_ + maximumvalue + str_ + defaultvalue + str_ ) ; } else { util . checkparameter ( maximumvalue > defaultvalue , str_ + maximumvalue + str_ + defaultvalue + str_ ) ; } } else if ( hasminimumvalue ) { if ( inclusive && minimumvalueinclusive ) { util . checkparameter ( maximumvalue >= minimumvalue , str_ + maximumvalue + str_ + minimumvalue + str_ ) ; } else { util . checkparameter ( maximumvalue > minimumvalue , str_ + maximumvalue + str_ + minimumvalue + str_ ) ; } } this . hasmaximumvalue = bool_ ; this . maximumvalue = maximumvalue ; this . maximumvalueinclusive = inclusive ; return this ; }	Set the maximum value.
public void addbroadcastsetforsumfunction ( string name , dataset < ? > data ) { this . bcvarssum . add ( new tuple2 < > ( name , data ) ) ; }	Adds a data set as a broadcast set to the sum function.
public void addbroadcastsetforapplyfunction ( string name , dataset < ? > data ) { this . bcvarsapply . add ( new tuple2 < > ( name , data ) ) ; }	Adds a data set as a broadcast set to the apply function.
@ suppresswarnings ( str_ ) public < x > streamrecord < x > replace ( x element ) { this . value = ( t ) element ; return ( streamrecord < x > ) this ; }	Replace the currently stored value by the given new value.
@ suppresswarnings ( str_ ) public < x > streamrecord < x > replace ( x value , long timestamp ) { this . timestamp = timestamp ; this . value = ( t ) value ; this . hastimestamp = bool_ ; return ( streamrecord < x > ) this ; }	Replace the currently stored value by the given new value and the currently storedtimestamp with the new timestamp.
public streamrecord < t > copy ( t valuecopy ) { streamrecord < t > copy = new streamrecord < > ( valuecopy ) ; copy . timestamp = this . timestamp ; copy . hastimestamp = this . hastimestamp ; return copy ; }	Creates a copy of this stream record.
public void copyto ( t valuecopy , streamrecord < t > target ) { target . value = valuecopy ; target . timestamp = this . timestamp ; target . hastimestamp = this . hastimestamp ; }	Copies this record into the new stream record.
@ override public void onevent ( taskevent event ) { if ( event instanceof terminationevent ) { terminationsignaled = bool_ ; } else if ( event instanceof allworkersdoneevent ) { allworkersdoneevent wde = ( allworkersdoneevent ) event ; aggregatornames = wde . getaggregatornames ( ) ; aggregates = wde . getaggregates ( usercodeclassloader ) ; } else { throw new illegalargumentexception ( str_ ) ; } latch . countdown ( ) ; }	Barrier will release the waiting thread if an event occurs.
public static mesostaskmanagerparameters create ( configuration flinkconfig ) { list < constraintevaluator > constraints = parseconstraints ( flinkconfig . getstring ( mesos_constraints_hard_hostattr ) ) ;	Create the Mesos TaskManager parameters.
public static list < string > builduris ( option < string > uris ) { if ( uris . isempty ( ) ) { return collections . emptylist ( ) ; } else { list < string > urislist = new arraylist < > ( ) ; for ( string uri : uris . get ( ) . split ( str_ ) ) { urislist . add ( uri . trim ( ) ) ; } return urislist ; } }	Build a list of URIs for providing custom artifacts to Mesos tasks.
public static < t extends restfulgateway > optional < staticfileserverhandler < t > > tryloadwebcontent ( gatewayretriever < ? extends t > leaderretriever , time timeout , file tmpdir ) throws ioexception { if ( isflinkruntimewebinclasspath ( ) ) { return optional . of ( new staticfileserverhandler < > ( leaderretriever , timeout , tmpdir ) ) ; } else { return optional . empty ( ) ; } }	Checks whether the flink-runtime-web dependency is available and if so returns aStaticFileServerHandler which can serve the static file contents.
@ override public iterator < t > sample ( final iterator < t > input ) { if ( fraction == num_ ) { return emptyiterable ; } return new samplediterator < t > ( ) { t currentelement ; int currentcount = num_ ; @ override public boolean hasnext ( ) { if ( currentcount > num_ ) { return bool_ ; } else { samplingprocess ( ) ; if ( currentcount > num_ ) { return bool_ ; } else { return bool_ ; } } } @ override public t next ( ) { if ( currentcount <= num_ ) { samplingprocess ( ) ; } currentcount -- ; return currentelement ; } public int poisson_ge1 ( double p ) {	Sample the input elements, for each input element, generate its count following a poissondistribution.
public static simpledateformat newdateformat ( string format ) { simpledateformat sdf = new simpledateformat ( format , locale . root ) ; sdf . setlenient ( bool_ ) ; return sdf ; }	Creates a new date formatter with Farrago specific options.
private static long firstmondayoffirstweek ( int year ) { final long janfirst = ymdtojulian ( year , num_ , num_ ) ; final long janfirstdow = floormod ( janfirst + num_ , num_ ) ;	Returns the first day of the first week of a year.Per ISO-8601 it is the Monday of the week that contains Jan 4,or equivalently, it is a Monday between Dec 29 and Jan 4.Sometimes it is in the year before the given year.
public static long addmonths ( long timestamp , int m ) { final long millis = datetimeutils . floormod ( timestamp , datetimeutils . millis_per_day ) ; timestamp -= millis ; final long x = addmonths ( ( int ) ( timestamp / datetimeutils . millis_per_day ) , m ) ; return x * datetimeutils . millis_per_day + millis ; }	Adds a given number of months to a timestamp, represented as the numberof milliseconds since the epoch.
public static int addmonths ( int date , int m ) { int y0 = ( int ) datetimeutils . unixdateextract ( timeunitrange . year , date ) ; int m0 = ( int ) datetimeutils . unixdateextract ( timeunitrange . month , date ) ; int d0 = ( int ) datetimeutils . unixdateextract ( timeunitrange . day , date ) ; int y = m / num_ ; y0 += y ; m0 += m - y * num_ ; int last = lastday ( y0 , m0 ) ; if ( d0 > last ) { d0 = num_ ; if ( ++ m0 > num_ ) { m0 = num_ ; ++ y0 ; } } return datetimeutils . ymdtounixdate ( y0 , m0 , d0 ) ; }	Adds a given number of months to a date, represented as the number ofdays since the epoch.
public static int subtractmonths ( int date0 , int date1 ) { if ( date0 < date1 ) { return - subtractmonths ( date1 , date0 ) ; }	Finds the number of months between two dates, each represented as thenumber of days since the epoch.
public static singleinputsemanticproperties addsourcefieldoffset ( singleinputsemanticproperties props , int numinputfields , int offset ) { singleinputsemanticproperties offsetprops = new singleinputsemanticproperties ( ) ; if ( props . getreadfields ( num_ ) != null ) { fieldset offsetreadfields = new fieldset ( ) ; for ( int r : props . getreadfields ( num_ ) ) { offsetreadfields = offsetreadfields . addfield ( r + offset ) ; } offsetprops . addreadfields ( offsetreadfields ) ; } for ( int s = num_ ; s < numinputfields ; s ++ ) { fieldset targetfields = props . getforwardingtargetfields ( num_ , s ) ; for ( int t : targetfields ) { offsetprops . addforwardedfield ( s + offset , t ) ; } } return offsetprops ; }	Creates SemanticProperties by adding an offset to each input field index of the given SemanticProperties.
public static dualinputsemanticproperties addsourcefieldoffsets ( dualinputsemanticproperties props , int numinputfields1 , int numinputfields2 , int offset1 , int offset2 ) { dualinputsemanticproperties offsetprops = new dualinputsemanticproperties ( ) ;	Creates SemanticProperties by adding offsets to each input field index of the given SemanticProperties.
public static memorysize parse ( string text , memoryunit defaultunit ) throws illegalargumentexception { if ( ! hasunit ( text ) ) { return parse ( text + defaultunit . getunits ( ) [ num_ ] ) ; } return parse ( text ) ; }	Parses the given string with a default unit.
protected void buildinitialtable ( final mutableobjectiterator < bt > input ) throws ioexception {	Creates the initial hash table.
final void buildbloomfilterforbucket ( int bucketinsegmentpos , memorysegment bucket , hashpartition < bt , pt > p ) { final int count = bucket . getshort ( bucketinsegmentpos + header_count_offset ) ; if ( count <= num_ ) { return ; } int [ ] hashcodes = new int [ count ] ;	Set all the bucket memory except bucket header as the bit set of bloom filter, and use hash code of build recordsto build bloom filter.
public static int getnumwritebehindbuffers ( int numbuffers ) { int numiobufs = ( int ) ( math . log ( numbuffers ) / math . log ( num_ ) - num_ ) ; return numiobufs > num_ ? num_ : numiobufs ; }	Determines the number of buffers to be used for asynchronous write behind.
public jobwithjars getplanwithoutjars ( ) throws programinvocationexception { if ( isusingprogramentrypoint ( ) ) { return new jobwithjars ( getplan ( ) , collections . < url > emptylist ( ) , classpaths , usercodeclassloader ) ; } else { throw new programinvocationexception ( str_ + jobwithjars . class . getsimplename ( ) + str_ , getplan ( ) . getjobid ( ) ) ; } }	Returns the plan without the required jars when the files are already provided by the cluster.
public list < url > getalllibraries ( ) { list < url > libs = new arraylist < url > ( this . extractedtemplibraries . size ( ) + num_ ) ; if ( jarfile != null ) { libs . add ( jarfile ) ; } for ( file tmplib : this . extractedtemplibraries ) { try { libs . add ( tmplib . getabsolutefile ( ) . touri ( ) . tourl ( ) ) ; } catch ( malformedurlexception e ) { throw new runtimeexception ( str_ , e ) ; } } return libs ; }	Returns all provided libraries needed to run the program.
private plan getplan ( ) throws programinvocationexception { if ( this . plan == null ) { thread . currentthread ( ) . setcontextclassloader ( this . usercodeclassloader ) ; this . plan = createplanfromprogram ( this . program , this . args ) ; } return this . plan ; }	Returns the plan as generated from the Pact Assembler.
private static plan createplanfromprogram ( program program , string [ ] options ) throws programinvocationexception { try { return program . getplan ( options ) ; } catch ( throwable t ) { throw new programinvocationexception ( str_ + t . getmessage ( ) , t ) ; } }	Takes the jar described by the given file and invokes its pact assembler class toassemble a plan.
public static taskmanagerservicesconfiguration fromconfiguration ( configuration configuration , long maxjvmheapmemory , inetaddress remoteaddress , boolean localcommunication ) { final string [ ] tmpdirs = configurationutils . parsetempdirectories ( configuration ) ; string [ ] localstaterootdir = configurationutils . parselocalstatedirectories ( configuration ) ; if ( localstaterootdir . length == num_ ) {	Utility method to extract TaskManager config parameters from the configuration and tosanity check them.
public tableoperation create ( settableoperationtype type , tableoperation left , tableoperation right , boolean all ) { failifstreaming ( type , all ) ; validatesetoperation ( type , left , right ) ; return new settableoperation ( left , right , type , all ) ; }	Creates a valid algebraic operation.
@ override protected union < t > translatetodataflow ( operator < t > input1 , operator < t > input2 ) { return new union < t > ( input1 , input2 , unionlocationname ) ; }	Returns the BinaryNodeTranslation of the Union.
public < t > t getfieldnotnull ( int pos ) { t field = getfield ( pos ) ; if ( field != null ) { return field ; } else { throw new nullfieldexception ( pos ) ; } }	Gets the field at the specified position, throws NullFieldException if the field is null.
public static tuple newinstance ( int arity ) { switch ( arity ) { case num_ : return tuple0 . instance ; case num_ : return new tuple1 ( ) ; case num_ : return new tuple2 ( ) ; case num_ : return new tuple3 ( ) ; case num_ : return new tuple4 ( ) ; case num_ : return new tuple5 ( ) ; case num_ : return new tuple6 ( ) ; case num_ : return new tuple7 ( ) ; case num_ : return new tuple8 ( ) ; case num_ : return new tuple9 ( ) ; case num_ : return new tuple10 ( ) ; case num_ : return new tuple11 ( ) ; case num_ : return new tuple12 ( ) ; case num_ : return new tuple13 ( ) ; case num_ : return new tuple14 ( ) ; case num_ : return new tuple15 ( ) ; case num_ : return new tuple16 ( ) ; case num_ : return new tuple17 ( ) ; case num_ : return new tuple18 ( ) ; case num_ : return new tuple19 ( ) ; case num_ : return new tuple20 ( ) ; case num_ : return new tuple21 ( ) ; case num_ : return new tuple22 ( ) ; case num_ : return new tuple23 ( ) ; case num_ : return new tuple24 ( ) ; case num_ : return new tuple25 ( ) ; default : throw new illegalargumentexception ( str_ + max_arity + str_ ) ; } }	GENERATED FROM org.apache.flink.api.java.tuple.TupleGenerator.
public final void streambufferwithoutgroups ( iterator < in > iterator , collector < out > c ) { singleelementpushbackiterator < in > i = new singleelementpushbackiterator < > ( iterator ) ; try { int size ; if ( i . hasnext ( ) ) { while ( bool_ ) { int sig = in . readint ( ) ; switch ( sig ) { case signal_buffer_request : if ( i . hasnext ( ) ) { size = sender . sendbuffer ( i ) ; sendwritenotification ( size , i . hasnext ( ) ) ; } else { throw new runtimeexception ( str_ ) ; } break ; case signal_finished : return ; case signal_error : try { outprinter . join ( ) ; } catch ( interruptedexception e ) { outprinter . interrupt ( ) ; } try { errorprinter . join ( ) ; } catch ( interruptedexception e ) { errorprinter . interrupt ( ) ; } throw new runtimeexception ( str_ + function . getruntimecontext ( ) . gettaskname ( ) + str_ + msg ) ; default : receiver . collectbuffer ( c , sig ) ; sendreadconfirmation ( ) ; break ; } } } } catch ( sockettimeoutexception ignored ) { throw new runtimeexception ( str_ + function . getruntimecontext ( ) . gettaskname ( ) + str_ + msg . get ( ) ) ; } catch ( exception e ) { throw new runtimeexception ( str_ + function . getruntimecontext ( ) . gettaskname ( ) + str_ + msg . get ( ) , e ) ; } }	Sends all values contained in the iterator to the external process and collects all results.
@ visiblefortesting protected < k , v > kafkaproducer < k , v > getkafkaproducer ( properties props ) { return new kafkaproducer < > ( props ) ; }	Used for testing only.
@ override public void invoke ( in next , context context ) throws exception {	Called when new data arrives to the sink, and forwards it to Kafka.
public < t > broadcastvariablematerialization < t , ? > materializebroadcastvariable ( string name , int superstep , batchtask < ? , ? > holder , mutablereader < ? > reader , typeserializerfactory < t > serializerfactory ) throws ioexception { final broadcastvariablekey key = new broadcastvariablekey ( holder . getenvironment ( ) . getjobvertexid ( ) , name , superstep ) ; while ( bool_ ) { final broadcastvariablematerialization < t , object > newmat = new broadcastvariablematerialization < t , object > ( key ) ; final broadcastvariablematerialization < ? , ? > previous = variables . putifabsent ( key , newmat ) ; @ suppresswarnings ( str_ ) final broadcastvariablematerialization < t , ? > materialization = ( previous == null ) ? newmat : ( broadcastvariablematerialization < t , ? > ) previous ; try { materialization . materializevariable ( reader , serializerfactory , holder ) ; return materialization ; } catch ( materializationexpiredexception e ) {	Materializes the broadcast variable for the given name, scoped to the given task and its iteration superstep.
public void setgrouporder ( int inputnum , ordering order ) { if ( inputnum == num_ ) { this . grouporder1 = order ; } else if ( inputnum == num_ ) { this . grouporder2 = order ; } else { throw new indexoutofboundsexception ( ) ; } }	Sets the order of the elements within a group for the given input.
public ordering appendordering ( integer index , class < ? extends comparable < ? > > type , order order ) { if ( index < num_ ) { throw new illegalargumentexception ( str_ ) ; } if ( order == null ) { throw new nullpointerexception ( ) ; } if ( order == order . none ) { throw new illegalargumentexception ( str_ ) ; } if ( ! this . indexes . contains ( index ) ) { this . indexes = this . indexes . addfield ( index ) ; this . types . add ( type ) ; this . orders . add ( order ) ; } return this ; }	Extends this ordering by appending an additional order requirement.If the index has been previously appended then the unmodified Orderingis returned.
@ override protected amazonkinesis createkinesisclient ( properties configprops ) { clientconfiguration awsclientconfig = new clientconfigurationfactory ( ) . getconfig ( ) ; setawsclientconfigproperties ( awsclientconfig , configprops ) ; awscredentialsprovider credentials = getcredentialsprovider ( configprops ) ; awsclientconfig . setuseragentprefix ( string . format ( user_agent_format , environmentinformation . getversion ( ) , environmentinformation . getrevisioninformation ( ) . commitid ) ) ; amazondynamodbstreamsadapterclient adapterclient = new amazondynamodbstreamsadapterclient ( credentials , awsclientconfig ) ; if ( configprops . containskey ( aws_endpoint ) ) { adapterclient . setendpoint ( configprops . getproperty ( aws_endpoint ) ) ; } else { adapterclient . setregion ( region . getregion ( regions . fromname ( configprops . getproperty ( aws_region ) ) ) ) ; } return adapterclient ; }	Creates an AmazonDynamoDBStreamsAdapterClient.Uses it as the internal client interacting with the DynamoDB streams.
public static string concat ( characterfilter filter , character delimiter , string ... components ) { stringbuilder sb = new stringbuilder ( ) ; sb . append ( filter . filtercharacters ( components [ num_ ] ) ) ; for ( int x = num_ ; x < components . length ; x ++ ) { sb . append ( delimiter ) ; sb . append ( filter . filtercharacters ( components [ x ] ) ) ; } return sb . tostring ( ) ; }	Concatenates the given component names separated by the delimiter character.
public static void main ( string [ ] args ) throws ioexception { string outputdirectory = args [ num_ ] ; for ( final restapiversion apiversion : restapiversion . values ( ) ) { if ( apiversion == restapiversion . v0 ) {	Generates the REST API documentation.
@ suppresswarnings ( str_ ) public static < t extends specificrecord > typeinformation < row > converttotypeinfo ( class < t > avroclass ) { preconditions . checknotnull ( avroclass , str_ ) ;	Converts an Avro class into a nested row structure with deterministic field order and datatypes that are compatible with Flink's Table & SQL API.
@ suppresswarnings ( str_ ) public static < t > typeinformation < t > converttotypeinfo ( string avroschemastring ) { preconditions . checknotnull ( avroschemastring , str_ ) ; final schema schema ; try { schema = new schema . parser ( ) . parse ( avroschemastring ) ; } catch ( schemaparseexception e ) { throw new illegalargumentexception ( str_ , e ) ; } return ( typeinformation < t > ) converttotypeinfo ( schema ) ; }	Converts an Avro schema string into a nested row structure with deterministic field order and datatypes that are compatible with Flink's Table & SQL API.
public void registertypewithkryoserializer ( class < ? > type , class < ? extends serializer < ? > > serializerclass ) { config . registertypewithkryoserializer ( type , serializerclass ) ; }	Registers the given Serializer via its class as a serializer for the given type at the KryoSerializer.
public < x > datasource < x > fromcollection ( collection < x > data , typeinformation < x > type ) { return fromcollection ( data , type , utils . getcalllocationname ( ) ) ; }	Creates a DataSet from the given non-empty collection.
private < x > datasource < x > fromparallelcollection ( splittableiterator < x > iterator , typeinformation < x > type , string calllocationname ) { return new datasource < > ( this , new paralleliteratorinputformat < > ( iterator ) , type , calllocationname ) ; }	private helper for passing different call location names.
protected void registercachedfileswithplan ( plan p ) throws ioexception { for ( tuple2 < string , distributedcacheentry > entry : cachefile ) { p . registercachedfile ( entry . f0 , entry . f1 ) ; } }	Registers all files that were registered at this execution environment's cache registry of thegiven plan's cache registry.
private void processevent ( nfastate nfastate , in event , long timestamp ) throws exception { try ( sharedbufferaccessor < in > sharedbufferaccessor = partialmatches . getaccessor ( ) ) { collection < map < string , list < in > > > patterns = nfa . process ( sharedbufferaccessor , nfastate , event , timestamp , aftermatchskipstrategy , ceptimerservice ) ; processmatchedsequences ( patterns , timestamp ) ; } }	Process the given event by giving it to the NFA and outputting the produced set of matchedevent sequences.
private static < in , out > singleoutputstreamoperator < out > addoperator ( datastream < in > in , asyncfunction < in , out > func , long timeout , int bufsize , outputmode mode ) { typeinformation < out > outtypeinfo = typeextractor . getunaryoperatorreturntype ( func , asyncfunction . class , num_ , num_ , new int [ ] { num_ , num_ } , in . gettype ( ) , utils . getcalllocationname ( ) , bool_ ) ;	Add an AsyncWaitOperator.
public static < in , out > singleoutputstreamoperator < out > unorderedwait ( datastream < in > in , asyncfunction < in , out > func , long timeout , timeunit timeunit , int capacity ) { return addoperator ( in , func , timeunit . tomillis ( timeout ) , capacity , outputmode . unordered ) ; }	Add an AsyncWaitOperator. The order of output stream records may be reordered.
public static < in , out > singleoutputstreamoperator < out > orderedwait ( datastream < in > in , asyncfunction < in , out > func , long timeout , timeunit timeunit , int capacity ) { return addoperator ( in , func , timeunit . tomillis ( timeout ) , capacity , outputmode . ordered ) ; }	Add an AsyncWaitOperator. The order to process input records is guaranteed to be the same asinput ones.
public string getjobparameter ( string key , string defaultvalue ) { final globaljobparameters conf = context . getexecutionconfig ( ) . getglobaljobparameters ( ) ; if ( conf != null && conf . tomap ( ) . containskey ( key ) ) { return conf . tomap ( ) . get ( key ) ; } else { return defaultvalue ; } }	Gets the global job parameter value associated with the given key as a string.
public static deadline fromnow ( duration duration ) { return new deadline ( math . addexact ( system . nanotime ( ) , duration . tonanos ( ) ) ) ; }	Constructs a Deadline that is a given duration after now.
public void start ( resourcemanagerid newresourcemanagerid , executor newmainthreadexecutor , resourceactions newresourceactions ) { log . info ( str_ ) ; this . resourcemanagerid = preconditions . checknotnull ( newresourcemanagerid ) ; mainthreadexecutor = preconditions . checknotnull ( newmainthreadexecutor ) ; resourceactions = preconditions . checknotnull ( newresourceactions ) ; started = bool_ ; taskmanagertimeoutcheck = scheduledexecutor . schedulewithfixeddelay ( ( ) -> mainthreadexecutor . execute ( ( ) -> checktaskmanagertimeouts ( ) ) , num_ , taskmanagertimeout . tomilliseconds ( ) , timeunit . milliseconds ) ; slotrequesttimeoutcheck = scheduledexecutor . schedulewithfixeddelay ( ( ) -> mainthreadexecutor . execute ( ( ) -> checkslotrequesttimeouts ( ) ) , num_ , slotrequesttimeout . tomilliseconds ( ) , timeunit . milliseconds ) ; }	Starts the slot manager with the given leader id and resource manager actions.
public void suspend ( ) { log . info ( str_ ) ;	Suspends the component. This clears the internal state of the slot manager.
public boolean registerslotrequest ( slotrequest slotrequest ) throws slotmanagerexception { checkinit ( ) ; if ( checkduplicaterequest ( slotrequest . getallocationid ( ) ) ) { log . debug ( str_ , slotrequest . getallocationid ( ) ) ; return bool_ ; } else { pendingslotrequest pendingslotrequest = new pendingslotrequest ( slotrequest ) ; pendingslotrequests . put ( slotrequest . getallocationid ( ) , pendingslotrequest ) ; try { internalrequestslot ( pendingslotrequest ) ; } catch ( resourcemanagerexception e ) {	Requests a slot with the respective resource profile.
public boolean unregisterslotrequest ( allocationid allocationid ) { checkinit ( ) ; pendingslotrequest pendingslotrequest = pendingslotrequests . remove ( allocationid ) ; if ( null != pendingslotrequest ) { log . debug ( str_ , allocationid ) ; cancelpendingslotrequest ( pendingslotrequest ) ; return bool_ ; } else { log . debug ( str_ , allocationid ) ; return bool_ ; } }	Cancels and removes a pending slot request with the given allocation id.
public void registertaskmanager ( final taskexecutorconnection taskexecutorconnection , slotreport initialslotreport ) { checkinit ( ) ; log . debug ( str_ , taskexecutorconnection . getresourceid ( ) , taskexecutorconnection . getinstanceid ( ) ) ;	Registers a new task manager at the slot manager.
public boolean unregistertaskmanager ( instanceid instanceid ) { checkinit ( ) ; log . debug ( str_ , instanceid ) ; taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . remove ( instanceid ) ; if ( null != taskmanagerregistration ) { internalunregistertaskmanager ( taskmanagerregistration ) ; return bool_ ; } else { log . debug ( str_ , instanceid ) ; return bool_ ; } }	Unregisters the task manager identified by the given instance id and its associated slotsfrom the slot manager.
public boolean reportslotstatus ( instanceid instanceid , slotreport slotreport ) { checkinit ( ) ; log . debug ( str_ , instanceid , slotreport ) ; taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . get ( instanceid ) ; if ( null != taskmanagerregistration ) { for ( slotstatus slotstatus : slotreport ) { updateslot ( slotstatus . getslotid ( ) , slotstatus . getallocationid ( ) , slotstatus . getjobid ( ) ) ; } return bool_ ; } else { log . debug ( str_ , instanceid ) ; return bool_ ; } }	Reports the current slot allocations for a task manager identified by the given instance id.
public void freeslot ( slotid slotid , allocationid allocationid ) { checkinit ( ) ; taskmanagerslot slot = slots . get ( slotid ) ; if ( null != slot ) { if ( slot . getstate ( ) == taskmanagerslot . state . allocated ) { if ( objects . equals ( allocationid , slot . getallocationid ( ) ) ) { taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . get ( slot . getinstanceid ( ) ) ; if ( taskmanagerregistration == null ) { throw new illegalstateexception ( str_ + slot . getinstanceid ( ) + str_ ) ; } updateslotstate ( slot , taskmanagerregistration , null , null ) ; } else { log . debug ( str_ + str_ , slotid , allocationid , slot . getallocationid ( ) ) ; } } else { log . debug ( str_ , allocationid ) ; } } else { log . debug ( str_ , slotid ) ; } }	Free the given slot from the given allocation.
protected pendingslotrequest findmatchingrequest ( resourceprofile slotresourceprofile ) { for ( pendingslotrequest pendingslotrequest : pendingslotrequests . values ( ) ) { if ( ! pendingslotrequest . isassigned ( ) && slotresourceprofile . ismatching ( pendingslotrequest . getresourceprofile ( ) ) ) { return pendingslotrequest ; } } return null ; }	Finds a matching slot request for a given resource profile.
protected taskmanagerslot findmatchingslot ( resourceprofile requestresourceprofile ) { iterator < map . entry < slotid , taskmanagerslot > > iterator = freeslots . entryset ( ) . iterator ( ) ; while ( iterator . hasnext ( ) ) { taskmanagerslot taskmanagerslot = iterator . next ( ) . getvalue ( ) ;	Finds a matching slot for a given resource profile.
private void registerslot ( slotid slotid , allocationid allocationid , jobid jobid , resourceprofile resourceprofile , taskexecutorconnection taskmanagerconnection ) { if ( slots . containskey ( slotid ) ) {	Registers a slot for the given task manager at the slot manager.
private boolean updateslot ( slotid slotid , allocationid allocationid , jobid jobid ) { final taskmanagerslot slot = slots . get ( slotid ) ; if ( slot != null ) { final taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . get ( slot . getinstanceid ( ) ) ; if ( taskmanagerregistration != null ) { updateslotstate ( slot , taskmanagerregistration , allocationid , jobid ) ; return bool_ ; } else { throw new illegalstateexception ( str_ + slot . getinstanceid ( ) + str_ ) ; } } else { log . debug ( str_ , slotid ) ; return bool_ ; } }	Updates a slot with the given allocation id.
private void internalrequestslot ( pendingslotrequest pendingslotrequest ) throws resourcemanagerexception { final resourceprofile resourceprofile = pendingslotrequest . getresourceprofile ( ) ; taskmanagerslot taskmanagerslot = findmatchingslot ( resourceprofile ) ; if ( taskmanagerslot != null ) { allocateslot ( taskmanagerslot , pendingslotrequest ) ; } else { optional < pendingtaskmanagerslot > pendingtaskmanagerslotoptional = findfreematchingpendingtaskmanagerslot ( resourceprofile ) ; if ( ! pendingtaskmanagerslotoptional . ispresent ( ) ) { pendingtaskmanagerslotoptional = allocateresource ( resourceprofile ) ; } pendingtaskmanagerslotoptional . ifpresent ( pendingtaskmanagerslot -> assignpendingtaskmanagerslot ( pendingslotrequest , pendingtaskmanagerslot ) ) ; } }	Tries to allocate a slot for the given slot request.
private void allocateslot ( taskmanagerslot taskmanagerslot , pendingslotrequest pendingslotrequest ) { preconditions . checkstate ( taskmanagerslot . getstate ( ) == taskmanagerslot . state . free ) ; taskexecutorconnection taskexecutorconnection = taskmanagerslot . gettaskmanagerconnection ( ) ; taskexecutorgateway gateway = taskexecutorconnection . gettaskexecutorgateway ( ) ; final completablefuture < acknowledge > completablefuture = new completablefuture < > ( ) ; final allocationid allocationid = pendingslotrequest . getallocationid ( ) ; final slotid slotid = taskmanagerslot . getslotid ( ) ; final instanceid instanceid = taskmanagerslot . getinstanceid ( ) ; taskmanagerslot . assignpendingslotrequest ( pendingslotrequest ) ; pendingslotrequest . setrequestfuture ( completablefuture ) ; returnpendingtaskmanagerslotifassigned ( pendingslotrequest ) ; taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . get ( instanceid ) ; if ( taskmanagerregistration == null ) { throw new illegalstateexception ( str_ + instanceid + str_ ) ; } taskmanagerregistration . markused ( ) ;	Allocates the given slot for the given slot request.
private void handlefreeslot ( taskmanagerslot freeslot ) { preconditions . checkstate ( freeslot . getstate ( ) == taskmanagerslot . state . free ) ; pendingslotrequest pendingslotrequest = findmatchingrequest ( freeslot . getresourceprofile ( ) ) ; if ( null != pendingslotrequest ) { allocateslot ( freeslot , pendingslotrequest ) ; } else { freeslots . put ( freeslot . getslotid ( ) , freeslot ) ; } }	Handles a free slot.
private void removeslot ( slotid slotid ) { taskmanagerslot slot = slots . remove ( slotid ) ; if ( null != slot ) { freeslots . remove ( slotid ) ; if ( slot . getstate ( ) == taskmanagerslot . state . pending ) {	Removes the given slot from the slot manager.
private void removeslotrequestfromslot ( slotid slotid , allocationid allocationid ) { taskmanagerslot taskmanagerslot = slots . get ( slotid ) ; if ( null != taskmanagerslot ) { if ( taskmanagerslot . getstate ( ) == taskmanagerslot . state . pending && objects . equals ( allocationid , taskmanagerslot . getassignedslotrequest ( ) . getallocationid ( ) ) ) { taskmanagerregistration taskmanagerregistration = taskmanagerregistrations . get ( taskmanagerslot . getinstanceid ( ) ) ; if ( taskmanagerregistration == null ) { throw new illegalstateexception ( str_ + taskmanagerslot . getinstanceid ( ) + str_ ) ; }	Removes a pending slot request identified by the given allocation id from a slot identifiedby the given slot id.
private void handlefailedslotrequest ( slotid slotid , allocationid allocationid , throwable cause ) { pendingslotrequest pendingslotrequest = pendingslotrequests . get ( allocationid ) ; log . debug ( str_ , allocationid , slotid , cause ) ; if ( null != pendingslotrequest ) { pendingslotrequest . setrequestfuture ( null ) ; try { internalrequestslot ( pendingslotrequest ) ; } catch ( resourcemanagerexception e ) { pendingslotrequests . remove ( allocationid ) ; resourceactions . notifyallocationfailure ( pendingslotrequest . getjobid ( ) , allocationid , e ) ; } } else { log . debug ( str_ , allocationid ) ; } }	Handles a failed slot request.
private void cancelpendingslotrequest ( pendingslotrequest pendingslotrequest ) { completablefuture < acknowledge > request = pendingslotrequest . getrequestfuture ( ) ; returnpendingtaskmanagerslotifassigned ( pendingslotrequest ) ; if ( null != request ) { request . cancel ( bool_ ) ; } }	Cancels the given slot request.
protected flinkkafkaconsumerbase < row > getkafkaconsumer ( string topic , properties properties , deserializationschema < row > deserializationschema ) { flinkkafkaconsumerbase < row > kafkaconsumer = createkafkaconsumer ( topic , properties , deserializationschema ) ; switch ( startupmode ) { case earliest : kafkaconsumer . setstartfromearliest ( ) ; break ; case latest : kafkaconsumer . setstartfromlatest ( ) ; break ; case group_offsets : kafkaconsumer . setstartfromgroupoffsets ( ) ; break ; case specific_offsets : kafkaconsumer . setstartfromspecificoffsets ( specificstartupoffsets ) ; break ; } return kafkaconsumer ; }	Returns a version-specific Kafka consumer with the start position configured.
public void triggercheckpointonbarrier ( checkpointmetadata checkpointmetadata , checkpointoptions checkpointoptions , checkpointmetrics checkpointmetrics ) throws exception { throw new unsupportedoperationexception ( string . format ( str_ , this . getclass ( ) . getname ( ) ) ) ; }	This method is called when a checkpoint is triggered as a result of receiving checkpointbarriers on all input streams.
public map < string , object > getallaccumulatorresults ( ) { return accumulatorresults . entryset ( ) . stream ( ) . collect ( collectors . tomap ( map . entry :: getkey , entry -> entry . getvalue ( ) . getunchecked ( ) ) ) ; }	Gets all accumulators produced by the job.
@ deprecated @ publicevolving public integer getintcounterresult ( string accumulatorname ) { object result = this . accumulatorresults . get ( accumulatorname ) . getunchecked ( ) ; if ( result == null ) { return null ; } if ( ! ( result instanceof integer ) ) { throw new classcastexception ( str_ + accumulatorname + str_ + result . getclass ( ) ) ; } return ( integer ) result ; }	Gets the accumulator with the given name as an integer.
protected twophasecommitsinkfunction < in , txn , context > settransactiontimeout ( long transactiontimeout ) { checkargument ( transactiontimeout >= num_ , str_ ) ; this . transactiontimeout = transactiontimeout ; return this ; }	Sets the transaction timeout.
public int hash ( ) { hash ^= num_ * count ; hash ^= hash > > > num_ ; hash *= num_ ; hash ^= hash > > > num_ ; hash *= num_ ; hash ^= hash > > > num_ ; return hash ; }	Finalize and return the MurmurHash output.
static set < string > extractportkeys ( configuration config ) { final linkedhashset < string > tmportkeys = new linkedhashset < > ( tm_port_keys ) ; final string portkeys = config . getstring ( port_assignments ) ; if ( portkeys != null ) { arrays . stream ( portkeys . split ( str_ ) ) . map ( string :: trim ) . peek ( key -> log . debug ( str_ ) ) . foreach ( tmportkeys :: add ) ; } return collections . unmodifiableset ( tmportkeys ) ; }	Get the port keys representing the TM's configured endpoints. This includes mandatory TM endpoints such asdata and rpc as well as optionally configured endpoints for services such as prometheus reporter.
static void configureartifactserver ( mesosartifactserver server , containerspecification container ) throws ioexception {	Configures an artifact server to serve the artifacts associated with a container specification.
public circulantgraph addrange ( long offset , long length ) { preconditions . checkargument ( offset >= minimum_offset , str_ + minimum_offset ) ; preconditions . checkargument ( length <= vertexcount - offset , str_ ) ; offsetranges . add ( new offsetrange ( offset , length ) ) ; return this ; }	Required configuration for each range of offsets in the graph.
public static curatorframework usenamespaceandensurepath ( final curatorframework client , final string path ) throws exception { preconditions . checknotnull ( client , str_ ) ; preconditions . checknotnull ( path , str_ ) ;	Returns a facade of the client that uses the specified namespace, and ensures that all nodesin the path exist.
public static fulltypeinfo getfulltemplatetype ( type type , int templateposition ) { if ( type instanceof parameterizedtype ) { return getfulltemplatetype ( ( ( parameterizedtype ) type ) . getactualtypearguments ( ) [ templateposition ] ) ; } else { throw new illegalargumentexception ( ) ; } }	Extract the full template type information from the given type's template parameter at thegiven position.
public static fulltypeinfo getfulltemplatetype ( type type ) { if ( type instanceof parameterizedtype ) { parameterizedtype parameterizedtype = ( parameterizedtype ) type ; fulltypeinfo [ ] templatetypeinfos = new fulltypeinfo [ parameterizedtype . getactualtypearguments ( ) . length ] ; for ( int i = num_ ; i < parameterizedtype . getactualtypearguments ( ) . length ; i ++ ) { templatetypeinfos [ i ] = getfulltemplatetype ( parameterizedtype . getactualtypearguments ( ) [ i ] ) ; } return new fulltypeinfo ( ( class < ? > ) parameterizedtype . getrawtype ( ) , templatetypeinfos ) ; } else { return new fulltypeinfo ( ( class < ? > ) type , null ) ; } }	Extract the full type information from the given type.
static string sqltoregexlike ( string sqlpattern , char escapechar ) { int i ; final int len = sqlpattern . length ( ) ; final stringbuilder javapattern = new stringbuilder ( len + len ) ; for ( i = num_ ; i < len ; i ++ ) { char c = sqlpattern . charat ( i ) ; if ( java_regex_specials . indexof ( c ) >= num_ ) { javapattern . append ( str_ ) ; } if ( c == escapechar ) { if ( i == ( sqlpattern . length ( ) - num_ ) ) { throw invalidescapesequence ( sqlpattern , i ) ; } char nextchar = sqlpattern . charat ( i + num_ ) ; if ( ( nextchar == str_ ) || ( nextchar == str_ ) || ( nextchar == escapechar ) ) { javapattern . append ( nextchar ) ; i ++ ; } else { throw invalidescapesequence ( sqlpattern , i ) ; } } else if ( c == str_ ) { javapattern . append ( str_ ) ; } else if ( c == str_ ) { javapattern . append ( str_ ) ; } else { javapattern . append ( c ) ; } } return javapattern . tostring ( ) ; }	Translates a SQL LIKE pattern to Java regex pattern.
static string sqltoregexsimilar ( string sqlpattern , charsequence escapestr ) { final char escapechar ; if ( escapestr != null ) { if ( escapestr . length ( ) != num_ ) { throw invalidescapecharacter ( escapestr . tostring ( ) ) ; } escapechar = escapestr . charat ( num_ ) ; } else { escapechar = num_ ; } return sqltoregexsimilar ( sqlpattern , escapechar ) ; }	Translates a SQL SIMILAR pattern to Java regex pattern, with optionalescape string.
static string sqltoregexsimilar ( string sqlpattern , char escapechar ) { similarescaperulechecking ( sqlpattern , escapechar ) ; boolean insidecharacterenumeration = bool_ ; final stringbuilder javapattern = new stringbuilder ( sqlpattern . length ( ) * num_ ) ; final int len = sqlpattern . length ( ) ; for ( int i = num_ ; i < len ; i ++ ) { char c = sqlpattern . charat ( i ) ; if ( c == escapechar ) { if ( i == ( len - num_ ) ) {	Translates SQL SIMILAR pattern to Java regex pattern.
private static string tohtmltable ( final list < optionwithmetainfo > options ) { stringbuilder htmltable = new stringbuilder ( ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; for ( optionwithmetainfo option : options ) { htmltable . append ( tohtmlstring ( option ) ) ; } htmltable . append ( str_ ) ; htmltable . append ( str_ ) ; return htmltable . tostring ( ) ; }	Transforms this configuration group into HTML formatted table.Options are sorted alphabetically by key.
private static string tohtmlstring ( final optionwithmetainfo optionwithmetainfo ) { configoption < ? > option = optionwithmetainfo . option ; string defaultvalue = stringifydefault ( optionwithmetainfo ) ; return str_ + str_ + str_ + escapecharacters ( option . key ( ) ) + str_ + str_ + escapecharacters ( addwordbreakopportunities ( defaultvalue ) ) + str_ + str_ + formatter . format ( option . description ( ) ) + str_ + str_ ; }	Transforms option to table row.
@ override public void dispose ( ) { if ( this . disposed ) { return ; } super . dispose ( ) ;	Should only be called by one thread, and only after all accesses to the DB happened.
public boolean startswith ( charsequence prefix , int startindex ) { final char [ ] thischars = this . value ; final int plen = this . len ; final int slen = prefix . length ( ) ; if ( ( startindex < num_ ) || ( startindex > plen - slen ) ) { return bool_ ; } int spos = num_ ; while ( spos < slen ) { if ( thischars [ startindex ++ ] != prefix . charat ( spos ++ ) ) { return bool_ ; } } return bool_ ; }	Checks whether the substring, starting at the specified index, starts with the given prefix string.
private void grow ( int size ) { if ( this . value . length < size ) { char [ ] value = new char [ math . max ( this . value . length * num_ / num_ , size ) ] ; system . arraycopy ( this . value , num_ , value , num_ , this . len ) ; this . value = value ; } }	Grow and retain content.
@ deprecated public optional < tablestats > gettablestats ( ) { descriptorproperties normalizedprops = new descriptorproperties ( ) ; normalizedprops . putproperties ( normalizedprops ) ; optional < long > rowcount = normalizedprops . getoptionallong ( statistics_row_count ) ; if ( rowcount . ispresent ( ) ) { map < string , columnstats > columnstats = readcolumnstats ( normalizedprops , statistics_columns ) ; return optional . of ( new tablestats ( rowcount . get ( ) , columnstats ) ) ; } else { return optional . empty ( ) ; } }	Reads table statistics from the descriptors properties.
@ override public int close ( ) throws ioexception { if ( ! writer . isclosed ( ) ) { int currentpositioninsegment = getcurrentpositioninsegment ( ) ;	Closes this OutputView, closing the underlying writer.
public void addbroadcastset ( string name , dataset < ? > data ) { this . bcvars . add ( new tuple2 < > ( name , data ) ) ; }	Adds a data set as a broadcast set to the compute function.
public optimizedplan compile ( plan program ) throws compilerexception { final optimizerpostpass postpasser = getpostpassfromplan ( program ) ; return compile ( program , postpasser ) ; }	Translates the given program to an OptimizedPlan, where all nodes have their local strategy assignedand all channels have a shipping strategy assigned.For more details on the optimization phase, see the comments for{.
public void registerbufferpool ( bufferpool bufferpool ) { checkargument ( bufferpool . getnumberofrequiredmemorysegments ( ) >= getnumberofsubpartitions ( ) , str_ ) ; checkstate ( this . bufferpool == null , str_ ) ; this . bufferpool = checknotnull ( bufferpool ) ; }	Registers a buffer pool with this result partition.
public void finish ( ) throws ioexception { boolean success = bool_ ; try { checkinproducestate ( ) ; for ( resultsubpartition subpartition : subpartitions ) { subpartition . finish ( ) ; } success = bool_ ; } finally { if ( success ) { isfinished = bool_ ; notifypipelinedconsumers ( ) ; } } }	Finishes the result partition.
public void release ( throwable cause ) { if ( isreleased . compareandset ( bool_ , bool_ ) ) { log . debug ( str_ , owningtaskname , this ) ;	Releases the result partition.
public resultsubpartitionview createsubpartitionview ( int index , bufferavailabilitylistener availabilitylistener ) throws ioexception { int refcnt = pendingreferences . get ( ) ; checkstate ( refcnt != - num_ , str_ ) ; checkstate ( refcnt > num_ , str_ ) ; checkelementindex ( index , subpartitions . length , str_ ) ; resultsubpartitionview readview = subpartitions [ index ] . createreadview ( availabilitylistener ) ; log . debug ( str_ , readview ) ; return readview ; }	Returns the requested subpartition.
@ override public void releasememory ( int torelease ) throws ioexception { checkargument ( torelease > num_ ) ; for ( resultsubpartition subpartition : subpartitions ) { torelease -= subpartition . releasememory ( ) ;	Releases buffers held by this result partition.
void pin ( ) { while ( bool_ ) { int refcnt = pendingreferences . get ( ) ; if ( refcnt >= num_ ) { if ( pendingreferences . compareandset ( refcnt , refcnt + subpartitions . length ) ) { break ; } } else { throw new illegalstateexception ( str_ ) ; } } }	Pins the result partition.
void onconsumedsubpartition ( int subpartitionindex ) { if ( isreleased . get ( ) ) { return ; } int refcnt = pendingreferences . decrementandget ( ) ; if ( refcnt == num_ ) { partitionmanager . onconsumedpartition ( this ) ; } else if ( refcnt < num_ ) { throw new illegalstateexception ( str_ ) ; } log . debug ( str_ , this , subpartitionindex , pendingreferences ) ; }	Notification when a subpartition is released.
private void notifypipelinedconsumers ( ) { if ( sendscheduleorupdateconsumersmessage && ! hasnotifiedpipelinedconsumers && partitiontype . ispipelined ( ) ) { partitionconsumablenotifier . notifypartitionconsumable ( jobid , partitionid , taskactions ) ; hasnotifiedpipelinedconsumers = bool_ ; } }	Notifies pipelined consumers of this result partition once.
public rmatgraph < t > setconstants ( float a , float b , float c ) { preconditions . checkargument ( a >= num_ && b >= num_ && c >= num_ && a + b + c <= num_ , str_ ) ; this . a = a ; this . b = b ; this . c = c ; return this ; }	The parameters for recursively subdividing the adjacency matrix.
public rmatgraph < t > setnoise ( boolean noiseenabled , float noise ) { preconditions . checkargument ( noise >= num_ && noise <= num_ , str_ ) ; this . noiseenabled = noiseenabled ; this . noise = noise ; return this ; }	Enable and configure noise.
@ suppresswarnings ( { str_ , str_ } ) public datastream < t > closewith ( datastream < t > feedbackstream ) { collection < streamtransformation < ? > > predecessors = feedbackstream . gettransformation ( ) . gettransitivepredecessors ( ) ; if ( ! predecessors . contains ( this . transformation ) ) { throw new unsupportedoperationexception ( str_ ) ; } ( ( feedbacktransformation ) gettransformation ( ) ) . addfeedbackedge ( feedbackstream . gettransformation ( ) ) ; return feedbackstream ; }	Closes the iteration. This method defines the end of the iterativeprogram part that will be fed back to the start of the iteration. A common usage pattern for streaming iterations is to use outputsplitting to send a part of the closing data stream to the head. Refer to{.
public void open ( ) { isrunning = bool_ ;	Opens the interactive CLI shell.
public static slotprofile nolocality ( resourceprofile resourceprofile ) { return new slotprofile ( resourceprofile , collections . emptylist ( ) , collections . emptylist ( ) ) ; }	Returns a slot profile for the given resource profile, without any locality requirements.
public static slotprofile preferredlocality ( resourceprofile resourceprofile , collection < taskmanagerlocation > preferredlocations ) { return new slotprofile ( resourceprofile , preferredlocations , collections . emptylist ( ) ) ; }	Returns a slot profile for the given resource profile and the preferred locations.
public static slotprofile priorallocation ( resourceprofile resourceprofile , collection < allocationid > priorallocations ) { return new slotprofile ( resourceprofile , collections . emptylist ( ) , priorallocations ) ; }	Returns a slot profile for the given resource profile and the prior allocations.
public final void sendcombinedmessage ( message combinedmessage ) { outvalue . f1 = either . right ( combinedmessage ) ; out . collect ( outvalue ) ; }	Sends the combined message to the target vertex.
@ override public void aggregate ( t value ) { if ( value == null ) { nullcount ++ ; } else if ( isnan ( value ) ) { nancount ++ ; } else if ( isinfinite ( value ) ) { infinitycount ++ ; } else { nonmissingcount ++ ; min . aggregate ( value ) ; max . aggregate ( value ) ; sum . aggregate ( value ) ; double doublevalue = value . doublevalue ( ) ; double delta = doublevalue - mean . value ( ) ; mean = mean . add ( delta / nonmissingcount ) ; m2 = m2 . add ( delta * ( doublevalue - mean . value ( ) ) ) ; } }	Add a value to the current aggregation.
@ override public void combine ( aggregator < t , numericcolumnsummary < t > > othersametype ) { numericsummaryaggregator < t > other = ( numericsummaryaggregator < t > ) othersametype ; nullcount += other . nullcount ; nancount += other . nancount ; infinitycount += other . infinitycount ; if ( nonmissingcount == num_ ) { nonmissingcount = other . nonmissingcount ; min = other . min ; max = other . max ; sum = other . sum ; mean = other . mean ; m2 = other . m2 ; } else if ( other . nonmissingcount != num_ ) { long combinedcount = nonmissingcount + other . nonmissingcount ; min . combine ( other . min ) ; max . combine ( other . max ) ; sum . combine ( other . sum ) ; double deltamean = other . mean . value ( ) - mean . value ( ) ; mean = mean . add ( deltamean * other . nonmissingcount / combinedcount ) ; m2 = m2 . add ( other . m2 ) . add ( deltamean * deltamean * nonmissingcount * other . nonmissingcount / combinedcount ) ; nonmissingcount = combinedcount ; } }	combine two aggregations.
public cassandrasink < in > name ( string name ) { if ( usedatastreamsink ) { getsinktransformation ( ) . setname ( name ) ; } else { getstreamtransformation ( ) . setname ( name ) ; } return this ; }	Sets the name of this sink.
@ publicevolving public cassandrasink < in > uid ( string uid ) { if ( usedatastreamsink ) { getsinktransformation ( ) . setuid ( uid ) ; } else { getstreamtransformation ( ) . setuid ( uid ) ; } return this ; }	Sets an ID for this operator.
public cassandrasink < in > setparallelism ( int parallelism ) { if ( usedatastreamsink ) { getsinktransformation ( ) . setparallelism ( parallelism ) ; } else { getstreamtransformation ( ) . setparallelism ( parallelism ) ; } return this ; }	Sets the parallelism for this sink.
public cassandrasink < in > slotsharinggroup ( string slotsharinggroup ) { if ( usedatastreamsink ) { getsinktransformation ( ) . setslotsharinggroup ( slotsharinggroup ) ; } else { getstreamtransformation ( ) . setslotsharinggroup ( slotsharinggroup ) ; } return this ; }	Sets the slot sharing group of this operation.
public final v put ( k key , v value ) { final int hash = hash ( key ) ; final int slot = indexof ( hash ) ;	Inserts the given value, mapped under the given key.
public v get ( k key ) { final int hash = hash ( key ) ; final int slot = indexof ( hash ) ;	Looks up the value mapped under the given key.
@ override public iterator < entry < k , v > > iterator ( ) { return new iterator < entry < k , v > > ( ) { private final entry < k , v > [ ] tab = keymap . this . table ; private entry < k , v > nextentry ; private int nextpos = num_ ; @ override public boolean hasnext ( ) { if ( nextentry != null ) { return bool_ ; } else { while ( nextpos < tab . length ) { entry < k , v > e = tab [ nextpos ++ ] ; if ( e != null ) { nextentry = e ; return bool_ ; } } return bool_ ; } } @ override public entry < k , v > next ( ) { if ( nextentry != null || hasnext ( ) ) { entry < k , v > e = nextentry ; nextentry = nextentry . next ; return e ; } else { throw new nosuchelementexception ( ) ; } } @ override public void remove ( ) { throw new unsupportedoperationexception ( ) ; } } ; }	Creates an iterator over the entries of this map.
public void initializebuffermetrics ( task task ) { final metricgroup buffers = addgroup ( str_ ) ; buffers . gauge ( str_ , new inputbuffersgauge ( task ) ) ; buffers . gauge ( str_ , new outputbuffersgauge ( task ) ) ; buffers . gauge ( str_ , new inputbufferpoolusagegauge ( task ) ) ; buffers . gauge ( str_ , new outputbufferpoolusagegauge ( task ) ) ; }	Initialize Buffer Metrics for a task.
public keygrouprange getintersection ( keygrouprange other ) { int start = math . max ( startkeygroup , other . startkeygroup ) ; int end = math . min ( endkeygroup , other . endkeygroup ) ; return start <= end ? new keygrouprange ( start , end ) : empty_key_group_range ; }	Create a range that represent the intersection between this range and the given range.
public static keygrouprange of ( int startkeygroup , int endkeygroup ) { return startkeygroup <= endkeygroup ? new keygrouprange ( startkeygroup , endkeygroup ) : empty_key_group_range ; }	Factory method that also handles creation of empty key-groups.
public static void terminaterpcservice ( rpcservice rpcservice , time timeout ) throws interruptedexception , executionexception , timeoutexception { rpcservice . stopservice ( ) . get ( timeout . tomilliseconds ( ) , timeunit . milliseconds ) ; }	Shuts the given rpc service down and waits for its termination.
public static void terminaterpcservices ( time timeout , rpcservice ... rpcservices ) throws interruptedexception , executionexception , timeoutexception { final collection < completablefuture < ? > > terminationfutures = new arraylist < > ( rpcservices . length ) ; for ( rpcservice service : rpcservices ) { if ( service != null ) { terminationfutures . add ( service . stopservice ( ) ) ; } } futureutils . waitforall ( terminationfutures ) . get ( timeout . tomilliseconds ( ) , timeunit . milliseconds ) ; }	Shuts the given rpc services down and waits for their termination.
public void setbroadcastinputs ( list < namedchannel > broadcastinputs ) { if ( broadcastinputs != null ) { this . broadcastinputs = broadcastinputs ;	Sets a list of all broadcast inputs attached to this node.
private void stopresources ( boolean waitforshutdown ) throws interruptedexception { emitter . stop ( ) ; emitterthread . interrupt ( ) ; executor . shutdown ( ) ; if ( waitforshutdown ) { try { if ( ! executor . awaittermination ( num_ , timeunit . days ) ) { executor . shutdownnow ( ) ; } } catch ( interruptedexception e ) { executor . shutdownnow ( ) ; thread . currentthread ( ) . interrupt ( ) ; } if ( thread . holdslock ( checkpointinglock ) ) { while ( emitterthread . isalive ( ) ) { checkpointinglock . wait ( num_ ) ; } } emitterthread . join ( ) ; } else { executor . shutdownnow ( ) ; } }	Close the operator's resources.
private static void assertnotendofinput ( final jsonparser p , @ nullable final jsontoken jsontoken ) { checkstate ( jsontoken != null , str_ , p . getcurrentlocation ( ) ) ; }	Asserts that the provided JsonToken is not null, i.e., not at the end of the input.
@ deprecated public void setfirstinputs ( list < operator < in1 > > inputs ) { this . input1 = operator . createunioncascade ( inputs ) ; }	Sets the first input to the union of the given operators.
@ deprecated public void setsecondinputs ( list < operator < in2 > > inputs ) { this . input2 = operator . createunioncascade ( inputs ) ; }	Sets the second input to the union of the given operators.
private static void updatejoboverview ( file weboverviewdir , file webdir ) { try ( jsongenerator gen = jacksonfactory . creategenerator ( historyserver . createorgetfile ( webdir , jobsoverviewheaders . url ) ) ) { file [ ] overviews = new file ( weboverviewdir . getpath ( ) ) . listfiles ( ) ; if ( overviews != null ) { collection < jobdetails > alljobs = new arraylist < > ( overviews . length ) ; for ( file overview : overviews ) { multiplejobsdetails subjobs = mapper . readvalue ( overview , multiplejobsdetails . class ) ; alljobs . addall ( subjobs . getjobs ( ) ) ; } mapper . writevalue ( gen , new multiplejobsdetails ( alljobs ) ) ; } } catch ( ioexception ioe ) { log . error ( str_ , ioe ) ; } }	This method replicates the JSON response that would be given by the JobsOverviewHandler whenlisting both running and finished jobs.
public optional < tuple2 < string , uuid > > getleadernow ( ) throws exception { completablefuture < tuple2 < string , uuid > > leaderfuture = this . atomicleaderfuture . get ( ) ; if ( leaderfuture != null ) { if ( leaderfuture . isdone ( ) ) { return optional . of ( leaderfuture . get ( ) ) ; } else { return optional . empty ( ) ; } } else { return optional . empty ( ) ; } }	Returns the current leader information if available.
public static < e extends enum < e > > typeinformation < e > enum ( class < e > enumtype ) { return new enumtypeinfo < > ( enumtype ) ; }	Returns type information for Java enumerations.
public joinoperatorsetspredicatebase where ( string ... fields ) { return new joinoperatorsetspredicatebase ( new keys . expressionkeys < > ( fields , input1 . gettype ( ) ) ) ; }	Continues a Join transformation. Defines the fields of the first join {.
public instanceid registertaskmanager ( taskmanagergateway taskmanagergateway , taskmanagerlocation taskmanagerlocation , hardwaredescription resources , int numberofslots ) { synchronized ( this . lock ) { if ( this . isshutdown ) { throw new illegalstateexception ( str_ ) ; } instance prior = registeredhostsbyresource . get ( taskmanagerlocation . getresourceid ( ) ) ; if ( prior != null ) { throw new illegalstateexception ( str_ + taskmanagerlocation . addressstring ( ) + str_ + prior . getid ( ) ) ; } boolean wasdead = this . deadhosts . remove ( taskmanagerlocation . getresourceid ( ) ) ; if ( wasdead ) { log . info ( str_ + taskmanagerlocation . addressstring ( ) + str_ ) ; } instanceid instanceid = new instanceid ( ) ; instance host = new instance ( taskmanagergateway , taskmanagerlocation , instanceid , resources , numberofslots ) ; registeredhostsbyid . put ( instanceid , host ) ; registeredhostsbyresource . put ( taskmanagerlocation . getresourceid ( ) , host ) ; totalnumberofalivetaskslots += numberofslots ; if ( log . isinfoenabled ( ) ) { log . info ( string . format ( str_ + str_ + str_ , taskmanagerlocation . gethostname ( ) , taskmanagergateway . getaddress ( ) , instanceid , registeredhostsbyid . size ( ) , totalnumberofalivetaskslots ) ) ; } host . reportheartbeat ( ) ;	Registers a task manager.
public void unregisteralltaskmanagers ( ) { for ( instance instance : registeredhostsbyid . values ( ) ) { deadhosts . add ( instance . gettaskmanagerid ( ) ) ; instance . markdead ( ) ; totalnumberofalivetaskslots -= instance . gettotalnumberofslots ( ) ; notifydeadinstance ( instance ) ; } registeredhostsbyid . clear ( ) ; registeredhostsbyresource . clear ( ) ; }	Unregisters all currently registered TaskManagers from the InstanceManager.
public static row of ( object ... values ) { row row = new row ( values . length ) ; for ( int i = num_ ; i < values . length ; i ++ ) { row . setfield ( i , values [ i ] ) ; } return row ; }	Creates a new Row and assigns the given values to the Row's fields.This is more convenient than using the constructor.
public static row copy ( row row ) { final row newrow = new row ( row . fields . length ) ; system . arraycopy ( row . fields , num_ , newrow . fields , num_ , row . fields . length ) ; return newrow ; }	Creates a new Row which copied from another row.This method does not perform a deep copy.
public static row project ( row row , int [ ] fields ) { final row newrow = new row ( fields . length ) ; for ( int i = num_ ; i < fields . length ; i ++ ) { newrow . fields [ i ] = row . fields [ fields [ i ] ] ; } return newrow ; }	Creates a new Row with projected fields from another row.This method does not perform a deep copy.
public static void copytounsafe ( memorysegment [ ] segments , int offset , object target , int pointer , int numbytes ) { if ( infirstsegment ( segments , offset , numbytes ) ) { segments [ num_ ] . copytounsafe ( offset , target , pointer , numbytes ) ; } else { copymultisegmentstounsafe ( segments , offset , target , pointer , numbytes ) ; } }	Copy segments to target unsafe pointer.
public static byte [ ] getbytes ( memorysegment [ ] segments , int baseoffset , int sizeinbytes ) {	Maybe not copied, if want copy, please use copyTo.
public static int hashbywords ( memorysegment [ ] segments , int offset , int numbytes ) { if ( infirstsegment ( segments , offset , numbytes ) ) { return murmurhashutil . hashbytesbywords ( segments [ num_ ] , offset , numbytes ) ; } else { return hashmultisegbywords ( segments , offset , numbytes ) ; } }	hash segments to int, numBytes must be aligned to 4 bytes.
public static int hash ( memorysegment [ ] segments , int offset , int numbytes ) { if ( infirstsegment ( segments , offset , numbytes ) ) { return murmurhashutil . hashbytes ( segments [ num_ ] , offset , numbytes ) ; } else { return hashmultiseg ( segments , offset , numbytes ) ; } }	hash segments to int.
public static void bitunset ( memorysegment segment , int baseoffset , int index ) { int offset = baseoffset + ( ( index & bit_byte_position_mask ) > > > num_ ) ; byte current = segment . get ( offset ) ; current &= ~ ( num_ << ( index & bit_byte_index_mask ) ) ; segment . put ( offset , current ) ; }	unset bit.
public static boolean bitget ( memorysegment segment , int baseoffset , int index ) { int offset = baseoffset + ( ( index & bit_byte_position_mask ) > > > num_ ) ; byte current = segment . get ( offset ) ; return ( current & ( num_ << ( index & bit_byte_index_mask ) ) ) != num_ ; }	read bit.
public static void bitunset ( memorysegment [ ] segments , int baseoffset , int index ) { if ( segments . length == num_ ) { memorysegment segment = segments [ num_ ] ; int offset = baseoffset + ( ( index & bit_byte_position_mask ) > > > num_ ) ; byte current = segment . get ( offset ) ; current &= ~ ( num_ << ( index & bit_byte_index_mask ) ) ; segment . put ( offset , current ) ; } else { bitunsetmultisegments ( segments , baseoffset , index ) ; } }	unset bit from segments.
public static void bitset ( memorysegment [ ] segments , int baseoffset , int index ) { if ( segments . length == num_ ) { int offset = baseoffset + ( ( index & bit_byte_position_mask ) > > > num_ ) ; memorysegment segment = segments [ num_ ] ; byte current = segment . get ( offset ) ; current |= ( num_ << ( index & bit_byte_index_mask ) ) ; segment . put ( offset , current ) ; } else { bitsetmultisegments ( segments , baseoffset , index ) ; } }	set bit from segments.
public static boolean bitget ( memorysegment [ ] segments , int baseoffset , int index ) { int offset = baseoffset + ( ( index & bit_byte_position_mask ) > > > num_ ) ; byte current = getbyte ( segments , offset ) ; return ( current & ( num_ << ( index & bit_byte_index_mask ) ) ) != num_ ; }	read bit from segments.
public static boolean getboolean ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getboolean ( offset ) ; } else { return getbooleanmultisegments ( segments , offset ) ; } }	get boolean from segments.
public static void setboolean ( memorysegment [ ] segments , int offset , boolean value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putboolean ( offset , value ) ; } else { setbooleanmultisegments ( segments , offset , value ) ; } }	set boolean from segments.
public static byte getbyte ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . get ( offset ) ; } else { return getbytemultisegments ( segments , offset ) ; } }	get byte from segments.
public static void setbyte ( memorysegment [ ] segments , int offset , byte value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . put ( offset , value ) ; } else { setbytemultisegments ( segments , offset , value ) ; } }	set byte from segments.
public static int getint ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getint ( offset ) ; } else { return getintmultisegments ( segments , offset ) ; } }	get int from segments.
public static void setint ( memorysegment [ ] segments , int offset , int value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putint ( offset , value ) ; } else { setintmultisegments ( segments , offset , value ) ; } }	set int from segments.
public static long getlong ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getlong ( offset ) ; } else { return getlongmultisegments ( segments , offset ) ; } }	get long from segments.
public static void setlong ( memorysegment [ ] segments , int offset , long value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putlong ( offset , value ) ; } else { setlongmultisegments ( segments , offset , value ) ; } }	set long from segments.
public static short getshort ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getshort ( offset ) ; } else { return getshortmultisegments ( segments , offset ) ; } }	get short from segments.
public static void setshort ( memorysegment [ ] segments , int offset , short value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putshort ( offset , value ) ; } else { setshortmultisegments ( segments , offset , value ) ; } }	set short from segments.
public static float getfloat ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getfloat ( offset ) ; } else { return getfloatmultisegments ( segments , offset ) ; } }	get float from segments.
public static void setfloat ( memorysegment [ ] segments , int offset , float value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putfloat ( offset , value ) ; } else { setfloatmultisegments ( segments , offset , value ) ; } }	set float from segments.
public static double getdouble ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getdouble ( offset ) ; } else { return getdoublemultisegments ( segments , offset ) ; } }	get double from segments.
public static void setdouble ( memorysegment [ ] segments , int offset , double value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putdouble ( offset , value ) ; } else { setdoublemultisegments ( segments , offset , value ) ; } }	set double from segments.
public static char getchar ( memorysegment [ ] segments , int offset ) { if ( infirstsegment ( segments , offset , num_ ) ) { return segments [ num_ ] . getchar ( offset ) ; } else { return getcharmultisegments ( segments , offset ) ; } }	get char from segments.
public static void setchar ( memorysegment [ ] segments , int offset , char value ) { if ( infirstsegment ( segments , offset , num_ ) ) { segments [ num_ ] . putchar ( offset , value ) ; } else { setcharmultisegments ( segments , offset , value ) ; } }	set char from segments.
public static int find ( memorysegment [ ] segments1 , int offset1 , int numbytes1 , memorysegment [ ] segments2 , int offset2 , int numbytes2 ) { if ( numbytes2 == num_ ) {	Find equal segments2 in segments1.
public boolean exists ( final path f ) throws ioexception { try { return ( getfilestatus ( f ) != null ) ; } catch ( filenotfoundexception e ) { return bool_ ; } }	Check if exists.
private static filesystemfactory loadhadoopfsfactory ( ) { final classloader cl = filesystem . class . getclassloader ( ) ;	Utility loader for the Hadoop file system factory.We treat the Hadoop FS factory in a special way, because we use it as a catchall for file systems schemes not supported directly in Flink.
@ suppresswarnings ( str_ ) public void startregistration ( ) { if ( canceled ) {	This method resolves the target address to a callable gateway and starts theregistration after that.
@ suppresswarnings ( str_ ) private void register ( final g gateway , final int attempt , final long timeoutmillis ) {	This method performs a registration attempt and triggers either a success notification or a retry,depending on the result.
@ override public void exceptioncaught ( channelhandlercontext ctx , throwable cause ) throws exception { if ( cause instanceof transportexception ) { notifyallchannelsoferrorandclose ( cause ) ; } else { final socketaddress remoteaddr = ctx . channel ( ) . remoteaddress ( ) ; final transportexception tex ;	Called on exceptions in the client handler pipeline.
public static type extracttypefromlambda ( class < ? > baseclass , lambdaexecutable exec , int [ ] lambdatypeargumentindices , int paramlen , int baseparameterslen ) { type output = exec . getparametertypes ( ) [ paramlen - baseparameterslen + lambdatypeargumentindices [ num_ ] ] ; for ( int i = num_ ; i < lambdatypeargumentindices . length ; i ++ ) { validatelambdatype ( baseclass , output ) ; output = extracttypeargument ( output , lambdatypeargumentindices [ i ] ) ; } validatelambdatype ( baseclass , output ) ; return output ; }	Extracts type from given index from lambda.
public static type extracttypeargument ( type t , int index ) throws invalidtypesexception { if ( t instanceof parameterizedtype ) { type [ ] actualtypearguments = ( ( parameterizedtype ) t ) . getactualtypearguments ( ) ; if ( index < num_ || index >= actualtypearguments . length ) { throw new invalidtypesexception ( str_ + index + str_ + actualtypearguments . length + str_ ) ; } else { return actualtypearguments [ index ] ; } } else { throw new invalidtypesexception ( str_ + t + str_ ) ; } }	This method extracts the n-th type argument from the given type.
public static list < method > getalldeclaredmethods ( class < ? > clazz ) { list < method > result = new arraylist < > ( ) ; while ( clazz != null ) { method [ ] methods = clazz . getdeclaredmethods ( ) ; collections . addall ( result , methods ) ; clazz = clazz . getsuperclass ( ) ; } return result ; }	Returns all declared methods of a class including methods of superclasses.
public static class < ? > typetoclass ( type t ) { if ( t instanceof class ) { return ( class < ? > ) t ; } else if ( t instanceof parameterizedtype ) { return ( ( class < ? > ) ( ( parameterizedtype ) t ) . getrawtype ( ) ) ; } throw new illegalargumentexception ( str_ ) ; }	Convert ParameterizedType or Class to a Class.
public static boolean sametypevars ( type t1 , type t2 ) { return t1 instanceof typevariable && t2 instanceof typevariable && ( ( typevariable < ? > ) t1 ) . getname ( ) . equals ( ( ( typevariable < ? > ) t2 ) . getname ( ) ) && ( ( typevariable < ? > ) t1 ) . getgenericdeclaration ( ) . equals ( ( ( typevariable < ? > ) t2 ) . getgenericdeclaration ( ) ) ; }	Checks whether two types are type variables describing the same.
public static type gettypehierarchy ( list < type > typehierarchy , type t , class < ? > stopatclass ) { while ( ! ( isclasstype ( t ) && typetoclass ( t ) . equals ( stopatclass ) ) ) { typehierarchy . add ( t ) ; t = typetoclass ( t ) . getgenericsuperclass ( ) ; if ( t == null ) { break ; } } return t ; }	Traverses the type hierarchy of a type up until a certain stop class is found.
public static boolean hassuperclass ( class < ? > clazz , string superclassname ) { list < type > hierarchy = new arraylist < > ( ) ; gettypehierarchy ( hierarchy , clazz , object . class ) ; for ( type t : hierarchy ) { if ( isclasstype ( t ) && typetoclass ( t ) . getname ( ) . equals ( superclassname ) ) { return bool_ ; } } return bool_ ; }	Returns true if the given class has a superclass of given name.
public static class < ? > getrawclass ( type t ) { if ( isclasstype ( t ) ) { return typetoclass ( t ) ; } else if ( t instanceof genericarraytype ) { type component = ( ( genericarraytype ) t ) . getgenericcomponenttype ( ) ; return array . newinstance ( getrawclass ( component ) , num_ ) . getclass ( ) ; } return object . class ; }	Returns the raw class of both parameterized types and generic arrays.Returns java.lang.Object for all other types.
public static void validatelambdatype ( class < ? > baseclass , type t ) { if ( ! ( t instanceof class ) ) { return ; } final class < ? > clazz = ( class < ? > ) t ; if ( clazz . gettypeparameters ( ) . length > num_ ) { throw new invalidtypesexception ( str_ + clazz . getsimplename ( ) + str_ + str_ + str_ + baseclass . getname ( ) + str_ + str_ ) ; } }	Checks whether the given type has the generic parameters declared in the class definition.
public void clear ( ) { streamnodes = new hashmap < > ( ) ; virtualselectnodes = new hashmap < > ( ) ; virtualsideoutputnodes = new hashmap < > ( ) ; virtualpartitionnodes = new hashmap < > ( ) ; vertexidtobrokerid = new hashmap < > ( ) ; vertexidtolooptimeout = new hashmap < > ( ) ; iterationsourcesinkpairs = new hashset < > ( ) ; sources = new hashset < > ( ) ; sinks = new hashset < > ( ) ; }	Remove all registered nodes etc.
public void addvirtualselectnode ( integer originalid , integer virtualid , list < string > selectednames ) { if ( virtualselectnodes . containskey ( virtualid ) ) { throw new illegalstateexception ( str_ + virtualid ) ; } virtualselectnodes . put ( virtualid , new tuple2 < integer , list < string > > ( originalid , selectednames ) ) ; }	Adds a new virtual node that is used to connect a downstream vertex to only the outputswith the selected names.
public void addvirtualpartitionnode ( integer originalid , integer virtualid , streampartitioner < ? > partitioner ) { if ( virtualpartitionnodes . containskey ( virtualid ) ) { throw new illegalstateexception ( str_ + virtualid ) ; } virtualpartitionnodes . put ( virtualid , new tuple2 < integer , streampartitioner < ? > > ( originalid , partitioner ) ) ; }	Adds a new virtual node that is used to connect a downstream vertex to an input with acertain partitioning.
public string getslotsharinggroup ( integer id ) { if ( virtualsideoutputnodes . containskey ( id ) ) { integer mappedid = virtualsideoutputnodes . get ( id ) . f0 ; return getslotsharinggroup ( mappedid ) ; } else if ( virtualselectnodes . containskey ( id ) ) { integer mappedid = virtualselectnodes . get ( id ) . f0 ; return getslotsharinggroup ( mappedid ) ; } else if ( virtualpartitionnodes . containskey ( id ) ) { integer mappedid = virtualpartitionnodes . get ( id ) . f0 ; return getslotsharinggroup ( mappedid ) ; } else { streamnode node = getstreamnode ( id ) ; return node . getslotsharinggroup ( ) ; } }	Determines the slot sharing group of an operation across virtual nodes.
public boolean ischeckpointingenabled ( ) { if ( snapshotsettings == null ) { return bool_ ; } long checkpointinterval = snapshotsettings . getcheckpointcoordinatorconfiguration ( ) . getcheckpointinterval ( ) ; return checkpointinterval > num_ && checkpointinterval < long . max_value ; }	Checks if the checkpointing was enabled for this job graph.
public int getmaximumparallelism ( ) { int maxparallelism = - num_ ; for ( jobvertex vertex : taskvertices . values ( ) ) { maxparallelism = math . max ( vertex . getparallelism ( ) , maxparallelism ) ; } return maxparallelism ; }	Gets the maximum parallelism of all operations in this job graph.
public void addjar ( path jar ) { if ( jar == null ) { throw new illegalargumentexception ( ) ; } if ( ! userjars . contains ( jar ) ) { userjars . add ( jar ) ; } }	Adds the path of a JAR file required to run the job on a task manager.
public void adduserartifact ( string name , distributedcache . distributedcacheentry file ) { if ( file == null ) { throw new illegalargumentexception ( ) ; } userartifacts . putifabsent ( name , file ) ; }	Adds the path of a custom file required to run the job on a task manager.
public void adduserjarblobkey ( permanentblobkey key ) { if ( key == null ) { throw new illegalargumentexception ( ) ; } if ( ! userjarblobkeys . contains ( key ) ) { userjarblobkeys . add ( key ) ; } }	Adds the BLOB referenced by the key to the JobGraph's dependencies.
public static < c > programtargetdescriptor of ( c clusterid , jobid jobid , string webinterfaceurl ) { string clusteridstring ; try {	Creates a program target description from deployment classes.
public keygrouprangeoffsets getintersection ( keygrouprange keygrouprange ) { preconditions . checknotnull ( keygrouprange ) ; keygrouprange intersection = this . keygrouprange . getintersection ( keygrouprange ) ; long [ ] suboffsets = new long [ intersection . getnumberofkeygroups ( ) ] ; if ( suboffsets . length > num_ ) { system . arraycopy ( offsets , computekeygroupindex ( intersection . getstartkeygroup ( ) ) , suboffsets , num_ , suboffsets . length ) ; } return new keygrouprangeoffsets ( intersection , suboffsets ) ; }	Returns a key-group range with offsets which is the intersection of the internal key-group range with the givenkey-group range.
public static decimal frombigdecimal ( bigdecimal bd , int precision , int scale ) { bd = bd . setscale ( scale , roundingmode . half_up ) ; if ( bd . precision ( ) > precision ) { return null ; } long longval = - num_ ; if ( precision <= max_compact_precision ) { longval = bd . movepointright ( scale ) . longvalueexact ( ) ; } return new decimal ( precision , scale , longval , bd ) ; }	then `precision` is checked. if precision overflow, it will return `null`.
public decimal floor ( ) { bigdecimal bd = tobigdecimal ( ) . setscale ( num_ , roundingmode . floor ) ; return frombigdecimal ( bd , bd . precision ( ) , num_ ) ; }	note that result may exceed the original precision.
public static long casttointegral ( decimal dec ) { bigdecimal bd = dec . tobigdecimal ( ) ;	to cast to floats, overflow will not happen, because precision<=38.
@ publicevolving public < acc , r > singleoutputstreamoperator < r > aggregate ( aggregatefunction < t , acc , r > function , typeinformation < acc > accumulatortype , typeinformation < r > resulttype ) { checknotnull ( function , str_ ) ; checknotnull ( accumulatortype , str_ ) ; checknotnull ( resulttype , str_ ) ; if ( function instanceof richfunction ) { throw new unsupportedoperationexception ( str_ ) ; } return aggregate ( function , new passthroughwindowfunction < k , w , r > ( ) , accumulatortype , resulttype ) ; }	Applies the given aggregation function to each window.
public void handin ( string key , v obj ) { if ( ! retrievesharedqueue ( key ) . offer ( obj ) ) { throw new runtimeexception ( str_ ) ; } }	Hand in the object to share.
private finalapplicationstatus getyarnstatus ( applicationstatus status ) { if ( status == null ) { return finalapplicationstatus . undefined ; } else { switch ( status ) { case succeeded : return finalapplicationstatus . succeeded ; case failed : return finalapplicationstatus . failed ; case canceled : return finalapplicationstatus . killed ; default : return finalapplicationstatus . undefined ; } } }	Converts a Flink application status enum to a YARN application status enum.
protected void writeleaderinformation ( uuid leadersessionid ) {	Writes the current leader's address as well the given leader session ID to ZooKeeper.
public static mesosconfiguration createmesosschedulerconfiguration ( configuration flinkconfig , string hostname ) { protos . frameworkinfo . builder frameworkinfo = protos . frameworkinfo . newbuilder ( ) . sethostname ( hostname ) ; protos . credential . builder credential = null ; if ( ! flinkconfig . contains ( mesosoptions . master_url ) ) { throw new illegalconfigurationexception ( mesosoptions . master_url . key ( ) + str_ ) ; } string masterurl = flinkconfig . getstring ( mesosoptions . master_url ) ; duration failovertimeout = finiteduration . apply ( flinkconfig . getinteger ( mesosoptions . failover_timeout_seconds ) , timeunit . seconds ) ; frameworkinfo . setfailovertimeout ( failovertimeout . toseconds ( ) ) ; frameworkinfo . setname ( flinkconfig . getstring ( mesosoptions . resourcemanager_framework_name ) ) ; frameworkinfo . setrole ( flinkconfig . getstring ( mesosoptions . resourcemanager_framework_role ) ) ; frameworkinfo . setuser ( flinkconfig . getstring ( mesosoptions . resourcemanager_framework_user ) ) ; if ( flinkconfig . contains ( mesosoptions . resourcemanager_framework_principal ) ) { frameworkinfo . setprincipal ( flinkconfig . getstring ( mesosoptions . resourcemanager_framework_principal ) ) ; credential = protos . credential . newbuilder ( ) ; credential . setprincipal ( frameworkinfo . getprincipal ( ) ) ;	Loads and validates the Mesos scheduler configuration.
public static void applyoverlays ( configuration configuration , containerspecification containerspec ) throws ioexception {	Generate a container specification as a TaskManager template.
public static configuration loadconfiguration ( configuration dynamicproperties , logger log ) { configuration configuration = globalconfiguration . loadconfigurationwithdynamicproperties ( dynamicproperties ) ;	Loads the global configuration, adds the given dynamic properties configuration, and setsthe temp directory paths.
public static configuration loadconfiguration ( final string configdir , @ nullable final configuration dynamicproperties ) { if ( configdir == null ) { throw new illegalargumentexception ( str_ ) ; } final file confdirfile = new file ( configdir ) ; if ( ! ( confdirfile . exists ( ) ) ) { throw new illegalconfigurationexception ( str_ + configdir + str_ + confdirfile . getabsolutepath ( ) + str_ ) ; }	Loads the configuration files from the specified directory.
public static configuration loadconfigurationwithdynamicproperties ( configuration dynamicproperties ) { final string configdir = system . getenv ( configconstants . env_flink_conf_dir ) ; if ( configdir == null ) { return new configuration ( dynamicproperties ) ; } return loadconfiguration ( configdir , dynamicproperties ) ; }	Loads the global configuration and adds the given dynamic propertiesconfiguration.
public static boolean issensitive ( string key ) { preconditions . checknotnull ( key , str_ ) ; final string keyinlower = key . tolowercase ( ) ; for ( string hidekey : sensitive_keys ) { if ( keyinlower . length ( ) >= hidekey . length ( ) && keyinlower . contains ( hidekey ) ) { return bool_ ; } } return bool_ ; }	Check whether the key is a hidden key.
public boolean close ( ) { lock . lock ( ) ; try { if ( open ) { if ( elements . isempty ( ) ) { open = bool_ ; nonempty . signalall ( ) ; return bool_ ; } else { return bool_ ; } } else {	Tries to close the queue.
public boolean addifopen ( e element ) { requirenonnull ( element ) ; lock . lock ( ) ; try { if ( open ) { elements . addlast ( element ) ; if ( elements . size ( ) == num_ ) { nonempty . signalall ( ) ; } } return open ; } finally { lock . unlock ( ) ; } }	Tries to add an element to the queue, if the queue is still open.
public void add ( e element ) throws illegalstateexception { requirenonnull ( element ) ; lock . lock ( ) ; try { if ( open ) { elements . addlast ( element ) ; if ( elements . size ( ) == num_ ) { nonempty . signalall ( ) ; } } else { throw new illegalstateexception ( str_ ) ; } } finally { lock . unlock ( ) ; } }	Adds the element to the queue, or fails with an exception, if the queue is closed.Checking whether the queue is open and adding the element is one atomic operation.
public e peek ( ) { lock . lock ( ) ; try { if ( open ) { if ( elements . size ( ) > num_ ) { return elements . getfirst ( ) ; } else { return null ; } } else { throw new illegalstateexception ( str_ ) ; } } finally { lock . unlock ( ) ; } }	Returns the queue's next element without removing it, if the queue is non-empty.Otherwise, returns null.
public e poll ( ) { lock . lock ( ) ; try { if ( open ) { if ( elements . size ( ) > num_ ) { return elements . removefirst ( ) ; } else { return null ; } } else { throw new illegalstateexception ( str_ ) ; } } finally { lock . unlock ( ) ; } }	Returns the queue's next element and removes it, the queue is non-empty.Otherwise, this method returns null.
public list < e > pollbatch ( ) { lock . lock ( ) ; try { if ( open ) { if ( elements . size ( ) > num_ ) { arraylist < e > result = new arraylist < > ( elements ) ; elements . clear ( ) ; return result ; } else { return null ; } } else { throw new illegalstateexception ( str_ ) ; } } finally { lock . unlock ( ) ; } }	Returns all of the queue's current elements in a list, if the queue is non-empty.Otherwise, this method returns null.
public e getelementblocking ( ) throws interruptedexception { lock . lock ( ) ; try { while ( open && elements . isempty ( ) ) { nonempty . await ( ) ; } if ( open ) { return elements . removefirst ( ) ; } else { throw new illegalstateexception ( str_ ) ; } } finally { lock . unlock ( ) ; } }	Returns the next element in the queue.
private < t > void addentry ( streamelementqueueentry < t > streamelementqueueentry ) { assert ( lock . isheldbycurrentthread ( ) ) ; if ( streamelementqueueentry . iswatermark ( ) ) { lastset = new hashset < > ( capacity ) ; if ( firstset . isempty ( ) ) { firstset . add ( streamelementqueueentry ) ; } else { set < streamelementqueueentry < ? > > watermarkset = new hashset < > ( num_ ) ; watermarkset . add ( streamelementqueueentry ) ; uncompletedqueue . offer ( watermarkset ) ; } uncompletedqueue . offer ( lastset ) ; } else { lastset . add ( streamelementqueueentry ) ; } streamelementqueueentry . oncomplete ( ( streamelementqueueentry < t > value ) -> { try { oncompletehandler ( value ) ; } catch ( interruptedexception e ) {	Add the given stream element queue entry to the current last set if it is not a watermark.If it is a watermark, then stop adding to the current last set, insert the watermark into itsown set and add a new last set.
private streamgraph generateinternal ( list < streamtransformation < ? > > transformations ) { for ( streamtransformation < ? > transformation : transformations ) { transform ( transformation ) ; } return streamgraph ; }	This starts the actual transformation, beginning from the sinks.
private string determineslotsharinggroup ( string specifiedgroup , collection < integer > inputids ) { if ( specifiedgroup != null ) { return specifiedgroup ; } else { string inputgroup = null ; for ( int id : inputids ) { string inputgroupcandidate = streamgraph . getslotsharinggroup ( id ) ; if ( inputgroup == null ) { inputgroup = inputgroupcandidate ; } else if ( ! inputgroup . equals ( inputgroupcandidate ) ) { return str_ ; } } return inputgroup == null ? str_ : inputgroup ; } }	Determines the slot sharing group for an operation based on the slot sharing group set bythe user and the slot sharing groups of the inputs.
public static void installasshutdownhook ( logger logger , long delaymillis ) { checkargument ( delaymillis >= num_ , str_ ) ;	Installs the safeguard shutdown hook.
public void start ( jobleaderidactions initialjobleaderidactions ) throws exception { if ( isstarted ( ) ) { clear ( ) ; } this . jobleaderidactions = preconditions . checknotnull ( initialjobleaderidactions ) ; }	Start the service with the given job leader actions.
public void clear ( ) throws exception { exception exception = null ; for ( jobleaderidlistener listener : jobleaderidlisteners . values ( ) ) { try { listener . stop ( ) ; } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } } if ( exception != null ) { exceptionutils . rethrowexception ( exception , str_ + jobleaderidservice . class . getsimplename ( ) + str_ ) ; } jobleaderidlisteners . clear ( ) ; }	Stop and clear the currently registered job leader id listeners.
public void addjob ( jobid jobid ) throws exception { preconditions . checknotnull ( jobleaderidactions ) ; log . debug ( str_ , jobid ) ; if ( ! jobleaderidlisteners . containskey ( jobid ) ) { leaderretrievalservice leaderretrievalservice = highavailabilityservices . getjobmanagerleaderretriever ( jobid ) ; jobleaderidlistener jobidlistener = new jobleaderidlistener ( jobid , jobleaderidactions , leaderretrievalservice ) ; jobleaderidlisteners . put ( jobid , jobidlistener ) ; } }	Add a job to be monitored to retrieve the job leader id.
public void removejob ( jobid jobid ) throws exception { log . debug ( str_ , jobid ) ; jobleaderidlistener listener = jobleaderidlisteners . remove ( jobid ) ; if ( listener != null ) { listener . stop ( ) ; } }	Remove the given job from being monitored by the service.
public static configuration generatetaskmanagerconfiguration ( configuration baseconfig , string jobmanagerhostname , int jobmanagerport , int numslots , finiteduration registrationtimeout ) { configuration cfg = cloneconfiguration ( baseconfig ) ; if ( jobmanagerhostname != null && ! jobmanagerhostname . isempty ( ) ) { cfg . setstring ( jobmanageroptions . address , jobmanagerhostname ) ; } if ( jobmanagerport > num_ ) { cfg . setinteger ( jobmanageroptions . port , jobmanagerport ) ; } cfg . setstring ( taskmanageroptions . registration_timeout , registrationtimeout . tostring ( ) ) ; if ( numslots != - num_ ) { cfg . setinteger ( taskmanageroptions . num_task_slots , numslots ) ; } return cfg ; }	Generate a task manager configuration.
public static void writeconfiguration ( configuration cfg , file file ) throws ioexception { try ( filewriter fwrt = new filewriter ( file ) ; printwriter out = new printwriter ( fwrt ) ) { for ( string key : cfg . keyset ( ) ) { string value = cfg . getstring ( key , null ) ; out . print ( key ) ; out . print ( str_ ) ; out . println ( value ) ; } } }	Writes a Flink YAML config file from a Flink Configuration object.
public static void substitutedeprecatedconfigkey ( configuration config , string deprecated , string designated ) {	Sets the value of a new config key to the value of a deprecated config key.
public static void substitutedeprecatedconfigprefix ( configuration config , string deprecatedprefix , string designatedprefix ) {	Sets the value of a new config key to the value of a deprecated config key.
public static string gettaskmanagershellcommand ( configuration flinkconfig , containeredtaskmanagerparameters tmparams , string configdirectory , string logdirectory , boolean haslogback , boolean haslog4j , boolean haskrb5 , class < ? > mainclass ) { final map < string , string > startcommandvalues = new hashmap < > ( ) ; startcommandvalues . put ( str_ , str_ ) ; arraylist < string > params = new arraylist < > ( ) ; params . add ( string . format ( str_ , tmparams . taskmanagerheapsizemb ( ) ) ) ; params . add ( string . format ( str_ , tmparams . taskmanagerheapsizemb ( ) ) ) ; if ( tmparams . taskmanagerdirectmemorylimitmb ( ) >= num_ ) { params . add ( string . format ( str_ , tmparams . taskmanagerdirectmemorylimitmb ( ) ) ) ; } startcommandvalues . put ( str_ , stringutils . join ( params , str_ ) ) ; string javaopts = flinkconfig . getstring ( coreoptions . flink_jvm_options ) ; if ( flinkconfig . getstring ( coreoptions . flink_tm_jvm_options ) . length ( ) > num_ ) { javaopts += str_ + flinkconfig . getstring ( coreoptions . flink_tm_jvm_options ) ; }	Generates the shell command to start a task manager.
public static configuration cloneconfiguration ( configuration configuration ) { final configuration clonedconfiguration = new configuration ( configuration ) ; if ( clonedconfiguration . getboolean ( use_local_default_tmp_dirs ) ) { clonedconfiguration . removeconfig ( coreoptions . tmp_dirs ) ; clonedconfiguration . removeconfig ( use_local_default_tmp_dirs ) ; } return clonedconfiguration ; }	Clones the given configuration and resets instance specific config options.
public boolean readbufferfromfilechannel ( buffer buffer ) throws ioexception { checkargument ( filechannel . size ( ) - filechannel . position ( ) > num_ ) ;	Reads data from the object's file channel into the given buffer.
@ override public void collect ( final key key , final value val ) throws ioexception { this . outtuple . f0 = key ; this . outtuple . f1 = val ; this . flinkcollector . collect ( outtuple ) ; }	Use the wrapped Flink collector to collect a key-value pair for Flink.
public boolean ismatchingtopic ( string topic ) { if ( isfixedtopics ( ) ) { return getfixedtopics ( ) . contains ( topic ) ; } else { return topicpattern . matcher ( topic ) . matches ( ) ; } }	Check if the input topic matches the topics described by this KafkaTopicDescriptor.
public static offsetcommitmode fromconfiguration ( boolean enableautocommit , boolean enablecommitoncheckpoint , boolean enablecheckpointing ) { if ( enablecheckpointing ) {	Determine the offset commit mode using several configuration values.
void assignexclusivesegments ( list < memorysegment > segments ) { checkstate ( this . initialcredit == num_ , str_ + str_ ) ; checknotnull ( segments ) ; checkargument ( segments . size ( ) > num_ , str_ ) ; this . initialcredit = segments . size ( ) ; this . numrequiredbuffers = segments . size ( ) ; synchronized ( bufferqueue ) { for ( memorysegment segment : segments ) { bufferqueue . addexclusivebuffer ( new networkbuffer ( segment , this ) , numrequiredbuffers ) ; } } }	Assigns exclusive buffers to this input channel, and this method should be called only onceafter this input channel is created.
@ visiblefortesting @ override public void requestsubpartition ( int subpartitionindex ) throws ioexception , interruptedexception { if ( partitionrequestclient == null ) {	Requests a remote subpartition.
void retriggersubpartitionrequest ( int subpartitionindex ) throws ioexception , interruptedexception { checkstate ( partitionrequestclient != null , str_ ) ; if ( increasebackoff ( ) ) { partitionrequestclient . requestsubpartition ( partitionid , subpartitionindex , this , getcurrentbackoff ( ) ) ; } else { failpartitionrequest ( ) ; } }	Retriggers a remote subpartition request.
@ override public void recycle ( memorysegment segment ) { int numaddedbuffers ; synchronized ( bufferqueue ) {	Exclusive buffer is recycled to this input channel directly and it may trigger return extrafloating buffer and notify increased credit to the producer.
void onsenderbacklog ( int backlog ) throws ioexception { int numrequestedbuffers = num_ ; synchronized ( bufferqueue ) {	Receives the backlog from the producer's buffer response.
public void registerongoingoperation ( final k operationkey , final completablefuture < r > operationresultfuture ) { final resultaccesstracker < r > inprogress = resultaccesstracker . inprogress ( ) ; registeredoperationtriggers . put ( operationkey , inprogress ) ; operationresultfuture . whencomplete ( ( result , error ) -> { if ( error == null ) { completedoperations . put ( operationkey , inprogress . finishoperation ( either . right ( result ) ) ) ; } else { completedoperations . put ( operationkey , inprogress . finishoperation ( either . left ( error ) ) ) ; } registeredoperationtriggers . remove ( operationkey ) ; } ) ; }	Registers an ongoing operation with the cache.
@ nullable public inetsocketaddress getserveraddress ( ) { synchronized ( lock ) { preconditions . checkstate ( state != state . created , str_ ) ; channel server = this . serverchannel ; if ( server != null ) { try { return ( ( inetsocketaddress ) server . localaddress ( ) ) ; } catch ( exception e ) { log . error ( str_ , e ) ; } } return null ; } }	Returns the address on which this endpoint is accepting requests.
@ visiblefortesting static void createuploaddir ( final path uploaddir , final logger log , final boolean initialcreation ) throws ioexception { if ( ! files . exists ( uploaddir ) ) { if ( initialcreation ) { log . info ( str_ + uploaddir ) ; } else { log . warn ( str_ + str_ , uploaddir ) ; } checkandcreateuploaddir ( uploaddir , log ) ; } }	Creates the upload dir if needed.
public matchiterator get ( long key , int hashcode ) { int bucket = hashcode & numbucketsmask ; int bucketoffset = bucket << num_ ; memorysegment segment = buckets [ bucketoffset > > > segmentsizebits ] ; int segoffset = bucketoffset & segmentsizemask ; while ( bool_ ) { long address = segment . getlong ( segoffset + num_ ) ; if ( address != invalid_address ) { if ( segment . getlong ( segoffset ) == key ) { return valueiter ( address ) ; } else { bucket = ( bucket + num_ ) & numbucketsmask ; if ( segoffset + num_ < segmentsize ) { segoffset += num_ ; } else { bucketoffset = bucket << num_ ; segoffset = bucketoffset & segmentsizemask ; segment = buckets [ bucketoffset > > > segmentsizebits ] ; } } } else { return valueiter ( invalid_address ) ; } } }	Returns an iterator for all the values for the given key, or null if no value found.
private void updateindex ( long key , int hashcode , long address , int size , memorysegment datasegment , int currentpositioninsegment ) throws ioexception { assert ( numkeys <= numbuckets / num_ ) ; int bucketid = hashcode & numbucketsmask ;	Update the address in array for given key.
public void registerlistener ( jobid jobid , kvstateregistrylistener listener ) { final kvstateregistrylistener previousvalue = listeners . putifabsent ( jobid , listener ) ; if ( previousvalue != null ) { throw new illegalstateexception ( str_ + jobid + str_ ) ; } }	Registers a listener with the registry.
public kvstateid registerkvstate ( jobid jobid , jobvertexid jobvertexid , keygrouprange keygrouprange , string registrationname , internalkvstate < ? , ? , ? > kvstate ) { kvstateid kvstateid = new kvstateid ( ) ; if ( registeredkvstates . putifabsent ( kvstateid , new kvstateentry < > ( kvstate ) ) == null ) { final kvstateregistrylistener listener = getkvstateregistrylistener ( jobid ) ; if ( listener != null ) { listener . notifykvstateregistered ( jobid , jobvertexid , keygrouprange , registrationname , kvstateid ) ; } return kvstateid ; } else { throw new illegalstateexception ( str_ + registrationname + str_ + kvstateid + str_ ) ; } }	Registers the KvState instance and returns the assigned ID.
public void unregisterkvstate ( jobid jobid , jobvertexid jobvertexid , keygrouprange keygrouprange , string registrationname , kvstateid kvstateid ) { kvstateentry < ? , ? , ? > entry = registeredkvstates . remove ( kvstateid ) ; if ( entry != null ) { entry . clear ( ) ; final kvstateregistrylistener listener = getkvstateregistrylistener ( jobid ) ; if ( listener != null ) { listener . notifykvstateunregistered ( jobid , jobvertexid , keygrouprange , registrationname ) ; } } }	Unregisters the KvState instance identified by the given KvStateID.
public binarymergeiterator < entry > getmergingiterator ( list < channelwithmeta > channelids , list < fileiochannel > openchannels ) throws ioexception {	Returns an iterator that iterates over the merged result from all given channels.
public list < channelwithmeta > mergechannellist ( list < channelwithmeta > channelids ) throws ioexception {	Merges the given sorted runs to a smaller number of sorted runs.
private channelwithmeta mergechannels ( list < channelwithmeta > channelids ) throws ioexception {	Merges the sorted runs described by the given Channel IDs into a single sorted run.
public boolean ismetby ( localproperties other ) { if ( this . ordering != null ) {	Checks, if this set of properties, as interesting properties, is met by the givenproperties.
public void parameterizechannel ( channel channel ) { localproperties current = channel . getlocalproperties ( ) ; if ( ismetby ( current ) ) {	Parametrizes the local strategy fields of a channel such that the channel produces the desired local properties.
public boolean get ( ) { switch ( state ) { case unset : return valueifunset ; case false : return bool_ ; case true : return bool_ ; case conflicting : return valueifconflicting ; default : throw new runtimeexception ( str_ ) ; } }	Get the boolean state.
public boolean conflictswith ( optionalboolean other ) { return state == state . conflicting || other . state == state . conflicting || ( state == state . true && other . state == state . false ) || ( state == state . false && other . state == state . true ) ; }	The conflicting states are true with false and false with true.
public void mergewith ( optionalboolean other ) { if ( state == other . state ) {	State transitions.- if the states are the same then no change- if either state is unset then change to the other state- if the states are conflicting then set to the conflicting state.
@ publicevolving @ suppresswarnings ( str_ ) public restartstrategies . restartstrategyconfiguration getrestartstrategy ( ) { if ( restartstrategyconfiguration instanceof restartstrategies . fallbackrestartstrategyconfiguration ) {	Returns the restart strategy which has been set for the current job.
@ suppresswarnings ( str_ ) public void registertypewithkryoserializer ( class < ? > type , class < ? extends serializer > serializerclass ) { if ( type == null || serializerclass == null ) { throw new nullpointerexception ( str_ ) ; } @ suppresswarnings ( str_ ) class < ? extends serializer < ? > > castedserializerclass = ( class < ? extends serializer < ? > > ) serializerclass ; registeredtypeswithkryoserializerclasses . put ( type , castedserializerclass ) ; }	Registers the given Serializer via its class as a serializer for the given type at the KryoSerializer.
public linkedhashset < class < ? > > getregisteredkryotypes ( ) { if ( isforcekryoenabled ( ) ) {	Returns the registered Kryo types.
public completablefuture < acknowledge > start ( final jobmasterid newjobmasterid ) throws exception {	Start the rpc service and begin to run the job.
@ override public completablefuture < void > onstop ( ) { log . info ( str_ , jobgraph . getname ( ) , jobgraph . getjobid ( ) ) ;	Suspend the job and shutdown all other services including rpc.
@ override public completablefuture < acknowledge > updatetaskexecutionstate ( final taskexecutionstate taskexecutionstate ) { checknotnull ( taskexecutionstate , str_ ) ; if ( executiongraph . updatestate ( taskexecutionstate ) ) { return completablefuture . completedfuture ( acknowledge . get ( ) ) ; } else { return futureutils . completedexceptionally ( new executiongraphexception ( str_ + taskexecutionstate . getid ( ) + str_ ) ) ; } }	Updates the task execution state for a given task.
public option defaultvalue ( string defaultvalue ) throws requiredparametersexception { if ( this . choices . isempty ( ) ) { return this . setdefaultvalue ( defaultvalue ) ; } else { if ( this . choices . contains ( defaultvalue ) ) { return this . setdefaultvalue ( defaultvalue ) ; } else { throw new requiredparametersexception ( str_ + defaultvalue + str_ + this . longname ) ; } } }	Define a default value for the option.
public option choices ( string ... choices ) throws requiredparametersexception { if ( this . defaultvalue != null ) { if ( arrays . aslist ( choices ) . contains ( defaultvalue ) ) { collections . addall ( this . choices , choices ) ; } else { throw new requiredparametersexception ( str_ + this . longname + str_ + defaultvalue ) ; } } else { collections . addall ( this . choices , choices ) ; } return this ; }	Restrict the list of possible values of the parameter.
public static int getint ( properties config , string key , int defaultvalue ) { string val = config . getproperty ( key ) ; if ( val == null ) { return defaultvalue ; } else { try { return integer . parseint ( val ) ; } catch ( numberformatexception nfe ) { throw new illegalargumentexception ( str_ + key + str_ + str_ + val + str_ + defaultvalue + str_ ) ; } } }	Get integer from properties.This method throws an exception if the integer is not valid.
public static long getlong ( properties config , string key , long defaultvalue ) { string val = config . getproperty ( key ) ; if ( val == null ) { return defaultvalue ; } else { try { return long . parselong ( val ) ; } catch ( numberformatexception nfe ) { throw new illegalargumentexception ( str_ + key + str_ + str_ + val + str_ + defaultvalue + str_ ) ; } } }	Get long from properties.This method throws an exception if the long is not valid.
public static long getlong ( properties config , string key , long defaultvalue , logger logger ) { try { return getlong ( config , key , defaultvalue ) ; } catch ( illegalargumentexception iae ) { logger . warn ( iae . getmessage ( ) ) ; return defaultvalue ; } }	Get long from properties.This method only logs if the long is not valid.
checkpointstatshistory createsnapshot ( ) { if ( readonly ) { throw new unsupportedoperationexception ( str_ ) ; } list < abstractcheckpointstats > checkpointshistory ; map < long , abstractcheckpointstats > checkpointsbyid ; checkpointsbyid = new hashmap < > ( checkpointsarray . length ) ; if ( maxsize == num_ ) { checkpointshistory = collections . emptylist ( ) ; } else { abstractcheckpointstats [ ] newcheckpointsarray = new abstractcheckpointstats [ checkpointsarray . length ] ; system . arraycopy ( checkpointsarray , nextpos , newcheckpointsarray , num_ , checkpointsarray . length - nextpos ) ; system . arraycopy ( checkpointsarray , num_ , newcheckpointsarray , checkpointsarray . length - nextpos , nextpos ) ; checkpointshistory = arrays . aslist ( newcheckpointsarray ) ;	Creates a snapshot of the current state.
void addinprogresscheckpoint ( pendingcheckpointstats pending ) { if ( readonly ) { throw new unsupportedoperationexception ( str_ ) ; } if ( maxsize == num_ ) { return ; } checknotnull ( pending , str_ ) ;	Adds an in progress checkpoint to the checkpoint history.
boolean replacependingcheckpointbyid ( abstractcheckpointstats completedorfailed ) { checkargument ( ! completedorfailed . getstatus ( ) . isinprogress ( ) , str_ ) ; if ( readonly ) { throw new unsupportedoperationexception ( str_ ) ; }	Searches for the in progress checkpoint with the given ID and replacesit with the given completed or failed checkpoint.
public static messagetype toparquettype ( typeinformation < ? > typeinformation , boolean legacymode ) { return ( messagetype ) convertfield ( null , typeinformation , type . repetition . optional , legacymode ) ; }	Converts Flink Internal Type to Parquet schema.
public static int hashunsafebytesbywords ( object base , long offset , int lengthinbytes ) { return hashunsafebytesbywords ( base , offset , lengthinbytes , default_seed ) ; }	Hash unsafe bytes, length must be aligned to 4 bytes.
public static int hashunsafebytes ( object base , long offset , int lengthinbytes ) { return hashunsafebytes ( base , offset , lengthinbytes , default_seed ) ; }	Hash unsafe bytes.
public static int hashbytesbywords ( memorysegment segment , int offset , int lengthinbytes ) { return hashbytesbywords ( segment , offset , lengthinbytes , default_seed ) ; }	Hash bytes in MemorySegment, length must be aligned to 4 bytes.
public static int hashbytes ( memorysegment segment , int offset , int lengthinbytes ) { return hashbytes ( segment , offset , lengthinbytes , default_seed ) ; }	Hash bytes in MemorySegment.
@ nullable public serializedvalue < jobinformation > getserializedjobinformation ( ) { if ( serializedjobinformation instanceof nonoffloaded ) { nonoffloaded < jobinformation > jobinformation = ( nonoffloaded < jobinformation > ) serializedjobinformation ; return jobinformation . serializedvalue ; } else { throw new illegalstateexception ( str_ ) ; } }	Return the sub task's serialized job information.
@ nullable public serializedvalue < taskinformation > getserializedtaskinformation ( ) { if ( serializedtaskinformation instanceof nonoffloaded ) { nonoffloaded < taskinformation > taskinformation = ( nonoffloaded < taskinformation > ) serializedtaskinformation ; return taskinformation . serializedvalue ; } else { throw new illegalstateexception ( str_ ) ; } }	Return the sub task's serialized task information.
@ override public void accept ( visitor < plannode > visitor ) { for ( sinkplannode node : this . datasinks ) { node . accept ( visitor ) ; } }	Applies the given visitor top down to all nodes, starting at the sinks.
boolean inserttobucket ( int hashcode , int pointer , boolean spillingallowed , boolean sizeaddandcheckresize ) throws ioexception { final int poshashcode = findbucket ( hashcode ) ;	Insert into bucket by hashCode and pointer.
boolean appendrecordandinsert ( binaryrow record , int hashcode ) throws ioexception { final int poshashcode = findbucket ( hashcode ) ;	Append record and insert to bucket.
private boolean findfirstsamebuildrow ( memorysegment bucket , int searchhashcode , int bucketinsegmentoffset , binaryrow buildrowtoinsert ) { int posinsegment = bucketinsegmentoffset + bucket_header_length ; int countinbucket = bucket . getshort ( bucketinsegmentoffset + header_count_offset ) ; int numinbucket = num_ ; randomaccessinputview view = partition . getbuildstateinputview ( ) ; while ( countinbucket != num_ ) { while ( numinbucket < countinbucket ) { final int thiscode = bucket . getint ( posinsegment ) ; posinsegment += hash_code_len ; if ( thiscode == searchhashcode ) { final int pointer = bucket . getint ( bucketinsegmentoffset + bucket_pointer_start_offset + ( numinbucket * pointer_len ) ) ; numinbucket ++ ; try { view . setreadposition ( pointer ) ; binaryrow row = table . binarybuildsideserializer . mapfrompages ( table . reusebuildrow , view ) ; if ( buildrowtoinsert . equals ( row ) ) { return bool_ ; } } catch ( ioexception e ) { throw new runtimeexception ( str_ + e . getmessage ( ) , e ) ; } } else { numinbucket ++ ; } }	For distinct build.
void startlookup ( int hashcode ) { final int poshashcode = findbucket ( hashcode ) ;	Probe start lookup joined build rows.
private static boolean repstep ( bufferedreader in , boolean readconsoleinput ) throws ioexception , interruptedexception {	Read-Evaluate-Print step for the REPL.
public static list < inputchanneldeploymentdescriptor > fromedges ( list < executionedge > edges , boolean allowlazydeployment ) { return edges . stream ( ) . map ( edge -> fromedgeandvalidate ( allowlazydeployment , edge ) ) . collect ( collectors . tolist ( ) ) ; }	Creates an input channel deployment descriptor for each partition.
long refreshandgettotal ( ) { long total = num_ ; for ( inputchannel channel : inputgate . getinputchannels ( ) . values ( ) ) { if ( channel instanceof remoteinputchannel ) { remoteinputchannel rc = ( remoteinputchannel ) channel ; total += rc . unsynchronizedgetnumberofqueuedbuffers ( ) ; } } return total ; }	Iterates over all input channels and collects the total number of queued buffers in abest-effort way.
int refreshandgetmin ( ) { int min = integer . max_value ; collection < inputchannel > channels = inputgate . getinputchannels ( ) . values ( ) ; for ( inputchannel channel : channels ) { if ( channel instanceof remoteinputchannel ) { remoteinputchannel rc = ( remoteinputchannel ) channel ; int size = rc . unsynchronizedgetnumberofqueuedbuffers ( ) ; min = math . min ( min , size ) ; } } if ( min == integer . max_value ) {	Iterates over all input channels and collects the minimum number of queued buffers in achannel in a best-effort way.
int refreshandgetmax ( ) { int max = num_ ; for ( inputchannel channel : inputgate . getinputchannels ( ) . values ( ) ) { if ( channel instanceof remoteinputchannel ) { remoteinputchannel rc = ( remoteinputchannel ) channel ; int size = rc . unsynchronizedgetnumberofqueuedbuffers ( ) ; max = math . max ( max , size ) ; } } return max ; }	Iterates over all input channels and collects the maximum number of queued buffers in achannel in a best-effort way.
float refreshandgetavg ( ) { long total = num_ ; int count = num_ ; for ( inputchannel channel : inputgate . getinputchannels ( ) . values ( ) ) { if ( channel instanceof remoteinputchannel ) { remoteinputchannel rc = ( remoteinputchannel ) channel ; int size = rc . unsynchronizedgetnumberofqueuedbuffers ( ) ; total += size ; ++ count ; } } return count == num_ ? num_ : total / ( float ) count ; }	Iterates over all input channels and collects the average number of queued buffers in achannel in a best-effort way.
static jarfilewithentryclass findonlyentryclass ( iterable < file > jarfiles ) throws ioexception { list < jarfilewithentryclass > jarswithentryclasses = new arraylist < > ( ) ; for ( file jarfile : jarfiles ) { findentryclass ( jarfile ) . ifpresent ( entryclass -> jarswithentryclasses . add ( new jarfilewithentryclass ( jarfile , entryclass ) ) ) ; } int size = jarswithentryclasses . size ( ) ; if ( size == num_ ) { throw new nosuchelementexception ( str_ ) ; } if ( size == num_ ) { return jarswithentryclasses . get ( num_ ) ; }	Returns a JAR file with its entry class as specified in the manifest.
@ visiblefortesting static optional < string > findentryclass ( file jarfile ) throws ioexception { return findfirstmanifestattribute ( jarfile , packagedprogram . manifest_attribute_assembler_class , packagedprogram . manifest_attribute_main_class ) ; }	Returns the entry class as specified in the manifest of the provided JAR file. The following manifest attributes are checked in order to find the entry class: {.
private static optional < string > findfirstmanifestattribute ( file jarfile , string ... attributes ) throws ioexception { if ( attributes . length == num_ ) { return optional . empty ( ) ; } try ( jarfile f = new jarfile ( jarfile ) ) { return findfirstmanifestattribute ( f , attributes ) ; } }	Returns the value of the first manifest attribute found in the provided JAR file.
@ override public final typeserializer < t > restoreserializer ( ) { if ( serializer == null ) { throw new illegalstateexception ( str_ + str_ ) ; } else if ( serializer instanceof unloadabledummytypeserializer ) { throwable originalerror = ( ( unloadabledummytypeserializer < ? > ) serializer ) . getoriginalerror ( ) ; throw new illegalstateexception ( str_ + str_ + getclass ( ) . getname ( ) + str_ + str_ + str_ , originalerror ) ; } else { return this . serializer ; } }	Creates a serializer using this configuration, that is capable of reading datawritten by the serializer described by this configuration.
private static < v , r extends serializable > accumulator < v , r > mergesingle ( accumulator < ? , ? > target , accumulator < ? , ? > tomerge ) { @ suppresswarnings ( str_ ) accumulator < v , r > typedtarget = ( accumulator < v , r > ) target ; @ suppresswarnings ( str_ ) accumulator < v , r > typedtomerge = ( accumulator < v , r > ) tomerge ; typedtarget . merge ( typedtomerge ) ; return typedtarget ; }	Workaround method for type safety.
public static map < string , optionalfailure < object > > toresultmap ( map < string , accumulator < ? , ? > > accumulators ) { map < string , optionalfailure < object > > resultmap = new hashmap < > ( ) ; for ( map . entry < string , accumulator < ? , ? > > entry : accumulators . entryset ( ) ) { resultmap . put ( entry . getkey ( ) , wrapunchecked ( entry . getkey ( ) , ( ) -> entry . getvalue ( ) . getlocalvalue ( ) ) ) ; } return resultmap ; }	Transform the Map with accumulators into a Map containing only theresults.
public static map < string , optionalfailure < object > > deserializeaccumulators ( map < string , serializedvalue < optionalfailure < object > > > serializedaccumulators , classloader loader ) throws ioexception , classnotfoundexception { if ( serializedaccumulators == null || serializedaccumulators . isempty ( ) ) { return collections . emptymap ( ) ; } map < string , optionalfailure < object > > accumulators = new hashmap < > ( serializedaccumulators . size ( ) ) ; for ( map . entry < string , serializedvalue < optionalfailure < object > > > entry : serializedaccumulators . entryset ( ) ) { optionalfailure < object > value = null ; if ( entry . getvalue ( ) != null ) { value = entry . getvalue ( ) . deserializevalue ( loader ) ; } accumulators . put ( entry . getkey ( ) , value ) ; } return accumulators ; }	Takes the serialized accumulator results and tries to deserialize them using the providedclass loader.
public void prepareandcommitoffsets ( map < kafkatopicpartition , long > internaloffsets ) throws exception { for ( map . entry < kafkatopicpartition , long > entry : internaloffsets . entryset ( ) ) { kafkatopicpartition tp = entry . getkey ( ) ; long lastprocessedoffset = entry . getvalue ( ) ; if ( lastprocessedoffset != null && lastprocessedoffset >= num_ ) { setoffsetinzookeeper ( curatorclient , groupid , tp . gettopic ( ) , tp . getpartition ( ) , lastprocessedoffset + num_ ) ; } } }	Commits offsets for Kafka partitions to ZooKeeper.
public void publish ( taskevent event ) { synchronized ( listeners ) { for ( eventlistener < taskevent > listener : listeners . get ( event . getclass ( ) ) ) { listener . onevent ( event ) ; } } }	Publishes the task event to all subscribed event listeners.
public static void register ( final logger log ) { synchronized ( signalhandler . class ) { if ( registered ) { return ; } registered = bool_ ; final string [ ] signals = operatingsystem . iswindows ( ) ? new string [ ] { str_ , str_ } : new string [ ] { str_ , str_ , str_ } ; stringbuilder bld = new stringbuilder ( ) ; bld . append ( str_ ) ; string separator = str_ ; for ( string signalname : signals ) { try { new handler ( signalname , log ) ; bld . append ( separator ) ; bld . append ( signalname ) ; separator = str_ ; } catch ( exception e ) { log . info ( str_ , e ) ; } } bld . append ( str_ ) ; log . info ( bld . tostring ( ) ) ; } }	Register some signal handlers.
private static < x extends copyablevalue < x > > copyablevalueserializer < x > createcopyablevalueserializer ( class < x > clazz ) { return new copyablevalueserializer < x > ( clazz ) ; }	utility method to summon the necessary bound.
private static void registerfactory ( type t , class < ? extends typeinfofactory > factory ) { preconditions . checknotnull ( t , str_ ) ; preconditions . checknotnull ( factory , str_ ) ; if ( ! typeinfofactory . class . isassignablefrom ( factory ) ) { throw new illegalargumentexception ( str_ ) ; } if ( registeredtypeinfofactories . containskey ( t ) ) { throw new invalidtypesexception ( str_ + t + str_ ) ; } registeredtypeinfofactories . put ( t , factory ) ; }	Registers a type information factory globally for a certain type.
@ suppresswarnings ( str_ ) private < in1 , in2 , out > typeinformation < out > createtypeinfofromfactory ( type t , arraylist < type > typehierarchy , typeinformation < in1 > in1type , typeinformation < in2 > in2type ) { final arraylist < type > factoryhierarchy = new arraylist < > ( typehierarchy ) ; final typeinfofactory < ? super out > factory = getclosestfactory ( factoryhierarchy , t ) ; if ( factory == null ) { return null ; } final type factorydefiningtype = factoryhierarchy . get ( factoryhierarchy . size ( ) - num_ ) ;	Creates type information using a factory if for this type or super types.
@ internal public static < out > typeinfofactory < out > gettypeinfofactory ( type t ) { final class < ? > factoryclass ; if ( registeredtypeinfofactories . containskey ( t ) ) { factoryclass = registeredtypeinfofactories . get ( t ) ; } else { if ( ! isclasstype ( t ) || ! typetoclass ( t ) . isannotationpresent ( typeinfo . class ) ) { return null ; } final typeinfo typeinfoannotation = typetoclass ( t ) . getannotation ( typeinfo . class ) ; factoryclass = typeinfoannotation . value ( ) ;	Returns the type information factory for a type using the factory registry or annotations.
private static < out > typeinfofactory < ? super out > getclosestfactory ( arraylist < type > typehierarchy , type t ) { typeinfofactory factory = null ; while ( factory == null && isclasstype ( t ) && ! ( typetoclass ( t ) . equals ( object . class ) ) ) { typehierarchy . add ( t ) ; factory = gettypeinfofactory ( t ) ; t = typetoclass ( t ) . getgenericsuperclass ( ) ; if ( t == null ) { break ; } } return factory ; }	Traverses the type hierarchy up until a type information factory can be found.
public static boolean isproperclass ( class < ? > clazz ) { int mods = clazz . getmodifiers ( ) ; return ! ( modifier . isabstract ( mods ) || modifier . isinterface ( mods ) || modifier . isnative ( mods ) ) ; }	Checks, whether the class is a proper class, i.e.
private void trydensemode ( ) { if ( numspillfiles != num_ ) { return ; } long minkey = long . max_value ; long maxkey = long . min_value ; long recordcount = num_ ; for ( longhashpartition p : this . partitionsbeingbuilt ) { long partitionrecords = p . getbuildsiderecordcount ( ) ; recordcount += partitionrecords ; if ( partitionrecords > num_ ) { if ( p . getminkey ( ) < minkey ) { minkey = p . getminkey ( ) ; } if ( p . getmaxkey ( ) > maxkey ) { maxkey = p . getmaxkey ( ) ; } } } if ( buildspillretbuffernumbers != num_ ) { throw new runtimeexception ( str_ + buildspillretbuffernumbers ) ; } long range = maxkey - minkey + num_ ; if ( range <= recordcount * num_ || range <= segmentsize / num_ ) {	After build end, try to use dense mode.
@ override public rocksdbrestoreresult restore ( ) throws ioexception , statemigrationexception , rocksdbexception { opendb ( ) ; for ( keyedstatehandle keyedstatehandle : restorestatehandles ) { if ( keyedstatehandle != null ) { if ( ! ( keyedstatehandle instanceof keygroupsstatehandle ) ) { throw new illegalstateexception ( str_ + str_ + keygroupsstatehandle . class + str_ + keyedstatehandle . getclass ( ) ) ; } this . currentkeygroupsstatehandle = ( keygroupsstatehandle ) keyedstatehandle ; restorekeygroupsinstatehandle ( ) ; } } return new rocksdbrestoreresult ( this . db , defaultcolumnfamilyhandle , nativemetricmonitor , - num_ , null , null ) ; }	Restores all key-groups data that is referenced by the passed state handles.
private void restorekeygroupsinstatehandle ( ) throws ioexception , statemigrationexception , rocksdbexception { try { currentstatehandleinstream = currentkeygroupsstatehandle . openinputstream ( ) ; cancelstreamregistry . registercloseable ( currentstatehandleinstream ) ; currentstatehandleinview = new datainputviewstreamwrapper ( currentstatehandleinstream ) ; restorekvstatemetadata ( ) ; restorekvstatedata ( ) ; } finally { if ( cancelstreamregistry . unregistercloseable ( currentstatehandleinstream ) ) { ioutils . closequietly ( currentstatehandleinstream ) ; } } }	Restore one key groups state handle.
public void rundetached ( jobgraph job ) throws jobexecutionexception , interruptedexception { checknotnull ( job , str_ ) ; final completablefuture < jobsubmissionresult > submissionfuture = submitjob ( job ) ; try { submissionfuture . get ( ) ; } catch ( executionexception e ) { throw new jobexecutionexception ( job . getjobid ( ) , exceptionutils . stripexecutionexception ( e ) ) ; } }	This method executes a job in detached mode. The method returns immediately after the jobhas been added to the.
@ override public jobexecutionresult executejobblocking ( jobgraph job ) throws jobexecutionexception , interruptedexception { checknotnull ( job , str_ ) ; final completablefuture < jobsubmissionresult > submissionfuture = submitjob ( job ) ; final completablefuture < jobresult > jobresultfuture = submissionfuture . thencompose ( ( jobsubmissionresult ignored ) -> requestjobresult ( job . getjobid ( ) ) ) ; final jobresult jobresult ; try { jobresult = jobresultfuture . get ( ) ; } catch ( executionexception e ) { throw new jobexecutionexception ( job . getjobid ( ) , str_ , exceptionutils . stripexecutionexception ( e ) ) ; } try { return jobresult . tojobexecutionresult ( thread . currentthread ( ) . getcontextclassloader ( ) ) ; } catch ( ioexception | classnotfoundexception e ) { throw new jobexecutionexception ( job . getjobid ( ) , e ) ; } }	This method runs a job in blocking mode.
protected metricregistryimpl createmetricregistry ( configuration config ) { return new metricregistryimpl ( metricregistryconfiguration . fromconfiguration ( config ) , reportersetup . fromconfiguration ( config ) ) ; }	Factory method to create the metric registry for the mini cluster.
protected rpcservice createrpcservice ( akkarpcserviceconfiguration akkarpcserviceconfig , boolean remoteenabled , string bindaddress ) { final config akkaconfig ; if ( remoteenabled ) { akkaconfig = akkautils . getakkaconfig ( akkarpcserviceconfig . getconfiguration ( ) , bindaddress , num_ ) ; } else { akkaconfig = akkautils . getakkaconfig ( akkarpcserviceconfig . getconfiguration ( ) ) ; } final config effectiveakkaconfig = akkautils . testdispatcherconfig ( ) . withfallback ( akkaconfig ) ; final actorsystem actorsystem = akkautils . createactorsystem ( effectiveakkaconfig ) ; return new akkarpcservice ( actorsystem , akkarpcserviceconfig ) ; }	Factory method to instantiate the RPC service.
private boolean generatenodehash ( streamnode node , hashfunction hashfunction , map < integer , byte [ ] > hashes , boolean ischainingenabled , streamgraph streamgraph ) {	Generates a hash for the node and returns whether the operation wassuccessful.
private byte [ ] generateuserspecifiedhash ( streamnode node , hasher hasher ) { hasher . putstring ( node . gettransformationuid ( ) , charset . forname ( str_ ) ) ; return hasher . hash ( ) . asbytes ( ) ; }	Generates a hash from a user-specified ID.
private byte [ ] generatedeterministichash ( streamnode node , hasher hasher , map < integer , byte [ ] > hashes , boolean ischainingenabled , streamgraph streamgraph ) {	Generates a deterministic hash from node-local properties and input andoutput edges.
public static int murmurhash ( int code ) { code *= num_ ; code = integer . rotateleft ( code , num_ ) ; code *= num_ ; code = integer . rotateleft ( code , num_ ) ; code = code * num_ + num_ ; code ^= num_ ; code = bitmix ( code ) ; if ( code >= num_ ) { return code ; } else if ( code != integer . min_value ) { return - code ; } else { return num_ ; } }	This function hashes an integer value.
public static int rounduptopoweroftwo ( int x ) { x = x - num_ ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; x |= x > > num_ ; return x + num_ ; }	Round the given number to the next power of two.
public completablefuture < list < stacktraceelement [ ] > > requeststacktracesample ( final stacktracesampleabletask task , @ nonnegative final int numsamples , final time delaybetweensamples , final int maxstacktracedepth ) { checknotnull ( task , str_ ) ; checkargument ( numsamples > num_ , str_ ) ; checknotnull ( delaybetweensamples , str_ ) ; return requeststacktracesample ( task , numsamples , delaybetweensamples , maxstacktracedepth , new arraylist < > ( numsamples ) , new completablefuture < > ( ) ) ; }	Returns a future that completes with a given number of stack trace samples of a task thread.
@ override protected int require ( int required ) throws kryoexception { if ( required > capacity ) { throw new kryoexception ( str_ + capacity + str_ + str_ + required ) ; } position = num_ ; int bytesread = num_ ; int count ; while ( bool_ ) { count = fill ( buffer , bytesread , required - bytesread ) ; if ( count == - num_ ) { throw new kryoexception ( new eofexception ( str_ ) ) ; } bytesread += count ; if ( bytesread == required ) { break ; } } limit = required ; return required ; }	Require makes sure that at least required number of bytes are kept in the buffer.
@ override protected final void acknowledgeids ( long checkpointid , set < uid > uniqueids ) { log . debug ( str_ , checkpointid ) ; iterator < tuple2 < long , list < sessionid > > > iterator = sessionidspersnapshot . iterator ( ) ; while ( iterator . hasnext ( ) ) { final tuple2 < long , list < sessionid > > next = iterator . next ( ) ; long id = next . f0 ; if ( id <= checkpointid ) { acknowledgesessionids ( next . f1 ) ;	Acknowledges the session ids.
public final string functionidentifier ( ) { final string md5 = encodingutils . hex ( encodingutils . md5 ( encodingutils . encodeobjecttostring ( this ) ) ) ; return getclass ( ) . getcanonicalname ( ) . replace ( str_ , str_ ) . concat ( str_ ) . concat ( md5 ) ; }	Returns a unique, serialized representation for this function.
public static jobid fromhexstring ( string hexstring ) { try { return new jobid ( stringutils . hexstringtobyte ( hexstring ) ) ; } catch ( exception e ) { throw new illegalargumentexception ( str_ + hexstring + str_ + str_ , e ) ; } }	Parses a JobID from the given string.
protected long initrankend ( baserow row ) throws exception { if ( isconstantrankend ) { return rankend ; } else { long rankendvalue = rankendstate . value ( ) ; long currankend = rankendfetcher . apply ( row ) ; if ( rankendvalue == null ) { rankend = currankend ; rankendstate . update ( rankend ) ; return rankend ; } else { rankend = rankendvalue ; if ( rankend != currankend ) {	Initialize rank end.
protected boolean checksortkeyinbufferrange ( baserow sortkey , topnbuffer buffer ) { comparator < baserow > comparator = buffer . getsortkeycomparator ( ) ; map . entry < baserow , collection < baserow > > worstentry = buffer . lastentry ( ) ; if ( worstentry == null ) {	Checks whether the record should be put into the buffer.
public void open ( runtimecontext cepruntimecontext , configuration conf ) throws exception { for ( state < t > state : getstates ( ) ) { for ( statetransition < t > transition : state . getstatetransitions ( ) ) { iterativecondition condition = transition . getcondition ( ) ; functionutils . setfunctionruntimecontext ( condition , cepruntimecontext ) ; functionutils . openfunction ( condition , conf ) ; } } }	Initialization method for the NFA.
public void close ( ) throws exception { for ( state < t > state : getstates ( ) ) { for ( statetransition < t > transition : state . getstatetransitions ( ) ) { iterativecondition condition = transition . getcondition ( ) ; functionutils . closefunction ( condition ) ; } } }	Tear-down method for the NFA.
private map < string , list < eventid > > extractcurrentmatches ( final sharedbufferaccessor < t > sharedbufferaccessor , final computationstate computationstate ) throws exception { if ( computationstate . getpreviousbufferentry ( ) == null ) { return new hashmap < > ( ) ; } list < map < string , list < eventid > > > paths = sharedbufferaccessor . extractpatterns ( computationstate . getpreviousbufferentry ( ) , computationstate . getversion ( ) ) ; if ( paths . isempty ( ) ) { return new hashmap < > ( ) ; }	Extracts all the sequences of events from the start to the given computation state.
@ suppresswarnings ( str_ ) public static < t > typeinformation < t > convert ( string jsonschema ) { preconditions . checknotnull ( jsonschema , str_ ) ; final objectmapper mapper = new objectmapper ( ) ; mapper . getfactory ( ) . enable ( jsonparser . feature . allow_comments ) . enable ( jsonparser . feature . allow_unquoted_field_names ) . enable ( jsonparser . feature . allow_single_quotes ) ; final jsonnode node ; try { node = mapper . readtree ( jsonschema ) ; } catch ( ioexception e ) { throw new illegalargumentexception ( str_ , e ) ; } return ( typeinformation < t > ) converttype ( str_ , node , node ) ; }	Converts a JSON schema into Flink's type information.
public throwable geterror ( classloader usercodeclassloader ) { if ( this . throwable == null ) { return null ; } else { return this . throwable . deserializeerror ( usercodeclassloader ) ; } }	Gets the attached exception, which is in serialized form.
protected char [ ] getpasswordfromcredentialproviders ( string name ) throws ioexception { char [ ] pass = null ; try { list < credentialprovider > providers = credentialproviderfactory . getproviders ( this ) ; if ( providers != null ) { for ( credentialprovider provider : providers ) { try { credentialentry entry = provider . getcredentialentry ( name ) ; if ( entry != null ) { pass = entry . getcredential ( ) ; break ; } } catch ( ioexception ioe ) { throw new ioexception ( str_ + name + str_ + str_ + provider . getclass ( ) . getname ( ) + str_ , ioe ) ; } } } } catch ( ioexception ioe ) { throw new ioexception ( str_ , ioe ) ; } return pass ; }	Try and resolve the provided element name as a credential provideralias.
public dataset < t > closewith ( dataset < t > iterationresult ) { return new bulkiterationresultset < t > ( getexecutionenvironment ( ) , gettype ( ) , this , iterationresult ) ; }	Closes the iteration. This method defines the end of the iterative program part.
public byte [ ] getbytes ( ) { byte [ ] bytes = new byte [ size ] ; longtobytearray ( lowerpart , bytes , num_ ) ; longtobytearray ( upperpart , bytes , size_of_long ) ; return bytes ; }	Gets the bytes underlying this ID.
public final string tohexstring ( ) { if ( this . hexstring == null ) { final byte [ ] ba = new byte [ size ] ; longtobytearray ( this . lowerpart , ba , num_ ) ; longtobytearray ( this . upperpart , ba , size_of_long ) ; this . hexstring = stringutils . bytetohexstring ( ba ) ; } return this . hexstring ; }	Returns pure String representation of the ID in hexadecimal.
private static long bytearraytolong ( byte [ ] ba , int offset ) { long l = num_ ; for ( int i = num_ ; i < size_of_long ; ++ i ) { l |= ( ba [ offset + size_of_long - num_ - i ] & num_ ) << ( i << num_ ) ; } return l ; }	Converts the given byte array to a long.
private static void longtobytearray ( long l , byte [ ] ba , int offset ) { for ( int i = num_ ; i < size_of_long ; ++ i ) { final int shift = i << num_ ;	Converts a long to a byte array.
public static < k , vv , ev , m > gathersumapplyiteration < k , vv , ev , m > withedges ( dataset < edge < k , ev > > edges , gatherfunction < vv , ev , m > gather , sumfunction < vv , ev , m > sum , applyfunction < k , vv , m > apply , int maximumnumberofiterations ) { return new gathersumapplyiteration < > ( gather , sum , apply , edges , maximumnumberofiterations ) ; }	Creates a new gather-sum-apply iteration operator for graphs.
public int put ( baserow sortkey , baserow value ) { currenttopnum += num_ ;	Appends a record into the buffer.
void removeall ( baserow sortkey ) { collection < baserow > list = treemap . get ( sortkey ) ; if ( list != null ) { currenttopnum -= list . size ( ) ; treemap . remove ( sortkey ) ; } }	Removes all record list from the buffer under the sortKey.
baserow removelast ( ) { map . entry < baserow , collection < baserow > > last = treemap . lastentry ( ) ; baserow lastelement = null ; if ( last != null ) { collection < baserow > list = last . getvalue ( ) ; lastelement = getlastelement ( list ) ; if ( lastelement != null ) { if ( list . remove ( lastelement ) ) { currenttopnum -= num_ ; } if ( list . size ( ) == num_ ) { treemap . remove ( last . getkey ( ) ) ; } } } return lastelement ; }	Removes the last record of the last Entry in the buffer.
baserow getelement ( int rank ) { int currank = num_ ; iterator < map . entry < baserow , collection < baserow > > > iter = treemap . entryset ( ) . iterator ( ) ; while ( iter . hasnext ( ) ) { map . entry < baserow , collection < baserow > > entry = iter . next ( ) ; collection < baserow > list = entry . getvalue ( ) ; iterator < baserow > listiter = list . iterator ( ) ; while ( listiter . hasnext ( ) ) { baserow elem = listiter . next ( ) ; currank += num_ ; if ( currank == rank ) { return elem ; } } } return null ; }	Gets record which rank is given value.
public < k > datastream < t > partitioncustom ( partitioner < k > partitioner , int field ) { keys . expressionkeys < t > outexpressionkeys = new keys . expressionkeys < > ( new int [ ] { field } , gettype ( ) ) ; return partitioncustom ( partitioner , outexpressionkeys ) ; }	Partitions a tuple DataStream on the specified key fields using a custom partitioner.This method takes the key position to partition on, and a partitioner that accepts the key type.
public < k > datastream < t > partitioncustom ( partitioner < k > partitioner , keyselector < t , k > keyselector ) { return setconnectiontype ( new custompartitionerwrapper < > ( clean ( partitioner ) , clean ( keyselector ) ) ) ; }	Partitions a DataStream on the key returned by the selector, using a custom partitioner.This method takes the key selector to get the key to partition on, and a partitioner thataccepts the key type.
private < k > datastream < t > partitioncustom ( partitioner < k > partitioner , keys < t > keys ) { keyselector < t , k > keyselector = keyselectorutil . getselectorforonekey ( keys , partitioner , gettype ( ) , getexecutionconfig ( ) ) ; return setconnectiontype ( new custompartitionerwrapper < > ( clean ( partitioner ) , clean ( keyselector ) ) ) ; }	private helper method for custom partitioning.
@ deprecated public singleoutputstreamoperator < t > assigntimestamps ( timestampextractor < t > extractor ) {	Extracts a timestamp from an element and assigns it as the internal timestamp of that element.The internal timestamps are, for example, used to to event-time window operations.
@ suppresswarnings ( str_ ) @ publicevolving public < x extends tuple > datastreamsink < t > writeascsv ( string path , writemode writemode , string rowdelimiter , string fielddelimiter ) { preconditions . checkargument ( gettype ( ) . istupletype ( ) , str_ ) ; csvoutputformat < x > of = new csvoutputformat < > ( new path ( path ) , rowdelimiter , fielddelimiter ) ; if ( writemode != null ) { of . setwritemode ( writemode ) ; } return writeusingoutputformat ( ( outputformat < t > ) of ) ; }	Writes a DataStream to the file specified by the path parameter.
@ publicevolving public datastreamsink < t > writeusingoutputformat ( outputformat < t > format ) { return addsink ( new outputformatsinkfunction < > ( format ) ) ; }	Writes the dataStream into an output, described by an OutputFormat.
@ publicevolving public < r > singleoutputstreamoperator < r > transform ( string operatorname , typeinformation < r > outtypeinfo , oneinputstreamoperator < t , r > operator ) {	Method for passing user defined operators along with the typeinformation that will transform the DataStream.
protected datastream < t > setconnectiontype ( streampartitioner < t > partitioner ) { return new datastream < > ( this . getexecutionenvironment ( ) , new partitiontransformation < > ( this . gettransformation ( ) , partitioner ) ) ; }	Internal function for setting the partitioner for the DataStream.
public event next ( int minip , int maxip ) { final double p = rnd . nextdouble ( ) ; if ( p * num_ >= states . size ( ) ) {	Creates a new random event.
private static long getsizeofphysicalmemoryforwindows ( ) { bufferedreader bi = null ; try { process proc = runtime . getruntime ( ) . exec ( str_ ) ; bi = new bufferedreader ( new inputstreamreader ( proc . getinputstream ( ) ) ) ; string line = bi . readline ( ) ; if ( line == null ) { return - num_ ; } if ( ! line . startswith ( str_ ) ) { return - num_ ; } long sizeofphyiscalmemory = num_ ; while ( ( line = bi . readline ( ) ) != null ) { if ( line . isempty ( ) ) { continue ; } line = line . replaceall ( str_ , str_ ) ; sizeofphyiscalmemory += long . parselong ( line ) ; } return sizeofphyiscalmemory ; } catch ( throwable t ) { log . error ( str_ + str_ , t ) ; return - num_ ; } finally { if ( bi != null ) { try { bi . close ( ) ; } catch ( throwable ignored ) { } } } }	Returns the size of the physical memory in bytes on Windows.
public < r > mapoperator < t , r > map ( mapfunction < t , r > mapper ) { if ( mapper == null ) { throw new nullpointerexception ( str_ ) ; } string calllocation = utils . getcalllocationname ( ) ; typeinformation < r > resulttype = typeextractor . getmapreturntypes ( mapper , gettype ( ) , calllocation , bool_ ) ; return new mapoperator < > ( this , resulttype , clean ( mapper ) , calllocation ) ; }	Applies a Map transformation on this DataSet. The transformation calls a {.
public list < t > collect ( ) throws exception { final string id = new abstractid ( ) . tostring ( ) ; final typeserializer < t > serializer = gettype ( ) . createserializer ( getexecutionenvironment ( ) . getconfig ( ) ) ; this . output ( new utils . collecthelper < > ( id , serializer ) ) . name ( str_ ) ; jobexecutionresult res = getexecutionenvironment ( ) . execute ( ) ; arraylist < byte [ ] > accresult = res . getaccumulatorresult ( id ) ; if ( accresult != null ) { try { return serializedlistaccumulator . deserializelist ( accresult , serializer ) ; } catch ( classnotfoundexception e ) { throw new runtimeexception ( str_ , e ) ; } catch ( ioexception e ) { throw new runtimeexception ( str_ , e ) ; } } else { throw new runtimeexception ( str_ ) ; } }	Convenience method to get the elements of a DataSet as a List.As DataSet can contain a lot of data, this method should be used with caution.
public unionoperator < t > union ( dataset < t > other ) { return new unionoperator < > ( this , other , utils . getcalllocationname ( ) ) ; }	Creates a union of this DataSet with an other DataSet.
public partitionoperator < t > partitionbyhash ( int ... fields ) { return new partitionoperator < > ( this , partitionmethod . hash , new keys . expressionkeys < > ( fields , gettype ( ) ) , utils . getcalllocationname ( ) ) ; }	Hash-partitions a DataSet on the specified key fields.
public < k extends comparable < k > > partitionoperator < t > partitionbyhash ( keyselector < t , k > keyextractor ) { final typeinformation < k > keytype = typeextractor . getkeyselectortypes ( keyextractor , gettype ( ) ) ; return new partitionoperator < > ( this , partitionmethod . hash , new keys . selectorfunctionkeys < > ( clean ( keyextractor ) , this . gettype ( ) , keytype ) , utils . getcalllocationname ( ) ) ; }	Partitions a DataSet using the specified KeySelector.
public partitionoperator < t > partitionbyrange ( int ... fields ) { return new partitionoperator < > ( this , partitionmethod . range , new keys . expressionkeys < > ( fields , gettype ( ) ) , utils . getcalllocationname ( ) ) ; }	Range-partitions a DataSet on the specified key fields.
public < k > partitionoperator < t > partitioncustom ( partitioner < k > partitioner , int field ) { return new partitionoperator < > ( this , new keys . expressionkeys < > ( new int [ ] { field } , gettype ( ) ) , clean ( partitioner ) , utils . getcalllocationname ( ) ) ; }	Partitions a tuple DataSet on the specified key fields using a custom partitioner.This method takes the key position to partition on, and a partitioner that accepts the key type.
public < k extends comparable < k > > partitionoperator < t > partitioncustom ( partitioner < k > partitioner , keyselector < t , k > keyextractor ) { final typeinformation < k > keytype = typeextractor . getkeyselectortypes ( keyextractor , gettype ( ) ) ; return new partitionoperator < > ( this , new keys . selectorfunctionkeys < > ( keyextractor , gettype ( ) , keytype ) , clean ( partitioner ) , utils . getcalllocationname ( ) ) ; }	Partitions a DataSet on the key returned by the selector, using a custom partitioner.This method takes the key selector to get the key to partition on, and a partitioner thataccepts the key type.
public < k > sortpartitionoperator < t > sortpartition ( keyselector < t , k > keyextractor , order order ) { final typeinformation < k > keytype = typeextractor . getkeyselectortypes ( keyextractor , gettype ( ) ) ; return new sortpartitionoperator < > ( this , new keys . selectorfunctionkeys < > ( clean ( keyextractor ) , gettype ( ) , keytype ) , order , utils . getcalllocationname ( ) ) ; }	Locally sorts the partitions of the DataSet on the extracted key in the specified order.The DataSet can be sorted on multiple values by returning a tuple from the KeySelector.
public t getdefaultvalue ( ) { if ( defaultvalue != null ) { if ( serializer != null ) { return serializer . copy ( defaultvalue ) ; } else { throw new illegalstateexception ( str_ ) ; } } else { return null ; } }	Returns the default value.
public void setqueryable ( string queryablestatename ) { preconditions . checkargument ( ttlconfig . getupdatetype ( ) == statettlconfig . updatetype . disabled , str_ ) ; if ( this . queryablestatename == null ) { this . queryablestatename = preconditions . checknotnull ( queryablestatename , str_ ) ; } else { throw new illegalstateexception ( str_ ) ; } }	Sets the name for queries of state created from this descriptor.
public void initializeserializerunlessset ( executionconfig executionconfig ) { if ( serializer == null ) { checkstate ( typeinfo != null , str_ ) ;	Initializes the serializer, unless it has been initialized before.
@ override public row nextrecord ( row row ) throws ioexception { try { if ( ! hasnext ) { return null ; } for ( int pos = num_ ; pos < row . getarity ( ) ; pos ++ ) { row . setfield ( pos , resultset . getobject ( pos + num_ ) ) ; }	Stores the next resultSet row in a tuple.
private catalogtable validatepartitionspec ( objectpath tablepath , catalogpartitionspec partitionspec ) throws tablenotexistexception , tablenotpartitionedexception , partitionspecinvalidexception { catalogtable table = validatepartitionedtable ( tablepath ) ; list < string > partitionkeys = table . getpartitionkeys ( ) ; map < string , string > spec = partitionspec . getpartitionspec ( ) ;	Validate the partitioned table and partitionSpec.
private catalogtable validatepartitionedtable ( objectpath tablepath ) throws tablenotexistexception , tablenotpartitionedexception { catalogbasetable basetable = gettable ( tablepath ) ; if ( ! ( basetable instanceof catalogtable ) ) { throw new catalogexception ( string . format ( str_ , tablepath . getfullname ( ) , catalogname ) ) ; } catalogtable table = ( catalogtable ) basetable ; if ( ! table . ispartitioned ( ) ) { throw new tablenotpartitionedexception ( catalogname , tablepath ) ; } return table ; }	Validate the partitioned table.
protected void increasebuffersinbacklog ( bufferconsumer buffer ) { assert thread . holdslock ( buffers ) ; if ( buffer != null && buffer . isbuffer ( ) ) { buffersinbacklog ++ ; } }	Increases the number of non-event buffers by one after adding a non-eventbuffer into this subpartition.
void lookupselecthints ( sqlselect select , sqlparserpos pos , collection < sqlmoniker > hintlist ) { idinfo info = idpositions . get ( pos . tostring ( ) ) ; if ( ( info == null ) || ( info . scope == null ) ) { sqlnode fromnode = select . getfrom ( ) ; final sqlvalidatorscope fromscope = getfromscope ( select ) ; lookupfromhints ( fromnode , fromscope , pos , hintlist ) ; } else { lookupnamecompletionhints ( info . scope , info . id . names , info . id . getparserposition ( ) , hintlist ) ; } }	Looks up completion hints for a syntactically correct select SQL that hasbeen parsed into an expression tree.
public final void lookupnamecompletionhints ( sqlvalidatorscope scope , list < string > names , sqlparserpos pos , collection < sqlmoniker > hintlist ) {	Populates a list of all the valid alternatives for an identifier.
protected void validatenamespace ( final sqlvalidatornamespace namespace , reldatatype targetrowtype ) { namespace . validate ( targetrowtype ) ; if ( namespace . getnode ( ) != null ) { setvalidatednodetype ( namespace . getnode ( ) , namespace . gettype ( ) ) ; } }	Validates a namespace.
protected sqlselect createsourceselectforupdate ( sqlupdate call ) { final sqlnodelist selectlist = new sqlnodelist ( sqlparserpos . zero ) ; selectlist . add ( sqlidentifier . star ( sqlparserpos . zero ) ) ; int ordinal = num_ ; for ( sqlnode exp : call . getsourceexpressionlist ( ) ) {	Creates the SELECT statement that putatively feeds rows into an UPDATEstatement to be updated.
protected sqlselect createsourceselectfordelete ( sqldelete call ) { final sqlnodelist selectlist = new sqlnodelist ( sqlparserpos . zero ) ; selectlist . add ( sqlidentifier . star ( sqlparserpos . zero ) ) ; sqlnode sourcetable = call . gettargettable ( ) ; if ( call . getalias ( ) != null ) { sourcetable = sqlvalidatorutil . addalias ( sourcetable , call . getalias ( ) . getsimple ( ) ) ; } return new sqlselect ( sqlparserpos . zero , null , selectlist , sourcetable , call . getcondition ( ) , null , null , null , null , null , null ) ; }	Creates the SELECT statement that putatively feeds rows into a DELETEstatement to be deleted.
reldatatype gettableconstructorrowtype ( sqlcall values , sqlvalidatorscope scope ) { final list < sqlnode > rows = values . getoperandlist ( ) ; assert rows . size ( ) >= num_ ; final list < reldatatype > rowtypes = new arraylist < > ( ) ; for ( final sqlnode row : rows ) { assert row . getkind ( ) == sqlkind . row ; sqlcall rowconstructor = ( sqlcall ) row ;	Returns null if there is no common type.
reldatatype derivetypeimpl ( sqlvalidatorscope scope , sqlnode operand ) { derivetypevisitor v = new derivetypevisitor ( scope ) ; final reldatatype type = operand . accept ( v ) ; return objects . requirenonnull ( scope . nullifytype ( operand , type ) ) ; }	Derives the type of a node, never null.
protected void addtoselectlist ( list < sqlnode > list , set < string > aliases , list < map . entry < string , reldatatype > > fieldlist , sqlnode exp , sqlvalidatorscope scope , final boolean includesystemvars ) { string alias = sqlvalidatorutil . getalias ( exp , - num_ ) ; string uniquealias = sqlvalidatorutil . uniquify ( alias , aliases , sqlvalidatorutil . expr_suggester ) ; if ( ! alias . equals ( uniquealias ) ) { exp = sqlvalidatorutil . addalias ( exp , uniquealias ) ; } fieldlist . add ( pair . of ( uniquealias , derivetype ( scope , exp ) ) ) ; list . add ( exp ) ; }	Adds an expression to a select list, ensuring that its alias does notclash with any existing expressions on the list.
protected void registernamespace ( sqlvalidatorscope usingscope , string alias , sqlvalidatornamespace ns , boolean forcenullable ) { namespaces . put ( ns . getnode ( ) , ns ) ; if ( usingscope != null ) { usingscope . addchild ( ns , alias , forcenullable ) ; } }	Registers a new namespace, and adds it as a child of its parent scope.Derived class can override this method to tinker with namespaces as theyare created.
private sqlnode getagg ( sqlselect select ) { final selectscope selectscope = getrawselectscope ( select ) ; if ( selectscope != null ) { final list < sqlnode > selectlist = selectscope . getexpandedselectlist ( ) ; if ( selectlist != null ) { return aggfinder . findagg ( selectlist ) ; } } return aggfinder . findagg ( select . getselectlist ( ) ) ; }	If there is at least one call to an aggregate function, returns thefirst.
private void registeroperandsubqueries ( sqlvalidatorscope parentscope , sqlcall call , int operandordinal ) { sqlnode operand = call . operand ( operandordinal ) ; if ( operand == null ) { return ; } if ( operand . getkind ( ) . belongsto ( sqlkind . query ) && call . getoperator ( ) . argumentmustbescalar ( operandordinal ) ) { operand = sqlstdoperatortable . scalar_query . createcall ( operand . getparserposition ( ) , operand ) ; call . setoperand ( operandordinal , operand ) ; } registersubqueries ( parentscope , operand ) ; }	Registers any sub-queries inside a given call operand, and converts theoperand to a scalar sub-query if the operator requires it.
private void validatenoaggs ( aggfinder aggfinder , sqlnode node , string clause ) { final sqlcall agg = aggfinder . findagg ( node ) ; if ( agg == null ) { return ; } final sqloperator op = agg . getoperator ( ) ; if ( op == sqlstdoperatortable . over ) { throw newvalidationerror ( agg , resource . windowedaggregateillegalinclause ( clause ) ) ; } else if ( op . isgroup ( ) || op . isgroupauxiliary ( ) ) { throw newvalidationerror ( agg , resource . groupfunctionmustappearingroupbyclause ( op . getname ( ) ) ) ; } else { throw newvalidationerror ( agg , resource . aggregateillegalinclause ( clause ) ) ; } }	Throws an error if there is an aggregate or windowed aggregate in thegiven clause.
protected void validateselect ( sqlselect select , reldatatype targetrowtype ) { assert targetrowtype != null ;	Validates a SELECT statement.
private boolean isrolledupcolumnallowedinagg ( sqlidentifier identifier , sqlvalidatorscope scope , sqlcall aggcall , sqlnode parent ) { pair < string , string > pair = findtablecolumnpair ( identifier , scope ) ; if ( pair == null ) { return bool_ ; } string tablealias = pair . left ; string columnname = pair . right ; table table = findtable ( tablealias ) ; if ( table != null ) { return table . rolledupcolumnvalidinsideagg ( columnname , aggcall , parent , catalogreader . getconfig ( ) ) ; } return bool_ ; }	Returns true iff the given column is valid inside the given aggCall.
private boolean isrolledupcolumn ( sqlidentifier identifier , sqlvalidatorscope scope ) { pair < string , string > pair = findtablecolumnpair ( identifier , scope ) ; if ( pair == null ) { return bool_ ; } string tablealias = pair . left ; string columnname = pair . right ; table table = findtable ( tablealias ) ; if ( table != null ) { return table . isrolledup ( columnname ) ; } return bool_ ; }	Returns true iff the given column is actually rolled up.
private void validatemodality ( sqlnode query ) { final sqlmodality modality = deducemodality ( query ) ; if ( query instanceof sqlselect ) { final sqlselect select = ( sqlselect ) query ; validatemodality ( select , modality , bool_ ) ; } else if ( query . getkind ( ) == sqlkind . values ) { switch ( modality ) { case stream : throw newvalidationerror ( query , static . resource . cannotstreamvalues ( ) ) ; } } else { assert query . isa ( sqlkind . set_query ) ; final sqlcall call = ( sqlcall ) query ; for ( sqlnode operand : call . getoperandlist ( ) ) { if ( deducemodality ( operand ) != modality ) { throw newvalidationerror ( operand , static . resource . streamsetopinconsistentinputs ( ) ) ; } validatemodality ( operand ) ; } } }	Validates that a query can deliver the modality it promises.
private sqlmodality deducemodality ( sqlnode query ) { if ( query instanceof sqlselect ) { sqlselect select = ( sqlselect ) query ; return select . getmodifiernode ( sqlselectkeyword . stream ) != null ? sqlmodality . stream : sqlmodality . relation ; } else if ( query . getkind ( ) == sqlkind . values ) { return sqlmodality . relation ; } else { assert query . isa ( sqlkind . set_query ) ; final sqlcall call = ( sqlcall ) query ; return deducemodality ( call . getoperandlist ( ) . get ( num_ ) ) ; } }	Return the intended modality of a SELECT or set-op.
private boolean hassortedprefix ( selectscope scope , sqlnodelist orderlist ) { return issortcompatible ( scope , orderlist . get ( num_ ) , bool_ ) ; }	Returns whether the prefix is sorted.
protected void validateorderlist ( sqlselect select ) {	Validates the ORDER BY clause of a SELECT statement.
private void validategroupbyitem ( sqlselect select , sqlnode groupbyitem ) { final sqlvalidatorscope groupbyscope = getgroupscope ( select ) ; groupbyscope . validateexpr ( groupbyitem ) ; }	Validates an item in the GROUP BY clause of a SELECT statement.
private void validateorderitem ( sqlselect select , sqlnode orderitem ) { switch ( orderitem . getkind ( ) ) { case descending : validatefeature ( resource . sqlconformance_orderbydesc ( ) , orderitem . getparserposition ( ) ) ; validateorderitem ( select , ( ( sqlcall ) orderitem ) . operand ( num_ ) ) ; return ; } final sqlvalidatorscope orderscope = getorderscope ( select ) ; validateexpr ( orderitem , orderscope ) ; }	Validates an item in the ORDER BY clause of a SELECT statement.
protected void validategroupclause ( sqlselect select ) { sqlnodelist grouplist = select . getgroup ( ) ; if ( grouplist == null ) { return ; } final string clause = str_ ; validatenoaggs ( aggoroverfinder , grouplist , clause ) ; final sqlvalidatorscope groupscope = getgroupscope ( select ) ; inferunknowntypes ( unknowntype , groupscope , grouplist ) ;	Validates the GROUP BY clause of a SELECT statement.
private void handlescalarsubquery ( sqlselect parentselect , sqlselect selectitem , list < sqlnode > expandedselectitems , set < string > aliaslist , list < map . entry < string , reldatatype > > fieldlist ) {	Processes SubQuery found in Select list.
protected reldatatype createtargetrowtype ( sqlvalidatortable table , sqlnodelist targetcolumnlist , boolean append ) { reldatatype baserowtype = table . getrowtype ( ) ; if ( targetcolumnlist == null ) { return baserowtype ; } list < reldatatypefield > targetfields = baserowtype . getfieldlist ( ) ; final list < map . entry < string , reldatatype > > fields = new arraylist < > ( ) ; if ( append ) { for ( reldatatypefield targetfield : targetfields ) { fields . add ( pair . of ( sqlutil . derivealiasfromordinal ( fields . size ( ) ) , targetfield . gettype ( ) ) ) ; } } final set < integer > assignedfields = new hashset < > ( ) ; final relopttable relopttable = table instanceof relopttable ? ( ( relopttable ) table ) : null ; for ( sqlnode node : targetcolumnlist ) { sqlidentifier id = ( sqlidentifier ) node ; reldatatypefield targetfield = sqlvalidatorutil . gettargetfield ( baserowtype , typefactory , id , catalogreader , relopttable ) ; if ( targetfield == null ) { throw newvalidationerror ( id , resource . unknowntargetcolumn ( id . tostring ( ) ) ) ; } if ( ! assignedfields . add ( targetfield . getindex ( ) ) ) { throw newvalidationerror ( id , resource . duplicatetargetcolumn ( targetfield . getname ( ) ) ) ; } fields . add ( targetfield ) ; } return typefactory . createstructtype ( fields ) ; }	Derives a row-type for INSERT and UPDATE operations.
private void checkconstraint ( sqlvalidatortable validatortable , sqlnode source , reldatatype targetrowtype ) { final modifiableviewtable modifiableviewtable = validatortable . unwrap ( modifiableviewtable . class ) ; if ( modifiableviewtable != null && source instanceof sqlcall ) { final table table = modifiableviewtable . unwrap ( table . class ) ; final reldatatype tablerowtype = table . getrowtype ( typefactory ) ; final list < reldatatypefield > tablefields = tablerowtype . getfieldlist ( ) ;	Validates insert values against the constraint of a modifiable view.
private void checkconstraint ( sqlvalidatortable validatortable , sqlupdate update , reldatatype targetrowtype ) { final modifiableviewtable modifiableviewtable = validatortable . unwrap ( modifiableviewtable . class ) ; if ( modifiableviewtable != null ) { final table table = modifiableviewtable . unwrap ( table . class ) ; final reldatatype tablerowtype = table . getrowtype ( typefactory ) ; final map < integer , rexnode > projectmap = reloptutil . getcolumnconstraints ( modifiableviewtable , targetrowtype , typefactory ) ; final map < string , integer > nametoindex = sqlvalidatorutil . mapnametoindex ( tablerowtype . getfieldlist ( ) ) ;	Validates updates against the constraint of a modifiable view.
private sqlnode getnthexpr ( sqlnode query , int ordinal , int sourcecount ) { if ( query instanceof sqlinsert ) { sqlinsert insert = ( sqlinsert ) query ; if ( insert . gettargetcolumnlist ( ) != null ) { return insert . gettargetcolumnlist ( ) . get ( ordinal ) ; } else { return getnthexpr ( insert . getsource ( ) , ordinal , sourcecount ) ; } } else if ( query instanceof sqlupdate ) { sqlupdate update = ( sqlupdate ) query ; if ( update . gettargetcolumnlist ( ) != null ) { return update . gettargetcolumnlist ( ) . get ( ordinal ) ; } else if ( update . getsourceexpressionlist ( ) != null ) { return update . getsourceexpressionlist ( ) . get ( ordinal ) ; } else { return getnthexpr ( update . getsourceselect ( ) , ordinal , sourcecount ) ; } } else if ( query instanceof sqlselect ) { sqlselect select = ( sqlselect ) query ; if ( select . getselectlist ( ) . size ( ) == sourcecount ) { return select . getselectlist ( ) . get ( ordinal ) ; } else { return query ;	Locates the n'th expression in an INSERT or UPDATE query.
private void validateaccess ( sqlnode node , sqlvalidatortable table , sqlaccessenum requiredaccess ) { if ( table != null ) { sqlaccesstype access = table . getallowedaccess ( ) ; if ( ! access . allowsaccess ( requiredaccess ) ) { throw newvalidationerror ( node , resource . accessnotallowed ( requiredaccess . name ( ) , table . getqualifiedname ( ) . tostring ( ) ) ) ; } } }	Validates access to a table.
protected void validatevalues ( sqlcall node , reldatatype targetrowtype , final sqlvalidatorscope scope ) { assert node . getkind ( ) == sqlkind . values ; final list < sqlnode > operands = node . getoperandlist ( ) ; for ( sqlnode operand : operands ) { if ( ! ( operand . getkind ( ) == sqlkind . row ) ) { throw util . needtoimplement ( str_ ) ; } sqlcall rowconstructor = ( sqlcall ) operand ; if ( conformance . isinsertsubsetcolumnsallowed ( ) && targetrowtype . isstruct ( ) && rowconstructor . operandcount ( ) < targetrowtype . getfieldcount ( ) ) { targetrowtype = typefactory . createstructtype ( targetrowtype . getfieldlist ( ) . sublist ( num_ , rowconstructor . operandcount ( ) ) ) ; } else if ( targetrowtype . isstruct ( ) && rowconstructor . operandcount ( ) != targetrowtype . getfieldcount ( ) ) { return ; } inferunknowntypes ( targetrowtype , scope , rowconstructor ) ; if ( targetrowtype . isstruct ( ) ) { for ( pair < sqlnode , reldatatypefield > pair : pair . zip ( rowconstructor . getoperandlist ( ) , targetrowtype . getfieldlist ( ) ) ) { if ( ! pair . right . gettype ( ) . isnullable ( ) && sqlutil . isnullliteral ( pair . left , bool_ ) ) { throw newvalidationerror ( node , resource . columnnotnullable ( pair . right . getname ( ) ) ) ; } } } } for ( sqlnode operand : operands ) { operand . validate ( this , scope ) ; }	Validates a VALUES clause.
private static string alias ( sqlnode item ) { assert item instanceof sqlcall ; assert item . getkind ( ) == sqlkind . as ; final sqlidentifier identifier = ( ( sqlcall ) item ) . operand ( num_ ) ; return identifier . getsimple ( ) ; }	Returns the alias of a "expr AS alias" expression.
public static outputstreamandpath createentropyaware ( filesystem fs , path path , writemode writemode ) throws ioexception {	Handles entropy injection across regular and entropy-aware file systems. If the given file system is entropy-aware (a implements {.
@ override public fsstatebackend configure ( configuration config , classloader classloader ) { return new fsstatebackend ( this , config , classloader ) ; }	Creates a copy of this state backend that uses the values defined in the configurationfor fields where that were not specified in this state backend.
public static list < resolverrule > getresolverrules ( ) { return arrays . aslist ( resolverrules . lookup_call_by_name , resolverrules . flatten_star_reference , resolverrules . expand_column_functions , resolverrules . over_windows , resolverrules . field_resolve , resolverrules . flatten_call , resolverrules . resolve_call_by_arguments , resolverrules . verify_no_more_unresolved_expressions ) ; }	List of rules that will be applied during expression resolution.
public logicalwindow resolvegroupwindow ( groupwindow window ) { expression alias = window . getalias ( ) ; if ( ! ( alias instanceof unresolvedreferenceexpression ) ) { throw new validationexception ( str_ ) ; } final string windowname = ( ( unresolvedreferenceexpression ) alias ) . getname ( ) ; list < expression > resolvedtimefieldexpression = prepareexpressions ( collections . singletonlist ( window . gettimefield ( ) ) ) ; if ( resolvedtimefieldexpression . size ( ) != num_ ) { throw new validationexception ( str_ ) ; } plannerexpression timefield = resolvedtimefieldexpression . get ( num_ ) . accept ( bridgeconverter ) ;	Converts an API class to a logical window for planning with expressions already resolved.
public void start ( slotactions initialslotactions ) { this . slotactions = preconditions . checknotnull ( initialslotactions ) ; timerservice . start ( this ) ; started = bool_ ; }	Start the task slot table with the given slot actions.
public boolean allocateslot ( int index , jobid jobid , allocationid allocationid , time slottimeout ) { checkinit ( ) ; taskslot taskslot = taskslots . get ( index ) ; boolean result = taskslot . allocate ( jobid , allocationid ) ; if ( result ) {	Allocate the slot with the given index for the given job and allocation id.
public int freeslot ( allocationid allocationid , throwable cause ) throws slotnotfoundexception { checkinit ( ) ; taskslot taskslot = gettaskslot ( allocationid ) ; if ( taskslot != null ) { if ( log . isdebugenabled ( ) ) { log . debug ( str_ , taskslot , cause ) ; } else { log . info ( str_ , taskslot ) ; } final jobid jobid = taskslot . getjobid ( ) ; if ( taskslot . markfree ( ) ) {	Tries to free the slot.
public boolean isvalidtimeout ( allocationid allocationid , uuid ticket ) { checkinit ( ) ; return timerservice . isvalid ( allocationid , ticket ) ; }	Check whether the timeout with ticket is valid for the given allocation id.
public boolean isallocated ( int index , jobid jobid , allocationid allocationid ) { taskslot taskslot = taskslots . get ( index ) ; return taskslot . isallocated ( jobid , allocationid ) ; }	Check whether the slot for the given index is allocated for the given job and allocation id.
public boolean trymarkslotactive ( jobid jobid , allocationid allocationid ) { taskslot taskslot = gettaskslot ( allocationid ) ; if ( taskslot != null && taskslot . isallocated ( jobid , allocationid ) ) { return taskslot . markactive ( ) ; } else { return bool_ ; } }	Try to mark the specified slot as active if it has been allocated by the given job.
public boolean addtask ( task task ) throws slotnotfoundexception , slotnotactiveexception { preconditions . checknotnull ( task ) ; taskslot taskslot = gettaskslot ( task . getallocationid ( ) ) ; if ( taskslot != null ) { if ( taskslot . isactive ( task . getjobid ( ) , task . getallocationid ( ) ) ) { if ( taskslot . add ( task ) ) { taskslotmappings . put ( task . getexecutionid ( ) , new taskslotmapping ( task , taskslot ) ) ; return bool_ ; } else { return bool_ ; } } else { throw new slotnotactiveexception ( task . getjobid ( ) , task . getallocationid ( ) ) ; } } else { throw new slotnotfoundexception ( task . getallocationid ( ) ) ; } }	Add the given task to the slot identified by the task's allocation id.
public task removetask ( executionattemptid executionattemptid ) { checkinit ( ) ; taskslotmapping taskslotmapping = taskslotmappings . remove ( executionattemptid ) ; if ( taskslotmapping != null ) { task task = taskslotmapping . gettask ( ) ; taskslot taskslot = taskslotmapping . gettaskslot ( ) ; taskslot . remove ( task . getexecutionid ( ) ) ; if ( taskslot . isreleasing ( ) && taskslot . isempty ( ) ) { slotactions . freeslot ( taskslot . getallocationid ( ) ) ; } return task ; } else { return null ; } }	Remove the task with the given execution attempt id from its task slot.
public task gettask ( executionattemptid executionattemptid ) { taskslotmapping taskslotmapping = taskslotmappings . get ( executionattemptid ) ; if ( taskslotmapping != null ) { return taskslotmapping . gettask ( ) ; } else { return null ; } }	Get the task for the given execution attempt id.
public kafka properties ( properties properties ) { preconditions . checknotnull ( properties ) ; if ( this . kafkaproperties == null ) { this . kafkaproperties = new hashmap < > ( ) ; } this . kafkaproperties . clear ( ) ; properties . foreach ( ( k , v ) -> this . kafkaproperties . put ( ( string ) k , ( string ) v ) ) ; return this ; }	Sets the configuration properties for the Kafka consumer.
public kafka property ( string key , string value ) { preconditions . checknotnull ( key ) ; preconditions . checknotnull ( value ) ; if ( this . kafkaproperties == null ) { this . kafkaproperties = new hashmap < > ( ) ; } kafkaproperties . put ( key , value ) ; return this ; }	Adds a configuration properties for the Kafka consumer.
public kafka startfromspecificoffsets ( map < integer , long > specificoffsets ) { this . startupmode = startupmode . specific_offsets ; this . specificoffsets = preconditions . checknotnull ( specificoffsets ) ; return this ; }	Configures to start reading partitions from specific offsets, set independently for each partition.Resets previously set offsets.
public kafka startfromspecificoffset ( int partition , long specificoffset ) { this . startupmode = startupmode . specific_offsets ; if ( this . specificoffsets == null ) { this . specificoffsets = new hashmap < > ( ) ; } this . specificoffsets . put ( partition , specificoffset ) ; return this ; }	Configures to start reading partitions from specific offsets and specifies the given offset forthe given partition.
public kafka sinkpartitionercustom ( class < ? extends flinkkafkapartitioner > partitionerclass ) { sinkpartitionertype = connector_sink_partitioner_value_custom ; sinkpartitionerclass = preconditions . checknotnull ( partitionerclass ) ; return this ; }	Configures how to partition records from Flink's partitions into Kafka's partitions. This strategy allows for a custom partitioner by providing an implementationof {.
public static int assignkeytoparalleloperator ( object key , int maxparallelism , int parallelism ) { return computeoperatorindexforkeygroup ( maxparallelism , parallelism , assigntokeygroup ( key , maxparallelism ) ) ; }	Assigns the given key to a parallel operator index.
public static int computedefaultmaxparallelism ( int operatorparallelism ) { checkparallelismpreconditions ( operatorparallelism ) ; return math . min ( math . max ( mathutils . rounduptopoweroftwo ( operatorparallelism + ( operatorparallelism / num_ ) ) , default_lower_bound_max_parallelism ) , upper_bound_max_parallelism ) ; }	Computes a default maximum parallelism from the operator parallelism.
@ override public jobexecutionresult executeplan ( plan plan ) throws exception { if ( plan == null ) { throw new illegalargumentexception ( str_ ) ; } synchronized ( this . lock ) {	Executes the given program on a local runtime and waits for the job to finish.
public static jobexecutionresult execute ( program pa , string ... args ) throws exception { return execute ( pa . getplan ( args ) ) ; }	Executes the given program.
public static string optimizerplanasjson ( plan plan ) throws exception { final int parallelism = plan . getdefaultparallelism ( ) == executionconfig . parallelism_default ? num_ : plan . getdefaultparallelism ( ) ; optimizer pc = new optimizer ( new datastatistics ( ) , new configuration ( ) ) ; pc . setdefaultparallelism ( parallelism ) ; optimizedplan op = pc . compile ( plan ) ; return new planjsondumpgenerator ( ) . getoptimizerplanasjson ( op ) ; }	Creates a JSON representation of the given dataflow's execution plan.
public static string getplanasjson ( plan plan ) { list < datasinknode > sinks = optimizer . createpreoptimizedplan ( plan ) ; return new planjsondumpgenerator ( ) . getpactplanasjson ( sinks ) ; }	Creates a JSON representation of the given dataflow plan.
public final void resolve ( x value ) { preconditions . checkstate ( ! resolved , str_ ) ; this . value = preconditions . checknotnull ( value ) ; this . resolved = bool_ ; }	Resolves this parameter for the given value.
protected shardconsumer createshardconsumer ( integer subscribedshardstateindex , streamshardhandle subscribedshard , sequencenumber lastsequencenum , shardmetricsreporter shardmetricsreporter ) { return new shardconsumer < > ( this , subscribedshardstateindex , subscribedshard , lastsequencenum , this . kinesisproxyfactory . create ( configprops ) , shardmetricsreporter ) ; }	Create a new shard consumer.Override this method to customize shard consumer behavior in subclasses.
public hashmap < streamshardmetadata , sequencenumber > snapshotstate ( ) {	Creates a snapshot of the current last processed sequence numbers of each subscribed shard.
public void advancelastdiscoveredshardofstream ( string stream , string shardid ) { string lastseenshardidofstream = this . subscribedstreamstolastdiscoveredshardids . get ( stream ) ;	Updates the last discovered shard of a subscribed stream; only updates if the update is valid.
public int registernewsubscribedshardstate ( kinesisstreamshardstate newsubscribedshardstate ) { synchronized ( checkpointlock ) { subscribedshardsstate . add ( newsubscribedshardstate ) ;	Register a new subscribed shard state.
@ visiblefortesting protected void emitwatermark ( ) { log . debug ( str_ , indexofthisconsumersubtask , getcurrenttimemillis ( ) ) ; long potentialwatermark = long . max_value ; long idletime = ( shardidleintervalmillis > num_ ) ? getcurrenttimemillis ( ) - shardidleintervalmillis : long . max_value ; for ( map . entry < integer , shardwatermarkstate > e : shardwatermarks . entryset ( ) ) {	Called periodically to emit a watermark.
public graphanalyticbase < k , vv , ev , t > setparallelism ( int parallelism ) { preconditions . checkargument ( parallelism > num_ || parallelism == parallelism_default , str_ ) ; this . parallelism = parallelism ; return this ; }	Set the parallelism for this analytic's operators.
public static string createrandomname ( string prefix ) { preconditions . checknotnull ( prefix , str_ ) ; long nameoffset ;	Creates a random name of the form prefix_X, where X is an increasing number.
@ override public void dispose ( ) throws exception { exception exception = null ; streamtask < ? , ? > containingtask = getcontainingtask ( ) ; closeableregistry taskcloseableregistry = containingtask != null ? containingtask . getcancelables ( ) : null ; try { if ( taskcloseableregistry == null || taskcloseableregistry . unregistercloseable ( operatorstatebackend ) ) { operatorstatebackend . close ( ) ; } } catch ( exception e ) { exception = e ; } try { if ( taskcloseableregistry == null || taskcloseableregistry . unregistercloseable ( keyedstatebackend ) ) { keyedstatebackend . close ( ) ; } } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } try { if ( operatorstatebackend != null ) { operatorstatebackend . dispose ( ) ; } } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } try { if ( keyedstatebackend != null ) { keyedstatebackend . dispose ( ) ; } } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } if ( exception != null ) { throw exception ; } }	This method is called at the very end of the operator's life, both in the case of a successfulcompletion of the operation, and in the case of a failure and canceling.
public void snapshotstate ( statesnapshotcontext context ) throws exception { final keyedstatebackend < ? > keyedstatebackend = getkeyedstatebackend ( ) ;	Stream operators with state, which want to participate in a snapshot need to override this hook method.
public void putproperties ( map < string , string > properties ) { for ( map . entry < string , string > property : properties . entryset ( ) ) { put ( property . getkey ( ) , property . getvalue ( ) ) ; } }	Adds a set of properties.
public void putproperties ( descriptorproperties otherproperties ) { for ( map . entry < string , string > otherproperty : otherproperties . properties . entryset ( ) ) { put ( otherproperty . getkey ( ) , otherproperty . getvalue ( ) ) ; } }	Adds a set of descriptor properties.
public void putclass ( string key , class < ? > clazz ) { checknotnull ( key ) ; checknotnull ( clazz ) ; final string error = instantiationutil . checkforinstantiationerror ( clazz ) ; if ( error != null ) { throw new validationexception ( str_ + clazz . getname ( ) + str_ + error ) ; } put ( key , clazz . getname ( ) ) ; }	Adds a class under the given key.
public void putstring ( string key , string str ) { checknotnull ( key ) ; checknotnull ( str ) ; put ( key , str ) ; }	Adds a string under the given key.
public void putboolean ( string key , boolean b ) { checknotnull ( key ) ; put ( key , boolean . tostring ( b ) ) ; }	Adds a boolean under the given key.
public void putlong ( string key , long l ) { checknotnull ( key ) ; put ( key , long . tostring ( l ) ) ; }	Adds a long under the given key.
public void putint ( string key , int i ) { checknotnull ( key ) ; put ( key , integer . tostring ( i ) ) ; }	Adds an integer under the given key.
public void putcharacter ( string key , char c ) { checknotnull ( key ) ; put ( key , character . tostring ( c ) ) ; }	Adds a character under the given key.
public void puttableschema ( string key , tableschema schema ) { checknotnull ( key ) ; checknotnull ( schema ) ; final string [ ] fieldnames = schema . getfieldnames ( ) ; final typeinformation < ? > [ ] fieldtypes = schema . getfieldtypes ( ) ; final list < list < string > > values = new arraylist < > ( ) ; for ( int i = num_ ; i < schema . getfieldcount ( ) ; i ++ ) { values . add ( arrays . aslist ( fieldnames [ i ] , typestringutils . writetypeinfo ( fieldtypes [ i ] ) ) ) ; } putindexedfixedproperties ( key , arrays . aslist ( table_schema_name , table_schema_type ) , values ) ; }	Adds a table schema under the given key.
public void putindexedvariableproperties ( string key , list < map < string , string > > subkeyvalues ) { checknotnull ( key ) ; checknotnull ( subkeyvalues ) ; for ( int idx = num_ ; idx < subkeyvalues . size ( ) ; idx ++ ) { final map < string , string > values = subkeyvalues . get ( idx ) ; for ( map . entry < string , string > value : values . entryset ( ) ) { put ( key + str_ + idx + str_ + value . getkey ( ) , value . getvalue ( ) ) ; } } }	Adds an indexed mapping of properties under a common key.
public intermediateresultpartition getpartitionbyid ( intermediateresultpartitionid resultpartitionid ) {	Returns the partition with the given ID.
public string get ( string key ) { addtodefaults ( key , null ) ; unrequestedparameters . remove ( key ) ; return data . get ( key ) ; }	Returns the String value for the given key.If the key does not exist it will return null.
public string get ( string key , string defaultvalue ) { addtodefaults ( key , defaultvalue ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return value ; } }	Returns the String value for the given key.If the key does not exist it will return the given default value.
public boolean has ( string value ) { addtodefaults ( value , null ) ; unrequestedparameters . remove ( value ) ; return data . containskey ( value ) ; }	Check if value is set.
public int getint ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return integer . parseint ( value ) ; }	Returns the Integer value for the given key.The method fails if the key does not exist or the value is not an Integer.
public long getlong ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return long . parselong ( value ) ; }	Returns the Long value for the given key.The method fails if the key does not exist.
public float getfloat ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return float . valueof ( value ) ; }	Returns the Float value for the given key.The method fails if the key does not exist.
public float getfloat ( string key , float defaultvalue ) { addtodefaults ( key , float . tostring ( defaultvalue ) ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return float . valueof ( value ) ; } }	Returns the Float value for the given key.
public double getdouble ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return double . valueof ( value ) ; }	Returns the Double value for the given key.The method fails if the key does not exist.
public double getdouble ( string key , double defaultvalue ) { addtodefaults ( key , double . tostring ( defaultvalue ) ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return double . valueof ( value ) ; } }	Returns the Double value for the given key.
public boolean getboolean ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return boolean . valueof ( value ) ; }	Returns the Boolean value for the given key.The method fails if the key does not exist.
public boolean getboolean ( string key , boolean defaultvalue ) { addtodefaults ( key , boolean . tostring ( defaultvalue ) ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return boolean . valueof ( value ) ; } }	Returns the Boolean value for the given key.
public short getshort ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return short . valueof ( value ) ; }	Returns the Short value for the given key.The method fails if the key does not exist.
public short getshort ( string key , short defaultvalue ) { addtodefaults ( key , short . tostring ( defaultvalue ) ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return short . valueof ( value ) ; } }	Returns the Short value for the given key.
public byte getbyte ( string key ) { addtodefaults ( key , null ) ; string value = getrequired ( key ) ; return byte . valueof ( value ) ; }	Returns the Byte value for the given key.The method fails if the key does not exist.
public byte getbyte ( string key , byte defaultvalue ) { addtodefaults ( key , byte . tostring ( defaultvalue ) ) ; string value = get ( key ) ; if ( value == null ) { return defaultvalue ; } else { return byte . valueof ( value ) ; } }	Returns the Byte value for the given key.
private static string getfqdnhostname ( inetaddress inetaddress ) { string fqdnhostname ; try { fqdnhostname = inetaddress . getcanonicalhostname ( ) ; } catch ( throwable t ) { log . warn ( str_ + str_ ) ; log . debug ( str_ , t ) ; fqdnhostname = inetaddress . gethostaddress ( ) ; } return fqdnhostname ; }	Gets the fully qualified hostname of the TaskManager based on the network address.
public static string gethostname ( inetaddress inetaddress ) { string hostname ; string fqdnhostname = getfqdnhostname ( inetaddress ) ; if ( fqdnhostname . equals ( inetaddress . gethostaddress ( ) ) ) {	Gets the hostname of the TaskManager based on the network address.
public jdbcappendtablesinkbuilder setparametertypes ( typeinformation < ? > ... types ) { int [ ] ty = new int [ types . length ] ; for ( int i = num_ ; i < types . length ; ++ i ) { ty [ i ] = jdbctypeutil . typeinformationtosqltype ( types [ i ] ) ; } this . parametertypes = ty ; return this ; }	Specify the type of the rows that the sink will be accepting.
public jdbcappendtablesink build ( ) { preconditions . checknotnull ( parametertypes , str_ + str_ ) ; jdbcoutputformat format = jdbcoutputformat . buildjdbcoutputformat ( ) . setusername ( username ) . setpassword ( password ) . setdburl ( dburl ) . setquery ( query ) . setdrivername ( drivername ) . setbatchinterval ( batchsize ) . setsqltypes ( parametertypes ) . finish ( ) ; return new jdbcappendtablesink ( format ) ; }	Finalizes the configuration and checks validity.
@ suppresswarnings ( { str_ , str_ } ) private static < t > typeserializersnapshot < t > configureforbackwardscompatibility ( typeserializersnapshot < ? > snapshot , typeserializer < ? > serializer ) { typeserializersnapshot < t > typedsnapshot = ( typeserializersnapshot < t > ) snapshot ; typeserializer < t > typedserializer = ( typeserializer < t > ) serializer ; if ( snapshot instanceof typeserializerconfigsnapshot ) { ( ( typeserializerconfigsnapshot < t > ) typedsnapshot ) . setpriorserializer ( typedserializer ) ; } return typedsnapshot ; }	Utility method to bind the serializer and serializer snapshot to a commongeneric type variable.
public static < t > serializedcheckpointdata [ ] fromdeque ( arraydeque < tuple2 < long , set < t > > > checkpoints , typeserializer < t > serializer ) throws ioexception { return fromdeque ( checkpoints , serializer , new dataoutputserializer ( num_ ) ) ; }	Converts a list of checkpoints with elements into an array of SerializedCheckpointData.
public static < t > serializedcheckpointdata [ ] fromdeque ( arraydeque < tuple2 < long , set < t > > > checkpoints , typeserializer < t > serializer , dataoutputserializer outputbuffer ) throws ioexception { serializedcheckpointdata [ ] serializedcheckpoints = new serializedcheckpointdata [ checkpoints . size ( ) ] ; int pos = num_ ; for ( tuple2 < long , set < t > > checkpoint : checkpoints ) { outputbuffer . clear ( ) ; set < t > checkpointids = checkpoint . f1 ; for ( t id : checkpointids ) { serializer . serialize ( id , outputbuffer ) ; } serializedcheckpoints [ pos ++ ] = new serializedcheckpointdata ( checkpoint . f0 , outputbuffer . getcopyofbuffer ( ) , checkpointids . size ( ) ) ; } return serializedcheckpoints ; }	Converts a list of checkpoints into an array of SerializedCheckpointData.
public static < t > arraydeque < tuple2 < long , set < t > > > todeque ( serializedcheckpointdata [ ] data , typeserializer < t > serializer ) throws ioexception { arraydeque < tuple2 < long , set < t > > > deque = new arraydeque < > ( data . length ) ; datainputdeserializer deser = null ; for ( serializedcheckpointdata checkpoint : data ) { byte [ ] serializeddata = checkpoint . getserializeddata ( ) ; if ( deser == null ) { deser = new datainputdeserializer ( serializeddata , num_ , serializeddata . length ) ; } else { deser . setbuffer ( serializeddata ) ; } final set < t > ids = new hashset < > ( checkpoint . getnumids ( ) ) ; final int numids = checkpoint . getnumids ( ) ; for ( int i = num_ ; i < numids ; i ++ ) { ids . add ( serializer . deserialize ( deser ) ) ; } deque . addlast ( new tuple2 < long , set < t > > ( checkpoint . checkpointid , ids ) ) ; } return deque ; }	De-serializes an array of SerializedCheckpointData back into an ArrayDeque of element checkpoints.
private static file generatedefaultconfigfile ( ) { final file jaasconffile ; try { path jaasconfpath = files . createtempfile ( str_ , str_ ) ; try ( inputstream resourcestream = jaasmodule . class . getclassloader ( ) . getresourceasstream ( jaas_conf_resource_name ) ) { files . copy ( resourcestream , jaasconfpath , standardcopyoption . replace_existing ) ; } jaasconffile = jaasconfpath . tofile ( ) ; jaasconffile . deleteonexit ( ) ; } catch ( ioexception e ) { throw new runtimeexception ( str_ , e ) ; } return jaasconffile ; }	Generate the default JAAS config file.
public static list < expression > renamecolumns ( list < string > inputfields , list < expression > newaliases ) { linkedhashmap < string , expression > finalfields = new linkedhashmap < > ( ) ; inputfields . foreach ( field -> finalfields . put ( field , new unresolvedreferenceexpression ( field ) ) ) ; newaliases . foreach ( expr -> { string name = expr . accept ( renamecolumnextractor ) ; finalfields . put ( name , expr ) ; } ) ; return new arraylist < > ( finalfields . values ( ) ) ; }	Creates a projection list that renames existing columns to new names.
public static list < expression > dropfields ( list < string > inputfields , list < expression > dropexpressions ) { set < string > columnstodrop = dropexpressions . stream ( ) . map ( expr -> expr . accept ( dropcolumnsextractor ) ) . collect ( collectors . toset ( ) ) ; columnstodrop . foreach ( c -> { if ( ! inputfields . contains ( c ) ) { throw new validationexception ( format ( str_ , c ) ) ; } } ) ; return inputfields . stream ( ) . filter ( oldname -> ! columnstodrop . contains ( oldname ) ) . map ( unresolvedreferenceexpression :: new ) . collect ( collectors . tolist ( ) ) ; }	Creates a projection list that removes given columns.
public static < t > dataset < tuple2 < integer , long > > countelementsperpartition ( dataset < t > input ) { return input . mappartition ( new richmappartitionfunction < t , tuple2 < integer , long > > ( ) { @ override public void mappartition ( iterable < t > values , collector < tuple2 < integer , long > > out ) throws exception { long counter = num_ ; for ( t value : values ) { counter ++ ; } out . collect ( new tuple2 < > ( getruntimecontext ( ) . getindexofthissubtask ( ) , counter ) ) ; } } ) ; }	Method that goes over all the elements in each partition in order to retrievethe total number of elements.
public static < t > partitionoperator < t > partitionbyrange ( dataset < t > input , datadistribution distribution , int ... fields ) { return new partitionoperator < > ( input , partitionoperatorbase . partitionmethod . range , new keys . expressionkeys < > ( fields , input . gettype ( ) , bool_ ) , distribution , utils . getcalllocationname ( ) ) ; }	Range-partitions a DataSet on the specified tuple field positions.
public static < t , k extends comparable < k > > partitionoperator < t > partitionbyrange ( dataset < t > input , datadistribution distribution , keyselector < t , k > keyextractor ) { final typeinformation < k > keytype = typeextractor . getkeyselectortypes ( keyextractor , input . gettype ( ) ) ; return new partitionoperator < > ( input , partitionoperatorbase . partitionmethod . range , new keys . selectorfunctionkeys < > ( input . clean ( keyextractor ) , input . gettype ( ) , keytype ) , distribution , utils . getcalllocationname ( ) ) ; }	Range-partitions a DataSet using the specified key selector function.
public static < r extends tuple , t extends tuple > r summarize ( dataset < t > input ) throws exception { if ( ! input . gettype ( ) . istupletype ( ) ) { throw new illegalargumentexception ( str_ ) ; } final tupletypeinfobase < ? > intype = ( tupletypeinfobase < ? > ) input . gettype ( ) ; dataset < tuplesummaryaggregator < r > > result = input . mappartition ( new mappartitionfunction < t , tuplesummaryaggregator < r > > ( ) { @ override public void mappartition ( iterable < t > values , collector < tuplesummaryaggregator < r > > out ) throws exception { tuplesummaryaggregator < r > aggregator = summaryaggregatorfactory . create ( intype ) ; for ( tuple value : values ) { aggregator . aggregate ( value ) ; } out . collect ( aggregator ) ; } } ) . reduce ( new reducefunction < tuplesummaryaggregator < r > > ( ) { @ override public tuplesummaryaggregator < r > reduce ( tuplesummaryaggregator < r > agg1 , tuplesummaryaggregator < r > agg2 ) throws exception { agg1 . combine ( agg2 ) ; return agg1 ; } } ) ; return result . collect ( ) . get ( num_ ) . result ( ) ; }	Summarize a DataSet of Tuples by collecting single pass statistics for all columns. Example usage: {.
public csvreader ignorecomments ( string commentprefix ) { if ( commentprefix == null || commentprefix . length ( ) == num_ ) { throw new illegalargumentexception ( str_ ) ; } this . commentprefix = commentprefix ; return this ; }	Configures the string that starts comments.By default comments will be treated as invalid lines.This function only recognizes comments which start at the beginning of the line!.
public < t > datasource < t > pojotype ( class < t > pojotype , string ... pojofields ) { preconditions . checknotnull ( pojotype , str_ ) ; preconditions . checknotnull ( pojofields , str_ ) ; final typeinformation < t > ti = typeextractor . createtypeinfo ( pojotype ) ; if ( ! ( ti instanceof pojotypeinfo ) ) { throw new illegalargumentexception ( str_ + ti ) ; } final pojotypeinfo < t > pti = ( pojotypeinfo < t > ) ti ; csvinputformat < t > inputformat = new pojocsvinputformat < t > ( path , this . linedelimiter , this . fielddelimiter , pti , pojofields , this . includedmask ) ; configureinputformat ( inputformat ) ; return new datasource < t > ( executioncontext , inputformat , pti , utils . getcalllocationname ( ) ) ; }	Configures the reader to read the CSV data and parse it to the given type.
public static textelement code ( string text ) { textelement element = text ( text ) ; element . textstyles . add ( textstyle . code ) ; return element ; }	Creates a block of text formatted as code.
public void setanypartitioning ( fieldset partitionedfields ) { if ( partitionedfields == null ) { throw new nullpointerexception ( ) ; } this . partitioning = partitioningproperty . any_partitioning ; this . partitioningfields = partitionedfields ; this . ordering = null ; }	Sets these properties to request some partitioning on the given fields.
public void reset ( ) { this . partitioning = partitioningproperty . random_partitioned ; this . ordering = null ; this . partitioningfields = null ; this . datadistribution = null ; this . custompartitioner = null ; }	This method resets the properties to a state where no properties are given.
public void parameterizechannel ( channel channel , boolean globaldopchange , executionmode exchangemode , boolean breakpipeline ) {	Parametrizes the ship strategy fields of a channel such that the channel producesthe desired global properties.
public void addappconfigurationentry ( string name , appconfigurationentry ... entry ) { final appconfigurationentry [ ] existing = dynamicentries . get ( name ) ; final appconfigurationentry [ ] updated ; if ( existing == null ) { updated = arrays . copyof ( entry , entry . length ) ; } else { updated = merge ( existing , entry ) ; } dynamicentries . put ( name , updated ) ; }	Add entries for the given application name.
@ suppresswarnings ( str_ ) public final char getchar ( int index ) { final long pos = address + index ; if ( index >= num_ && pos <= addresslimit - num_ ) { return unsafe . getchar ( heapmemory , pos ) ; } else if ( address > addresslimit ) { throw new illegalstateexception ( str_ ) ; } else {	Reads a char value from the given position, in the system's native byte order.
@ suppresswarnings ( str_ ) public final void putchar ( int index , char value ) { final long pos = address + index ; if ( index >= num_ && pos <= addresslimit - num_ ) { unsafe . putchar ( heapmemory , pos , value ) ; } else if ( address > addresslimit ) { throw new illegalstateexception ( str_ ) ; } else {	Writes a char value to the given position, in the system's native byte order.
public final void putshort ( int index , short value ) { final long pos = address + index ; if ( index >= num_ && pos <= addresslimit - num_ ) { unsafe . putshort ( heapmemory , pos , value ) ; } else if ( address > addresslimit ) { throw new illegalstateexception ( str_ ) ; } else {	Writes the given short value into this buffer at the given position, usingthe native byte order of the system.
public final int compare ( memorysegment seg2 , int offset1 , int offset2 , int len ) { while ( len >= num_ ) { long l1 = this . getlongbigendian ( offset1 ) ; long l2 = seg2 . getlongbigendian ( offset2 ) ; if ( l1 != l2 ) { return ( l1 < l2 ) ^ ( l1 < num_ ) ^ ( l2 < num_ ) ? - num_ : num_ ; } offset1 += num_ ; offset2 += num_ ; len -= num_ ; } while ( len > num_ ) { int b1 = this . get ( offset1 ) & num_ ; int b2 = seg2 . get ( offset2 ) & num_ ; int cmp = b1 - b2 ; if ( cmp != num_ ) { return cmp ; } offset1 ++ ; offset2 ++ ; len -- ; } return num_ ; }	Compares two memory segment regions.
public final void swapbytes ( byte [ ] tempbuffer , memorysegment seg2 , int offset1 , int offset2 , int len ) { if ( ( offset1 | offset2 | len | ( tempbuffer . length - len ) ) >= num_ ) { final long thispos = this . address + offset1 ; final long otherpos = seg2 . address + offset2 ; if ( thispos <= this . addresslimit - len && otherpos <= seg2 . addresslimit - len ) {	Swaps bytes between two memory segments, using the given auxiliary buffer.
public final boolean equalto ( memorysegment seg2 , int offset1 , int offset2 , int length ) { int i = num_ ;	Equals two memory segment regions.
@ publicevolving public list < flatfielddescriptor > getflatfields ( string fieldexpression ) { list < flatfielddescriptor > result = new arraylist < flatfielddescriptor > ( ) ; this . getflatfields ( fieldexpression , num_ , result ) ; return result ; }	Returns the flat field descriptors for the given field expression.
@ publicevolving public typecomparator < t > createcomparator ( int [ ] logicalkeyfields , boolean [ ] orders , int logicalfieldoffset , executionconfig config ) { typecomparatorbuilder < t > builder = createtypecomparatorbuilder ( ) ; builder . initializetypecomparatorbuilder ( logicalkeyfields . length ) ; for ( int logicalkeyfieldindex = num_ ; logicalkeyfieldindex < logicalkeyfields . length ; logicalkeyfieldindex ++ ) { int logicalkeyfield = logicalkeyfields [ logicalkeyfieldindex ] ; int logicalfield = logicalfieldoffset ;	Generic implementation of the comparator creation. Composite types are supplying the infrastructureto create the actual comparators.
private path getyarnfilesdir ( final applicationid appid ) throws ioexception { final filesystem filesystem = filesystem . get ( yarnconfiguration ) ; final path homedir = filesystem . gethomedirectory ( ) ; return new path ( homedir , str_ + appid + str_ ) ; }	Returns the Path where the YARN application files should be uploaded to.
private void failsessionduringdeployment ( yarnclient yarnclient , yarnclientapplication yarnapplication ) { log . info ( str_ ) ; try { yarnclient . killapplication ( yarnapplication . getnewapplicationresponse ( ) . getapplicationid ( ) ) ; } catch ( exception e ) {	Kills YARN application and stops YARN client. Use this method to kill the App before it has been properly deployed.
private datastreamsink < t > setresources ( resourcespec minresources , resourcespec preferredresources ) { preconditions . checknotnull ( minresources , str_ ) ; preconditions . checknotnull ( preferredresources , str_ ) ; preconditions . checkargument ( minresources . isvalid ( ) && preferredresources . isvalid ( ) && minresources . lessthanorequal ( preferredresources ) , str_ ) ; transformation . setresources ( minresources , preferredresources ) ; return this ; }	Sets the minimum and preferred resources for this sink, and the lower and upper resource limits willbe considered in resource resize feature for future plan.
public void shutdown ( ) { synchronized ( lock ) {	Shuts down the file cache by cancelling all.
public future < path > createtmpfile ( string name , distributedcacheentry entry , jobid jobid , executionattemptid executionid ) throws exception { synchronized ( lock ) { map < string , future < path > > jobentries = entries . computeifabsent ( jobid , k -> new hashmap < > ( ) ) ;	If the file doesn't exists locally, retrieve the file from the blob-service.
public static networkenvironmentconfiguration fromconfiguration ( configuration configuration , long maxjvmheapmemory , boolean localtaskmanagercommunication , inetaddress taskmanageraddress ) { final int dataport = getdataport ( configuration ) ; final int pagesize = getpagesize ( configuration ) ; final int numberofnetworkbuffers = calculatenumberofnetworkbuffers ( configuration , maxjvmheapmemory ) ; final nettyconfig nettyconfig = createnettyconfig ( configuration , localtaskmanagercommunication , taskmanageraddress , dataport ) ; int initialrequestbackoff = configuration . getinteger ( taskmanageroptions . network_request_backoff_initial ) ; int maxrequestbackoff = configuration . getinteger ( taskmanageroptions . network_request_backoff_max ) ; int buffersperchannel = configuration . getinteger ( taskmanageroptions . network_buffers_per_channel ) ; int extrabufferspergate = configuration . getinteger ( taskmanageroptions . network_extra_buffers_per_gate ) ; boolean iscreditbased = nettyconfig != null && configuration . getboolean ( taskmanageroptions . network_credit_model ) ; return new networkenvironmentconfiguration ( numberofnetworkbuffers , pagesize , initialrequestbackoff , maxrequestbackoff , buffersperchannel , extrabufferspergate , iscreditbased , nettyconfig ) ; }	Utility method to extract network related parameters from the configuration and tosanity check them.
@ suppresswarnings ( str_ ) @ visiblefortesting public static boolean hasnewnetworkconfig ( final configuration config ) { return config . contains ( taskmanageroptions . network_buffers_memory_fraction ) || config . contains ( taskmanageroptions . network_buffers_memory_min ) || config . contains ( taskmanageroptions . network_buffers_memory_max ) || ! config . contains ( taskmanageroptions . network_num_buffers ) ; }	Returns whether the new network buffer memory configuration is present in the configurationobject, i.e.
@ suppresswarnings ( str_ ) private static int calculatenumberofnetworkbuffers ( configuration configuration , long maxjvmheapmemory ) { final int numberofnetworkbuffers ; if ( ! hasnewnetworkconfig ( configuration ) ) {	Calculates the number of network buffers based on configuration and jvm heap size.
public static int getpagesize ( configuration configuration ) { final int pagesize = checkeddowncast ( memorysize . parse ( configuration . getstring ( taskmanageroptions . memory_segment_size ) ) . getbytes ( ) ) ;	Parses the configuration to get the page size and validates the value.
public splitdataproperties < t > splitsorderedby ( int [ ] orderfields , order [ ] orders ) { if ( orderfields == null || orders == null ) { throw new invalidprogramexception ( str_ ) ; } else if ( orderfields . length == num_ ) { throw new invalidprogramexception ( str_ ) ; } else if ( orders . length == num_ ) { throw new invalidprogramexception ( str_ ) ; } else if ( orderfields . length != orders . length ) { throw new invalidprogramexception ( str_ ) ; } if ( this . splitgroupkeys != null ) { throw new invalidprogramexception ( str_ ) ; } this . splitordering = new ordering ( ) ; for ( int i = num_ ; i < orderfields . length ; i ++ ) { int pos = orderfields [ i ] ; int [ ] flatkeys = this . getallflatkeys ( new int [ ] { pos } ) ; for ( int key : flatkeys ) {	Defines that the data within an input split is sorted on the fields defined by the field positionsin the specified orders.All records of an input split must be emitted by the input format in the defined order.
public splitdataproperties < t > splitsorderedby ( string orderfields , order [ ] orders ) { if ( orderfields == null || orders == null ) { throw new invalidprogramexception ( str_ ) ; } string [ ] orderkeysa = orderfields . split ( str_ ) ; if ( orderkeysa . length == num_ ) { throw new invalidprogramexception ( str_ ) ; } else if ( orders . length == num_ ) { throw new invalidprogramexception ( str_ ) ; } else if ( orderkeysa . length != orders . length ) { throw new invalidprogramexception ( str_ ) ; } if ( this . splitgroupkeys != null ) { throw new invalidprogramexception ( str_ ) ; } this . splitordering = new ordering ( ) ; for ( int i = num_ ; i < orderkeysa . length ; i ++ ) { string keyexp = orderkeysa [ i ] ; keys . expressionkeys < t > ek = new keys . expressionkeys < > ( keyexp , this . type ) ; int [ ] flatkeys = ek . computelogicalkeypositions ( ) ; for ( int key : flatkeys ) {	Defines that the data within an input split is sorted on the fields defined by the field expressionsin the specified orders.
public static < t > t copy ( t from , kryo kryo , typeserializer < t > serializer ) { try { return kryo . copy ( from ) ; } catch ( kryoexception ke ) {	Tries to copy the given record from using the provided Kryo instance.
@ override public void open ( inputsplit ignored ) throws ioexception { this . session = cluster . connect ( ) ; this . resultset = session . execute ( query ) ; }	Opens a Session and executes the query.
private void redistributebuffers ( ) throws ioexception { assert thread . holdslock ( factorylock ) ;	Must be called from synchronized block.
public void close ( ) throws ioexception {	Closes all structures and deletes all temporary files.Even in the presence of failures, this method will try and continue closingfiles and deleting temporary files.
private aggregateoperator < t > aggregate ( aggregations agg , int field , string calllocationname ) { return new aggregateoperator < t > ( this , agg , field , calllocationname ) ; }	private helper that allows to set a different call location name.
public arraylist < memorysegment > resetoverflowbuckets ( ) { this . numoverflowsegments = num_ ; this . nextoverflowbucket = num_ ; arraylist < memorysegment > result = new arraylist < memorysegment > ( this . overflowsegments . length ) ; for ( int i = num_ ; i < this . overflowsegments . length ; i ++ ) { if ( this . overflowsegments [ i ] != null ) { result . add ( this . overflowsegments [ i ] ) ; } } this . overflowsegments = new memorysegment [ num_ ] ; return result ; }	resets overflow bucket counters and returns freed memory and should only be used for resizing.
public final long appendrecord ( t record ) throws ioexception { long pointer = this . writeview . getcurrentpointer ( ) ; try { this . serializer . serialize ( record , this . writeview ) ; this . recordcounter ++ ; return pointer ; } catch ( eofexception e ) {	Inserts the given object into the current buffer.
@ deprecated public void overwriterecordat ( long pointer , t record ) throws ioexception { long tmppointer = this . writeview . getcurrentpointer ( ) ; this . writeview . resetto ( pointer ) ; this . serializer . serialize ( record , this . writeview ) ; this . writeview . resetto ( tmppointer ) ; }	UNSAFE!! overwrites recordcauses inconsistency or data loss for overwriting everything but records of the exact same size.
public void allocatesegments ( int numberofsegments ) { while ( getblockcount ( ) < numberofsegments ) { memorysegment next = this . availablememory . nextsegment ( ) ; if ( next != null ) { this . partitionpages . add ( next ) ; } else { return ; } } }	attempts to allocate specified number of segments and should only be used by compaction partitionfails silently if not enough segments are available since next compaction could still succeed.
public static binaryinmemorysortbuffer createbuffer ( normalizedkeycomputer normalizedkeycomputer , abstractrowserializer < baserow > inputserializer , binaryrowserializer serializer , recordcomparator comparator , list < memorysegment > memory ) throws ioexception { checkargument ( memory . size ( ) >= min_required_buffers ) ; int totalnumbuffers = memory . size ( ) ; listmemorysegmentpool pool = new listmemorysegmentpool ( memory ) ; arraylist < memorysegment > recordbuffersegments = new arraylist < > ( num_ ) ; return new binaryinmemorysortbuffer ( normalizedkeycomputer , inputserializer , serializer , comparator , recordbuffersegments , new simplecollectingoutputview ( recordbuffersegments , pool , pool . pagesize ( ) ) , pool , totalnumbuffers ) ; }	Create a memory sorter in `insert` way.
@ override public void serializerecord ( t record ) throws ioexception { if ( checked ) { if ( databuffer . hasremaining ( ) ) { throw new illegalstateexception ( str_ ) ; } } serializationbuffer . clear ( ) ; lengthbuffer . clear ( ) ;	Serializes the complete record to an intermediate data serialization buffer.
@ override public serializationresult copytobufferbuilder ( bufferbuilder targetbuffer ) { targetbuffer . append ( lengthbuffer ) ; targetbuffer . append ( databuffer ) ; targetbuffer . commit ( ) ; return getserializationresult ( targetbuffer ) ; }	Copies an intermediate data serialization buffer into the target BufferBuilder.
private void enqueueavailablereader ( final networksequenceviewreader reader ) throws exception { if ( reader . isregisteredasavailable ( ) || ! reader . isavailable ( ) ) { return ; }	Try to enqueue the reader once receiving credit notification from the consumer or receivingnon-empty reader notification from the producer.
@ override public void invoke ( in value ) { try { byte [ ] msg = schema . serialize ( value ) ; if ( publishoptions == null ) { channel . basicpublish ( str_ , queuename , null , msg ) ; } else { boolean mandatory = publishoptions . computemandatory ( value ) ; boolean immediate = publishoptions . computeimmediate ( value ) ; preconditions . checkstate ( ! ( returnlistener == null && ( mandatory || immediate ) ) , str_ ) ; string rk = publishoptions . computeroutingkey ( value ) ; string exchange = publishoptions . computeexchange ( value ) ; channel . basicpublish ( exchange , rk , mandatory , immediate , publishoptions . computeproperties ( value ) , msg ) ; } } catch ( ioexception e ) { if ( logfailuresonly ) { log . error ( str_ , queuename , rmqconnectionconfig . gethost ( ) , e ) ; } else { throw new runtimeexception ( str_ + queuename + str_ + rmqconnectionconfig . gethost ( ) , e ) ; } } }	Called when new data arrives to the sink, and forwards it to RMQ.
@ override public void setinputtype ( typeinformation < ? > type , executionconfig executionconfig ) { if ( ! type . istupletype ( ) ) { throw new invalidprogramexception ( str_ + scalacsvoutputformat . class . getsimplename ( ) + str_ ) ; } }	The purpose of this method is solely to check whether the data type to be processedis in fact a tuple type.
public static < x > pattern < x , x > begin ( final string name ) { return new pattern < > ( name , null , consumingstrategy . strict , aftermatchskipstrategy . noskip ( ) ) ; }	Starts a new pattern sequence.
public < s extends f > pattern < t , s > subtype ( final class < s > subtypeclass ) { preconditions . checknotnull ( subtypeclass , str_ ) ; if ( condition == null ) { this . condition = new subtypecondition < f > ( subtypeclass ) ; } else { this . condition = new richandcondition < > ( condition , new subtypecondition < f > ( subtypeclass ) ) ; } @ suppresswarnings ( str_ ) pattern < t , s > result = ( pattern < t , s > ) this ; return result ; }	Applies a subtype constraint on the current pattern.
public pattern < t , f > until ( iterativecondition < f > untilcondition ) { preconditions . checknotnull ( untilcondition , str_ ) ; if ( this . untilcondition != null ) { throw new malformedpatternexception ( str_ ) ; } if ( ! quantifier . hasproperty ( quantifier . quantifierproperty . looping ) ) { throw new malformedpatternexception ( str_ ) ; } closurecleaner . clean ( untilcondition , bool_ ) ; this . untilcondition = untilcondition ; return this ; }	Applies a stop condition for a looping state.
public pattern < t , f > within ( time windowtime ) { if ( windowtime != null ) { this . windowtime = windowtime ; } return this ; }	Defines the maximum time interval in which a matching pattern has to be completed inorder to be considered valid.
public pattern < t , t > next ( final string name ) { return new pattern < > ( name , this , consumingstrategy . strict , aftermatchskipstrategy ) ; }	Appends a new pattern to the existing one.
public pattern < t , t > notnext ( final string name ) { if ( quantifier . hasproperty ( quantifier . quantifierproperty . optional ) ) { throw new unsupportedoperationexception ( str_ + str_ + str_ ) ; } return new pattern < > ( name , this , consumingstrategy . not_next , aftermatchskipstrategy ) ; }	Appends a new pattern to the existing one.
public pattern < t , t > notfollowedby ( final string name ) { if ( quantifier . hasproperty ( quantifier . quantifierproperty . optional ) ) { throw new unsupportedoperationexception ( str_ + str_ + str_ ) ; } return new pattern < > ( name , this , consumingstrategy . not_follow , aftermatchskipstrategy ) ; }	Appends a new pattern to the existing one.
public pattern < t , f > times ( int times ) { checkifnonotpattern ( ) ; checkifquantifierapplied ( ) ; preconditions . checkargument ( times > num_ , str_ ) ; this . quantifier = quantifier . times ( quantifier . getconsumingstrategy ( ) ) ; this . times = times . of ( times ) ; return this ; }	Specifies exact number of times that this pattern should be matched.
public pattern < t , f > times ( int from , int to ) { checkifnonotpattern ( ) ; checkifquantifierapplied ( ) ; this . quantifier = quantifier . times ( quantifier . getconsumingstrategy ( ) ) ; if ( from == num_ ) { this . quantifier . optional ( ) ; from = num_ ; } this . times = times . of ( from , to ) ; return this ; }	Specifies that the pattern can occur between from and to times.
public pattern < t , f > timesormore ( int times ) { checkifnonotpattern ( ) ; checkifquantifierapplied ( ) ; this . quantifier = quantifier . looping ( quantifier . getconsumingstrategy ( ) ) ; this . times = times . of ( times ) ; return this ; }	Specifies that this pattern can occur the specified times at least.This means at least the specified times and at most infinite number of events canbe matched to this pattern.
public static < t , f extends t > grouppattern < t , f > begin ( final pattern < t , f > group , final aftermatchskipstrategy aftermatchskipstrategy ) { return new grouppattern < > ( null , group , consumingstrategy . strict , aftermatchskipstrategy ) ; }	Starts a new pattern sequence.
public grouppattern < t , f > next ( pattern < t , f > group ) { return new grouppattern < > ( this , group , consumingstrategy . strict , aftermatchskipstrategy ) ; }	Appends a new group pattern to the existing one.
public void replace ( string pathinzookeeper , int expectedversion , t state ) throws exception { checknotnull ( pathinzookeeper , str_ ) ; checknotnull ( state , str_ ) ; final string path = normalizepath ( pathinzookeeper ) ; retrievablestatehandle < t > oldstatehandle = get ( path , bool_ ) ; retrievablestatehandle < t > newstatehandle = storage . store ( state ) ; boolean success = bool_ ; try {	Replaces a state handle in ZooKeeper and discards the old state handle.
public collection < string > getallpaths ( ) throws exception { final string path = str_ ; while ( bool_ ) { stat stat = client . checkexists ( ) . forpath ( path ) ; if ( stat == null ) { return collections . emptylist ( ) ; } else { try { return client . getchildren ( ) . forpath ( path ) ; } catch ( keeperexception . nonodeexception ignored ) {	Return a list of all valid paths for state handles.
@ suppresswarnings ( str_ ) public list < tuple2 < retrievablestatehandle < t > , string > > getallandlock ( ) throws exception { final list < tuple2 < retrievablestatehandle < t > , string > > statehandles = new arraylist < > ( ) ; boolean success = bool_ ; retry : while ( ! success ) { statehandles . clear ( ) ; stat stat = client . checkexists ( ) . forpath ( str_ ) ; if ( stat == null ) { break ;	Gets all available state handles from ZooKeeper and locks the respective state nodes.
public void releaseandtryremoveall ( ) throws exception { collection < string > children = getallpaths ( ) ; exception exception = null ; for ( string child : children ) { try { releaseandtryremove ( str_ + child ) ; } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } } if ( exception != null ) { throw new exception ( str_ , exception ) ; } }	Releases all lock nodes of this ZooKeeperStateHandleStores and tries to remove all state nodes whichare not locked anymore. The delete operation is executed asynchronously.
public void release ( string pathinzookeeper ) throws exception { final string path = normalizepath ( pathinzookeeper ) ; try { client . delete ( ) . forpath ( getlockpath ( path ) ) ; } catch ( keeperexception . nonodeexception ignored ) {	Releases the lock from the node under the given ZooKeeper path.
public void releaseall ( ) throws exception { collection < string > children = getallpaths ( ) ; exception exception = null ; for ( string child : children ) { try { release ( child ) ; } catch ( exception e ) { exception = exceptionutils . firstorsuppressed ( e , exception ) ; } } if ( exception != null ) { throw new exception ( str_ , exception ) ; } }	Releases all lock nodes of this ZooKeeperStateHandleStore.
public void deletechildren ( ) throws exception { final string path = str_ + client . getnamespace ( ) ; log . info ( str_ , path ) ; zkpaths . deletechildren ( client . getzookeeperclient ( ) . getzookeeper ( ) , path , bool_ ) ; }	Recursively deletes all children.
@ suppresswarnings ( str_ ) private retrievablestatehandle < t > get ( string pathinzookeeper , boolean lock ) throws exception { checknotnull ( pathinzookeeper , str_ ) ; final string path = normalizepath ( pathinzookeeper ) ; if ( lock ) {	Gets a state handle from ZooKeeper and optionally locks it.
public void set ( int index ) { preconditions . checkargument ( index < bitlength && index >= num_ ) ; int byteindex = ( index & byte_position_mask ) > > > num_ ; byte current = memorysegment . get ( offset + byteindex ) ; current |= ( num_ << ( index & byte_index_mask ) ) ; memorysegment . put ( offset + byteindex , current ) ; }	Sets the bit at specified index.
@ override public final void cogroup ( iterable < in1 > first , iterable < in2 > second , collector < out > out ) throws exception { streamer . streambufferwithgroups ( first . iterator ( ) , second . iterator ( ) , out ) ; }	Calls the external python function.
void registercolumnfamily ( string columnfamilyname , columnfamilyhandle handle ) { metricgroup group = metricgroup . addgroup ( columnfamilyname ) ; for ( string property : options . getproperties ( ) ) { rocksdbnativemetricview gauge = new rocksdbnativemetricview ( handle , property ) ; group . gauge ( property , gauge ) ; } }	Register gauges to pull native metrics for the column family.
private void setproperty ( columnfamilyhandle handle , string property , rocksdbnativemetricview metricview ) { if ( metricview . isclosed ( ) ) { return ; } try { synchronized ( lock ) { if ( rocksdb != null ) { long value = rocksdb . getlongproperty ( handle , property ) ; metricview . setvalue ( value ) ; } } } catch ( rocksdbexception e ) { metricview . close ( ) ; log . warn ( str_ , property , e ) ; } }	Updates the value of metricView if the reference is still valid.
@ override public string getmessage ( ) { string ret = super . getmessage ( ) ; if ( filename != null ) { ret += ( str_ + filename ) ; if ( linenumber != - num_ ) { ret += str_ + linenumber ; } if ( columnnumber != - num_ ) { ret += str_ + columnnumber ; } } return ret ; }	Returns a message containing the String passed to a constructor as well as line and column numbers and filename if any of these are known.
public static int bernstein ( string key ) { int hash = num_ ; int i ; for ( i = num_ ; i < key . length ( ) ; ++ i ) { hash = num_ * hash + key . charat ( i ) ; } return hash ; }	Bernstein's hash.
public string nextto ( string delimiters ) throws jsonexception { char c ; stringbuilder sb = new stringbuilder ( ) ; for ( ; ; ) { c = this . next ( ) ; if ( delimiters . indexof ( c ) >= num_ || c == num_ || c == str_ || c == str_ ) { if ( c != num_ ) { this . back ( ) ; } return sb . tostring ( ) . trim ( ) ; } sb . append ( c ) ; } }	Get the text up but not including one of the specified delimiter characters or the end of line, whichever comes first.
private static void appenddigits ( final appendable buffer , final int value ) throws ioexception { buffer . append ( ( char ) ( value / num_ + str_ ) ) ; buffer . append ( ( char ) ( value % num_ + str_ ) ) ; }	Appends two digits to the given buffer.
private static void appendfulldigits ( final appendable buffer , int value , int minfieldwidth ) throws ioexception {	Appends all digits to the given buffer.
private void readobject ( final objectinputstream in ) throws ioexception , classnotfoundexception { in . defaultreadobject ( ) ; final calendar definingcalendar = calendar . getinstance ( timezone , locale ) ; init ( definingcalendar ) ; }	Create the object after serialization.
private static map < string , integer > appenddisplaynames ( final calendar cal , final locale locale , final int field , final stringbuilder regex ) { final map < string , integer > values = new hashmap < > ( ) ; final map < string , integer > displaynames = cal . getdisplaynames ( field , calendar . all_styles , locale ) ; final treeset < string > sorted = new treeset < > ( longer_first_lowercase ) ; for ( final map . entry < string , integer > displayname : displaynames . entryset ( ) ) { final string key = displayname . getkey ( ) . tolowercase ( locale ) ; if ( sorted . add ( key ) ) { values . put ( key , displayname . getvalue ( ) ) ; } } for ( final string symbol : sorted ) { simplequote ( regex , symbol ) . append ( str_ ) ; } return values ; }	Get the short and long values displayed for a field.
private strategy getstrategy ( final char f , final int width , final calendar definingcalendar ) { switch ( f ) { default : throw new illegalargumentexception ( str_ + f + str_ ) ; case str_ : return day_of_year_strategy ; case str_ : return getlocalespecificstrategy ( calendar . day_of_week , definingcalendar ) ; case str_ : return day_of_week_in_month_strategy ; case str_ : return getlocalespecificstrategy ( calendar . era , definingcalendar ) ; case str_ :	Obtain a Strategy given a field from a SimpleDateFormat pattern.
private static concurrentmap < locale , strategy > getcache ( final int field ) { synchronized ( caches ) { if ( caches [ field ] == null ) { caches [ field ] = new concurrenthashmap < > ( num_ ) ; } return caches [ field ] ; } }	Get a cache of Strategies for a particular field.
private strategy getlocalespecificstrategy ( final int field , final calendar definingcalendar ) { final concurrentmap < locale , strategy > cache = getcache ( field ) ; strategy strategy = cache . get ( locale ) ; if ( strategy == null ) { strategy = field == calendar . zone_offset ? new timezonestrategy ( locale ) : new caseinsensitivetextstrategy ( field , definingcalendar , locale ) ; final strategy incache = cache . putifabsent ( locale , strategy ) ; if ( incache != null ) { return incache ; } } return strategy ; }	Construct a Strategy that parses a Text field.
private f getdatetimeinstance ( final integer datestyle , final integer timestyle , final timezone timezone , locale locale ) { if ( locale == null ) { locale = locale . getdefault ( ) ; } final string pattern = getpatternforstyle ( datestyle , timestyle , locale ) ; return getinstance ( pattern , timezone , locale ) ; }	This must remain private, see LANG-884.
public object nextmeta ( ) throws jsonexception { char c ; char q ; do { c = next ( ) ; } while ( character . iswhitespace ( c ) ) ; switch ( c ) { case num_ : throw syntaxerror ( str_ ) ; case str_ : return xml . lt ; case str_ : return xml . gt ; case str_ : return xml . slash ; case str_ : return xml . eq ; case str_ : return xml . bang ; case str_ : return xml . quest ; case str_ : case str_ : q = c ; for ( ; ; ) { c = next ( ) ; if ( c == num_ ) { throw syntaxerror ( str_ ) ; } if ( c == q ) { return boolean . true ; } } default : for ( ; ; ) { c = next ( ) ; if ( character . iswhitespace ( c ) ) { return boolean . true ; } switch ( c ) { case num_ : case str_ : case str_ : case str_ : case str_ : case str_ : case str_ : case str_ : case str_ : back ( ) ; return boolean . true ; } } } }	Returns the next XML meta token.
public boolean skippast ( string to ) throws jsonexception { boolean b ; char c ; int i ; int j ; int offset = num_ ; int length = to . length ( ) ; char [ ] circle = new char [ length ] ; for ( i = num_ ; i < length ; i += num_ ) { c = next ( ) ; if ( c == num_ ) { return bool_ ; } circle [ i ] = c ; } for ( ; ; ) { j = offset ; b = bool_ ; for ( i = num_ ; i < length ; i += num_ ) { if ( circle [ j ] != to . charat ( i ) ) { b = bool_ ; break ; } j += num_ ; if ( j >= length ) { j -= length ; } } if ( b ) { return bool_ ; } c = next ( ) ; if ( c == num_ ) { return bool_ ; } circle [ offset ] = c ; offset += num_ ; if ( offset >= length ) { offset -= length ; } } }	Skip characters until past the requested string.
public string filter ( final string input ) { reset ( ) ; string s = input ; debug ( str_ ) ; debug ( str_ + input ) ; s = escapecomments ( s ) ; debug ( str_ + s ) ; s = balancehtml ( s ) ; debug ( str_ + s ) ; s = checktags ( s ) ; debug ( str_ + s ) ; s = processremoveblanks ( s ) ; debug ( str_ + s ) ; s = validateentities ( s ) ; debug ( str_ + s ) ; debug ( str_ ) ; return s ; }	given a user submitted input String, filter out any invalid or restricted html.
@ override public void dumprequest ( map < string , object > result ) { exchange . getqueryparameters ( ) . foreach ( ( k , v ) -> { if ( config . getrequestfilteredqueryparameters ( ) . contains ( k ) ) {	impl of dumping request query parameter to result.
@ override protected void putdumpinfoto ( map < string , object > result ) { if ( this . queryparametersmap . size ( ) > num_ ) { result . put ( dumpconstants . query_parameters , queryparametersmap ) ; } }	put queryParametersMap to result.
public void sendmail ( string to , string subject , string content ) throws messagingexception { properties props = new properties ( ) ; props . put ( str_ , emailconfg . getuser ( ) ) ; props . put ( str_ , emailconfg . gethost ( ) ) ; props . put ( str_ , emailconfg . getport ( ) ) ; props . put ( str_ , str_ ) ; props . put ( str_ , emailconfg . getdebug ( ) ) ; props . put ( str_ , emailconfg . getauth ( ) ) ; props . put ( str_ , emailconfg . host ) ; smtpauthenticator auth = new smtpauthenticator ( emailconfg . getuser ( ) , ( string ) secret . get ( secretconstants . email_password ) ) ; session session = session . getinstance ( props , auth ) ; mimemessage message = new mimemessage ( session ) ; message . setfrom ( new internetaddress ( emailconfg . getuser ( ) ) ) ; message . addrecipient ( message . recipienttype . to , new internetaddress ( to ) ) ; message . setsubject ( subject ) ; message . setcontent ( content , str_ ) ;	Send email with a string content.
public void sendmailwithattachment ( string to , string subject , string content , string filename ) throws messagingexception { properties props = new properties ( ) ; props . put ( str_ , emailconfg . getuser ( ) ) ; props . put ( str_ , emailconfg . gethost ( ) ) ; props . put ( str_ , emailconfg . getport ( ) ) ; props . put ( str_ , str_ ) ; props . put ( str_ , emailconfg . getdebug ( ) ) ; props . put ( str_ , emailconfg . getauth ( ) ) ; props . put ( str_ , emailconfg . host ) ; smtpauthenticator auth = new smtpauthenticator ( emailconfg . getuser ( ) , ( string ) secret . get ( secretconstants . email_password ) ) ; session session = session . getinstance ( props , auth ) ; mimemessage message = new mimemessage ( session ) ; message . setfrom ( new internetaddress ( emailconfg . getuser ( ) ) ) ; message . addrecipient ( message . recipienttype . to , new internetaddress ( to ) ) ; message . setsubject ( subject ) ;	Send email with a string content and attachment.
private static void handlesingletonclass ( string key , string value ) throws exception { object object = handlevalue ( value ) ; if ( key . contains ( str_ ) ) { string [ ] interfaces = key . split ( str_ ) ; for ( string aninterface : interfaces ) { servicemap . put ( aninterface , object ) ; } } else { servicemap . put ( key , object ) ; } }	For each singleton definition, create object with the initializer class and method,and push it into the service map with the key of the class name.
private static void handlesingletonlist ( string key , list < object > value ) throws exception { list < string > interfaceclasses = new arraylist ( ) ; if ( key . contains ( str_ ) ) { string [ ] interfaces = key . split ( str_ ) ; interfaceclasses . addall ( arrays . aslist ( interfaces ) ) ; } else { interfaceclasses . add ( key ) ; }	For each singleton definition, create object for the interface with the implementation class,and push it into the service map with key and implemented object.
public static < t > t getbean ( class < t > interfaceclass , class typeclass ) { object object = servicemap . get ( interfaceclass . getname ( ) + str_ + typeclass . getname ( ) + str_ ) ; if ( object == null ) return null ; if ( object instanceof object [ ] ) { return ( t ) array . get ( object , num_ ) ; } else { return ( t ) object ; } }	Get a cached singleton object from service map by interface class and generic type class.The serviceMap is constructed from service.yml which defines interface and generic typeto implementation mapping.
public static < t > t [ ] getbeans ( class < t > interfaceclass ) { object object = servicemap . get ( interfaceclass . getname ( ) ) ; if ( object == null ) return null ; if ( object instanceof object [ ] ) { return ( t [ ] ) object ; } else { object array = array . newinstance ( interfaceclass , num_ ) ; array . set ( array , num_ , object ) ; return ( t [ ] ) array ; } }	Get a list of cached singleton objects from service map by interface class.
public byte [ ] tobytearray ( ) { final byte [ ] b = new byte [ this . len ] ; if ( this . len > num_ ) { system . arraycopy ( this . array , num_ , b , num_ , this . len ) ; } return b ; }	Converts the content of this buffer to an array of bytes.
public string getlastpathsegment ( ) { if ( stringutils . isblank ( path ) ) { return stringutils . empty ; } string segment = path ; segment = stringutils . substringafterlast ( segment , str_ ) ; return segment ; }	Gets the last URL path segment without the query string.If there are segment to return,an empty string will be returned instead.
public boolean isportdefault ( ) { return ( protocol_https . equalsignorecase ( protocol ) && port == default_https_port ) || ( protocol_http . equalsignorecase ( protocol ) && port == default_http_port ) ; }	Whether this URL uses the default port for the protocol.
public static string toabsolute ( string baseurl , string relativeurl ) { string relurl = relativeurl ;	Converts a relative URL to an absolute one, based on the suppliedbase URL.
public static string generaterandomcodeverifier ( securerandom entropysource , int entropybytes ) { byte [ ] randombytes = new byte [ entropybytes ] ; entropysource . nextbytes ( randombytes ) ; return base64 . geturlencoder ( ) . withoutpadding ( ) . encodetostring ( randombytes ) ; }	Generates a random code verifier string using the provided entropy source and the specifiednumber of bytes of entropy.
public static void addproviderstopathhandler ( pathresourceprovider [ ] pathresourceproviders , pathhandler pathhandler ) { if ( pathresourceproviders != null && pathresourceproviders . length > num_ ) { for ( pathresourceprovider pathresourceprovider : pathresourceproviders ) { if ( pathresourceprovider . isprefixpath ( ) ) { pathhandler . addprefixpath ( pathresourceprovider . getpath ( ) , new resourcehandler ( pathresourceprovider . getresourcemanager ( ) ) ) ; } else { pathhandler . addexactpath ( pathresourceprovider . getpath ( ) , new resourcehandler ( pathresourceprovider . getresourcemanager ( ) ) ) ; } } } }	Helper to add given PathResourceProviders to a PathHandler.
public static list < predicatedhandler > getpredicatedhandlers ( predicatedhandlersprovider [ ] predicatedhandlersproviders ) { list < predicatedhandler > predicatedhandlers = new arraylist < > ( ) ; if ( predicatedhandlersproviders != null && predicatedhandlersproviders . length > num_ ) { for ( predicatedhandlersprovider predicatedhandlersprovider : predicatedhandlersproviders ) { predicatedhandlers . addall ( predicatedhandlersprovider . getpredicatedhandlers ( ) ) ; } } return predicatedhandlers ; }	Helper for retrieving all PredicatedHandlers from the given list of PredicatedHandlersProviders.
public static boolean isresourcepath ( string requestpath , pathresourceprovider [ ] pathresourceproviders ) { boolean isresourcepath = bool_ ; if ( pathresourceproviders != null && pathresourceproviders . length > num_ ) { for ( pathresourceprovider pathresourceprovider : pathresourceproviders ) { if ( ( pathresourceprovider . isprefixpath ( ) && requestpath . startswith ( pathresourceprovider . getpath ( ) ) ) || ( ! pathresourceprovider . isprefixpath ( ) && requestpath . equals ( pathresourceprovider . getpath ( ) ) ) ) { isresourcepath = bool_ ; } } } return isresourcepath ; }	Helper to check if a given requestPath could resolve to a PathResourceProvider.
public static result < tokenresponse > gettokenresult ( tokenrequest tokenrequest , string envtag ) { final atomicreference < result < tokenresponse > > reference = new atomicreference < > ( ) ; final http2client client = http2client . getinstance ( ) ; final countdownlatch latch = new countdownlatch ( num_ ) ; final clientconnection connection ; try { if ( tokenrequest . getserverurl ( ) != null ) { connection = client . connect ( new uri ( tokenrequest . getserverurl ( ) ) , http2client . worker , http2client . ssl , http2client . buffer_pool , tokenrequest . enablehttp2 ? optionmap . create ( undertowoptions . enable_http2 , bool_ ) : optionmap . empty ) . get ( ) ; } else if ( tokenrequest . getserviceid ( ) != null ) { cluster cluster = singletonservicefactory . getbean ( cluster . class ) ; string url = cluster . servicetourl ( str_ , tokenrequest . getserviceid ( ) , envtag , null ) ; connection = client . connect ( new uri ( url ) , http2client . worker , http2client . ssl , http2client . buffer_pool , tokenrequest . enablehttp2 ? optionmap . create ( undertowoptions . enable_http2 , bool_ ) : optionmap . empty ) . get ( ) ; } else {	Get an access token from the token service.
public static string getkey ( keyrequest keyrequest , string envtag ) throws clientexception { final http2client client = http2client . getinstance ( ) ; final countdownlatch latch = new countdownlatch ( num_ ) ; final clientconnection connection ; try { if ( keyrequest . getserverurl ( ) != null ) { connection = client . connect ( new uri ( keyrequest . getserverurl ( ) ) , http2client . worker , http2client . ssl , http2client . buffer_pool , keyrequest . enablehttp2 ? optionmap . create ( undertowoptions . enable_http2 , bool_ ) : optionmap . empty ) . get ( ) ; } else if ( keyrequest . getserviceid ( ) != null ) { cluster cluster = singletonservicefactory . getbean ( cluster . class ) ; string url = cluster . servicetourl ( str_ , keyrequest . getserviceid ( ) , envtag , null ) ; connection = client . connect ( new uri ( url ) , http2client . worker , http2client . ssl , http2client . buffer_pool , keyrequest . enablehttp2 ? optionmap . create ( undertowoptions . enable_http2 , bool_ ) : optionmap . empty ) . get ( ) ; } else {	Get the certificate from key distribution service of OAuth 2.0 provider with the kid.
private static result < jwt > renewcctokensync ( final jwt jwt ) {	renew Client Credential token synchronously.When success will renew the Jwt jwt passed in.When fail will return Status code so that can be handled by caller.
private static void renewcctokenasync ( final jwt jwt ) {	renew the given Jwt jwt asynchronously.When fail, it will swallow the exception, so no need return type to be handled by caller.
private static result < jwt > getcctokenremotely ( final jwt jwt ) { tokenrequest tokenrequest = new clientcredentialsrequest ( ) ;	get Client Credential token from auth server.
private static string escapexml ( string nonescapedxmlstr ) { stringbuilder escapedxml = new stringbuilder ( ) ; for ( int i = num_ ; i < nonescapedxmlstr . length ( ) ; i ++ ) { char c = nonescapedxmlstr . charat ( i ) ; switch ( c ) { case str_ : escapedxml . append ( str_ ) ; break ; case str_ : escapedxml . append ( str_ ) ; break ; case str_ : escapedxml . append ( str_ ) ; break ; case str_ : escapedxml . append ( str_ ) ; break ; case str_ : escapedxml . append ( str_ ) ; break ; default : if ( c > num_ ) { escapedxml . append ( str_ + ( ( int ) c ) + str_ ) ; } else { escapedxml . append ( c ) ; } } } return escapedxml . tostring ( ) ; }	Instead of including a large library just for escaping xml, using this util.it should be used in very rare cases because the server should not return xml format message.
public static void adjustnochunkedencoding ( clientrequest request , string requestbody ) { string fixedlengthstring = request . getrequestheaders ( ) . getfirst ( headers . content_length ) ; string transferencodingstring = request . getrequestheaders ( ) . getlast ( headers . transfer_encoding ) ; if ( transferencodingstring != null ) { request . getrequestheaders ( ) . remove ( headers . transfer_encoding ) ; }	this method is to support sending a server which doesn't support chunked transfer encoding.
private void attachformdatabody ( final httpserverexchange exchange ) throws ioexception { object data ; formparserfactory formparserfactory = formparserfactory . builder ( ) . build ( ) ; formdataparser parser = formparserfactory . createparser ( exchange ) ; if ( parser != null ) { formdata formdata = parser . parseblocking ( ) ; data = bodyconverter . convert ( formdata ) ; exchange . putattachment ( request_body , data ) ; } }	Method used to parse the body into FormData and attach it into exchange.
private void attachjsonbody ( final httpserverexchange exchange , string string ) throws ioexception { object body ; if ( string != null ) { string = string . trim ( ) ; if ( string . startswith ( str_ ) ) { body = config . getinstance ( ) . getmapper ( ) . readvalue ( string , new typereference < map < string , object > > ( ) { } ) ; } else if ( string . startswith ( str_ ) ) { body = config . getinstance ( ) . getmapper ( ) . readvalue ( string , new typereference < list < object > > ( ) { } ) ; } else {	Method used to parse the body into a Map or a List and attach it into exchange.
public static string maskstring ( string input , string key ) { string output = input ; map < string , object > stringconfig = ( map < string , object > ) config . get ( mask_type_string ) ; if ( stringconfig != null ) { map < string , object > keyconfig = ( map < string , object > ) stringconfig . get ( key ) ; if ( keyconfig != null ) { set < string > patterns = keyconfig . keyset ( ) ; for ( string pattern : patterns ) { output = output . replaceall ( pattern , ( string ) keyconfig . get ( pattern ) ) ; } } } return output ; }	Mask the input string with a list of patterns indexed by key in string section in mask.jsonThis is usually used to mask header values, query parameters and uri parameters.
public static string maskjson ( string input , string key ) { documentcontext ctx = jsonpath . parse ( input ) ; return maskjson ( ctx , key ) ; }	Replace values in JSON using json path.
public void skipwhitespace ( final charsequence buf , final parsercursor cursor ) { args . notnull ( buf , str_ ) ; args . notnull ( cursor , str_ ) ; int pos = cursor . getpos ( ) ; final int indexfrom = cursor . getpos ( ) ; final int indexto = cursor . getupperbound ( ) ; for ( int i = indexfrom ; i < indexto ; i ++ ) { final char current = buf . charat ( i ) ; if ( ! iswhitespace ( current ) ) { break ; } pos ++ ; } cursor . updatepos ( pos ) ; }	Skips semantically insignificant whitespace characters and moves the cursor to the closestnon-whitespace character.
public void copycontent ( final charsequence buf , final parsercursor cursor , final bitset delimiters , final stringbuilder dst ) { args . notnull ( buf , str_ ) ; args . notnull ( cursor , str_ ) ; args . notnull ( dst , str_ ) ; int pos = cursor . getpos ( ) ; final int indexfrom = cursor . getpos ( ) ; final int indexto = cursor . getupperbound ( ) ; for ( int i = indexfrom ; i < indexto ; i ++ ) { final char current = buf . charat ( i ) ; if ( ( delimiters != null && delimiters . get ( current ) ) || iswhitespace ( current ) ) { break ; } pos ++ ; dst . append ( current ) ; } cursor . updatepos ( pos ) ; }	Transfers content into the destination buffer until a whitespace character or any ofthe given delimiters is encountered.
public void copyquotedcontent ( final charsequence buf , final parsercursor cursor , final stringbuilder dst ) { args . notnull ( buf , str_ ) ; args . notnull ( cursor , str_ ) ; args . notnull ( dst , str_ ) ; if ( cursor . atend ( ) ) { return ; } int pos = cursor . getpos ( ) ; int indexfrom = cursor . getpos ( ) ; final int indexto = cursor . getupperbound ( ) ; char current = buf . charat ( pos ) ; if ( current != dquote ) { return ; } pos ++ ; indexfrom ++ ; boolean escaped = bool_ ; for ( int i = indexfrom ; i < indexto ; i ++ , pos ++ ) { current = buf . charat ( i ) ; if ( escaped ) { if ( current != dquote && current != escape ) { dst . append ( escape ) ; } dst . append ( current ) ; escaped = bool_ ; } else { if ( current == dquote ) { pos ++ ; break ; } if ( current == escape ) { escaped = bool_ ; } else if ( current != cr && current != lf ) { dst . append ( current ) ; } } } cursor . updatepos ( pos ) ; }	Transfers content enclosed with quote marks into the destination buffer.
static void logresult ( map < string , object > result , dumpconfig config ) { consumer < string > loggerfunc = getloggerfuncbasedonlevel ( config . getloglevel ( ) ) ; if ( config . isusejson ( ) ) { logresultusingjson ( result , loggerfunc ) ; } else { int startlevel = - num_ ; stringbuilder sb = new stringbuilder ( str_ ) ; _logresult ( result , startlevel , config . getindentsize ( ) , sb ) ; loggerfunc . accept ( sb . tostring ( ) ) ; } }	A help method to log result pojo.
private static < t > void _logresult ( t result , int level , int indentsize , stringbuilder info ) { if ( result instanceof map ) { level += num_ ; int finallevel = level ; ( ( map ) result ) . foreach ( ( k , v ) -> { info . append ( str_ ) ; info . append ( gettabbasedonlevel ( finallevel , indentsize ) ) . append ( k . tostring ( ) ) . append ( str_ ) ; _logresult ( v , finallevel , indentsize , info ) ; } ) ; } else if ( result instanceof list ) { int finallevel = level ; ( ( list ) result ) . foreach ( element -> _logresult ( element , finallevel , indentsize , info ) ) ; } else if ( result instanceof string ) { info . append ( str_ ) . append ( result ) ; } else if ( result != null ) { try { logger . warn ( gettabbasedonlevel ( level , indentsize ) + str_ , result ) ; } catch ( exception e ) { logger . error ( str_ , result . getclass ( ) . gettypename ( ) ) ; } } }	this method actually append result to result string.
private static string gettabbasedonlevel ( int level , int indentsize ) { stringbuilder sb = new stringbuilder ( ) ; for ( int i = num_ ; i < level ; i ++ ) { for ( int j = num_ ; j < indentsize ; j ++ ) { sb . append ( str_ ) ; } } return sb . tostring ( ) ; }	calculate indent for formatting.
private url removeunnecessaryparmas ( url url ) { url . getparameters ( ) . remove ( urlparamtype . codec . getname ( ) ) ; return url ; }	client doesn't need to know codec.
@ override public void dumpresponse ( map < string , object > result ) { this . statuscoderesult = string . valueof ( exchange . getstatuscode ( ) ) ; this . putdumpinfoto ( result ) ; }	impl of dumping response status code to result.
@ override protected void putdumpinfoto ( map < string , object > result ) { if ( stringutils . isnotblank ( this . statuscoderesult ) ) { result . put ( dumpconstants . status_code , this . statuscoderesult ) ; } }	put this.statusCodeResult to result.
public static string getuuid ( ) { uuid id = uuid . randomuuid ( ) ; bytebuffer bb = bytebuffer . wrap ( new byte [ num_ ] ) ; bb . putlong ( id . getmostsignificantbits ( ) ) ; bb . putlong ( id . getleastsignificantbits ( ) ) ; return base64 . encodebase64urlsafestring ( bb . array ( ) ) ; }	Generate UUID across the entire app and it is used for correlationId.
public static string quote ( final string value ) { if ( value == null ) { return null ; } string result = value ; if ( ! result . startswith ( str_ ) ) { result = str_ + result ; } if ( ! result . endswith ( str_ ) ) { result = result + str_ ; } return result ; }	Quote the given string if needed.
@ override public string servicetourl ( string protocol , string serviceid , string tag , string requestkey ) { url url = loadbalance . select ( discovery ( protocol , serviceid , tag ) , requestkey ) ; if ( logger . isdebugenabled ( ) ) logger . debug ( str_ + url ) ;	Implement serviceToUrl with client side service discovery.
private string getservertlsfingerprint ( ) { string fingerprint = null ; map < string , object > serverconfig = config . getinstance ( ) . getjsonmapconfignocache ( str_ ) ; map < string , object > secretconfig = config . getinstance ( ) . getjsonmapconfignocache ( str_ ) ;	We can get it from server module but we don't want mutual dependency. Soget it from config and keystore directly.
private void docustomserveridentitycheck ( x509certificate cert ) throws certificateexception { if ( endpointidentificationalgorithm . apis == identityalg ) { apinamechecker . verifyandthrow ( trustednameset , cert ) ; } }	check server identify as per tls.trustedNames in client.yml.Notes: this method should only be applied to verify server certificates on the client side.
private void checkidentity ( sslsession session , x509certificate cert ) throws certificateexception { if ( session == null ) { throw new certificateexception ( str_ ) ; } if ( endpointidentificationalgorithm . https == identityalg ) { string hostname = session . getpeerhost ( ) ; apinamechecker . verifyandthrow ( hostname , cert ) ; } }	check server identify against hostnames.
public static trustmanager [ ] decorate ( trustmanager [ ] trustmanagers , tlsconfig tlsconfig ) { if ( null != trustmanagers && trustmanagers . length > num_ ) { trustmanager [ ] decoratedtrustmanagers = new trustmanager [ trustmanagers . length ] ; for ( int i = num_ ; i < trustmanagers . length ; ++ i ) { trustmanager trustmanager = trustmanagers [ i ] ; if ( trustmanager instanceof x509trustmanager ) { decoratedtrustmanagers [ i ] = new clientx509extendedtrustmanager ( ( x509trustmanager ) trustmanager , tlsconfig ) ; } else { decoratedtrustmanagers [ i ] = trustmanager ; } } return decoratedtrustmanagers ; } return trustmanagers ; }	This method converts existing X509TrustManagers to ClientX509ExtendedTrustManagers.
@ override protected void putdumpinfoto ( map < string , object > result ) { if ( stringutils . isnotblank ( this . url ) ) { result . put ( dumpconstants . url , this . url ) ; } }	put this.url to result.
@ override public void handlerequest ( final httpserverexchange exchange ) throws exception {	Check iterate the configuration on both request and response section and updateheaders accordingly.
public static string gethostname ( socketaddress socketaddress ) { if ( socketaddress == null ) { return null ; } if ( socketaddress instanceof inetsocketaddress ) { inetaddress addr = ( ( inetsocketaddress ) socketaddress ) . getaddress ( ) ; if ( addr != null ) { return addr . gethostaddress ( ) ; } } return null ; }	return ip to avoid lookup dns.
public static object mergeobject ( object config , class clazz ) { merge ( config ) ; return convertmaptoobj ( ( map < string , object > ) config , clazz ) ; }	Merge map config with values generated by ConfigInjection.class and return mapping object.
private static void merge ( object m1 ) { if ( m1 instanceof map ) { iterator < object > fieldnames = ( ( map < object , object > ) m1 ) . keyset ( ) . iterator ( ) ; string fieldname = null ; while ( fieldnames . hasnext ( ) ) { fieldname = string . valueof ( fieldnames . next ( ) ) ; object field1 = ( ( map < string , object > ) m1 ) . get ( fieldname ) ; if ( field1 != null ) { if ( field1 instanceof map || field1 instanceof list ) { merge ( field1 ) ;	Search the config map recursively, expand List and Map level by level util no further expand.
private static object convertmaptoobj ( map < string , object > map , class clazz ) { objectmapper mapper = new objectmapper ( ) ; object obj = mapper . convertvalue ( map , clazz ) ; return obj ; }	Method used to convert map to object based on the reference class provided.
@ override public double getmean ( ) { if ( values . length == num_ ) { return num_ ; } double sum = num_ ; for ( long value : values ) { sum += value ; } return sum / values . length ; }	Returns the arithmetic mean of the values in the snapshot.
@ override public double getstddev ( ) {	Returns the standard deviation of the values in the snapshot.
@ override public void dump ( outputstream output ) { try ( printwriter out = new printwriter ( new outputstreamwriter ( output , utf_8 ) ) ) { for ( long value : values ) { out . printf ( str_ , value ) ; } } }	Writes the values of the snapshot to the given stream.
public static object constructbynamedparams ( class clazz , map params ) throws exception { object obj = clazz . getconstructor ( ) . newinstance ( ) ; method [ ] allmethods = clazz . getmethods ( ) ; for ( method method : allmethods ) { if ( method . getname ( ) . startswith ( str_ ) ) { object [ ] o = new object [ num_ ] ; string propertyname = introspector . decapitalize ( method . getname ( ) . substring ( num_ ) ) ; if ( params . containskey ( propertyname ) ) { o [ num_ ] = params . get ( propertyname ) ; method . invoke ( obj , o ) ; } } } return obj ; }	Build an object out of a given class and a map for field names to values.
public static object constructbyparameterizedconstructor ( class clazz , list parameters ) throws exception {	Build an object out of a given class and a list of single element maps of object type to value.A constructor is searched for that matches the given set.
public static metricname name ( string name , string ... names ) { final int length ; if ( names == null ) { length = num_ ; } else { length = names . length ; } final string [ ] parts = new string [ length + num_ ] ; parts [ num_ ] = name ; system . arraycopy ( names , num_ , parts , num_ , length ) ; return metricname . build ( parts ) ; }	Shorthand method for backwards compatibility in creating metric names.Uses {.
public void removeall ( ) { for ( iterator < map . entry < metricname , metric > > it = metrics . entryset ( ) . iterator ( ) ; it . hasnext ( ) ; ) { map . entry < metricname , metric > entry = it . next ( ) ; metric metric = entry . getvalue ( ) ; if ( metric != null ) { onmetricremoved ( entry . getkey ( ) , metric ) ; } it . remove ( ) ; } }	Removes all the metrics in registry.
public void stop ( ) { executor . shutdown ( ) ;	Stops the reporter and shuts down its thread of execution.Uses the shutdown pattern from http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html.
public void report ( ) { synchronized ( this ) { report ( registry . getgauges ( filter ) , registry . getcounters ( filter ) , registry . gethistograms ( filter ) , registry . getmeters ( filter ) , registry . gettimers ( filter ) ) ; } }	Report the current values of all metrics in the registry.
private static void serveroptioninit ( ) { map < string , object > mapconfig = config . getinstance ( ) . getjsonmapconfignocache ( server_config_name ) ; serveroption . serveroptioninit ( mapconfig , getserverconfig ( ) ) ; }	Method used to initialize server options. If the user has configured a valid server option,load it into the server configuration, otherwise use the default value.
static public void shutdown ( ) {	implement shutdown hook here.
protected static void mergestatusconfig ( ) { map < string , object > appstatusconfig = config . getinstance ( ) . getjsonmapconfignocache ( status_config_name [ num_ ] ) ; if ( appstatusconfig == null ) { return ; } map < string , object > statusconfig = config . getinstance ( ) . getjsonmapconfig ( status_config_name [ num_ ] ) ;	method used to merge status.yml and app-status.yml.
public static url register ( string serviceid , int port ) { try { registry = singletonservicefactory . getbean ( registry . class ) ; if ( registry == null ) throw new runtimeexception ( str_ ) ;	Register the service to the Consul or other service registry.
public void append ( final string str ) { final string s = str != null ? str : str_ ; final int strlen = s . length ( ) ; final int newlen = this . len + strlen ; if ( newlen > this . array . length ) { expand ( newlen ) ; } s . getchars ( num_ , strlen , this . array , this . len ) ; this . len = newlen ; }	Appends chars of the given string to this buffer.
public char [ ] tochararray ( ) { final char [ ] b = new char [ this . len ] ; if ( this . len > num_ ) { system . arraycopy ( this . array , num_ , b , num_ , this . len ) ; } return b ; }	Converts the content of this buffer to an array of chars.
@ override protected void putdumpinfoto ( map < string , object > result ) { if ( stringutils . isnotblank ( this . bodycontent ) ) { result . put ( dumpconstants . body , this . bodycontent ) ; } }	put bodyContent to result.
@ override public void dumprequest ( map < string , object > result ) { string contenttype = exchange . getrequestheaders ( ) . getfirst ( headers . content_type ) ;	impl of dumping request body to result.
@ override public void dumpresponse ( map < string , object > result ) { byte [ ] responsebodyattachment = exchange . getattachment ( storeresponsestreamsinkconduit . response ) ; if ( responsebodyattachment != null ) { this . bodycontent = config . ismaskenabled ( ) ? mask . maskjson ( new bytearrayinputstream ( responsebodyattachment ) , str_ ) : new string ( responsebodyattachment , utf_8 ) ; } this . putdumpinfoto ( result ) ; }	impl of dumping response body to result.
private void dumpinputstream ( ) {	read from input stream, convert it to string, put into this.bodyContent.
private void dumpbodyattachment ( object requestbodyattachment ) { this . bodycontent = config . ismaskenabled ( ) ? mask . maskjson ( requestbodyattachment , str_ ) : requestbodyattachment . tostring ( ) ; }	read from body attachment from Body Handler, convert it to string, put into this.bodyContent.
static public x509certificate readcertificate ( string filename ) throws exception { inputstream instream = null ; x509certificate cert = null ; try { instream = config . getinstance ( ) . getinputstreamfromfile ( filename ) ; if ( instream != null ) { certificatefactory cf = certificatefactory . getinstance ( str_ ) ; cert = ( x509certificate ) cf . generatecertificate ( instream ) ; } else { logger . info ( str_ + encode . forjava ( filename ) + str_ ) ; } } catch ( exception e ) { logger . error ( str_ , e ) ; } finally { if ( instream != null ) { try { instream . close ( ) ; } catch ( ioexception ioe ) { logger . error ( str_ , ioe ) ; } } } return cert ; }	Read certificate from a file and convert it into X509Certificate object.
public static string getjwtfromauthorization ( string authorization ) { string jwt = null ; if ( authorization != null ) { string [ ] parts = authorization . split ( str_ ) ; if ( parts . length == num_ ) { string scheme = parts [ num_ ] ; string credentials = parts [ num_ ] ; pattern pattern = pattern . compile ( str_ , pattern . case_insensitive ) ; if ( pattern . matcher ( scheme ) . matches ( ) ) { jwt = credentials ; } } } return jwt ; }	Parse the jwt token from Authorization header.
public static string inputstreamtostring ( inputstream inputstream , charset charset ) throws ioexception { if ( inputstream != null && inputstream . available ( ) != - num_ ) { bytearrayoutputstream result = new bytearrayoutputstream ( ) ; byte [ ] buffer = new byte [ num_ ] ; int length ; while ( ( length = inputstream . read ( buffer ) ) != - num_ ) { result . write ( buffer , num_ , length ) ; } if ( charset != null ) { return result . tostring ( charset . name ( ) ) ; } return result . tostring ( standardcharsets . utf_8 . name ( ) ) ; } return null ; }	Convert an InputStream into a String.Highest performing conversion per: https://stackoverflow.com/a/35446009.
@ override public void dumprequest ( map < string , object > result ) { map < string , cookie > cookiesmap = exchange . getrequestcookies ( ) ; dumpcookies ( cookiesmap , str_ ) ; this . putdumpinfoto ( result ) ; }	impl of dumping request cookies to result.
@ override public void dumpresponse ( map < string , object > result ) { map < string , cookie > cookiesmap = exchange . getresponsecookies ( ) ; dumpcookies ( cookiesmap , str_ ) ; this . putdumpinfoto ( result ) ; }	impl of dumping response cookies to result.
private void dumpcookies ( map < string , cookie > cookiesmap , string maskkey ) { cookiesmap . foreach ( ( key , cookie ) -> { if ( ! config . getrequestfilteredcookies ( ) . contains ( cookie . getname ( ) ) ) { list < map < string , string > > cookieinfolist = new arraylist < > ( ) ;	put cookies info to cookieMap.
@ override protected void putdumpinfoto ( map < string , object > result ) { if ( this . cookiemap . size ( ) > num_ ) { result . put ( dumpconstants . cookies , cookiemap ) ; } }	put cookieMap to result.
public static boolean issame ( list < url > urls1 , list < url > urls2 ) { if ( urls1 == null || urls2 == null ) { return bool_ ; } if ( urls1 . size ( ) != urls2 . size ( ) ) { return bool_ ; } return urls1 . containsall ( urls2 ) ; }	Check if two lists have the same urls. If any list is empty, return false.
public static consulservice buildservice ( url url ) { consulservice service = new consulservice ( ) ; service . setaddress ( url . gethost ( ) ) ; service . setid ( consulutils . convertconsulserivceid ( url ) ) ; service . setname ( url . getpath ( ) ) ; service . setport ( url . getport ( ) ) ; list < string > tags = new arraylist < string > ( ) ; string env = url . getparameter ( constants . tag_environment ) ; if ( env != null ) tags . add ( env ) ; service . settags ( tags ) ; return service ; }	build consul service from url.
public static url buildurl ( consulservice service ) { url url = null ; if ( url == null ) { map < string , string > params = new hashmap < string , string > ( ) ;	build url from service.
public static string getpathfromserviceid ( string serviceid ) { return serviceid . substring ( serviceid . indexof ( str_ ) + num_ , serviceid . lastindexof ( str_ ) ) ; }	get path of url from service id in consul.
public static string getjwt ( jwtclaims claims ) throws joseexception { string jwt ; rsaprivatekey privatekey = ( rsaprivatekey ) getprivatekey ( jwtconfig . getkey ( ) . getfilename ( ) , ( string ) secretconfig . get ( jwt_private_key_password ) , jwtconfig . getkey ( ) . getkeyname ( ) ) ;	A static method that generate JWT token from JWT claims object.
private static privatekey getprivatekey ( string filename , string password , string key ) { if ( logger . isdebugenabled ( ) ) logger . debug ( str_ + filename + str_ + key ) ; privatekey privatekey = null ; try { keystore keystore = keystore . getinstance ( str_ ) ; keystore . load ( config . getinstance ( ) . getinputstreamfromfile ( filename ) , password . tochararray ( ) ) ; privatekey = ( privatekey ) keystore . getkey ( key , password . tochararray ( ) ) ; } catch ( exception e ) { logger . error ( str_ , e ) ; } if ( privatekey == null ) { logger . error ( str_ ) ; } return privatekey ; }	Get private key from java key store.
public static string totimeprecision ( final timeunit t ) { switch ( t ) { case hours : return str_ ; case minutes : return str_ ; case seconds : return str_ ; case milliseconds : return str_ ; case microseconds : return str_ ; case nanoseconds : return str_ ; default : enumset < timeunit > allowedtimeunits = enumset . of ( timeunit . hours , timeunit . minutes , timeunit . seconds , timeunit . milliseconds , timeunit . microseconds , timeunit . nanoseconds ) ; throw new illegalargumentexception ( str_ + allowedtimeunits ) ; } }	Convert from a TimeUnit to a influxDB timeunit String.
private synchronized jwt getjwt ( icachestrategy cachestrategy , jwt . key key ) { jwt result = cachestrategy . getcachedjwt ( key ) ; if ( result == null ) {	cache jwt if not exist.
private boolean isswitcherchange ( boolean switcherstatus ) { boolean ret = bool_ ; if ( switcherstatus != lastheartbeatswitcherstatus ) { ret = bool_ ; lastheartbeatswitcherstatus = switcherstatus ; logger . info ( str_ + switcherstatus ) ; } return ret ; }	check heart beat switcher status, if switcher is changed, then change lastHeartBeatSwitcherStatusto the latest status.
@ override public string getidentity ( ) { return protocol + constants . protocol_separator + host + str_ + port + str_ + getparameter ( urlparamtype . group . getname ( ) , urlparamtype . group . getvalue ( ) ) + str_ + getpath ( ) + str_ + getparameter ( urlparamtype . version . getname ( ) , urlparamtype . version . getvalue ( ) ) + str_ + getparameter ( urlparamtype . nodetype . getname ( ) , urlparamtype . nodetype . getvalue ( ) ) ; }	Return service identity, if two urls have the same identity, then same service.
@ override public boolean canserve ( url refurl ) { if ( refurl == null || ! this . getpath ( ) . equals ( refurl . getpath ( ) ) ) { return bool_ ; } if ( ! protocol . equals ( refurl . getprotocol ( ) ) ) { return bool_ ; } if ( ! constants . node_type_service . equals ( this . getparameter ( urlparamtype . nodetype . getname ( ) ) ) ) { return bool_ ; } string version = getparameter ( urlparamtype . version . getname ( ) , urlparamtype . version . getvalue ( ) ) ; string refversion = refurl . getparameter ( urlparamtype . version . getname ( ) , urlparamtype . version . getvalue ( ) ) ; if ( ! version . equals ( refversion ) ) { return bool_ ; }	check if this url can serve the refUrl.
public metricname resolve ( string p ) { final string next ; if ( p != null && ! p . isempty ( ) ) { if ( key != null && ! key . isempty ( ) ) { next = key + separator + p ; } else { next = p ; } } else { next = this . key ; } return new metricname ( next , tags ) ; }	Build the MetricName that is this with another path appended to it.The new MetricName inherits the tags of this one.
public metricname tagged ( map < string , string > add ) { final map < string , string > tags = new hashmap < > ( add ) ; tags . putall ( this . tags ) ; return new metricname ( key , tags ) ; }	Add tags to a metric name and return the newly created MetricName.
public static metricname join ( metricname ... parts ) { final stringbuilder namebuilder = new stringbuilder ( ) ; final map < string , string > tags = new hashmap < > ( ) ; boolean first = bool_ ; for ( metricname part : parts ) { final string name = part . getkey ( ) ; if ( name != null && ! name . isempty ( ) ) { if ( first ) { first = bool_ ; } else { namebuilder . append ( separator ) ; } namebuilder . append ( name ) ; } if ( ! part . gettags ( ) . isempty ( ) ) tags . putall ( part . gettags ( ) ) ; } return new metricname ( namebuilder . tostring ( ) , tags ) ; }	Join the specified set of metric names.
public static metricname build ( string ... parts ) { if ( parts == null || parts . length == num_ ) return metricname . empty ; if ( parts . length == num_ ) return new metricname ( parts [ num_ ] , empty_tags ) ; return new metricname ( buildname ( parts ) , empty_tags ) ; }	Build a new metric name using the specific path components.
static void initpaths ( ) { if ( config != null && config . getpaths ( ) != null ) { for ( pathchain pathchain : config . getpaths ( ) ) { pathchain . validate ( configname + str_ ) ;	Build "handlerListById" and "reqTypeMatcherMap" from the paths in the config.
static void initdefaulthandlers ( ) { if ( config != null && config . getdefaulthandlers ( ) != null ) { defaulthandlers = gethandlersfromexeclist ( config . getdefaulthandlers ( ) ) ; handlerlistbyid . put ( str_ , defaulthandlers ) ; } }	Build "defaultHandlers" from the defaultHandlers in the config.
private static void addsourcechain ( pathchain sourcechain ) { try { class sourceclass = class . forname ( sourcechain . getsource ( ) ) ; endpointsource source = ( endpointsource ) sourceclass . newinstance ( ) ; for ( endpointsource . endpoint endpoint : source . listendpoints ( ) ) { pathchain sourcedpath = new pathchain ( ) ; sourcedpath . setpath ( endpoint . getpath ( ) ) ; sourcedpath . setmethod ( endpoint . getmethod ( ) ) ; sourcedpath . setexec ( sourcechain . getexec ( ) ) ; sourcedpath . validate ( sourcechain . getsource ( ) ) ; addpathchain ( sourcedpath ) ; } } catch ( exception e ) { logger . error ( str_ + sourcechain ) ; if ( e instanceof runtimeexception ) { throw ( runtimeexception ) e ; } else { throw new runtimeexception ( e ) ; } } }	Add PathChains crated from the EndpointSource given in sourceChain.
public static void next ( httpserverexchange httpserverexchange ) throws exception { httphandler httphandler = getnext ( httpserverexchange ) ; if ( httphandler != null ) { httphandler . handlerequest ( httpserverexchange ) ; } else if ( lasthandler != null ) { lasthandler . handlerequest ( httpserverexchange ) ; } }	Handle the next request in the chain.
public static void next ( httpserverexchange httpserverexchange , httphandler next ) throws exception { if ( next != null ) { next . handlerequest ( httpserverexchange ) ; } else { next ( httpserverexchange ) ; } }	Go to the next handler if the given next is none null.
public static void next ( httpserverexchange httpserverexchange , string execname , boolean returntoorigflow ) throws exception { string currentchainid = httpserverexchange . getattachment ( chain_id ) ; integer currentnextindex = httpserverexchange . getattachment ( chain_seq ) ; httpserverexchange . putattachment ( chain_id , execname ) ; httpserverexchange . putattachment ( chain_seq , num_ ) ; next ( httpserverexchange ) ;	Allow nexting directly to a flow.
public static httphandler getnext ( httpserverexchange httpserverexchange ) { string chainid = httpserverexchange . getattachment ( chain_id ) ; list < httphandler > handlersforid = handlerlistbyid . get ( chainid ) ; integer nextindex = httpserverexchange . getattachment ( chain_seq ) ;	Returns the instance of the next handler, rather then calling handleRequeston it.
public static httphandler getnext ( httpserverexchange httpserverexchange , httphandler next ) throws exception { if ( next != null ) { return next ; } return getnext ( httpserverexchange ) ; }	Returns the instance of the next handler, or the given next param if it's notnull.
public static boolean start ( httpserverexchange httpserverexchange ) {	On the first step of the request, match the request against the configuredpaths.
public static boolean startdefaulthandlers ( httpserverexchange httpserverexchange ) {	If there is no matching path, the OrchestrationHandler is going to try to start the defaultHandlers.If there are default handlers defined, store the chain id within the exchange.Otherwise return false.
private static list < httphandler > gethandlersfromexeclist ( list < string > execs ) { list < httphandler > handlersfromexeclist = new arraylist < > ( ) ; if ( execs != null ) { for ( string exec : execs ) { list < httphandler > handlerlist = handlerlistbyid . get ( exec ) ; if ( handlerlist == null ) throw new runtimeexception ( str_ + exec ) ; for ( httphandler handler : handlerlist ) { if ( handler instanceof middlewarehandler ) {	Converts the list of chains and handlers to a flat list of handlers.
private static void registermiddlewarehandler ( object handler ) { if ( handler instanceof middlewarehandler ) {	Detect if the handler is a MiddlewareHandler instance.
private static void initmapdefinedhandler ( map < string , object > handler ) {	Helper method for generating the instance of a handler from its mapdefinition in config.
static tuple < string , class > splitclassandname ( string classlabel ) { string [ ] stringnamesplit = classlabel . split ( str_ ) ;	To support multiple instances of the same class, support a naming.
static void setconfig ( string configname ) throws exception { handler . configname = configname ; config = ( handlerconfig ) config . getinstance ( ) . getjsonobjectconfig ( configname , handlerconfig . class ) ; inithandlers ( ) ; initpaths ( ) ; }	Exposed for testing only.
public iclientrequestcomposable getcomposer ( clientrequestcomposers composername ) { iclientrequestcomposable composer = composersmap . get ( composername ) ; if ( composer == null ) { initdefaultcomposer ( composername ) ; } return composersmap . get ( composername ) ; }	get IClientRequestComposable based on ClientRequestComposers composer name.
@ override public double getmean ( ) { if ( values . length == num_ ) { return num_ ; } double sum = num_ ; for ( int i = num_ ; i < values . length ; i ++ ) { sum += values [ i ] * normweights [ i ] ; } return sum ; }	Returns the weighted arithmetic mean of the values in the snapshot.
@ override public double getstddev ( ) {	Returns the weighted standard deviation of the values in the snapshot.
public void validate ( string origin ) { list < string > problems = new arraylist < > ( ) ; if ( source == null ) { if ( path == null ) { problems . add ( str_ ) ; } else if ( method == null ) { problems . add ( str_ + path ) ; } } else { if ( path != null ) { problems . add ( str_ + source + str_ + path ) ; } if ( method != null ) { problems . add ( str_ + source + str_ + method ) ; } } if ( method != null && ! util . methods . contains ( method . touppercase ( ) ) ) { problems . add ( str_ + method ) ; } if ( ! problems . isempty ( ) ) { throw new runtimeexception ( str_ + origin + str_ + string . join ( str_ , problems ) + str_ ) ; } }	Validate the settings and raise Exception on error.The origin is used to help locate problems.
private void startlistenerthreadifnewservice ( url url ) { string servicename = url . getpath ( ) ; if ( ! lookupservices . containskey ( servicename ) ) { long value = lookupservices . putifabsent ( servicename , num_ ) ; if ( value == null ) { servicelookupthread lookupthread = new servicelookupthread ( servicename ) ; lookupthread . setdaemon ( bool_ ) ; lookupthread . start ( ) ; } } }	if new service registered, start a new lookup threadeach serviceName start a lookup thread to discover service.
private consulresponse < list < consulservice > > lookupconsulservice ( string servicename , long lastconsulindexid ) { consulresponse < list < consulservice > > response = client . lookuphealthservice ( servicename , null , lastconsulindexid , getconsultoken ( ) ) ; return response ; }	directly fetch consul service data.
private void updateservicecache ( string servicename , concurrenthashmap < string , list < url > > serviceurls , boolean neednotify ) { if ( serviceurls != null && ! serviceurls . isempty ( ) ) { list < url > urls = servicecache . get ( servicename ) ; if ( urls == null ) { if ( logger . isdebugenabled ( ) ) { try { logger . debug ( str_ + config . getinstance ( ) . getmapper ( ) . writevalueasstring ( serviceurls ) ) ; } catch ( exception e ) { } } servicecache . put ( servicename , serviceurls . get ( servicename ) ) ; } for ( map . entry < string , list < url > > entry : serviceurls . entryset ( ) ) { boolean change = bool_ ; if ( urls != null ) { list < url > newurls = entry . getvalue ( ) ; if ( newurls == null || newurls . isempty ( ) || consulutils . issame ( newurls , urls ) ) { change = bool_ ; } else { servicecache . put ( servicename , newurls ) ; } } if ( change && neednotify ) { notifyexecutor . execute ( new notifyservice ( entry . getkey ( ) , entry . getvalue ( ) ) ) ; logger . info ( str_ + entry . getkey ( ) ) ; stringbuilder sb = new stringbuilder ( ) ; for ( url url : entry . getvalue ( ) ) { sb . append ( url . geturi ( ) ) . append ( str_ ) ; } logger . info ( str_ + sb . tostring ( ) ) ; } } } }	update service cache of the serviceName.update local cache when service list changed,if need notify, notify service.
public static void verifyandthrow ( final set < string > nameset , final x509certificate cert ) throws certificateexception { if ( ! verify ( nameset , cert ) ) { throw new certificateexception ( str_ + nameset + str_ ) ; } }	Perform server identify check using given names and throw CertificateException if the check fails.
public static void verifyandthrow ( final string name , final x509certificate cert ) throws certificateexception { if ( ! verify ( name , cert ) ) { throw new certificateexception ( str_ + name + str_ ) ; } }	Perform server identify check using given name and throw CertificateException if the check fails.
public void addauthtoken ( clientrequest request , string token ) { if ( token != null && ! token . startswith ( str_ ) ) { if ( token . touppercase ( ) . startswith ( str_ ) ) {	Add Authorization Code grant token the caller app gets from OAuth2 server.This is the method called from client like web server.
public void addauthtokentrace ( clientrequest request , string token , string traceabilityid ) { if ( token != null && ! token . startswith ( str_ ) ) { if ( token . touppercase ( ) . startswith ( str_ ) ) {	Add Authorization Code grant token the caller app gets from OAuth2 server and add traceabilityIdThis is the method called from client like web server that want to have traceabilityId pass through.
public result propagateheaders ( clientrequest request , final httpserverexchange exchange ) { string tid = exchange . getrequestheaders ( ) . getfirst ( httpstringconstants . traceability_id ) ; string token = exchange . getrequestheaders ( ) . getfirst ( headers . authorization ) ; string cid = exchange . getrequestheaders ( ) . getfirst ( httpstringconstants . correlation_id ) ; return populateheader ( request , token , cid , tid ) ; }	Support API to API calls with scope token.
public result populateheader ( clientrequest request , string authtoken , string correlationid , string traceabilityid ) { if ( traceabilityid != null ) { addauthtokentrace ( request , authtoken , traceabilityid ) ; } else { addauthtoken ( request , authtoken ) ; } result < jwt > result = tokenmanager . getjwt ( request ) ; if ( result . isfailure ( ) ) { return failure . of ( result . geterror ( ) ) ; } request . getrequestheaders ( ) . put ( httpstringconstants . correlation_id , correlationid ) ; request . getrequestheaders ( ) . put ( httpstringconstants . scope_token , str_ + result . getresult ( ) . getjwt ( ) ) ; return result ; }	Support API to API calls with scope token.
public static sslcontext createsslcontext ( ) throws ioexception { map < string , object > tlsmap = ( map < string , object > ) clientconfig . get ( ) . getmappedconfig ( ) . get ( tls ) ; return null == tlsmap ? null : createsslcontext ( ( string ) tlsmap . get ( tlsconfig . default_group_key ) ) ; }	default method for creating ssl context.
public completablefuture < clientconnection > connectasync ( uri uri ) { return this . connectasync ( null , uri , com . networknt . client . http2client . worker , com . networknt . client . http2client . ssl , com . networknt . client . http2client . buffer_pool , optionmap . create ( undertowoptions . enable_http2 , bool_ ) ) ; }	Create async connection with default config value.
static char [ ] tochararray ( final charsequence cs ) { if ( cs instanceof string ) { return ( ( string ) cs ) . tochararray ( ) ; } final int sz = cs . length ( ) ; final char [ ] array = new char [ cs . length ( ) ] ; for ( int i = num_ ; i < sz ; i ++ ) { array [ i ] = cs . charat ( i ) ; } return array ; }	Green implementation of toCharArray.
static boolean regionmatches ( final charsequence cs , final boolean ignorecase , final int thisstart , final charsequence substring , final int start , final int length ) { if ( cs instanceof string && substring instanceof string ) { return ( ( string ) cs ) . regionmatches ( ignorecase , thisstart , ( string ) substring , start , length ) ; } int index1 = thisstart ; int index2 = start ; int tmplen = length ;	Green implementation of regionMatches.
private static filesystem createzipfilesystem ( string zipfilename , boolean create ) throws ioexception {	Returns a zip file system.
public static void list ( string zipfilename ) throws ioexception { if ( logger . isdebugenabled ( ) ) logger . debug ( str_ , zipfilename ) ;	List the contents of the specified zip file.
public static void deleteoldfiles ( string dirpath , int olderthanminute ) { file folder = new file ( dirpath ) ; if ( folder . exists ( ) ) { file [ ] listfiles = folder . listfiles ( ) ; long eligiblefordeletion = system . currenttimemillis ( ) - ( olderthanminute * num_ * num_ ) ; for ( file listfile : listfiles ) { if ( listfile . lastmodified ( ) < eligiblefordeletion ) { if ( ! listfile . delete ( ) ) { logger . error ( str_ , listfile ) ; } } } } }	Delele old files.
public static bytebuffer tobytebuffer ( string s ) { bytebuffer buffer = bytebuffer . allocatedirect ( s . length ( ) ) ; buffer . put ( s . getbytes ( utf_8 ) ) ; buffer . flip ( ) ; return buffer ; }	convert String to ByteBuffer.
public static bytebuffer tobytebuffer ( file file ) { bytebuffer buffer = bytebuffer . allocatedirect ( ( int ) file . length ( ) ) ; try { buffer . put ( tobytearray ( new fileinputstream ( file ) ) ) ; } catch ( ioexception e ) { logger . error ( str_ + e . getmessage ( ) ) ; } buffer . flip ( ) ; return buffer ; }	Convert a File into a ByteBuffer.
public static string gettempdir ( ) {	get temp dir from OS.
public static byte [ ] tobytearray ( inputstream is ) throws ioexception { bytearrayoutputstream output = new bytearrayoutputstream ( ) ; try { byte [ ] b = new byte [ buffer_size ] ; int n = num_ ; while ( ( n = is . read ( b ) ) != - num_ ) { output . write ( b , num_ , n ) ; } return output . tobytearray ( ) ; } finally { output . close ( ) ; } }	Reads and returns the rest of the given input stream as a byte array.Caller is responsible for closing the given input stream.
public static object getinjectvalue ( string string ) { matcher m = pattern . matcher ( string ) ; stringbuffer sb = new stringbuffer ( ) ;	Method used to generate the values from environment variables or "values.yaml".
public static boolean isexclusionconfigfile ( string configname ) { list < object > exclusionconfigfilelist = ( exclusionmap == null ) ? new arraylist < > ( ) : ( list < object > ) exclusionmap . get ( exclusion_config_file_list ) ; return centralized_management . equals ( configname ) || scalable_config . equals ( configname ) || exclusionconfigfilelist . contains ( configname ) ; }	Double check values and exclusions to ensure no dead loop.
private static object typecast ( string str ) { if ( str == null || str . equals ( str_ ) ) { return null ; }	Method used to cast string into int, double or boolean.
public list < irequestdumpable > createrequestdumpers ( dumpconfig config , httpserverexchange exchange ) { requestdumperfactory factory = new requestdumperfactory ( ) ; list < irequestdumpable > dumpers = new arraylist < > ( ) ; for ( string dumpernames : requestdumpers ) { irequestdumpable dumper = factory . create ( dumpernames , config , exchange ) ; dumpers . add ( dumper ) ; } return dumpers ; }	use RequestDumperFactory to create dumpers listed in this.requestDumpers.
public list < iresponsedumpable > createresponsedumpers ( dumpconfig config , httpserverexchange exchange ) { responsedumperfactory factory = new responsedumperfactory ( ) ; list < iresponsedumpable > dumpers = new arraylist < > ( ) ; for ( string dumpernames : responsedumpers ) { iresponsedumpable dumper = factory . create ( dumpernames , config , exchange ) ; dumpers . add ( dumper ) ; } return dumpers ; }	use ResponseDumperFactory to create dumpers listed in this.responseDumpers.
public static string defaultorigin ( httpserverexchange exchange ) { string host = networkutils . formatpossibleipv6address ( exchange . gethostname ( ) ) ; string protocol = exchange . getrequestscheme ( ) ; int port = exchange . gethostport ( ) ;	Determine the default origin, to allow for local access.
public static string sanitizedefaultport ( string url ) { int afterschemeindex = url . indexof ( str_ ) ; if ( afterschemeindex < num_ ) { return url ; } string scheme = url . substring ( num_ , afterschemeindex ) ; int fromindex = scheme . length ( ) + num_ ;	Removes the port from a URL if this port is the default one for the URL's scheme.
public void addfirst ( propertysource < ? > propertysource ) { if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ + propertysource . getname ( ) + str_ ) ; } removeifpresent ( propertysource ) ; this . propertysourcelist . add ( num_ , propertysource ) ; }	Add the given property source object with highest precedence.
public void addbefore ( string relativepropertysourcename , propertysource < ? > propertysource ) { if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ + propertysource . getname ( ) + str_ + relativepropertysourcename + str_ ) ; } assertlegalrelativeaddition ( relativepropertysourcename , propertysource ) ; removeifpresent ( propertysource ) ; int index = assertpresentandgetindex ( relativepropertysourcename ) ; addatindex ( index , propertysource ) ; }	Add the given property source object with precedence immediately higher thanthe named relative property source.
public void replace ( string name , propertysource < ? > propertysource ) { if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ + name + str_ + propertysource . getname ( ) + str_ ) ; } int index = assertpresentandgetindex ( name ) ; this . propertysourcelist . set ( index , propertysource ) ; }	Replace the property source with the given name with the given propertysource object.
protected void assertlegalrelativeaddition ( string relativepropertysourcename , propertysource < ? > propertysource ) { string newpropertysourcename = propertysource . getname ( ) ; if ( relativepropertysourcename . equals ( newpropertysourcename ) ) { throw new illegalargumentexception ( str_ + newpropertysourcename + str_ ) ; } }	Ensure that the given property source is not being added relative to itself.
private void addatindex ( int index , propertysource < ? > propertysource ) { removeifpresent ( propertysource ) ; this . propertysourcelist . add ( index , propertysource ) ; }	Add the given property source at a particular index in the list.
private int assertpresentandgetindex ( string name ) { int index = this . propertysourcelist . indexof ( propertysource . named ( name ) ) ; if ( index == - num_ ) { throw new illegalargumentexception ( str_ + name + str_ ) ; } return index ; }	Assert that the named property source is present and return its index.
public void fail ( ) { hasfailure = bool_ ;	Countdown and fail-fast if the sub message is failed.
protected final void putint16 ( int i16 ) { ensurecapacity ( position + num_ ) ; byte [ ] buf = buffer ; buf [ position ++ ] = ( byte ) ( i16 & num_ ) ; buf [ position ++ ] = ( byte ) ( i16 > > > num_ ) ; }	Put 16-bit integer in the buffer.
protected final void putint32 ( long i32 ) { ensurecapacity ( position + num_ ) ; byte [ ] buf = buffer ; buf [ position ++ ] = ( byte ) ( i32 & num_ ) ; buf [ position ++ ] = ( byte ) ( i32 > > > num_ ) ; buf [ position ++ ] = ( byte ) ( i32 > > > num_ ) ; buf [ position ++ ] = ( byte ) ( i32 > > > num_ ) ; }	Put 32-bit integer in the buffer.
protected final void putstring ( string s ) { ensurecapacity ( position + ( s . length ( ) * num_ ) + num_ ) ; system . arraycopy ( s . getbytes ( ) , num_ , buffer , position , s . length ( ) ) ; position += s . length ( ) ; buffer [ position ++ ] = num_ ; }	Put a string in the buffer.
public static final string collatecharset ( string charset ) { string [ ] output = stringutils . split ( charset , str_ ) ; return output [ num_ ] . replace ( str_ , str_ ) . trim ( ) ; }	'utf8' COLLATE 'utf8_general_ci'.
public void updatebyquery ( essyncconfig config , map < string , object > paramstmp , map < string , object > esfielddata ) { if ( paramstmp . isempty ( ) ) { return ; } esmapping mapping = config . getesmapping ( ) ; boolquerybuilder querybuilder = querybuilders . boolquery ( ) ; paramstmp . foreach ( ( fieldname , value ) -> querybuilder . must ( querybuilders . termsquery ( fieldname , value ) ) ) ;	update by query.
public static string getcharset ( final int id ) { entry entry = getentry ( id ) ; if ( entry != null ) { return entry . mysqlcharset ; } else { logger . warn ( str_ + id ) ; return null ; } }	Return defined charset name for mysql.
public static string getcollation ( final int id ) { entry entry = getentry ( id ) ; if ( entry != null ) { return entry . mysqlcollation ; } else { logger . warn ( str_ + id ) ; return null ; } }	Return defined collaction name for mysql.
public static string getjavacharset ( final int id ) { entry entry = getentry ( id ) ; if ( entry != null ) { if ( entry . javacharset != null ) { return entry . javacharset ; } else { logger . warn ( str_ + id + str_ + entry . mysqlcharset + str_ + entry . mysqlcollation ) ; return null ; } } else { logger . warn ( str_ + id ) ; return null ; } }	Return converted charset name for java.
public static hashmode getpartitionhashcolumns ( string name , string pkhashconfigs ) { if ( stringutils . isempty ( pkhashconfigs ) ) { return null ; } list < partitiondata > datas = partitiondatas . get ( pkhashconfigs ) ; for ( partitiondata data : datas ) { if ( data . simplename != null ) { if ( data . simplename . equalsignorecase ( name ) ) { return data . hashmode ; } } else { if ( data . regexfilter . filter ( name ) ) { return data . hashmode ; } } } return null ; }	match return List , not match return null.
private final void decodefields ( logbuffer buffer , final int len ) { final int limit = buffer . limit ( ) ; buffer . limit ( len + buffer . position ( ) ) ; for ( int i = num_ ; i < columncnt ; i ++ ) { columninfo info = columninfo [ i ] ; switch ( info . type ) { case mysql_type_tiny_blob : case mysql_type_blob : case mysql_type_medium_blob : case mysql_type_long_blob : case mysql_type_double : case mysql_type_float : case mysql_type_geometry : case mysql_type_json : info . meta = buffer . getuint8 ( ) ; break ; case mysql_type_set : case mysql_type_enum : logger . warn ( str_ + str_ + info . type ) ; break ; case mysql_type_string : { int x = ( buffer . getuint8 ( ) << num_ ) ;	Decode field metadata by column types.
public logevent decode ( logbuffer buffer , logcontext context ) throws ioexception { final int limit = buffer . limit ( ) ; if ( limit >= formatdescriptionlogevent . log_event_header_len ) { logheader header = new logheader ( buffer , context . getformatdescription ( ) ) ; final int len = header . geteventlen ( ) ; if ( limit >= len ) { logevent event ; if ( handleset . get ( header . gettype ( ) ) ) { buffer . limit ( len ) ; try { event = decode ( buffer , header , context ) ; } catch ( ioexception e ) { if ( logger . iswarnenabled ( ) ) { logger . warn ( str_ + logevent . gettypename ( header . gettype ( ) ) + str_ + context . getlogposition ( ) , e ) ; } throw e ; } finally { buffer . limit ( limit ) ; } } else { event = new unknownlogevent ( header ) ; } if ( event != null ) {	Decoding an event from binary-log buffer.
public final int compareto ( string filename , final long position ) { final int val = this . filename . compareto ( filename ) ; if ( val == num_ ) { return ( int ) ( this . position - position ) ; } return val ; }	Compares with the specified fileName and position.
public final logbuffer duplicate ( final int pos , final int len ) { if ( pos + len > limit ) throw new illegalargumentexception ( str_ + ( pos + len ) ) ;	Return n bytes in this buffer.
public final logbuffer forward ( final int len ) { if ( position + len > origin + limit ) throw new illegalargumentexception ( str_ + ( position + len - origin ) ) ; this . position += len ; return this ; }	Forwards this buffer's position.
public final logbuffer consume ( final int len ) { if ( limit > len ) { limit -= len ; origin += len ; position = origin ; return this ; } else if ( limit == len ) { limit = num_ ; origin = num_ ; position = num_ ; return this ; } else { throw new illegalargumentexception ( str_ + len ) ; } }	Consume this buffer, moving origin and position.
public final int getint8 ( final int pos ) { if ( pos >= limit || pos < num_ ) throw new illegalargumentexception ( str_ + pos ) ; return buffer [ origin + pos ] ; }	Return 8-bit signed int from buffer.
public final int getuint8 ( final int pos ) { if ( pos >= limit || pos < num_ ) throw new illegalargumentexception ( str_ + pos ) ; return num_ & buffer [ origin + pos ] ; }	Return 8-bit unsigned int from buffer.
public final string getfixstring ( final int pos , final int len , string charsetname ) { if ( pos + len > limit || pos < num_ ) throw new illegalargumentexception ( str_ + ( pos < num_ ? pos : ( pos + len ) ) ) ; final int from = origin + pos ; final int end = from + len ; byte [ ] buf = buffer ; int found = from ; for ( ; ( found < end ) && buf [ found ] != str_ ; found ++ ) ; try { return new string ( buf , from , found - from , charsetname ) ; } catch ( unsupportedencodingexception e ) { throw new illegalargumentexception ( str_ + charsetname , e ) ; } }	Return fix length string from buffer.
public final string getfixstring ( final int len , string charsetname ) { if ( position + len > origin + limit ) throw new illegalargumentexception ( str_ + ( position + len - origin ) ) ; final int from = position ; final int end = from + len ; byte [ ] buf = buffer ; int found = from ; for ( ; ( found < end ) && buf [ found ] != str_ ; found ++ ) ; try { string string = new string ( buf , from , found - from , charsetname ) ; position += len ; return string ; } catch ( unsupportedencodingexception e ) { throw new illegalargumentexception ( str_ + charsetname , e ) ; } }	Return next fix length string from buffer.
public final string getstring ( final int pos , string charsetname ) { if ( pos >= limit || pos < num_ ) throw new illegalargumentexception ( str_ + pos ) ; byte [ ] buf = buffer ; final int len = ( num_ & buf [ origin + pos ] ) ; if ( pos + len + num_ > limit ) throw new illegalargumentexception ( str_ + ( pos + len + num_ ) ) ; try { return new string ( buf , origin + pos + num_ , len , charsetname ) ; } catch ( unsupportedencodingexception e ) { throw new illegalargumentexception ( str_ + charsetname , e ) ; } }	Return dynamic length string from buffer.
public final string getstring ( string charsetname ) { if ( position >= origin + limit ) throw new illegalargumentexception ( str_ + position ) ; byte [ ] buf = buffer ; final int len = ( num_ & buf [ position ] ) ; if ( position + len + num_ > origin + limit ) throw new illegalargumentexception ( str_ + ( position + len + num_ - origin ) ) ; try { string string = new string ( buf , position + num_ , len , charsetname ) ; position += len + num_ ; return string ; } catch ( unsupportedencodingexception e ) { throw new illegalargumentexception ( str_ + charsetname , e ) ; } }	Return next dynamic length string from buffer.
public final boolean nextonerow ( bitset columns , boolean after ) { final boolean hasonerow = buffer . hasremaining ( ) ; if ( hasonerow ) { int column = num_ ; for ( int i = num_ ; i < columnlen ; i ++ ) if ( columns . get ( i ) ) { column ++ ; } if ( after && partial ) { partialbits . clear ( ) ; long valueoptions = buffer . getpackedlong ( ) ; int partial_json_updates = num_ ; if ( ( valueoptions & partial_json_updates ) != num_ ) { partialbits . set ( num_ ) ; buffer . forward ( ( jsoncolumncount + num_ ) / num_ ) ; } } nullbitindex = num_ ; nullbits . clear ( ) ; buffer . fillbitmap ( nullbits , column ) ; } return hasonerow ; }	Extracting next row from packed buffer.
static int mysqltojavatype ( int type , final int meta , boolean isbinary ) { int javatype ; if ( type == logevent . mysql_type_string ) { if ( meta >= num_ ) { int byte0 = meta > > num_ ; if ( ( byte0 & num_ ) != num_ ) { type = byte0 | num_ ; } else { switch ( byte0 ) { case logevent . mysql_type_set : case logevent . mysql_type_enum : case logevent . mysql_type_string : type = byte0 ; } } } } switch ( type ) { case logevent . mysql_type_long : javatype = types . integer ; break ; case logevent . mysql_type_tiny : javatype = types . tinyint ; break ; case logevent . mysql_type_short : javatype = types . smallint ; break ; case logevent . mysql_type_int24 : javatype = types . integer ; break ; case logevent . mysql_type_longlong : javatype = types . bigint ; break ; case logevent . mysql_type_decimal : javatype = types . decimal ; break ; case logevent . mysql_type_newdecimal : javatype = types . decimal ; break ; case logevent . mysql_type_float : javatype = types . real ;	Maps the given MySQL type to the correct JDBC type.
protected void afterstarteventparser ( canaleventparser eventparser ) {	around event parser, default impl.
@ override public long lastmodified ( ) throws ioexception { long lastmodified = getfileforlastmodifiedcheck ( ) . lastmodified ( ) ; if ( lastmodified == num_ ) { throw new filenotfoundexception ( getdescription ( ) + str_ ) ; } return lastmodified ; }	This implementation checks the timestamp of the underlying File, ifavailable.
@ override public org . springframework . core . io . resource createrelative ( string relativepath ) throws ioexception { throw new filenotfoundexception ( str_ + getdescription ( ) ) ; }	This implementation throws a FileNotFoundException, assuming that relativeresources cannot be created for this resource.
public void setnamealiases ( map < string , list < string > > aliases ) { this . namealiases = new linkedmultivaluemap < string , string > ( aliases ) ; }	Set name aliases.
public static long readunsignedintlittleendian ( byte [ ] data , int index ) { long result = ( long ) ( data [ index ] & num_ ) | ( long ) ( ( data [ index + num_ ] & num_ ) << num_ ) | ( long ) ( ( data [ index + num_ ] & num_ ) << num_ ) | ( long ) ( ( data [ index + num_ ] & num_ ) << num_ ) ; return result ; }	Read 4 bytes in Little-endian byte order.
@ override public synchronized string format ( final logrecord record ) { buffer . setlength ( prefix . length ( ) ) ; buffer . append ( timestampformatter . format ( new date ( record . getmillis ( ) ) ) ) ; buffer . append ( str_ ) ; buffer . append ( levelnumbertocommonslevelname ( record . getlevel ( ) ) ) ; string [ ] parts = record . getsourceclassname ( ) . split ( str_ ) ; buffer . append ( str_ + parts [ parts . length - num_ ] + str_ + record . getsourcemethodname ( ) + str_ ) ; buffer . append ( suffix ) ; buffer . append ( formatmessage ( record ) ) . append ( lineseparator ) ; if ( record . getthrown ( ) != null ) { final stringwriter trace = new stringwriter ( ) ; record . getthrown ( ) . printstacktrace ( new printwriter ( trace ) ) ; buffer . append ( trace ) ; } return buffer . tostring ( ) ; }	Format the given log record and return the formatted string.
public string getseleniumscript ( string name ) { string rawfunction = readscript ( prefix + name ) ; return string . format ( str_ , rawfunction ) ; }	Loads the named Selenium script and returns it wrapped in an anonymous function.
public static registrationrequest fromjson ( map < string , object > raw ) throws jsonexception {	Create an object from a registration request formatted as a json string.
public void validate ( ) throws gridconfigurationexception {	Validate the current setting and throw a config exception is an invalid setup is detected.
public void forwardnewsessionrequestandupdateregistry ( testsession session ) throws newsessionexception { try ( newsessionpayload payload = newsessionpayload . create ( immutablemap . of ( str_ , session . getrequestedcapabilities ( ) ) ) ) { stringbuilder json = new stringbuilder ( ) ; payload . writeto ( json ) ; request . setbody ( json . tostring ( ) ) ; session . forward ( getrequest ( ) , getresponse ( ) , bool_ ) ; } catch ( ioexception e ) {	Forward the new session request to the TestSession that has been assigned, and parse theresponse to extract and return the external key assigned by the remote.
private void beforesessionevent ( ) throws newsessionexception { remoteproxy p = session . getslot ( ) . getproxy ( ) ; if ( p instanceof testsessionlistener ) { try { ( ( testsessionlistener ) p ) . beforesession ( session ) ; } catch ( exception e ) { log . severe ( str_ + e . getmessage ( ) ) ; e . printstacktrace ( ) ; throw new newsessionexception ( str_ , e ) ; } } }	calls the TestSessionListener is the proxy for that node has one specified.
public void waitforsessionbound ( ) throws interruptedexception , timeoutexception {	wait for the registry to match the request with a TestSlot.
public static expectedcondition < boolean > titleis ( final string title ) { return new expectedcondition < boolean > ( ) { private string currenttitle = str_ ; @ override public boolean apply ( webdriver driver ) { currenttitle = driver . gettitle ( ) ; return title . equals ( currenttitle ) ; } @ override public string tostring ( ) { return string . format ( str_ , title , currenttitle ) ; } } ; }	An expectation for checking the title of a page.
public static expectedcondition < boolean > titlecontains ( final string title ) { return new expectedcondition < boolean > ( ) { private string currenttitle = str_ ; @ override public boolean apply ( webdriver driver ) { currenttitle = driver . gettitle ( ) ; return currenttitle != null && currenttitle . contains ( title ) ; } @ override public string tostring ( ) { return string . format ( str_ , title , currenttitle ) ; } } ; }	An expectation for checking that the title contains a case-sensitive substring.
public static expectedcondition < boolean > urltobe ( final string url ) { return new expectedcondition < boolean > ( ) { private string currenturl = str_ ; @ override public boolean apply ( webdriver driver ) { currenturl = driver . getcurrenturl ( ) ; return currenturl != null && currenturl . equals ( url ) ; } @ override public string tostring ( ) { return string . format ( str_ , url , currenturl ) ; } } ; }	An expectation for the URL of the current page to be a specific url.
public static expectedcondition < boolean > urlcontains ( final string fraction ) { return new expectedcondition < boolean > ( ) { private string currenturl = str_ ; @ override public boolean apply ( webdriver driver ) { currenturl = driver . getcurrenturl ( ) ; return currenturl != null && currenturl . contains ( fraction ) ; } @ override public string tostring ( ) { return string . format ( str_ , fraction , currenturl ) ; } } ; }	An expectation for the URL of the current page to contain specific text.
public static expectedcondition < boolean > urlmatches ( final string regex ) { return new expectedcondition < boolean > ( ) { private string currenturl ; private pattern pattern ; private matcher matcher ; @ override public boolean apply ( webdriver driver ) { currenturl = driver . getcurrenturl ( ) ; pattern = pattern . compile ( regex ) ; matcher = pattern . matcher ( currenturl ) ; return matcher . find ( ) ; } @ override public string tostring ( ) { return string . format ( str_ , regex , currenturl ) ; } } ; }	Expectation for the URL to match a specific regular expression.
public static expectedcondition < webelement > presenceofelementlocated ( final by locator ) { return new expectedcondition < webelement > ( ) { @ override public webelement apply ( webdriver driver ) { return driver . findelement ( locator ) ; } @ override public string tostring ( ) { return str_ + locator ; } } ; }	An expectation for checking that an element is present on the DOM of a page.
public static expectedcondition < webelement > visibilityofelementlocated ( final by locator ) { return new expectedcondition < webelement > ( ) { @ override public webelement apply ( webdriver driver ) { try { return elementifvisible ( driver . findelement ( locator ) ) ; } catch ( staleelementreferenceexception e ) { return null ; } } @ override public string tostring ( ) { return str_ + locator ; } } ; }	An expectation for checking that an element is present on the DOM of a page and visible.Visibility means that the element is not only displayed but also has a height and width that isgreater than 0.
public static expectedcondition < webelement > visibilityof ( final webelement element ) { return new expectedcondition < webelement > ( ) { @ override public webelement apply ( webdriver driver ) { return elementifvisible ( element ) ; } @ override public string tostring ( ) { return str_ + element ; } } ; }	An expectation for checking that an element, known to be present on the DOM of a page, isvisible.
public static expectedcondition < list < webelement > > presenceofallelementslocatedby ( final by locator ) { return new expectedcondition < list < webelement > > ( ) { @ override public list < webelement > apply ( webdriver driver ) { list < webelement > elements = driver . findelements ( locator ) ; return elements . size ( ) > num_ ? elements : null ; } @ override public string tostring ( ) { return str_ + locator ; } } ; }	An expectation for checking that there is at least one element present on a web page.
public static expectedcondition < boolean > texttobepresentinelement ( final webelement element , final string text ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { try { string elementtext = element . gettext ( ) ; return elementtext . contains ( text ) ; } catch ( staleelementreferenceexception e ) { return null ; } } @ override public string tostring ( ) { return string . format ( str_ , text , element ) ; } } ; }	An expectation for checking if the given text is present in the specified element.
public static expectedcondition < boolean > texttobepresentinelementlocated ( final by locator , final string text ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { try { string elementtext = driver . findelement ( locator ) . gettext ( ) ; return elementtext . contains ( text ) ; } catch ( staleelementreferenceexception e ) { return null ; } } @ override public string tostring ( ) { return string . format ( str_ , text , locator ) ; } } ; }	An expectation for checking if the given text is present in the element that matches the givenlocator.
public static expectedcondition < boolean > invisibilityofelementlocated ( final by locator ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { try { return ! ( driver . findelement ( locator ) . isdisplayed ( ) ) ; } catch ( nosuchelementexception e ) {	An expectation for checking that an element is either invisible or not present on the DOM.
public static expectedcondition < boolean > invisibilityofelementwithtext ( final by locator , final string text ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { try { return ! driver . findelement ( locator ) . gettext ( ) . equals ( text ) ; } catch ( nosuchelementexception e ) {	An expectation for checking that an element with text is either invisible or not present on theDOM.
public static expectedcondition < boolean > stalenessof ( final webelement element ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver ignored ) { try {	Wait until an element is no longer attached to the DOM.
public static < t > expectedcondition < t > refreshed ( final expectedcondition < t > condition ) { return new expectedcondition < t > ( ) { @ override public t apply ( webdriver driver ) { try { return condition . apply ( driver ) ; } catch ( staleelementreferenceexception e ) { return null ; } } @ override public string tostring ( ) { return string . format ( str_ , condition ) ; } } ; }	Wrapper for a condition, which allows for elements to update by redrawing.This works around the problem of conditions which have two parts: find an element and thencheck for some condition on it.
public static expectedcondition < boolean > elementselectionstatetobe ( final webelement element , final boolean selected ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { return element . isselected ( ) == selected ; } @ override public string tostring ( ) { return string . format ( str_ , element , ( selected ? str_ : str_ ) ) ; } } ; }	An expectation for checking if the given element is selected.
public static expectedcondition < boolean > not ( final expectedcondition < ? > condition ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { object result = condition . apply ( driver ) ; return result == null || result . equals ( boolean . false ) ; } @ override public string tostring ( ) { return str_ + condition ; } } ; }	An expectation with the logical opposite condition of the given condition.Note that if the Condition you are inverting throws an exception that is caught by the IgnoredExceptions, the inversion will not take place and lead to confusing results.
public static expectedcondition < boolean > attributetobe ( final by locator , final string attribute , final string value ) { return new expectedcondition < boolean > ( ) { private string currentvalue = null ; @ override public boolean apply ( webdriver driver ) { webelement element = driver . findelement ( locator ) ; currentvalue = element . getattribute ( attribute ) ; if ( currentvalue == null || currentvalue . isempty ( ) ) { currentvalue = element . getcssvalue ( attribute ) ; } return value . equals ( currentvalue ) ; } @ override public string tostring ( ) { return string . format ( str_ , locator , value , currentvalue ) ; } } ; }	An expectation for checking WebElement with given locator has attribute with a specific value.
public static expectedcondition < boolean > texttobe ( final by locator , final string value ) { return new expectedcondition < boolean > ( ) { private string currentvalue = null ; @ override public boolean apply ( webdriver driver ) { try { currentvalue = driver . findelement ( locator ) . gettext ( ) ; return currentvalue . equals ( value ) ; } catch ( exception e ) { return bool_ ; } } @ override public string tostring ( ) { return string . format ( str_ , locator , value , currentvalue ) ; } } ; }	An expectation for checking WebElement with given locator has specific text.
public static expectedcondition < boolean > textmatches ( final by locator , final pattern pattern ) { return new expectedcondition < boolean > ( ) { private string currentvalue = null ; @ override public boolean apply ( webdriver driver ) { try { currentvalue = driver . findelement ( locator ) . gettext ( ) ; return pattern . matcher ( currentvalue ) . find ( ) ; } catch ( exception e ) { return bool_ ; } } @ override public string tostring ( ) { return string . format ( str_ , locator , pattern . pattern ( ) , currentvalue ) ; } } ; }	An expectation for checking WebElement with given locator has text with a value as a part ofit.
public static expectedcondition < list < webelement > > numberofelementstobemorethan ( final by locator , final integer number ) { return new expectedcondition < list < webelement > > ( ) { private integer currentnumber = num_ ; @ override public list < webelement > apply ( webdriver webdriver ) { list < webelement > elements = webdriver . findelements ( locator ) ; currentnumber = elements . size ( ) ; return currentnumber > number ? elements : null ; } @ override public string tostring ( ) { return string . format ( str_ , locator , number , currentnumber ) ; } } ; }	An expectation for checking number of WebElements with given locator being more than defined number.
public static expectedcondition < boolean > attributecontains ( final webelement element , final string attribute , final string value ) { return new expectedcondition < boolean > ( ) { private string currentvalue = null ; @ override public boolean apply ( webdriver driver ) { return getattributeorcssvalue ( element , attribute ) . map ( seen -> seen . contains ( value ) ) . orelse ( bool_ ) ; } @ override public string tostring ( ) { return string . format ( str_ , value , currentvalue ) ; } } ; }	An expectation for checking WebElement with given locator has attribute which contains specificvalue.
public static expectedcondition < boolean > attributetobenotempty ( final webelement element , final string attribute ) { return driver -> getattributeorcssvalue ( element , attribute ) . ispresent ( ) ; }	An expectation for checking WebElement any non empty value for given attribute.
public static expectedcondition < webelement > presenceofnestedelementlocatedby ( final webelement element , final by childlocator ) { return new expectedcondition < webelement > ( ) { @ override public webelement apply ( webdriver webdriver ) { return element . findelement ( childlocator ) ; } @ override public string tostring ( ) { return string . format ( str_ , childlocator ) ; } } ; }	An expectation for checking child WebElement as a part of parent element to be present.
public static expectedcondition < boolean > invisibilityofallelements ( final list < webelement > elements ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver webdriver ) { return elements . stream ( ) . allmatch ( expectedconditions :: isinvisible ) ; } @ override public string tostring ( ) { return str_ + elements ; } } ; }	An expectation for checking all elements from given list to be invisible.
public static expectedcondition < boolean > invisibilityof ( final webelement element ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver webdriver ) { return isinvisible ( element ) ; } @ override public string tostring ( ) { return str_ + element ; } } ; }	An expectation for checking the element to be invisible.
public static expectedcondition < boolean > or ( final expectedcondition < ? > ... conditions ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { runtimeexception lastexception = null ; for ( expectedcondition < ? > condition : conditions ) { try { object result = condition . apply ( driver ) ; if ( result != null ) { if ( result instanceof boolean ) { if ( boolean . true . equals ( result ) ) { return bool_ ; } } else { return bool_ ; } } } catch ( runtimeexception e ) { lastexception = e ; } } if ( lastexception != null ) { throw lastexception ; } return bool_ ; } @ override public string tostring ( ) { stringbuilder message = new stringbuilder ( str_ ) ; joiner . on ( str_ ) . appendto ( message , conditions ) ; return message . tostring ( ) ; } } ; }	An expectation with the logical or condition of the given list of conditions.Each condition is checked until at least one of them returns true or not null.
public static expectedcondition < boolean > and ( final expectedcondition < ? > ... conditions ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { for ( expectedcondition < ? > condition : conditions ) { object result = condition . apply ( driver ) ; if ( result instanceof boolean ) { if ( boolean . false . equals ( result ) ) { return bool_ ; } } if ( result == null ) { return bool_ ; } } return bool_ ; } @ override public string tostring ( ) { stringbuilder message = new stringbuilder ( str_ ) ; joiner . on ( str_ ) . appendto ( message , conditions ) ; return message . tostring ( ) ; } } ; }	An expectation with the logical and condition of the given list of conditions.Each condition is checked until all of them return true or not null.
public static expectedcondition < boolean > javascriptthrowsnoexceptions ( final string javascript ) { return new expectedcondition < boolean > ( ) { @ override public boolean apply ( webdriver driver ) { try { ( ( javascriptexecutor ) driver ) . executescript ( javascript ) ; return bool_ ; } catch ( webdriverexception e ) { return bool_ ; } } @ override public string tostring ( ) { return string . format ( str_ , javascript ) ; } } ; }	An expectation to check if js executable.Useful when you know that there should be a Javascript value or something at the stage.
public static expectedcondition < object > jsreturnsvalue ( final string javascript ) { return new expectedcondition < object > ( ) { @ override public object apply ( webdriver driver ) { try { object value = ( ( javascriptexecutor ) driver ) . executescript ( javascript ) ; if ( value instanceof list ) { return ( ( list < ? > ) value ) . isempty ( ) ? null : value ; } if ( value instanceof string ) { return ( ( string ) value ) . isempty ( ) ? null : value ; } return value ; } catch ( webdriverexception e ) { return null ; } } @ override public string tostring ( ) { return string . format ( str_ , javascript ) ; } } ; }	An expectation for String value from javascript.
@ beta public map < string , string > getalert ( ) { hashmap < string , string > toreturn = new hashmap < > ( ) ; toreturn . put ( str_ , getalerttext ( ) ) ; return collections . unmodifiablemap ( toreturn ) ; }	Used for serialising. Some of the drivers return the alert text like this.
@ suppresswarnings ( str_ ) public static string escape ( string toescape ) { if ( toescape . contains ( str_ ) && toescape . contains ( str_ ) ) { boolean quoteislast = bool_ ; if ( toescape . lastindexof ( str_ ) == toescape . length ( ) - num_ ) { quoteislast = bool_ ; } string [ ] substringswithoutquotes = toescape . split ( str_ ) ; stringbuilder quoted = new stringbuilder ( str_ ) ; for ( int i = num_ ; i < substringswithoutquotes . length ; i ++ ) { quoted . append ( str_ ) . append ( substringswithoutquotes [ i ] ) . append ( str_ ) ; quoted . append ( ( ( i == substringswithoutquotes . length - num_ ) ? ( quoteislast ? str_ : str_ ) : str_ ) ) ; } return quoted . tostring ( ) ; }	Convert strings with both quotes and ticks into a valid xpath componentFor example, {.
@ suppresswarnings ( str_ ) public static < t extends remoteproxy > t getnewinstance ( registrationrequest request , gridregistry registry ) { try { string proxyclass = request . getconfiguration ( ) . proxy ; if ( proxyclass == null ) { log . fine ( str_ ) ; proxyclass = baseremoteproxy . class . getcanonicalname ( ) ; } class < ? > clazz = class . forname ( proxyclass ) ; log . fine ( str_ + clazz . getname ( ) ) ; object [ ] args = new object [ ] { request , registry } ; class < ? > [ ] argsclass = new class [ ] { registrationrequest . class , gridregistry . class } ; constructor < ? > c = clazz . getconstructor ( argsclass ) ; object proxy = c . newinstance ( args ) ; if ( proxy instanceof remoteproxy ) { ( ( remoteproxy ) proxy ) . setuptimeoutlistener ( ) ; return ( t ) proxy ; } throw new invalidparameterexception ( str_ + proxy . getclass ( ) + str_ ) ; } catch ( invocationtargetexception e ) { throw new invalidparameterexception ( str_ + e . gettargetexception ( ) . getmessage ( ) ) ; } catch ( exception e ) { throw new invalidparameterexception ( str_ + e . getmessage ( ) ) ; } }	Takes a registration request and return the RemoteProxy associated to it.
public remoteproxy remove ( remoteproxy proxy ) {	Removes the specified instance from the proxySet.
public remotewebdriverbuilder oneof ( capabilities maybethis , capabilities ... oroneofthese ) { options . clear ( ) ; addalternative ( maybethis ) ; for ( capabilities anoroneofthese : oroneofthese ) { addalternative ( anoroneofthese ) ; } return this ; }	Clears the current set of alternative browsers and instead sets the list of possible choices tothe arguments given to this method.
public remotewebdriverbuilder addalternative ( capabilities options ) { map < string , object > serialized = validate ( objects . requirenonnull ( options ) ) ; this . options . add ( serialized ) ; return this ; }	Add to the list of possible configurations that might be asked for.
@ beta public string newwindow ( windowtype type ) { response response = execute ( str_ , immutablemap . of ( str_ , type == windowtype . tab ) ) ; return ( string ) response . getvalue ( ) ; }	Open either a new tab or window, depending on what is requested, and return the window handlewithout switching to it.
private string getconsoleiconpath ( desiredcapabilities cap ) { string name = consoleiconname ( cap ) ; string path = str_ ; inputstream in = thread . currentthread ( ) . getcontextclassloader ( ) . getresourceasstream ( path + name + str_ ) ; if ( in == null ) { return null ; } return str_ + path + name + str_ ; }	get the icon representing the browser for the grid.
private string getconfiginfo ( ) { stringbuilder builder = new stringbuilder ( ) ; builder . append ( str_ ) ; gridhubconfiguration config = getregistry ( ) . gethub ( ) . getconfiguration ( ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( prettyhtmlprint ( config ) ) ; builder . append ( getverboseconfig ( ) ) ;	retracing how the hub config was built to help debugging.
private string getverboseconfig ( ) { stringbuilder builder = new stringbuilder ( ) ; gridhubconfiguration config = getregistry ( ) . gethub ( ) . getconfiguration ( ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; gridhubconfiguration tmp = new gridhubconfiguration ( ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( prettyhtmlprint ( tmp ) ) ; if ( config . getrawargs ( ) != null ) { builder . append ( str_ ) ; builder . append ( string . join ( str_ , config . getrawargs ( ) ) ) ; if ( config . getconfigfile ( ) != null ) { builder . append ( str_ ) . append ( config . getconfigfile ( ) ) . append ( str_ ) ; try { builder . append ( string . join ( str_ , files . readalllines ( new file ( config . getconfigfile ( ) ) . topath ( ) ) ) ) ; } catch ( ioexception e ) { builder . append ( str_ ) . append ( e . getmessage ( ) ) . append ( str_ ) ; } } } builder . append ( str_ ) ;	Displays more detailed configuration.
@ override public testsession getnewsession ( map < string , object > requestedcapability ) { if ( down ) { return null ; } return super . getnewsession ( requestedcapability ) ; }	overwrites the session allocation to discard the proxy that are down.
@ override public httpresponse encode ( supplier < httpresponse > factory , response response ) { int status = response . getstatus ( ) == errorcodes . success ? http_ok : http_internal_error ; byte [ ] data = json . tojson ( getvaluetoencode ( response ) ) . getbytes ( utf_8 ) ; httpresponse httpresponse = factory . get ( ) ; httpresponse . setstatus ( status ) ; httpresponse . setheader ( cache_control , str_ ) ; httpresponse . setheader ( expires , str_ ) ; httpresponse . setheader ( content_length , string . valueof ( data . length ) ) ; httpresponse . setheader ( content_type , json_utf_8 . tostring ( ) ) ; httpresponse . setcontent ( data ) ; return httpresponse ; }	Encodes the given response as a HTTP response message.
public propertysetting propertysetting ( propertysetting setter ) { propertysetting previous = this . setter ; this . setter = objects . requirenonnull ( setter ) ; return previous ; }	Change how property setting is done.
public actions keyup ( charsequence key ) { if ( isbuildingactions ( ) ) { action . addaction ( new keyupaction ( jsonkeyboard , jsonmouse , askeys ( key ) ) ) ; } return addkeyaction ( key , codepoint -> tick ( defaultkeyboard . createkeyup ( codepoint ) ) ) ; }	Performs a modifier key release.
public actions release ( ) { if ( isbuildingactions ( ) ) { action . addaction ( new buttonreleaseaction ( jsonmouse , null ) ) ; } return tick ( defaultmouse . createpointerup ( button . left . asarg ( ) ) ) ; }	Releases the depressed left mouse button at the current mouse location.
public actions doubleclick ( ) { if ( isbuildingactions ( ) ) { action . addaction ( new doubleclickaction ( jsonmouse , null ) ) ; } return clickinticks ( left ) . clickinticks ( left ) ; }	Performs a double-click at the current mouse location.
public actions movetoelement ( webelement target ) { if ( isbuildingactions ( ) ) { action . addaction ( new movemouseaction ( jsonmouse , ( locatable ) target ) ) ; } return moveinticks ( target , num_ , num_ ) ; }	Moves the mouse to the middle of the element.
public actions movetoelement ( webelement target , int xoffset , int yoffset ) { if ( isbuildingactions ( ) ) { action . addaction ( new movetooffsetaction ( jsonmouse , ( locatable ) target , xoffset , yoffset ) ) ; }	Moves the mouse to an offset from the top-left corner of the element.The element is scrolled into view and its location is calculated using getBoundingClientRect.
public actions contextclick ( webelement target ) { if ( isbuildingactions ( ) ) { action . addaction ( new contextclickaction ( jsonmouse , ( locatable ) target ) ) ; } return moveinticks ( target , num_ , num_ ) . clickinticks ( right ) ; }	Performs a context-click at middle of the given element.
public actions contextclick ( ) { if ( isbuildingactions ( ) ) { action . addaction ( new contextclickaction ( jsonmouse , null ) ) ; } return clickinticks ( right ) ; }	Performs a context-click at the current mouse location.
public actions draganddrop ( webelement source , webelement target ) { if ( isbuildingactions ( ) ) { action . addaction ( new clickandholdaction ( jsonmouse , ( locatable ) source ) ) ; action . addaction ( new movemouseaction ( jsonmouse , ( locatable ) target ) ) ; action . addaction ( new buttonreleaseaction ( jsonmouse , ( locatable ) target ) ) ; } return moveinticks ( source , num_ , num_ ) . tick ( defaultmouse . createpointerdown ( left . asarg ( ) ) ) . moveinticks ( target , num_ , num_ ) . tick ( defaultmouse . createpointerup ( left . asarg ( ) ) ) ; }	A convenience method that performs click-and-hold at the location of the source element,moves to the location of the target element, then releases the mouse.
public actions draganddropby ( webelement source , int xoffset , int yoffset ) { if ( isbuildingactions ( ) ) { action . addaction ( new clickandholdaction ( jsonmouse , ( locatable ) source ) ) ; action . addaction ( new movetooffsetaction ( jsonmouse , null , xoffset , yoffset ) ) ; action . addaction ( new buttonreleaseaction ( jsonmouse , null ) ) ; } return moveinticks ( source , num_ , num_ ) . tick ( defaultmouse . createpointerdown ( left . asarg ( ) ) ) . tick ( defaultmouse . createpointermove ( duration . ofmillis ( num_ ) , origin . pointer ( ) , xoffset , yoffset ) ) . tick ( defaultmouse . createpointerup ( left . asarg ( ) ) ) ; }	A convenience method that performs click-and-hold at the location of the source element,moves by a given offset, then releases the mouse.
public actions pause ( long pause ) { if ( isbuildingactions ( ) ) { action . addaction ( new pauseaction ( pause ) ) ; } return tick ( new pause ( defaultmouse , duration . ofmillis ( pause ) ) ) ; }	Performs a pause.
public void wait ( string message , long timeoutinmilliseconds , long intervalinmilliseconds ) { long start = system . currenttimemillis ( ) ; long end = start + timeoutinmilliseconds ; while ( system . currenttimemillis ( ) < end ) { if ( until ( ) ) return ; try { thread . sleep ( intervalinmilliseconds ) ; } catch ( interruptedexception e ) { throw new runtimeexception ( e ) ; } } throw new waittimedoutexception ( message ) ; }	Wait until the "until" condition returns true or time runs out.
public string getqueryparameter ( string name ) { iterable < string > allparams = getqueryparameters ( name ) ; if ( allparams == null ) { return null ; } iterator < string > iterator = allparams . iterator ( ) ; return iterator . hasnext ( ) ? iterator . next ( ) : null ; }	Get a query parameter.
public httprequest addqueryparameter ( string name , string value ) { queryparameters . put ( objects . requirenonnull ( name , str_ ) , objects . requirenonnull ( value , str_ ) ) ; return this ; }	Set a query parameter, adding to existing values if present.
public crossdomainrpc loadrpc ( httpservletrequest request ) throws ioexception { charset encoding ; try { string enc = request . getcharacterencoding ( ) ; encoding = charset . forname ( enc ) ; } catch ( illegalargumentexception | nullpointerexception e ) { encoding = utf_8 ; }	Parses the request for a CrossDomainRpc.
private static capabilities dropcapabilities ( capabilities capabilities ) { if ( capabilities == null ) { return new immutablecapabilities ( ) ; } mutablecapabilities caps ; if ( islegacy ( capabilities ) ) { final set < string > toremove = sets . newhashset ( binary , profile ) ; caps = new mutablecapabilities ( maps . filterkeys ( capabilities . asmap ( ) , key -> ! toremove . contains ( key ) ) ) ; } else { caps = new mutablecapabilities ( capabilities ) ; }	Drops capabilities that we shouldn't send over the wire.Used for capabilities which aren't BeanToJson-convertable, and are only used by the locallauncher.
public file createtempdir ( string prefix , string suffix ) { try {	Create a temporary directory, and track it for deletion.
public void deletetempdir ( file file ) { if ( ! shouldreap ( ) ) { return ; }	Delete a temporary directory that we were responsible for creating.
public void deletetemporaryfiles ( ) { if ( ! shouldreap ( ) ) { return ; } for ( file file : temporaryfiles ) { try { filehandler . delete ( file ) ; } catch ( webdriverexception e ) {	Perform the operation that a shutdown hook would have.
public proxy setautodetect ( boolean autodetect ) { if ( this . autodetect == autodetect ) { return this ; } if ( autodetect ) { verifyproxytypecompatibility ( proxytype . autodetect ) ; this . proxytype = proxytype . autodetect ; } else { this . proxytype = proxytype . unspecified ; } this . autodetect = autodetect ; return this ; }	Specifies whether to autodetect proxy settings.
public proxy setsslproxy ( string sslproxy ) { verifyproxytypecompatibility ( proxytype . manual ) ; this . proxytype = proxytype . manual ; this . sslproxy = sslproxy ; return this ; }	Specify which proxy to use for SSL connections.
public proxy setsocksproxy ( string socksproxy ) { verifyproxytypecompatibility ( proxytype . manual ) ; this . proxytype = proxytype . manual ; this . socksproxy = socksproxy ; return this ; }	Specifies which proxy to use for SOCKS.
public proxy setsocksusername ( string username ) { verifyproxytypecompatibility ( proxytype . manual ) ; this . proxytype = proxytype . manual ; this . socksusername = username ; return this ; }	Specifies a username for the SOCKS proxy.
public proxy setsockspassword ( string password ) { verifyproxytypecompatibility ( proxytype . manual ) ; this . proxytype = proxytype . manual ; this . sockspassword = password ; return this ; }	Specifies a password for the SOCKS proxy.
public static level normalize ( level level ) { if ( levelmap . containskey ( level . intvalue ( ) ) ) { return levelmap . get ( level . intvalue ( ) ) ; } else if ( level . intvalue ( ) >= level . severe . intvalue ( ) ) { return level . severe ; } else if ( level . intvalue ( ) >= level . warning . intvalue ( ) ) { return level . warning ; } else if ( level . intvalue ( ) >= level . info . intvalue ( ) ) { return level . info ; } else { return level . fine ; } }	Normalizes the given level to one of those supported by Selenium.
public static string getname ( level level ) { level normalized = normalize ( level ) ; return normalized == level . fine ? debug : normalized . getname ( ) ; }	Converts the JDK level to a name supported by Selenium.
@ override public void definecommand ( string name , httpmethod method , string pathpattern ) { definecommand ( name , new commandspec ( method , pathpattern ) ) ; }	Defines a new command mapping.
public webelement findelement ( searchcontext context ) { list < webelement > allelements = findelements ( context ) ; if ( allelements == null || allelements . isempty ( ) ) { throw new nosuchelementexception ( str_ + tostring ( ) ) ; } return allelements . get ( num_ ) ; }	Find a single element.
public static map < string , sessionlogs > getsessionlogs ( map < string , object > rawsessionmap ) { map < string , sessionlogs > sessionlogsmap = new hashmap < > ( ) ; for ( map . entry < string , object > entry : rawsessionmap . entryset ( ) ) { string sessionid = entry . getkey ( ) ; if ( ! ( entry . getvalue ( ) instanceof map ) ) { throw new invalidargumentexception ( str_ + entry . getvalue ( ) ) ; } @ suppresswarnings ( str_ ) map < string , object > value = ( map < string , object > ) entry . getvalue ( ) ; sessionlogs sessionlogs = sessionlogs . fromjson ( value ) ; sessionlogsmap . put ( sessionid , sessionlogs ) ; } return sessionlogsmap ; }	Creates a session logs map, with session logs mapped to session IDs, givena raw session log map as a JSON object.
public void setenvironmentvariables ( map < string , string > environment ) { for ( map . entry < string , string > entry : environment . entryset ( ) ) { setenvironmentvariable ( entry . getkey ( ) , entry . getvalue ( ) ) ; } }	Adds the specified environment variables.
@ override public mutablecapabilities merge ( capabilities extracapabilities ) { if ( extracapabilities == null ) { return this ; } extracapabilities . asmap ( ) . foreach ( this :: setcapability ) ; return this ; }	Merge the extra capabilities provided into this DesiredCapabilities instance.
public inetaddress getip4nonloopbackaddressofthismachine ( ) { for ( networkinterface iface : networkinterfaceprovider . getnetworkinterfaces ( ) ) { final inetaddress ip4nonloopback = iface . getip4nonloopbackonly ( ) ; if ( ip4nonloopback != null ) { return ip4nonloopback ; } } throw new webdriverexception ( str_ ) ; }	Returns a non-loopback IP4 hostname of the local host.
public string obtainloopbackip4address ( ) { final networkinterface networkinterface = getloopbackandip4only ( ) ; if ( networkinterface != null ) { return networkinterface . getip4loopbackonly ( ) . gethostname ( ) ; } final string ipofip4loopback = getipofloopbackip4 ( ) ; if ( ipofip4loopback != null ) { return ipofip4loopback ; } if ( platform . getcurrent ( ) . is ( platform . unix ) ) { networkinterface linuxloopback = networkinterfaceprovider . getlointerface ( ) ; if ( linuxloopback != null ) { final inetaddress netaddress = linuxloopback . getip4loopbackonly ( ) ; if ( netaddress != null ) { return netaddress . gethostaddress ( ) ; } } } throw new webdriverexception ( str_ + getnetworkdiags ( ) + str_ ) ; }	Returns a single address that is guaranteed to resolve to an ipv4 representation of localhostThis may either be a hostname or an ip address, depending if we can guarantee what that thehostname will resolve to ip4.
public string serialize ( ) { stringbuilder sb = new stringbuilder ( ) ; boolean first = bool_ ; for ( string key : options . keyset ( ) ) { if ( first ) { first = bool_ ; } else { sb . append ( str_ ) ; } sb . append ( key ) . append ( str_ ) . append ( options . get ( key ) ) ; } return sb . tostring ( ) ; }	Serializes to the format "name=value;name=value".
public browserconfigurationoptions set ( string key , string value ) { if ( value != null ) { options . put ( key , value ) ; } return this ; }	Sets the given key to the given value unless the value is null.
public string executecommandonservlet ( string command ) { try { return getcommandresponseasstring ( command ) ; } catch ( ioexception e ) { if ( e instanceof connectexception ) { throw new seleniumexception ( e . getmessage ( ) , e ) ; } e . printstacktrace ( ) ; throw new unsupportedoperationexception ( str_ + command + str_ + e , e ) ; } }	Sends the specified command string to the bridge servlet.
public static string [ ] parsecsv ( string input ) { list < string > output = new arraylist < > ( ) ; stringbuffer sb = new stringbuffer ( ) ; for ( int i = num_ ; i < input . length ( ) ; i ++ ) { char c = input . charat ( i ) ; switch ( c ) { case str_ : output . add ( sb . tostring ( ) ) ; sb = new stringbuffer ( ) ; continue ; case str_ : i ++ ; c = input . charat ( i ) ;	Convert backslash-escaped comma-delimited string into String array.
public void merge ( standaloneconfiguration other ) { if ( other == null ) { return ; } if ( ismergeable ( integer . class , other . browsertimeout , browsertimeout ) ) { browsertimeout = other . browsertimeout ; } if ( ismergeable ( integer . class , other . jettymaxthreads , jettymaxthreads ) ) { jettymaxthreads = other . jettymaxthreads ; } if ( ismergeable ( integer . class , other . timeout , timeout ) ) { timeout = other . timeout ; }	copy another configuration's values into this one if they are set.
public map < string , object > tojson ( ) { map < string , object > json = new hashmap < > ( ) ; json . put ( str_ , browsertimeout ) ; json . put ( str_ , debug ) ; json . put ( str_ , jettymaxthreads ) ; json . put ( str_ , log ) ; json . put ( str_ , host ) ; json . put ( str_ , port ) ; json . put ( str_ , role ) ; json . put ( str_ , timeout ) ; serializefields ( json ) ; return json . entryset ( ) . stream ( ) . filter ( entry -> entry . getvalue ( ) != null ) . collect ( toimmutablesortedmap ( natural ( ) , map . entry :: getkey , map . entry :: getvalue ) ) ; }	Return a JsonElement representation of the configuration.
public static externalsessionkey fromresponsebody ( string responsebody ) throws newsessionexception { if ( responsebody != null && responsebody . startswith ( str_ ) ) { return new externalsessionkey ( responsebody . replace ( str_ , str_ ) ) ; } throw new newsessionexception ( str_ + responsebody ) ; }	extract the external key from the server response for a selenium1 new session request.
public < k extends throwable > fluentwait < t > ignoreall ( collection < class < ? extends k > > types ) { ignoredexceptions . addall ( types ) ; return this ; }	Configures this instance to ignore specific types of exceptions while waiting for a condition.Any exceptions not whitelisted will be allowed to propagate, terminating the wait.
private string tabconfig ( ) { stringbuilder builder = new stringbuilder ( ) ; builder . append ( str_ ) ; builder . append ( proxy . getconfig ( ) . tostring ( str_ ) ) ; builder . append ( str_ ) ; return builder . tostring ( ) ; }	content of the config tab.
private string tabbrowsers ( ) { stringbuilder builder = new stringbuilder ( ) ; builder . append ( str_ ) ; slotslines rclines = new slotslines ( ) ; slotslines wdlines = new slotslines ( ) ; for ( testslot slot : proxy . gettestslots ( ) ) { if ( slot . getprotocol ( ) == seleniumprotocol . selenium ) { rclines . add ( slot ) ; } else { wdlines . add ( slot ) ; } } if ( rclines . getlinestype ( ) . size ( ) != num_ ) { builder . append ( str_ ) ; builder . append ( getlines ( rclines ) ) ; } if ( wdlines . getlinestype ( ) . size ( ) != num_ ) { builder . append ( str_ ) ; builder . append ( getlines ( wdlines ) ) ; } builder . append ( str_ ) ; return builder . tostring ( ) ; }	content of the browsers tab.
private string getlines ( slotslines lines ) { stringbuilder builder = new stringbuilder ( ) ; for ( minicapability cap : lines . getlinestype ( ) ) { string icon = cap . geticon ( ) ; string version = cap . getversion ( ) ; builder . append ( str_ ) ; if ( version != null ) { builder . append ( str_ ) . append ( version ) ; } for ( testslot s : lines . getline ( cap ) ) { builder . append ( getsingleslothtml ( s , icon ) ) ; } builder . append ( str_ ) ; } return builder . tostring ( ) ; }	the lines of icon representing the possible slots.
private string nodetabs ( ) { stringbuilder builder = new stringbuilder ( ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; builder . append ( str_ ) ; return builder . tostring ( ) ; }	the tabs header.
public static string getplatform ( remoteproxy proxy ) { if ( proxy . gettestslots ( ) . size ( ) == num_ ) { return str_ ; } platform res = getplatform ( proxy . gettestslots ( ) . get ( num_ ) ) ; for ( testslot slot : proxy . gettestslots ( ) ) { platform tmp = getplatform ( slot ) ; if ( tmp != res ) { return str_ ; } res = tmp ; } if ( res == null ) { return str_ ; } return res . tostring ( ) ; }	return the platform for the proxy.
public void merge ( gridconfiguration other ) { if ( other == null ) { return ; } super . merge ( other ) ; if ( ismergeable ( integer . class , other . cleanupcycle , cleanupcycle ) ) { cleanupcycle = other . cleanupcycle ; } if ( ismergeable ( map . class , other . custom , custom ) ) { if ( custom == null ) { custom = new hashmap < > ( ) ; } custom . putall ( other . custom ) ; } if ( ismergeable ( integer . class , other . maxsession , maxsession ) && other . maxsession > num_ ) { maxsession = other . maxsession ; } if ( ismergeable ( list . class , other . servlets , servlets ) ) { servlets = other . servlets ; } if ( ismergeable ( list . class , other . withoutservlets , withoutservlets ) ) { withoutservlets = other . withoutservlets ; } }	replaces this instance of configuration value with the 'other' value if it's set.
public static class < ? extends servlet > createservlet ( string classname ) { try { return class . forname ( classname ) . assubclass ( servlet . class ) ; } catch ( classnotfoundexception e ) { log . warning ( str_ + classname + str_ + e . getmessage ( ) ) ; } return null ; }	Reflexion to create the servlet based on the class name.
protected void log ( sessionid sessionid , string commandname , object tolog , when when ) { if ( ! logger . isloggable ( level ) ) { return ; } string text = string . valueof ( tolog ) ; if ( commandname . equals ( drivercommand . execute_script ) || commandname . equals ( drivercommand . execute_async_script ) ) { if ( text . length ( ) > num_ && boolean . getboolean ( str_ ) ) { text = text . substring ( num_ , num_ ) + str_ ; } } switch ( when ) { case before : logger . log ( level , str_ + commandname + str_ + text ) ; break ; case after : logger . log ( level , str_ + text ) ; break ; case exception : logger . log ( level , str_ + text ) ; break ; default : logger . log ( level , text ) ; break ; } }	Override this to be notified at key points in the execution of a command.
public boolean isrunning ( ) { lock . lock ( ) ; try { return process != null && process . isrunning ( ) ; } catch ( illegalthreadstateexception e ) { return bool_ ; } finally { lock . unlock ( ) ; } }	Checks whether the driver child process is currently running.
public void start ( ) throws ioexception { lock . lock ( ) ; try { if ( process != null ) { return ; } process = new commandline ( this . executable , args . toarray ( new string [ ] { } ) ) ; process . setenvironmentvariables ( environment ) ; process . copyoutputto ( getoutputstream ( ) ) ; process . executeasync ( ) ; waituntilavailable ( ) ; } finally { lock . unlock ( ) ; } }	Starts this service if it is not already running.
public void stop ( ) { lock . lock ( ) ; webdriverexception tothrow = null ; try { if ( process == null ) { return ; } if ( hasshutdownendpoint ( ) ) { try { url killurl = new url ( url . tostring ( ) + str_ ) ; new urlchecker ( ) . waituntilunavailable ( num_ , seconds , killurl ) ; } catch ( malformedurlexception e ) { tothrow = new webdriverexception ( e ) ; } catch ( urlchecker . timeoutexception e ) { tothrow = new webdriverexception ( str_ , e ) ; } } process . destroy ( ) ; if ( getoutputstream ( ) instanceof fileoutputstream ) { try { getoutputstream ( ) . close ( ) ; } catch ( ioexception e ) { } } } finally { process = null ; lock . unlock ( ) ; } if ( tothrow != null ) { throw tothrow ; } }	Stops this service if it is currently running.
public touchactions singletap ( webelement onelement ) { if ( touchscreen != null ) { action . addaction ( new singletapaction ( touchscreen , ( locatable ) onelement ) ) ; } tick ( touchpointer . createpointerdown ( num_ ) ) ; tick ( touchpointer . createpointerup ( num_ ) ) ; return this ; }	Allows the execution of single tap on the screen, analogous to click using a Mouse.
public touchactions down ( int x , int y ) { if ( touchscreen != null ) { action . addaction ( new downaction ( touchscreen , x , y ) ) ; } return this ; }	Allows the execution of the gesture 'down' on the screen.
public touchactions up ( int x , int y ) { if ( touchscreen != null ) { action . addaction ( new upaction ( touchscreen , x , y ) ) ; } return this ; }	Allows the execution of the gesture 'up' on the screen.
public touchactions move ( int x , int y ) { if ( touchscreen != null ) { action . addaction ( new moveaction ( touchscreen , x , y ) ) ; } return this ; }	Allows the execution of the gesture 'move' on the screen.
public touchactions scroll ( webelement onelement , int xoffset , int yoffset ) { if ( touchscreen != null ) { action . addaction ( new scrollaction ( touchscreen , ( locatable ) onelement , xoffset , yoffset ) ) ; } return this ; }	Creates a scroll gesture that starts on a particular screen location.
public touchactions doubletap ( webelement onelement ) { if ( touchscreen != null ) { action . addaction ( new doubletapaction ( touchscreen , ( locatable ) onelement ) ) ; } return this ; }	Allows the execution of double tap on the screen, analogous to double click using a Mouse.
public touchactions longpress ( webelement onelement ) { if ( touchscreen != null ) { action . addaction ( new longpressaction ( touchscreen , ( locatable ) onelement ) ) ; } return this ; }	Allows the execution of long press gestures.
public touchactions scroll ( int xoffset , int yoffset ) { if ( touchscreen != null ) { action . addaction ( new scrollaction ( touchscreen , xoffset , yoffset ) ) ; } return this ; }	Allows the view to be scrolled by an x and y offset.
public touchactions flick ( int xspeed , int yspeed ) { if ( touchscreen != null ) { action . addaction ( new flickaction ( touchscreen , xspeed , yspeed ) ) ; } return this ; }	Sends a flick gesture to the current view.
public touchactions flick ( webelement onelement , int xoffset , int yoffset , int speed ) { if ( touchscreen != null ) { action . addaction ( new flickaction ( touchscreen , ( locatable ) onelement , xoffset , yoffset , speed ) ) ; } return this ; }	Allows the execution of flick gestures starting in a location's element.
public loggingpreferences addpreferences ( loggingpreferences prefs ) { if ( prefs == null ) { return this ; } for ( string logtype : prefs . getenabledlogtypes ( ) ) { enable ( logtype , prefs . getlevel ( logtype ) ) ; } return this ; }	Adds the given logging preferences giving them precedence over existingpreferences.
@ suppresswarnings ( str_ ) public t get ( ) { try { isloaded ( ) ; return ( t ) this ; } catch ( error e ) { load ( ) ; } isloaded ( ) ; return ( t ) this ; }	Ensure that the component is currently loaded.
public void add ( requesthandler request ) { lock . writelock ( ) . lock ( ) ; try { newsessionrequests . add ( request ) ; } finally { lock . writelock ( ) . unlock ( ) ; } }	Adds a request handler to this queue.
public void processqueue ( predicate < requesthandler > handlerconsumer , prioritizer prioritizer ) { comparator < requesthandler > comparator = prioritizer == null ? ordering . allequal ( ) :: compare : ( a , b ) -> prioritizer . compareto ( a . getrequest ( ) . getdesiredcapabilities ( ) , b . getrequest ( ) . getdesiredcapabilities ( ) ) ; lock . writelock ( ) . lock ( ) ; try { newsessionrequests . stream ( ) . sorted ( comparator ) . filter ( handlerconsumer ) . foreach ( requesthandler -> { if ( ! removenewsessionrequest ( requesthandler ) ) { log . severe ( str_ + requesthandler ) ; } } ) ; } finally { lock . writelock ( ) . unlock ( ) ; } }	Processes all the entries in this queue.
public boolean removenewsessionrequest ( requesthandler request ) { lock . writelock ( ) . lock ( ) ; try { return newsessionrequests . remove ( request ) ; } finally { lock . writelock ( ) . unlock ( ) ; } }	Remove a specific request.
public iterable < desiredcapabilities > getdesiredcapabilities ( ) { lock . readlock ( ) . lock ( ) ; try { return newsessionrequests . stream ( ) . map ( req -> new desiredcapabilities ( req . getrequest ( ) . getdesiredcapabilities ( ) ) ) . collect ( collectors . tolist ( ) ) ; } finally { lock . readlock ( ) . unlock ( ) ; } }	Provides the desired capabilities of all the items in this queue.
public static remotecommand parse ( string inputline ) { if ( null == inputline ) throw new nullpointerexception ( str_ ) ; string [ ] values = inputline . split ( str_ ) ; if ( values . length != numargsincludingboundaries ) { throw new illegalstateexception ( str_ + inputline + values . length ) ; } return new defaultremotecommand ( values [ firstindex ] , new string [ ] { values [ secondindex ] , values [ thirdindex ] } ) ; }	Factory method to create a RemoteCommand from a wiki-style input string.
public void addbrowser ( desiredcapabilities cap , int instances ) { string s = cap . getbrowsername ( ) ; if ( s == null || str_ . equals ( s ) ) { throw new invalidparameterexception ( cap + str_ ) ; } if ( cap . getplatform ( ) == null ) { cap . setplatform ( platform . getcurrent ( ) ) ; } cap . setcapability ( registrationrequest . max_instances , instances ) ; registrationrequest . getconfiguration ( ) . capabilities . add ( cap ) ; registrationrequest . getconfiguration ( ) . fixupcapabilities ( ) ; }	Adding the browser described by the capability, automatically finding out what platform thenode is launched from.
private gridhubconfiguration gethubconfiguration ( ) throws exception { string hubapi = str_ + registrationrequest . getconfiguration ( ) . gethubhost ( ) + str_ + registrationrequest . getconfiguration ( ) . gethubport ( ) + str_ ; url api = new url ( hubapi ) ; httpclient client = httpclientfactory . createclient ( api ) ; string url = api . toexternalform ( ) ; httprequest request = new httprequest ( get , url ) ; httpresponse response = client . execute ( request ) ; try ( reader reader = new stringreader ( response . getcontentstring ( ) ) ; jsoninput jsoninput = new json ( ) . newinput ( reader ) ) { return gridhubconfiguration . loadfromjson ( jsoninput ) ; } }	uses the hub API to get some of its configuration.
public static response success ( sessionid sessionid , object value ) { response response = new response ( ) ; response . setsessionid ( sessionid != null ? sessionid . tostring ( ) : null ) ; response . setvalue ( value ) ; response . setstatus ( errorcodes . success ) ; response . setstate ( errorcodes . success_string ) ; return response ; }	Creates a response object for a successful command execution.
public void createlogfileandaddtomap ( sessionid sessionid ) throws ioexception { file rclogfile ;	This creates log file object which represents logs in file form.
private void assignrequesttoproxy ( ) { while ( ! stop ) { try { testsessionavailable . await ( num_ , timeunit . seconds ) ; newsessionqueue . processqueue ( this :: takerequesthandler , gethub ( ) . getconfiguration ( ) . prioritizer ) ;	iterates the list of incoming session request to find a potential match in the list of proxies.If something changes in the registry, the matcher iteration is stopped to account for thatchange.
private void release ( testsession session , sessionterminationreason reason ) { try { lock . lock ( ) ; boolean removed = activetestsessions . remove ( session , reason ) ; if ( removed ) { firematcherstatechanged ( ) ; } } finally { lock . unlock ( ) ; } }	mark the session as finished for the registry. The resources that were associated to it are nowfree to be reserved by other tests.
private static executable locatefirefoxbinaryfromsystemproperty ( ) { string binaryname = system . getproperty ( firefoxdriver . systemproperty . browser_binary ) ; if ( binaryname == null ) return null ; file binary = new file ( binaryname ) ; if ( binary . exists ( ) && ! binary . isdirectory ( ) ) return new executable ( binary ) ; platform current = platform . getcurrent ( ) ; if ( current . is ( windows ) ) { if ( ! binaryname . endswith ( str_ ) ) { binaryname += str_ ; } } else if ( current . is ( mac ) ) { if ( ! binaryname . endswith ( str_ ) ) { binaryname += str_ ; } binaryname += str_ ; } binary = new file ( binaryname ) ; if ( binary . exists ( ) ) return new executable ( binary ) ; throw new webdriverexception ( string . format ( str_ , firefoxdriver . systemproperty . browser_binary , binaryname ) ) ; }	Locates the firefox binary from a system property.
private static stream < executable > locatefirefoxbinariesfromplatform ( ) { immutablelist . builder < executable > executables = new immutablelist . builder < > ( ) ; platform current = platform . getcurrent ( ) ; if ( current . is ( windows ) ) { executables . addall ( stream . of ( str_ , str_ , str_ ) . map ( firefoxbinary :: getpathsinprogramfiles ) . flatmap ( list :: stream ) . map ( file :: new ) . filter ( file :: exists ) . map ( executable :: new ) . collect ( tolist ( ) ) ) ; } else if ( current . is ( mac ) ) {	Locates the firefox binary by platform.
public synchronized void removesessionlogs ( sessionid sessionid ) { if ( storelogsonsessionquit ) { return ; } threadkey threadid = sessiontothreadmap . get ( sessionid ) ; sessionid sessionidforthread = threadtosessionmap . get ( threadid ) ; if ( threadid != null && sessionidforthread != null && sessionidforthread . equals ( sessionid ) ) { threadtosessionmap . remove ( threadid ) ; sessiontothreadmap . remove ( sessionid ) ; } persessionrecords . remove ( sessionid ) ; logfilerepository . removelogfile ( sessionid ) ; }	Removes session logs for the given session id.NB! If the handler has been configured to capture logs on quit no logs will be removed.
public synchronized string getlog ( sessionid sessionid ) throws ioexception {	This returns Selenium Remote Control logs associated with the sessionId.
public synchronized list < sessionid > getloggedsessions ( ) {	Returns a list of session IDs for which there are logs.The type of logs that are available depends on the log types providedby the driver.
public synchronized sessionlogs getalllogsforsession ( sessionid sessionid ) { sessionlogs sessionlogs = new sessionlogs ( ) ; if ( persessiondriverentries . containskey ( sessionid ) ) { map < string , logentries > typetoentriesmap = persessiondriverentries . get ( sessionid ) ; for ( string logtype : typetoentriesmap . keyset ( ) ) { sessionlogs . addlog ( logtype , typetoentriesmap . get ( logtype ) ) ; } persessiondriverentries . remove ( sessionid ) ; } return sessionlogs ; }	Gets all logs for a session.
public synchronized logentries getsessionlog ( sessionid sessionid ) throws ioexception { list < logentry > entries = new arraylist < > ( ) ; for ( logrecord record : records ( sessionid ) ) { if ( record . getlevel ( ) . intvalue ( ) >= serverloglevel . intvalue ( ) ) entries . add ( new logentry ( record . getlevel ( ) , record . getmillis ( ) , record . getmessage ( ) ) ) ; } return new logentries ( entries ) ; }	Returns the server log for the given session id.
public synchronized void fetchandstorelogsfromdriver ( sessionid sessionid , webdriver driver ) throws ioexception { if ( ! persessiondriverentries . containskey ( sessionid ) ) { persessiondriverentries . put ( sessionid , new hashmap < > ( ) ) ; } map < string , logentries > typetoentriesmap = persessiondriverentries . get ( sessionid ) ; if ( storelogsonsessionquit ) { typetoentriesmap . put ( logtype . server , getsessionlog ( sessionid ) ) ; set < string > logtypeset = driver . manage ( ) . logs ( ) . getavailablelogtypes ( ) ; for ( string logtype : logtypeset ) { typetoentriesmap . put ( logtype , driver . manage ( ) . logs ( ) . get ( logtype ) ) ; } } }	Fetches and stores available logs from the given session and driver.
public void update ( long a0 , long a1 , long a2 , long a3 ) { if ( done ) { throw new illegalstateexception ( str_ ) ; } v1 [ num_ ] += mul0 [ num_ ] + a0 ; v1 [ num_ ] += mul0 [ num_ ] + a1 ; v1 [ num_ ] += mul0 [ num_ ] + a2 ; v1 [ num_ ] += mul0 [ num_ ] + a3 ; for ( int i = num_ ; i < num_ ; ++ i ) { mul0 [ i ] ^= ( v1 [ i ] & num_ ) * ( v0 [ i ] > > > num_ ) ; v0 [ i ] += mul1 [ i ] ; mul1 [ i ] ^= ( v0 [ i ] & num_ ) * ( v1 [ i ] > > > num_ ) ; } v0 [ num_ ] += zippermerge0 ( v1 [ num_ ] , v1 [ num_ ] ) ; v0 [ num_ ] += zippermerge1 ( v1 [ num_ ] , v1 [ num_ ] ) ; v0 [ num_ ] += zippermerge0 ( v1 [ num_ ] , v1 [ num_ ] ) ; v0 [ num_ ] += zippermerge1 ( v1 [ num_ ] , v1 [ num_ ] ) ; v1 [ num_ ] += zippermerge0 ( v0 [ num_ ] , v0 [ num_ ] ) ; v1 [ num_ ] += zippermerge1 ( v0 [ num_ ] , v0 [ num_ ] ) ; v1 [ num_ ] += zippermerge0 ( v0 [ num_ ] , v0 [ num_ ] ) ; v1 [ num_ ] += zippermerge1 ( v0 [ num_ ] , v0 [ num_ ] ) ; }	Updates the hash with 32 bytes of data given as 4 longs.
protected void decrementlock ( sessionimplementor session , object key , lock lock ) { lock . unlock ( region . nexttimestamp ( ) ) ; region . put ( session , key , lock ) ; }	Unlock and re-put the given key, lock combination.
public void setconfig ( map < string , ? extends cacheconfig > config ) { this . configmap = ( map < string , cacheconfig > ) config ; }	Set cache config mapped by cache name.
public static redissoncache monitor ( meterregistry registry , redissoncache cache , iterable < tag > tags ) { new redissoncachemetrics ( cache , tags ) . bindto ( registry ) ; return cache ; }	Record metrics on a Redisson cache.
private remoteexecutorserviceasync asyncscheduledserviceatfixed ( string executorid , string requestid ) { scheduledtasksservice scheduledremoteservice = new scheduledtasksservice ( codec , name , commandexecutor , executorid , responses ) ; scheduledremoteservice . setterminationtopicname ( terminationtopicname ) ; scheduledremoteservice . settaskscountername ( taskscountername ) ; scheduledremoteservice . setstatusname ( statusname ) ; scheduledremoteservice . setschedulerqueuename ( schedulerqueuename ) ; scheduledremoteservice . setschedulerchannelname ( schedulerchannelname ) ; scheduledremoteservice . settasksname ( tasksname ) ; scheduledremoteservice . setrequestid ( new requestid ( requestid ) ) ; scheduledremoteservice . settasksretryintervalname ( tasksretryintervalname ) ; remoteexecutorserviceasync asyncscheduledserviceatfixed = scheduledremoteservice . get ( remoteexecutorserviceasync . class , remoteinvocationoptions . defaults ( ) . noack ( ) . noresult ( ) ) ; return asyncscheduledserviceatfixed ; }	Creates RemoteExecutorServiceAsync with special executor which overrides requestId generationand uses current requestId.
public static string tojson ( map < string , ? extends cacheconfig > config ) throws ioexception { return new cacheconfigsupport ( ) . tojson ( config ) ; }	Convert current configuration to JSON format.
public static string toyaml ( map < string , ? extends cacheconfig > config ) throws ioexception { return new cacheconfigsupport ( ) . toyaml ( config ) ; }	Convert current configuration to YAML format.
public static cronschedule dailyathourandminute ( int hour , int minute ) { string expression = string . format ( str_ , minute , hour ) ; return of ( expression ) ; }	Creates cron expression which schedule task executionevery day at the given time.
public static cronschedule weeklyondayandhourandminute ( int hour , int minute , integer ... daysofweek ) { if ( daysofweek == null || daysofweek . length == num_ ) { throw new illegalargumentexception ( str_ ) ; } string expression = string . format ( str_ , minute , hour , daysofweek [ num_ ] ) ; for ( int i = num_ ; i < daysofweek . length ; i ++ ) { expression = expression + str_ + daysofweek [ i ] ; } return of ( expression ) ; }	Creates cron expression which schedule task executionevery given days of the week at the given time.Use Calendar object constants to define day.
public static cronschedule monthlyondayandhourandminute ( int dayofmonth , int hour , int minute ) { string expression = string . format ( str_ , minute , hour , dayofmonth ) ; return of ( expression ) ; }	Creates cron expression which schedule task executionevery given day of the month at the given time.
public localcachedmapoptions < k , v > evictionpolicy ( evictionpolicy evictionpolicy ) { if ( evictionpolicy == null ) { throw new nullpointerexception ( str_ ) ; } this . evictionpolicy = evictionpolicy ; return this ; }	Sets eviction policy.
public final boolean awaituninterruptibly ( ) { try { return await ( num_ , timeunit . seconds ) ; } catch ( interruptedexception e ) { thread . currentthread ( ) . interrupt ( ) ; return bool_ ; } }	waiting for an open state.
protected void handlelockexpiry ( sharedsessioncontractimplementor session , object key , lockable lock ) { long ts = region . nexttimestamp ( ) + region . gettimeout ( ) ;	Handle the timeout of a previous lock mapped to this key.
public void start ( ) { if ( hasredissoninstance ) { redisson = redisson . create ( config ) ; } retrieveaddresses ( ) ; if ( config . getredissonnodeinitializer ( ) != null ) { config . getredissonnodeinitializer ( ) . onstartup ( this ) ; } int mapreduceworkers = config . getmapreduceworkers ( ) ; if ( mapreduceworkers != - num_ ) { if ( mapreduceworkers == num_ ) { mapreduceworkers = runtime . getruntime ( ) . availableprocessors ( ) ; } redisson . getexecutorservice ( rexecutorservice . mapreduce_name ) . registerworkers ( mapreduceworkers ) ; log . info ( str_ , mapreduceworkers ) ; } for ( entry < string , integer > entry : config . getexecutorserviceworkers ( ) . entryset ( ) ) { string name = entry . getkey ( ) ; int workers = entry . getvalue ( ) ; redisson . getexecutorservice ( name ) . registerworkers ( workers ) ; log . info ( str_ , workers , name ) ; } log . info ( str_ ) ; }	Start Redisson node instance.
public static object convertvalue ( final object value , final class < ? > converttype ) { if ( null == value ) { return convertnullvalue ( converttype ) ; } if ( value . getclass ( ) == converttype ) { return value ; } if ( value instanceof number ) { return convertnumbervalue ( value , converttype ) ; } if ( value instanceof date ) { return convertdatevalue ( value , converttype ) ; } if ( string . class . equals ( converttype ) ) { return value . tostring ( ) ; } else { return value ; } }	Convert value via expected class type.
public synchronized void remove ( final int statementid ) { mysqlbinarystatement binarystatement = getbinarystatement ( statementid ) ; if ( null != binarystatement ) { statementidassigner . remove ( binarystatement . getsql ( ) ) ; binarystatements . remove ( statementid ) ; } }	Remove expired cache statement.
public registrycenter load ( final registrycenterconfiguration regcenterconfig ) { preconditions . checknotnull ( regcenterconfig , str_ ) ; registrycenter result = newservice ( regcenterconfig . gettype ( ) , regcenterconfig . getproperties ( ) ) ; result . init ( regcenterconfig ) ; return result ; }	Load registry center from SPI.
public static string getexactlyvalue ( final string value ) { return null == value ? null : charmatcher . anyof ( str_ ) . removefrom ( value ) ; }	Get exactly value for SQL expression. remove special char for SQL expression .
public static string getexactlyexpression ( final string value ) { return null == value ? null : charmatcher . anyof ( str_ ) . removefrom ( value ) ; }	Get exactly SQL expression. remove space for SQL expression .
public static string getoriginalvalue ( final string value , final databasetype databasetype ) { if ( databasetype . mysql != databasetype ) { return value ; } try { defaultkeyword . valueof ( value . touppercase ( ) ) ; return string . format ( str_ , value ) ; } catch ( final illegalargumentexception ex ) { return getoriginalvalueformysqlkeyword ( value ) ; } }	Get original value for SQL expression.
public int skipwhitespace ( ) { int length = num_ ; while ( chartype . iswhitespace ( charat ( offset + length ) ) ) { length ++ ; } return offset + length ; }	skip whitespace.
public int skipcomment ( ) { char current = charat ( offset ) ; char next = charat ( offset + num_ ) ; if ( issinglelinecommentbegin ( current , next ) ) { return skipsinglelinecomment ( comment_begin_symbol_length ) ; } else if ( str_ == current ) { return skipsinglelinecomment ( mysql_special_comment_begin_symbol_length ) ; } else if ( ismultiplelinecommentbegin ( current , next ) ) { return skipmultilinecomment ( ) ; } return offset ; }	skip comment.
public token scanvariable ( ) { int length = num_ ; if ( str_ == charat ( offset + num_ ) ) { length ++ ; } while ( isvariablechar ( charat ( offset + length ) ) ) { length ++ ; } return new token ( literals . variable , input . substring ( offset , offset + length ) , offset + length ) ; }	scan variable.
public token scanidentifier ( ) { if ( str_ == charat ( offset ) ) { int length = getlengthuntilterminatedchar ( str_ ) ; return new token ( literals . identifier , input . substring ( offset , offset + length ) , offset + length ) ; } if ( str_ == charat ( offset ) ) { int length = getlengthuntilterminatedchar ( str_ ) ; return new token ( literals . identifier , input . substring ( offset , offset + length ) , offset + length ) ; } if ( str_ == charat ( offset ) ) { int length = getlengthuntilterminatedchar ( str_ ) ; return new token ( literals . identifier , input . substring ( offset , offset + length ) , offset + length ) ; } int length = num_ ; while ( isidentifierchar ( charat ( offset + length ) ) ) { length ++ ; } string literals = input . substring ( offset , offset + length ) ; if ( isambiguousidentifier ( literals ) ) { return new token ( processambiguousidentifier ( offset + length , literals ) , literals , offset + length ) ; } return new token ( dictionary . findtokentype ( literals , literals . identifier ) , literals , offset + length ) ; }	scan identifier.
public token scanhexdecimal ( ) { int length = hex_begin_symbol_length ; if ( str_ == charat ( offset + length ) ) { length ++ ; } while ( ishex ( charat ( offset + length ) ) ) { length ++ ; } return new token ( literals . hex , input . substring ( offset , offset + length ) , offset + length ) ; }	scan hex decimal.
public token scannumber ( ) { int length = num_ ; if ( str_ == charat ( offset + length ) ) { length ++ ; } length += getdigitallength ( offset + length ) ; boolean isfloat = bool_ ; if ( str_ == charat ( offset + length ) ) { isfloat = bool_ ; length ++ ; length += getdigitallength ( offset + length ) ; } if ( isscientificnotation ( offset + length ) ) { isfloat = bool_ ; length ++ ; if ( str_ == charat ( offset + length ) || str_ == charat ( offset + length ) ) { length ++ ; } length += getdigitallength ( offset + length ) ; } if ( isbinarynumber ( offset + length ) ) { isfloat = bool_ ; length ++ ; } return new token ( isfloat ? literals . float : literals . int , input . substring ( offset , offset + length ) , offset + length ) ; }	scan number.
public token scansymbol ( ) { int length = num_ ; while ( chartype . issymbol ( charat ( offset + length ) ) ) { length ++ ; } string literals = input . substring ( offset , offset + length ) ; symbol symbol ; while ( null == ( symbol = symbol . literalsof ( literals ) ) ) { literals = input . substring ( offset , offset + -- length ) ; } return new token ( symbol , literals , offset + length ) ; }	scan symbol.
public static datasourcepropertyprovider getprovider ( final datasource datasource ) { string datasourceclassname = datasource . getclass ( ) . getname ( ) ; return data_source_property_providers . containskey ( datasourceclassname ) ? data_source_property_providers . get ( datasourceclassname ) : new defaultdatasourcepropertyprovider ( ) ; }	Get data source property provider.
public static datasource getdatasource ( final string datasourceclassname , final map < string , object > datasourceproperties ) throws reflectiveoperationexception { datasource result = ( datasource ) class . forname ( datasourceclassname ) . newinstance ( ) ; for ( entry < string , object > entry : datasourceproperties . entryset ( ) ) { callsettermethod ( result , getsettermethodname ( entry . getkey ( ) ) , null == entry . getvalue ( ) ? null : entry . getvalue ( ) . tostring ( ) ) ; } return result ; }	Get data source.
public static sqlparser newinstance ( final databasetype dbtype , final encryptrule encryptrule , final shardingtablemetadata shardingtablemetadata , final string sql ) { if ( databasetype . mysql == dbtype || databasetype . h2 == dbtype ) { return new antlrparsingengine ( dbtype , sql , encryptrule , shardingtablemetadata ) ; } throw new sqlparsingunsupportedexception ( string . format ( str_ , dbtype ) ) ; }	Create Encrypt SQL parser.
public static int roundhalfup ( final object obj ) { if ( obj instanceof short ) { return ( short ) obj ; } if ( obj instanceof integer ) { return ( int ) obj ; } if ( obj instanceof long ) { return ( ( long ) obj ) . intvalue ( ) ; } if ( obj instanceof double ) { return new bigdecimal ( ( double ) obj ) . setscale ( num_ , bigdecimal . round_half_up ) . intvalue ( ) ; } if ( obj instanceof float ) { return new bigdecimal ( ( float ) obj ) . setscale ( num_ , bigdecimal . round_half_up ) . intvalue ( ) ; } if ( obj instanceof string ) { return new bigdecimal ( ( string ) obj ) . setscale ( num_ , bigdecimal . round_half_up ) . intvalue ( ) ; } throw new shardingexception ( str_ , obj ) ; }	Round half up.
public static number getexactlynumber ( final string value , final int radix ) { try { return getbiginteger ( value , radix ) ; } catch ( final numberformatexception ex ) { return new bigdecimal ( value ) ; } }	Get exactly number value and type.
public void parse ( final insertstatement insertstatement ) { lexerengine . unsupportedifequal ( getunsupportedkeywordsbeforeinto ( ) ) ; lexerengine . skipuntil ( defaultkeyword . into ) ; lexerengine . nexttoken ( ) ; tablereferencesclauseparser . parse ( insertstatement , bool_ ) ; skipbetweentableandvalues ( insertstatement ) ; }	Parse insert into.
public final void parse ( final sqlstatement sqlstatement , final boolean issingletableonly ) { do { parsetablereference ( sqlstatement , issingletableonly ) ; } while ( lexerengine . skipifequal ( symbol . comma ) ) ; }	Parse table references.
public final void parsesingletablewithoutalias ( final sqlstatement sqlstatement ) { int beginposition = lexerengine . getcurrenttoken ( ) . getendposition ( ) - lexerengine . getcurrenttoken ( ) . getliterals ( ) . length ( ) ; string literals = lexerengine . getcurrenttoken ( ) . getliterals ( ) ; int skippedschemanamelength = num_ ; lexerengine . nexttoken ( ) ; if ( lexerengine . skipifequal ( symbol . dot ) ) { skippedschemanamelength = literals . length ( ) + symbol . dot . getliterals ( ) . length ( ) ; literals = lexerengine . getcurrenttoken ( ) . getliterals ( ) ; lexerengine . nexttoken ( ) ; } sqlstatement . addsqltoken ( new tabletoken ( beginposition , literals , quotecharacter . getquotecharacter ( literals ) , skippedschemanamelength ) ) ; sqlstatement . gettables ( ) . add ( new table ( sqlutil . getexactlyvalue ( literals ) , null ) ) ; }	Parse single table without alias.
public static executorservice getexecutor ( final boolean isoccupythreadforperconnection , final transactiontype transactiontype , final channelid channelid ) { return ( isoccupythreadforperconnection || transactiontype . xa == transactiontype || transactiontype . base == transactiontype ) ? channelthreadexecutorgroup . getinstance ( ) . get ( channelid ) : userexecutorgroup . getinstance ( ) . getexecutorservice ( ) ; }	Get executor service.
public void appendplaceholder ( final shardingplaceholder shardingplaceholder ) { segments . add ( shardingplaceholder ) ; currentsegment = new stringbuilder ( ) ; segments . add ( currentsegment ) ; }	Append sharding placeholder.
public sqlbuilder rewrite ( final boolean issinglerouting ) { sqlbuilder result = new sqlbuilder ( parameters ) ; if ( sqltokens . isempty ( ) ) { return appendoriginalliterals ( result ) ; } appendinitialliterals ( ! issinglerouting , result ) ; appendtokensandplaceholders ( ! issinglerouting , result ) ; reviseparameters ( ) ; return result ; }	rewrite SQL.
public sqlunit generatesql ( final tableunit tableunit , final sqlbuilder sqlbuilder , final shardingdatasourcemetadata shardingdatasourcemetadata ) { return sqlbuilder . tosql ( tableunit , gettabletokens ( tableunit ) , shardingrule , shardingdatasourcemetadata ) ; }	Generate SQL string.
public static abstractinsertparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine , final shardingtablemetadata shardingtablemetadata ) { switch ( dbtype ) { case h2 : case mysql : return new mysqlinsertparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case oracle : return new oracleinsertparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case sqlserver : return new sqlserverinsertparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case postgresql : return new postgresqlinsertparser ( shardingrule , lexerengine , shardingtablemetadata ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create insert parser instance.
public static properties unmarshalproperties ( final string yamlcontent ) { return strings . isnullorempty ( yamlcontent ) ? new properties ( ) : new yaml ( ) . loadas ( yamlcontent , properties . class ) ; }	Unmarshal properties YAML.
public collection < string > getallinstancedatasourcenames ( ) { collection < string > result = new linkedlist < > ( ) ; for ( entry < string , datasourcemetadata > entry : datasourcemetadatamap . entryset ( ) ) { if ( ! isexisted ( entry . getkey ( ) , result ) ) { result . add ( entry . getkey ( ) ) ; } } return result ; }	Get all instance data source names.
public map < string , list < datanode > > getdatanodegroups ( ) { map < string , list < datanode > > result = new linkedhashmap < > ( actualdatanodes . size ( ) , num_ ) ; for ( datanode each : actualdatanodes ) { string datasourcename = each . getdatasourcename ( ) ; if ( ! result . containskey ( datasourcename ) ) { result . put ( datasourcename , new linkedlist < datanode > ( ) ) ; } result . get ( datasourcename ) . add ( each ) ; } return result ; }	Get data node groups.
public collection < string > getactualdatasourcenames ( ) { collection < string > result = new linkedhashset < > ( actualdatanodes . size ( ) ) ; for ( datanode each : actualdatanodes ) { result . add ( each . getdatasourcename ( ) ) ; } return result ; }	Get actual data source names.
public collection < string > getactualtablenames ( final string targetdatasource ) { collection < string > result = new linkedhashset < > ( actualdatanodes . size ( ) ) ; for ( datanode each : actualdatanodes ) { if ( targetdatasource . equals ( each . getdatasourcename ( ) ) ) { result . add ( each . gettablename ( ) ) ; } } return result ; }	Get actual table names via target data source name.
public optional < string > parseselectitemalias ( ) { if ( lexerengine . skipifequal ( defaultkeyword . as ) ) { return parsewithas ( null , bool_ , null ) ; } if ( lexerengine . equalany ( getdefaultavailablekeywordsforselectitemalias ( ) ) || lexerengine . equalany ( getcustomizedavailablekeywordsforselectitemalias ( ) ) ) { return parsealias ( null , bool_ , null ) ; } return optional . absent ( ) ; }	Parse alias for select item.
public optional < string > parsetablealias ( final sqlstatement sqlstatement , final boolean settabletoken , final string tablename ) { if ( lexerengine . skipifequal ( defaultkeyword . as ) ) { return parsewithas ( sqlstatement , settabletoken , tablename ) ; } if ( lexerengine . equalany ( getdefaultavailablekeywordsfortablealias ( ) ) || lexerengine . equalany ( getcustomizedavailablekeywordsfortablealias ( ) ) ) { return parsealias ( sqlstatement , settabletoken , tablename ) ; } return optional . absent ( ) ; }	Parse alias for table.
@ subscribe @ sneakythrows public final synchronized void renew ( final datasourcechangedevent datasourcechangedevent ) { datasource . close ( ) ; datasource = new shardingdatasource ( datasourceconverter . getdatasourcemap ( datasourcechangedevent . getdatasourceconfigurations ( ) ) , datasource . getshardingcontext ( ) . getshardingrule ( ) , datasource . getshardingcontext ( ) . getshardingproperties ( ) . getprops ( ) ) ; }	Renew sharding data source.
public void processparameters ( final list < object > parameters , final boolean isfetchall , final databasetype databasetype ) { fill ( parameters ) ; rewrite ( parameters , isfetchall , databasetype ) ; }	Fill parameters for rewrite limit.
public boolean isneedrewriterowcount ( final databasetype databasetype ) { return databasetype . mysql == databasetype || databasetype . postgresql == databasetype || databasetype . h2 == databasetype ; }	Judge is need rewrite row count or not.
public static xaconnection createxaconnection ( final databasetype databasetype , final xadatasource xadatasource , final connection connection ) { switch ( databasetype ) { case mysql : return new mysqlxaconnectionwrapper ( ) . wrap ( xadatasource , connection ) ; case postgresql : return new postgresqlxaconnectionwrapper ( ) . wrap ( xadatasource , connection ) ; case h2 : return new h2xaconnectionwrapper ( ) . wrap ( xadatasource , connection ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , databasetype ) ) ; } }	Create XA connection from normal connection.
public void add ( final orchestrationshardingschema orchestrationshardingschema ) { string schemaname = orchestrationshardingschema . getschemaname ( ) ; if ( ! schemagroup . containskey ( schemaname ) ) { schemagroup . put ( schemaname , new linkedlist < string > ( ) ) ; } schemagroup . get ( schemaname ) . add ( orchestrationshardingschema . getdatasourcename ( ) ) ; }	Add orchestration sharding schema.
public void put ( final string shardingschemaname , final collection < string > datasourcenames ) { schemagroup . put ( shardingschemaname , datasourcenames ) ; }	Put orchestration sharding schema.
public collection < string > getdatasourcenames ( final string shardingschemaname ) { return schemagroup . containskey ( shardingschemaname ) ? schemagroup . get ( shardingschemaname ) : collections . < string > emptylist ( ) ; }	Get data source names.
public orcondition buildcondition ( final orpredicatesegment sqlsegment , final sqlstatement sqlstatement ) { orcondition result = createorcondition ( sqlsegment , sqlstatement ) ; createencryptorpredicatefiller ( ) . fill ( sqlsegment , sqlstatement ) ; return result ; }	Build condition.
public static boolean isdcl ( final tokentype primarytokentype , final tokentype secondarytokentype ) { return statement_prefix . contains ( primarytokentype ) || ( primary_statement_prefix . contains ( primarytokentype ) && secondary_statement_prefix . contains ( secondarytokentype ) ) ; }	Is DCL statement.
public void close ( ) { shutdown_executor . execute ( new runnable ( ) { @ override public void run ( ) { try { executorservice . shutdown ( ) ; while ( ! executorservice . awaittermination ( num_ , timeunit . seconds ) ) { executorservice . shutdownnow ( ) ; } } catch ( final interruptedexception ex ) { thread . currentthread ( ) . interrupt ( ) ; } } } ) ; }	Close executor service.
@ sneakythrows public sqlstatement fill ( final collection < sqlsegment > sqlsegments , final sqlstatementrule rule ) { sqlstatement result = rule . getsqlstatementclass ( ) . newinstance ( ) ; result . setlogicsql ( sql ) ; for ( sqlsegment each : sqlsegments ) { optional < sqlsegmentfiller > filler = parsingruleregistry . findsqlsegmentfiller ( databasetype , each . getclass ( ) ) ; if ( filler . ispresent ( ) ) { dofill ( each , result , filler . get ( ) ) ; } } return result ; }	Fill SQL statement.
public final list < connection > getconnections ( final connectionmode connectionmode , final string datasourcename , final int connectionsize ) throws sqlexception { datasource datasource = getdatasourcemap ( ) . get ( datasourcename ) ; preconditions . checkstate ( null != datasource , str_ , datasourcename ) ; collection < connection > connections ; synchronized ( cachedconnections ) { connections = cachedconnections . get ( datasourcename ) ; } list < connection > result ; if ( connections . size ( ) >= connectionsize ) { result = new arraylist < > ( connections ) . sublist ( num_ , connectionsize ) ; } else if ( ! connections . isempty ( ) ) { result = new arraylist < > ( connectionsize ) ; result . addall ( connections ) ; list < connection > newconnections = createconnections ( datasourcename , connectionmode , datasource , connectionsize - connections . size ( ) ) ; result . addall ( newconnections ) ; synchronized ( cachedconnections ) { cachedconnections . putall ( datasourcename , newconnections ) ; } } else { result = new arraylist < > ( createconnections ( datasourcename , connectionmode , datasource , connectionsize ) ) ; synchronized ( cachedconnections ) { cachedconnections . putall ( datasourcename , result ) ; } } return result ; }	Get database connections.
public final void parse ( final selectstatement selectstatement ) { if ( ! lexerengine . skipifequal ( defaultkeyword . order ) ) { return ; } list < orderitem > result = new linkedlist < > ( ) ; lexerengine . skipifequal ( oraclekeyword . siblings ) ; lexerengine . accept ( defaultkeyword . by ) ; do { optional < orderitem > orderitem = parseselectorderbyitem ( selectstatement ) ; if ( orderitem . ispresent ( ) ) { result . add ( orderitem . get ( ) ) ; } } while ( lexerengine . skipifequal ( symbol . comma ) ) ; selectstatement . getorderbyitems ( ) . addall ( result ) ; }	Parse order by.
public boolean isalwaysfalse ( ) { if ( shardingconditions . isempty ( ) ) { return bool_ ; } for ( shardingcondition each : shardingconditions ) { if ( ! ( each instanceof alwaysfalseshardingcondition ) ) { return bool_ ; } } return bool_ ; }	Judge sharding conditions is always false or not.
public static boolean issymbol ( final char ch ) { return str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch || str_ == ch ; }	Judge is symbol or not.
@ suppresswarnings ( str_ ) public < t > t getvalue ( final shardingpropertiesconstant shardingpropertiesconstant ) { if ( cachedproperties . containskey ( shardingpropertiesconstant ) ) { return ( t ) cachedproperties . get ( shardingpropertiesconstant ) ; } string value = props . getproperty ( shardingpropertiesconstant . getkey ( ) ) ; if ( strings . isnullorempty ( value ) ) { object obj = props . get ( shardingpropertiesconstant . getkey ( ) ) ; if ( null == obj ) { value = shardingpropertiesconstant . getdefaultvalue ( ) ; } else { value = obj . tostring ( ) ; } } object result ; if ( boolean . class == shardingpropertiesconstant . gettype ( ) ) { result = boolean . valueof ( value ) ; } else if ( int . class == shardingpropertiesconstant . gettype ( ) ) { result = integer . valueof ( value ) ; } else if ( long . class == shardingpropertiesconstant . gettype ( ) ) { result = long . valueof ( value ) ; } else { result = value ; } cachedproperties . put ( shardingpropertiesconstant , result ) ; return ( t ) result ; }	Get property value.
@ sneakythrows public void init ( final extractorruledefinitionentity ruledefinitionentity ) { for ( extractorruleentity each : ruledefinitionentity . getrules ( ) ) { rules . put ( each . getid ( ) , ( sqlsegmentextractor ) class . forname ( each . getextractorclass ( ) ) . newinstance ( ) ) ; } }	Initialize SQL extractor rule definition.
public void clear ( ) throws sqlexception { clearstatements ( ) ; statements . clear ( ) ; parametersets . clear ( ) ; connections . clear ( ) ; resultsets . clear ( ) ; executegroups . clear ( ) ; }	Clear data.
public list < string > splitandevaluate ( ) { if ( null == inlineexpression ) { return collections . emptylist ( ) ; } return flatten ( evaluate ( split ( ) ) ) ; }	Split and evaluate inline expression.
public static boolean isbooleanvalue ( final string value ) { return boolean . true . tostring ( ) . equalsignorecase ( value ) || boolean . false . tostring ( ) . equalsignorecase ( value ) ; }	Judge is boolean value or not.
public static boolean isintvalue ( final string value ) { try { integer . parseint ( value ) ; return bool_ ; } catch ( final numberformatexception ex ) { return bool_ ; } }	Judge is int value or not.
public static boolean islongvalue ( final string value ) { try { long . parselong ( value ) ; return bool_ ; } catch ( final numberformatexception ex ) { return bool_ ; } }	Judge is long value or not.
public static void init ( ) { string tracerclassname = system . getproperty ( opentracing_tracer_class_name ) ; preconditions . checknotnull ( tracerclassname , str_ , opentracing_tracer_class_name ) ; try { init ( ( tracer ) class . forname ( tracerclassname ) . newinstance ( ) ) ; } catch ( final reflectiveoperationexception ex ) { throw new shardingexception ( str_ , ex ) ; } }	Initialize sharding tracer.
public sqlast parse ( ) { parsetree parsetree = sqlparserfactory . newinstance ( databasetype , sql ) . execute ( ) . getchild ( num_ ) ; if ( parsetree instanceof errornode ) { throw new sqlparsingunsupportedexception ( string . format ( str_ , sql ) ) ; } optional < sqlstatementrule > sqlstatementrule = parsingruleregistry . findsqlstatementrule ( databasetype , parsetree . getclass ( ) . getsimplename ( ) ) ; if ( sqlstatementrule . ispresent ( ) ) { return new sqlast ( ( parserrulecontext ) parsetree , sqlstatementrule . get ( ) ) ; } if ( parsingruleregistry instanceof encryptparsingruleregistry ) { return new sqlast ( ( parserrulecontext ) parsetree ) ; } throw new sqlparsingunsupportedexception ( string . format ( str_ , sql ) ) ; }	Parse SQL to abstract syntax tree.
public string getinstancesnodefullpath ( final string instanceid ) { return joiner . on ( str_ ) . join ( str_ , name , root , instances_node_path , instanceid ) ; }	Get instance node full path.
public string getdatasourcesnodefullpath ( final string schemadatasourcename ) { return joiner . on ( str_ ) . join ( str_ , name , root , data_sources_node_path , schemadatasourcename ) ; }	Get data source node full path.
public static lexerengine newinstance ( final databasetype dbtype , final string sql ) { switch ( dbtype ) { case h2 : return new lexerengine ( new h2lexer ( sql ) ) ; case mysql : return new lexerengine ( new mysqllexer ( sql ) ) ; case oracle : return new lexerengine ( new oraclelexer ( sql ) ) ; case sqlserver : return new lexerengine ( new sqlserverlexer ( sql ) ) ; case postgresql : return new lexerengine ( new postgresqllexer ( sql ) ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create lexical analysis engine instance.
public boolean execute ( final int [ ] columnindexes ) throws sqlexception { return execute ( new executor ( ) { @ override public boolean execute ( final statement statement , final string sql ) throws sqlexception { return statement . execute ( sql , columnindexes ) ; } } ) ; }	Execute SQL with column indexes.
public static boolean istclunsafe ( final databasetype databasetype , final tokentype tokentype , final lexerengine lexerengine ) { if ( defaultkeyword . set . equals ( tokentype ) || databasetype . sqlserver . equals ( databasetype ) && defaultkeyword . if . equals ( tokentype ) ) { lexerengine . skipuntil ( defaultkeyword . transaction , defaultkeyword . autocommit , defaultkeyword . implicit_transactions ) ; if ( ! lexerengine . isend ( ) ) { return bool_ ; } } return bool_ ; }	Is TCL statement.
public void addbatchforrouteunits ( final sqlrouteresult routeresult ) { handleoldrouteunits ( createbatchrouteunits ( routeresult . getrouteunits ( ) ) ) ; handlenewrouteunits ( createbatchrouteunits ( routeresult . getrouteunits ( ) ) ) ; batchcount ++ ; }	Add batch for route units.
public logicschema getlogicschema ( final string schemaname ) { return strings . isnullorempty ( schemaname ) ? null : logicschemas . get ( schemaname ) ; }	Get logic schema.
@ subscribe public synchronized void renew ( final schemaaddedevent schemaaddedevent ) { logicschemas . put ( schemaaddedevent . getshardingschemaname ( ) , createlogicschema ( schemaaddedevent . getshardingschemaname ( ) , collections . singletonmap ( schemaaddedevent . getshardingschemaname ( ) , datasourceconverter . getdatasourceparametermap ( schemaaddedevent . getdatasourceconfigurations ( ) ) ) , schemaaddedevent . getruleconfiguration ( ) , bool_ ) ) ; }	Renew to add new schema.
public static commandexecutor newinstance ( final postgresqlcommandpackettype commandpackettype , final postgresqlcommandpacket commandpacket , final backendconnection backendconnection ) { log . debug ( str_ , commandpackettype , commandpacket ) ; switch ( commandpackettype ) { case query : return new postgresqlcomqueryexecutor ( ( postgresqlcomquerypacket ) commandpacket , backendconnection ) ; case parse : return new postgresqlcomparseexecutor ( ( postgresqlcomparsepacket ) commandpacket , backendconnection ) ; case bind : return new postgresqlcombindexecutor ( ( postgresqlcombindpacket ) commandpacket , backendconnection ) ; case describe : return new postgresqlcomdescribeexecutor ( ) ; case execute : return new postgresqlcomexecuteexecutor ( ) ; case sync : return new postgresqlcomsyncexecutor ( ) ; case terminate : return new postgresqlcomterminationexecutor ( ) ; default : return new postgresqlunsupportedcommandexecutor ( ) ; } }	Create new instance of command executor.
public final void nexttoken ( ) { skipignoredtoken ( ) ; if ( isvariablebegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scanvariable ( ) ; } else if ( isncharbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , ++ offset ) . scanchars ( ) ; } else if ( isidentifierbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scanidentifier ( ) ; } else if ( ishexdecimalbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scanhexdecimal ( ) ; } else if ( isnumberbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scannumber ( ) ; } else if ( issymbolbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scansymbol ( ) ; } else if ( ischarsbegin ( ) ) { currenttoken = new tokenizer ( input , dictionary , offset ) . scanchars ( ) ; } else if ( isend ( ) ) { currenttoken = new token ( assist . end , str_ , offset ) ; } else { throw new sqlparsingexception ( this , assist . error ) ; } offset = currenttoken . getendposition ( ) ; }	Analyse next token.
public final void parse ( ) { collection < keyword > unsupportedrestkeywords = new linkedlist < > ( ) ; unsupportedrestkeywords . addall ( arrays . aslist ( defaultkeyword . union , defaultkeyword . intersect , defaultkeyword . except , defaultkeyword . minus ) ) ; unsupportedrestkeywords . addall ( arrays . aslist ( getunsupportedkeywordsrest ( ) ) ) ; lexerengine . unsupportedifequal ( unsupportedrestkeywords . toarray ( new keyword [ unsupportedrestkeywords . size ( ) ] ) ) ; }	Parse select rest.
public boolean issingletable ( ) { collection < string > tablenames = new treeset < > ( string . case_insensitive_order ) ; for ( table each : tables ) { tablenames . add ( each . getname ( ) ) ; } return num_ == tablenames . size ( ) ; }	Judge is single table or not.
public collection < string > gettablenames ( ) { collection < string > result = new linkedhashset < > ( tables . size ( ) , num_ ) ; for ( table each : tables ) { result . add ( each . getname ( ) ) ; } return result ; }	Get table names.
public optional < table > find ( final string tablenameoralias ) { optional < table > tablefromname = findtablefromname ( tablenameoralias ) ; return tablefromname . ispresent ( ) ? tablefromname : findtablefromalias ( tablenameoralias ) ; }	Find table via table name or alias.
public string skipparentheses ( final sqlstatement sqlstatement ) { stringbuilder result = new stringbuilder ( str_ ) ; int count = num_ ; if ( symbol . left_paren == lexer . getcurrenttoken ( ) . gettype ( ) ) { final int beginposition = lexer . getcurrenttoken ( ) . getendposition ( ) ; result . append ( symbol . left_paren . getliterals ( ) ) ; lexer . nexttoken ( ) ; while ( bool_ ) { if ( equalany ( symbol . question ) ) { sqlstatement . setparametersindex ( sqlstatement . getparametersindex ( ) + num_ ) ; } if ( assist . end == lexer . getcurrenttoken ( ) . gettype ( ) || ( symbol . right_paren == lexer . getcurrenttoken ( ) . gettype ( ) && num_ == count ) ) { break ; } if ( symbol . left_paren == lexer . getcurrenttoken ( ) . gettype ( ) ) { count ++ ; } else if ( symbol . right_paren == lexer . getcurrenttoken ( ) . gettype ( ) ) { count -- ; } lexer . nexttoken ( ) ; } result . append ( lexer . getinput ( ) . substring ( beginposition , lexer . getcurrenttoken ( ) . getendposition ( ) ) ) ; lexer . nexttoken ( ) ; } return result . tostring ( ) ; }	skip all tokens that inside parentheses.
public void accept ( final tokentype tokentype ) { if ( lexer . getcurrenttoken ( ) . gettype ( ) != tokentype ) { throw new sqlparsingexception ( lexer , tokentype ) ; } lexer . nexttoken ( ) ; }	Assert current token type should equals input token and go to next token type.
public boolean equalany ( final tokentype ... tokentypes ) { for ( tokentype each : tokentypes ) { if ( each == lexer . getcurrenttoken ( ) . gettype ( ) ) { return bool_ ; } } return bool_ ; }	Judge current token equals one of input tokens or not.
public void skipall ( final tokentype ... tokentypes ) { set < tokentype > tokentypeset = sets . newhashset ( tokentypes ) ; while ( tokentypeset . contains ( lexer . getcurrenttoken ( ) . gettype ( ) ) ) { lexer . nexttoken ( ) ; } }	Skip all input tokens.
public void skipuntil ( final tokentype ... tokentypes ) { set < tokentype > tokentypeset = sets . newhashset ( tokentypes ) ; tokentypeset . add ( assist . end ) ; while ( ! tokentypeset . contains ( lexer . getcurrenttoken ( ) . gettype ( ) ) ) { lexer . nexttoken ( ) ; } }	Skip until one of input tokens.
public void parse ( final selectstatement selectstatement ) { if ( ! lexerengine . skipifequal ( sqlserverkeyword . top ) ) { return ; } int beginposition = lexerengine . getcurrenttoken ( ) . getendposition ( ) ; if ( ! lexerengine . skipifequal ( symbol . left_paren ) ) { beginposition = lexerengine . getcurrenttoken ( ) . getendposition ( ) - lexerengine . getcurrenttoken ( ) . getliterals ( ) . length ( ) ; } sqlexpression sqlexpression = basicexpressionparser . parse ( selectstatement ) ; lexerengine . skipifequal ( symbol . right_paren ) ; limitvalue rowcountvalue ; if ( sqlexpression instanceof sqlnumberexpression ) { int rowcount = ( ( sqlnumberexpression ) sqlexpression ) . getnumber ( ) . intvalue ( ) ; rowcountvalue = new limitvalue ( rowcount , - num_ , bool_ ) ; selectstatement . addsqltoken ( new rowcounttoken ( beginposition , rowcount ) ) ; } else if ( sqlexpression instanceof sqlparametermarkerexpression ) { rowcountvalue = new limitvalue ( - num_ , ( ( sqlparametermarkerexpression ) sqlexpression ) . getindex ( ) , bool_ ) ; } else { throw new sqlparsingexception ( lexerengine ) ; } lexerengine . unsupportedifequal ( sqlserverkeyword . percent ) ; lexerengine . skipifequal ( defaultkeyword . with , sqlserverkeyword . ties ) ; if ( null == selectstatement . getlimit ( ) ) { limit limit = new limit ( ) ; limit . setrowcount ( rowcountvalue ) ; selectstatement . setlimit ( limit ) ; } else { selectstatement . getlimit ( ) . setrowcount ( rowcountvalue ) ; } }	Parse top.
public static mysqlerrpacket newinstance ( final int sequenceid , final exception cause ) { if ( cause instanceof sqlexception ) { sqlexception sqlexception = ( sqlexception ) cause ; return new mysqlerrpacket ( sequenceid , sqlexception . geterrorcode ( ) , sqlexception . getsqlstate ( ) , sqlexception . getmessage ( ) ) ; } if ( cause instanceof shardingctlexception ) { shardingctlexception shardingctlexception = ( shardingctlexception ) cause ; return new mysqlerrpacket ( sequenceid , shardingctlerrorcode . valueof ( shardingctlexception ) , shardingctlexception . getshardingctl ( ) ) ; } if ( cause instanceof tablemodifyintransactionexception ) { return new mysqlerrpacket ( sequenceid , mysqlservererrorcode . er_error_on_modifying_gtid_executed_table , ( ( tablemodifyintransactionexception ) cause ) . gettablename ( ) ) ; } if ( cause instanceof unknowndatabaseexception ) { return new mysqlerrpacket ( sequenceid , mysqlservererrorcode . er_bad_db_error , ( ( unknowndatabaseexception ) cause ) . getdatabasename ( ) ) ; } if ( cause instanceof nodatabaseselectedexception ) { return new mysqlerrpacket ( sequenceid , mysqlservererrorcode . er_no_db_error ) ; } return new mysqlerrpacket ( sequenceid , commonerrorcode . unknown_exception , cause . getmessage ( ) ) ; }	New instance of MytSQL ERR packet.
public static < t > void register ( final class < t > service ) { for ( t each : serviceloader . load ( service ) ) { registerserviceclass ( service , each ) ; } }	Register SPI service into map for new instance.
@ sneakythrows @ suppresswarnings ( str_ ) public static < t > collection < t > newserviceinstances ( final class < t > service ) { collection < t > result = new linkedlist < > ( ) ; if ( null == service_map . get ( service ) ) { return result ; } for ( class < ? > each : service_map . get ( service ) ) { result . add ( ( t ) each . newinstance ( ) ) ; } return result ; }	New service instances.
public static void main ( final string [ ] args ) throws ioexception { shardingconfiguration shardingconfig = new shardingconfigurationloader ( ) . load ( ) ; int port = getport ( args ) ; if ( null == shardingconfig . getserverconfiguration ( ) . getorchestration ( ) ) { startwithoutregistrycenter ( shardingconfig . getruleconfigurationmap ( ) , shardingconfig . getserverconfiguration ( ) . getauthentication ( ) , shardingconfig . getserverconfiguration ( ) . getprops ( ) , port ) ; } else { startwithregistrycenter ( shardingconfig . getserverconfiguration ( ) , shardingconfig . getruleconfigurationmap ( ) . keyset ( ) , shardingconfig . getruleconfigurationmap ( ) , port ) ; } }	Main entrance.
public collection < shardingexecutegroup < statementexecuteunit > > getexecuteunitgroups ( final collection < routeunit > routeunits , final sqlexecutepreparecallback callback ) throws sqlexception { return getsynchronizedexecuteunitgroups ( routeunits , callback ) ; }	Get execute unit groups.
public list < comparable < ? > > getconditionvalues ( final list < ? > parameters ) { list < comparable < ? > > result = new linkedlist < > ( positionvaluemap . values ( ) ) ; for ( entry < integer , integer > entry : positionindexmap . entryset ( ) ) { object parameter = parameters . get ( entry . getvalue ( ) ) ; if ( ! ( parameter instanceof comparable < ? > ) ) { throw new shardingexception ( str_ , parameter ) ; } if ( entry . getkey ( ) < result . size ( ) ) { result . add ( entry . getkey ( ) , ( comparable < ? > ) parameter ) ; } else { result . add ( ( comparable < ? > ) parameter ) ; } } return result ; }	Get condition values.
public static datasourceconfiguration getdatasourceconfiguration ( final datasource datasource ) { datasourceconfiguration result = new datasourceconfiguration ( datasource . getclass ( ) . getname ( ) ) ; result . getproperties ( ) . putall ( findallgetterproperties ( datasource ) ) ; return result ; }	Get data source configuration.
@ sneakythrows public datasource createdatasource ( ) { datasource result = ( datasource ) class . forname ( datasourceclassname ) . newinstance ( ) ; method [ ] methods = result . getclass ( ) . getmethods ( ) ; for ( entry < string , object > entry : properties . entryset ( ) ) { if ( skipped_property_names . contains ( entry . getkey ( ) ) ) { continue ; } optional < method > settermethod = findsettermethod ( methods , entry . getkey ( ) ) ; if ( settermethod . ispresent ( ) ) { settermethod . get ( ) . invoke ( result , entry . getvalue ( ) ) ; } } return result ; }	Create data source.
public void setstatus ( final connectionstatus update ) { status . getandset ( update ) ; if ( connectionstatus . terminated == status . get ( ) ) { resourcesynchronizer . donotify ( ) ; } }	Change connection status using get and set.
public void setrunningstatusifnecessary ( ) { if ( connectionstatus . transaction != status . get ( ) && connectionstatus . running != status . get ( ) ) { status . getandset ( connectionstatus . running ) ; } }	Change connection status to running if necessary.
void donotifyifnecessary ( ) { if ( status . compareandset ( connectionstatus . running , connectionstatus . release ) || status . compareandset ( connectionstatus . terminated , connectionstatus . release ) ) { resourcesynchronizer . donotify ( ) ; } }	Notify connection to finish wait if necessary.
public void waituntilconnectionreleasedifnecessary ( ) throws interruptedexception { if ( connectionstatus . running == status . get ( ) || connectionstatus . terminated == status . get ( ) ) { while ( ! status . compareandset ( connectionstatus . release , connectionstatus . running ) ) { resourcesynchronizer . doawaituntil ( ) ; } } }	Wait until connection is released if necessary.
public orderitem createorderitem ( ) { if ( orderbyitemsegment instanceof indexorderbyitemsegment ) { return createorderitem ( ( indexorderbyitemsegment ) orderbyitemsegment ) ; } if ( orderbyitemsegment instanceof columnorderbyitemsegment ) { return createorderitem ( selectstatement , ( columnorderbyitemsegment ) orderbyitemsegment ) ; } if ( orderbyitemsegment instanceof expressionorderbyitemsegment ) { return createorderitem ( selectstatement , ( expressionorderbyitemsegment ) orderbyitemsegment ) ; } throw new unsupportedoperationexception ( ) ; }	Create order item.
public void initlisteners ( ) { instancestatechangedlistener . watch ( changedtype . updated ) ; datasourcestatechangedlistener . watch ( changedtype . updated , changedtype . deleted ) ; }	Initialize all state changed listeners.
public void settransactiontype ( final transactiontype transactiontype ) { if ( null == schemaname ) { throw new shardingexception ( str_ ) ; } if ( isswitchfailed ( ) ) { throw new shardingexception ( str_ ) ; } this . transactiontype = transactiontype ; }	Change transaction type of current channel.
public void setcurrentschema ( final string schemaname ) { if ( isswitchfailed ( ) ) { throw new shardingexception ( str_ ) ; } this . schemaname = schemaname ; this . logicschema = logicschemas . getinstance ( ) . getlogicschema ( schemaname ) ; }	Change logic schema of current channel.
public list < connection > getconnections ( final connectionmode connectionmode , final string datasourcename , final int connectionsize ) throws sqlexception { if ( statehandler . isintransaction ( ) ) { return getconnectionswithtransaction ( connectionmode , datasourcename , connectionsize ) ; } else { return getconnectionswithouttransaction ( connectionmode , datasourcename , connectionsize ) ; } }	Get connections of current thread datasource.
public synchronized void close ( final boolean forceclose ) throws sqlexception { collection < sqlexception > exceptions = new linkedlist < > ( ) ; mastervisitedmanager . clear ( ) ; exceptions . addall ( closeresultsets ( ) ) ; exceptions . addall ( closestatements ( ) ) ; if ( ! statehandler . isintransaction ( ) || forceclose ) { exceptions . addall ( releaseconnections ( forceclose ) ) ; } statehandler . donotifyifnecessary ( ) ; throwsqlexceptionifnecessary ( exceptions ) ; }	Close cached connection.
public void parse ( final insertstatement insertstatement ) { if ( ! lexerengine . skipifequal ( getcustomizedinsertkeywords ( ) ) ) { return ; } lexerengine . accept ( defaultkeyword . duplicate ) ; lexerengine . accept ( defaultkeyword . key ) ; lexerengine . accept ( defaultkeyword . update ) ; do { column column = new column ( sqlutil . getexactlyvalue ( lexerengine . getcurrenttoken ( ) . getliterals ( ) ) , insertstatement . gettables ( ) . getsingletablename ( ) ) ; if ( shardingrule . isshardingcolumn ( column . getname ( ) , column . gettablename ( ) ) ) { throw new sqlparsingexception ( str_ , lexerengine . getcurrenttoken ( ) . gettype ( ) , lexerengine . getcurrenttoken ( ) . getliterals ( ) ) ; } basicexpressionparser . parse ( insertstatement ) ; lexerengine . accept ( symbol . eq ) ; if ( lexerengine . skipifequal ( defaultkeyword . values ) ) { lexerengine . accept ( symbol . left_paren ) ; basicexpressionparser . parse ( insertstatement ) ; lexerengine . accept ( symbol . right_paren ) ; } else { lexerengine . nexttoken ( ) ; } } while ( lexerengine . skipifequal ( symbol . comma ) ) ; }	Parse insert duplicate key update.
public static optional < condition > createcomparecondition ( final predicatecomparerightvalue comparerightvalue , final column column ) { return comparerightvalue . getexpression ( ) instanceof simpleexpressionsegment ? optional . of ( new condition ( column , ( ( simpleexpressionsegment ) comparerightvalue . getexpression ( ) ) . getsqlexpression ( ) ) ) : optional . < condition > absent ( ) ; }	Create condition of compare operator.
public static optional < condition > createincondition ( final predicateinrightvalue inrightvalue , final column column ) { list < sqlexpression > sqlexpressions = new linkedlist < > ( ) ; for ( expressionsegment each : inrightvalue . getsqlexpressions ( ) ) { if ( ! ( each instanceof simpleexpressionsegment ) ) { sqlexpressions . clear ( ) ; break ; } else { sqlexpressions . add ( ( ( simpleexpressionsegment ) each ) . getsqlexpression ( ) ) ; } } return sqlexpressions . isempty ( ) ? optional . < condition > absent ( ) : optional . of ( new condition ( column , sqlexpressions ) ) ; }	Create condition of IN operator.
public static optional < condition > createbetweencondition ( final predicatebetweenrightvalue betweenrightvalue , final column column ) { return betweenrightvalue . getbetweenexpression ( ) instanceof simpleexpressionsegment && betweenrightvalue . getandexpression ( ) instanceof simpleexpressionsegment ? optional . of ( new condition ( column , ( ( simpleexpressionsegment ) betweenrightvalue . getbetweenexpression ( ) ) . getsqlexpression ( ) , ( ( simpleexpressionsegment ) betweenrightvalue . getandexpression ( ) ) . getsqlexpression ( ) ) ) : optional . < condition > absent ( ) ; }	Create condition of BETWEEN ..
public void init ( final databasetype databasetype , final map < string , datasource > datasourcemap ) { for ( entry < transactiontype , shardingtransactionmanager > entry : transactionmanagermap . entryset ( ) ) { entry . getvalue ( ) . init ( databasetype , getresourcedatasources ( datasourcemap ) ) ; } }	Initialize sharding transaction managers.
public shardingtransactionmanager gettransactionmanager ( final transactiontype transactiontype ) { shardingtransactionmanager result = transactionmanagermap . get ( transactiontype ) ; if ( transactiontype . local != transactiontype ) { preconditions . checknotnull ( result , str_ , transactiontype ) ; } return result ; }	Get sharding transaction manager.
public void close ( ) throws exception { for ( entry < transactiontype , shardingtransactionmanager > entry : transactionmanagermap . entryset ( ) ) { entry . getvalue ( ) . close ( ) ; } }	Close sharding transaction managers.
public static abstractupdateparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine ) { switch ( dbtype ) { case h2 : case mysql : return new mysqlupdateparser ( shardingrule , lexerengine ) ; case oracle : return new oracleupdateparser ( shardingrule , lexerengine ) ; case sqlserver : return new sqlserverupdateparser ( shardingrule , lexerengine ) ; case postgresql : return new postgresqlupdateparser ( shardingrule , lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create update parser instance.
public static string getsqlstatementruledefinitionfilename ( final string rootdir , final databasetype databasetype ) { return joiner . on ( str_ ) . join ( rootdir , databasetype . name ( ) . tolowercase ( ) , sql_statement_rule_definition_file_name ) ; }	Get SQL statement rule definition file name.
public static optional < generatedkey > getgeneratekey ( final shardingrule shardingrule , final list < object > parameters , final insertstatement insertstatement ) { optional < string > generatekeycolumnname = shardingrule . findgeneratekeycolumnname ( insertstatement . gettables ( ) . getsingletablename ( ) ) ; if ( ! generatekeycolumnname . ispresent ( ) ) { return optional . absent ( ) ; } return iscontainsgeneratekeycolumn ( insertstatement , generatekeycolumnname . get ( ) ) ? findgeneratedkey ( parameters , insertstatement , generatekeycolumnname . get ( ) ) : optional . of ( creategeneratedkey ( shardingrule , insertstatement , generatekeycolumnname . get ( ) ) ) ; }	Get generate key.
public static string getdriverclassname ( final string url ) { for ( entry < string , string > entry : url_prefix_and_driver_class_name_mapper . entryset ( ) ) { if ( url . startswith ( entry . getkey ( ) ) ) { return entry . getvalue ( ) ; } } throw new shardingexception ( str_ , url , jdbcdriverurlrecognizer . class . getname ( ) ) ; }	Get JDBC driver class name.
public static datasourcemetadata newinstance ( final databasetype databasetype , final string url ) { switch ( databasetype ) { case h2 : return new h2datasourcemetadata ( url ) ; case mysql : return new mysqldatasourcemetadata ( url ) ; case oracle : return new oracledatasourcemetadata ( url ) ; case postgresql : return new postgresqldatasourcemetadata ( url ) ; case sqlserver : return new sqlserverdatasourcemetadata ( url ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , databasetype ) ) ; } }	Create new instance of data source meta data.
@ sneakythrows public static xadatasource build ( final databasetype databasetype , final datasource datasource ) { xadatasource result = createxadatasource ( databasetype ) ; properties xaproperties = xapropertiesfactory . createxaproperties ( databasetype ) . build ( swapper . swap ( datasource ) ) ; propertyutils . setproperties ( result , xaproperties ) ; return result ; }	Create XA data source through general data source.
public sqlstatement judge ( ) { lexerengine lexerengine = lexerenginefactory . newinstance ( databasetype . mysql , sql ) ; lexerengine . nexttoken ( ) ; while ( bool_ ) { tokentype tokentype = lexerengine . getcurrenttoken ( ) . gettype ( ) ; if ( tokentype instanceof keyword ) { if ( dqlstatement . isdql ( tokentype ) ) { return getdqlstatement ( ) ; } if ( dmlstatement . isdml ( tokentype ) ) { return getdmlstatement ( tokentype ) ; } if ( tclstatement . istcl ( tokentype ) ) { return gettclstatement ( ) ; } if ( dalstatement . isdal ( tokentype ) ) { return getdalstatement ( tokentype , lexerengine ) ; } lexerengine . nexttoken ( ) ; tokentype secondarytokentype = lexerengine . getcurrenttoken ( ) . gettype ( ) ; if ( ddlstatement . isddl ( tokentype , secondarytokentype ) ) { return getddlstatement ( ) ; } if ( dclstatement . isdcl ( tokentype , secondarytokentype ) ) { return getdclstatement ( ) ; } if ( tclstatement . istclunsafe ( databasetype . mysql , tokentype , lexerengine ) ) { return gettclstatement ( ) ; } if ( defaultkeyword . set . equals ( tokentype ) ) { return new setstatement ( ) ; } } else { lexerengine . nexttoken ( ) ; } if ( sql . touppercase ( ) . startswith ( str_ ) ) { return getdqlstatement ( ) ; } if ( tokentype instanceof assist && assist . end == tokentype ) { throw new sqlparsingexception ( str_ , sql ) ; } } }	Judge SQL type only.
public object getcell ( final int columnindex ) { preconditions . checkargument ( columnindex > num_ && columnindex < data . length + num_ ) ; return data [ columnindex - num_ ] ; }	Get data from cell.
public void setcell ( final int columnindex , final object value ) { preconditions . checkargument ( columnindex > num_ && columnindex < data . length + num_ ) ; data [ columnindex - num_ ] = value ; }	Set data for cell.
public void parse ( final insertstatement insertstatement , final shardingtablemetadata shardingtablemetadata ) { string tablename = insertstatement . gettables ( ) . getsingletablename ( ) ; insertstatement . getcolumnnames ( ) . addall ( lexerengine . equalany ( symbol . left_paren ) ? parsewithcolumn ( insertstatement ) : parsewithoutcolumn ( shardingtablemetadata , tablename ) ) ; }	Parse insert columns.
public static abstractdeleteparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine ) { switch ( dbtype ) { case h2 : case mysql : return new mysqldeleteparser ( shardingrule , lexerengine ) ; case oracle : return new oracledeleteparser ( shardingrule , lexerengine ) ; case sqlserver : return new sqlserverdeleteparser ( shardingrule , lexerengine ) ; case postgresql : return new postgresqldeleteparser ( shardingrule , lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create delete parser instance.
public static abstractshowparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine ) { switch ( dbtype ) { case h2 : case mysql : return new mysqlshowparser ( shardingrule , lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create show parser instance.
public static boolean isddl ( final tokentype primarytokentype , final tokentype secondarytokentype ) { return primary_statement_prefix . contains ( primarytokentype ) && ! not_secondary_statement_prefix . contains ( secondarytokentype ) ; }	Is DDL statement.
public void init ( final map < string , map < string , datasourceconfiguration > > datasourceconfigurationmap , final map < string , ruleconfiguration > schemarulemap , final authentication authentication , final properties props ) { for ( entry < string , map < string , datasourceconfiguration > > entry : datasourceconfigurationmap . entryset ( ) ) { configservice . persistconfiguration ( entry . getkey ( ) , datasourceconfigurationmap . get ( entry . getkey ( ) ) , schemarulemap . get ( entry . getkey ( ) ) , authentication , props , isoverwrite ) ; } stateservice . persistinstanceonline ( ) ; stateservice . persistdatasourcesnode ( ) ; listenermanager . initlisteners ( ) ; }	Initialize for orchestration.
public void parse ( final shardingrule shardingrule , final sqlstatement sqlstatement , final list < selectitem > items ) { aliasexpressionparser . parsetablealias ( ) ; if ( lexerengine . skipifequal ( defaultkeyword . where ) ) { parsewhere ( shardingrule , sqlstatement , items ) ; } }	Parse where.
public optional < sqlstatementrule > findsqlstatementrule ( final databasetype databasetype , final string contextclassname ) { return optional . fromnullable ( parserruledefinitions . get ( databasetype . h2 == databasetype ? databasetype . mysql : databasetype ) . getsqlstatementruledefinition ( ) . getrules ( ) . get ( contextclassname ) ) ; }	Find SQL statement rule.
public optional < sqlsegmentfiller > findsqlsegmentfiller ( final databasetype databasetype , final class < ? extends sqlsegment > sqlsegmentclass ) { return optional . fromnullable ( parserruledefinitions . get ( databasetype . h2 == databasetype ? databasetype . mysql : databasetype ) . getfillerruledefinition ( ) . getrules ( ) . get ( sqlsegmentclass ) ) ; }	Find SQL segment rule.
public string readstringnul ( ) { byte [ ] result = new byte [ bytebuf . bytesbefore ( ( byte ) num_ ) ] ; bytebuf . readbytes ( result ) ; bytebuf . skipbytes ( num_ ) ; return new string ( result ) ; }	Read null terminated string from byte buffers.
public static textprotocolbackendhandler newinstance ( final string sql , final backendconnection backendconnection ) { if ( sql . touppercase ( ) . startswith ( sctl_set ) ) { return new shardingctlsetbackendhandler ( sql , backendconnection ) ; } if ( sql . touppercase ( ) . startswith ( sctl_show ) ) { return new shardingctlshowbackendhandler ( sql , backendconnection ) ; } if ( sql . touppercase ( ) . startswith ( sctl_explain ) ) { return new shardingctlexplainbackendhandler ( sql , backendconnection ) ; } throw new illegalargumentexception ( sql ) ; }	Create new instance of sharding CTL backend handler.
public void optimize ( final sqlstatementrule rule , final sqlstatement sqlstatement ) { optional < sqlstatementoptimizer > optimizer = rule . getoptimizer ( ) ; if ( optimizer . ispresent ( ) ) { optimizer . get ( ) . optimize ( sqlstatement , shardingtablemetadata ) ; } }	Optimize SQL statement.
public static parserrulecontext getfirstchildnode ( final parserrulecontext node , final rulename rulename ) { optional < parserrulecontext > result = findfirstchildnode ( node , rulename ) ; preconditions . checkstate ( result . ispresent ( ) ) ; return result . get ( ) ; }	Get first child node.
public static optional < parserrulecontext > findfirstchildnode ( final parserrulecontext node , final rulename rulename ) { queue < parserrulecontext > parserrulecontexts = new linkedlist < > ( ) ; parserrulecontexts . add ( node ) ; parserrulecontext parserrulecontext ; while ( null != ( parserrulecontext = parserrulecontexts . poll ( ) ) ) { if ( ismatchednode ( parserrulecontext , rulename ) ) { return optional . of ( parserrulecontext ) ; } for ( int i = num_ ; i < parserrulecontext . getchildcount ( ) ; i ++ ) { if ( parserrulecontext . getchild ( i ) instanceof parserrulecontext ) { parserrulecontexts . add ( ( parserrulecontext ) parserrulecontext . getchild ( i ) ) ; } } } return optional . absent ( ) ; }	Find first child node.
public static optional < parserrulecontext > findfirstchildnodenonerecursive ( final parserrulecontext node , final rulename rulename ) { if ( ismatchednode ( node , rulename ) ) { return optional . of ( node ) ; } for ( int i = num_ ; i < node . getchildcount ( ) ; i ++ ) { if ( node . getchild ( i ) instanceof parserrulecontext ) { parserrulecontext child = ( parserrulecontext ) node . getchild ( i ) ; if ( ismatchednode ( child , rulename ) ) { return optional . of ( child ) ; } } } return optional . absent ( ) ; }	Find first child node none recursive.
public static optional < parserrulecontext > findsinglenodefromfirstdescendant ( final parserrulecontext node , final rulename rulename ) { parserrulecontext nextnode = node ; do { if ( ismatchednode ( nextnode , rulename ) ) { return optional . of ( nextnode ) ; } if ( num_ != nextnode . getchildcount ( ) || ! ( nextnode . getchild ( num_ ) instanceof parserrulecontext ) ) { return optional . absent ( ) ; } nextnode = ( parserrulecontext ) nextnode . getchild ( num_ ) ; } while ( null != nextnode ) ; return optional . absent ( ) ; }	Find single node from first descendant which only has one child.
public static collection < parserrulecontext > getalldescendantnodes ( final parserrulecontext node , final rulename rulename ) { collection < parserrulecontext > result = new linkedlist < > ( ) ; if ( ismatchednode ( node , rulename ) ) { result . add ( node ) ; } for ( parserrulecontext each : getchildrennodes ( node ) ) { result . addall ( getalldescendantnodes ( each , rulename ) ) ; } return result ; }	Get all descendant nodes.
public boolean containscolumn ( final string tablename , final string column ) { return containstable ( tablename ) && tables . get ( tablename ) . getcolumns ( ) . keyset ( ) . contains ( column . tolowercase ( ) ) ; }	Judge contains column from table meta data or not.
public collection < string > getallcolumnnames ( final string tablename ) { return tables . containskey ( tablename ) ? tables . get ( tablename ) . getcolumns ( ) . keyset ( ) : collections . < string > emptylist ( ) ; }	Get all column names via table.
public static aggregationunit create ( final aggregationtype type ) { switch ( type ) { case max : return new comparableaggregationunit ( bool_ ) ; case min : return new comparableaggregationunit ( bool_ ) ; case sum : case count : return new accumulationaggregationunit ( ) ; case avg : return new averageaggregationunit ( ) ; default : throw new unsupportedoperationexception ( type . name ( ) ) ; } }	Create aggregation unit instance.
public void execute ( final collection < t > targets , final forceexecutecallback < t > callback ) throws sqlexception { collection < sqlexception > exceptions = new linkedlist < > ( ) ; for ( t each : targets ) { try { callback . execute ( each ) ; } catch ( final sqlexception ex ) { exceptions . add ( ex ) ; } } throwsqlexceptionifnecessary ( exceptions ) ; }	Force execute.
public final t newservice ( final string type , final properties props ) { collection < t > typebasedservices = loadtypebasedservices ( type ) ; if ( typebasedservices . isempty ( ) ) { throw new shardingconfigurationexception ( str_ , classtype . getname ( ) , type ) ; } t result = typebasedservices . iterator ( ) . next ( ) ; result . setproperties ( props ) ; return result ; }	Create new instance for type based SPI.
public static void seterror ( final span span , final exception cause ) { span . settag ( tags . error . getkey ( ) , bool_ ) . log ( system . currenttimemillis ( ) , getreason ( cause ) ) ; }	Set error.
public static shardingrouter newinstance ( final shardingrule shardingrule , final shardingmetadata shardingmetadata , final databasetype databasetype , final parsingresultcache parsingresultcache ) { return hintmanager . isdatabaseshardingonly ( ) ? new databasehintsqlrouter ( shardingrule ) : new parsingsqlrouter ( shardingrule , shardingmetadata , databasetype , parsingresultcache ) ; }	Create new instance of sharding router.
public static sqlexecutecallback < integer > getpreparedupdatesqlexecutecallback ( final databasetype databasetype , final boolean isexceptionthrown ) { return new sqlexecutecallback < integer > ( databasetype , isexceptionthrown ) { @ override protected integer executesql ( final routeunit routeunit , final statement statement , final connectionmode connectionmode ) throws sqlexception { return ( ( preparedstatement ) statement ) . executeupdate ( ) ; } } ; }	Get update callback.
public static sqlexecutecallback < boolean > getpreparedsqlexecutecallback ( final databasetype databasetype , final boolean isexceptionthrown ) { return new sqlexecutecallback < boolean > ( databasetype , isexceptionthrown ) { @ override protected boolean executesql ( final routeunit routeunit , final statement statement , final connectionmode connectionmode ) throws sqlexception { return ( ( preparedstatement ) statement ) . execute ( ) ; } } ; }	Get execute callback.
public boolean haslogictable ( final string logictablename ) { for ( tablerule each : tablerules ) { if ( each . getlogictable ( ) . equals ( logictablename . tolowercase ( ) ) ) { return bool_ ; } } return bool_ ; }	Judge contains this logic table in this rule.
public string getbindingactualtable ( final string datasource , final string logictable , final string otheractualtable ) { int index = - num_ ; for ( tablerule each : tablerules ) { index = each . findactualtableindex ( datasource , otheractualtable ) ; if ( - num_ != index ) { break ; } } if ( - num_ == index ) { throw new shardingconfigurationexception ( str_ , datasource , otheractualtable ) ; } for ( tablerule each : tablerules ) { if ( each . getlogictable ( ) . equals ( logictable . tolowercase ( ) ) ) { return each . getactualdatanodes ( ) . get ( index ) . gettablename ( ) . tolowercase ( ) ; } } throw new shardingconfigurationexception ( str_ , datasource , logictable , otheractualtable ) ; }	Deduce actual table name from other actual table name in same binding table rule.
public final void parse ( final selectstatement selectstatement ) { if ( ! lexerengine . skipifequal ( defaultkeyword . group ) ) { return ; } lexerengine . accept ( defaultkeyword . by ) ; while ( bool_ ) { addgroupbyitem ( basicexpressionparser . parse ( selectstatement ) , selectstatement ) ; if ( ! lexerengine . equalany ( symbol . comma ) ) { break ; } lexerengine . nexttoken ( ) ; } lexerengine . skipall ( getskippedkeywordaftergroupby ( ) ) ; selectstatement . setgroupbylastindex ( lexerengine . getcurrenttoken ( ) . getendposition ( ) - lexerengine . getcurrenttoken ( ) . getliterals ( ) . length ( ) - num_ ) ; }	Parse group by.
public static abstractuseparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine ) { switch ( dbtype ) { case h2 : case mysql : return new mysqluseparser ( lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create use parser instance.
public long readintlenenc ( ) { int firstbyte = readint1 ( ) ; if ( firstbyte < num_ ) { return firstbyte ; } if ( num_ == firstbyte ) { return num_ ; } if ( num_ == firstbyte ) { return bytebuf . readshortle ( ) ; } if ( num_ == firstbyte ) { return bytebuf . readmediumle ( ) ; } return bytebuf . readlongle ( ) ; }	Read lenenc integer from byte buffers.
public void writeintlenenc ( final long value ) { if ( value < num_ ) { bytebuf . writebyte ( ( int ) value ) ; return ; } if ( value < math . pow ( num_ , num_ ) ) { bytebuf . writebyte ( num_ ) ; bytebuf . writeshortle ( ( int ) value ) ; return ; } if ( value < math . pow ( num_ , num_ ) ) { bytebuf . writebyte ( num_ ) ; bytebuf . writemediumle ( ( int ) value ) ; return ; } bytebuf . writebyte ( num_ ) ; bytebuf . writelongle ( value ) ; }	Write lenenc integer to byte buffers.
public string readstringlenenc ( ) { int length = ( int ) readintlenenc ( ) ; byte [ ] result = new byte [ length ] ; bytebuf . readbytes ( result ) ; return new string ( result ) ; }	Read lenenc string from byte buffers.
public void writestringlenenc ( final string value ) { if ( strings . isnullorempty ( value ) ) { bytebuf . writebyte ( num_ ) ; return ; } writeintlenenc ( value . getbytes ( ) . length ) ; bytebuf . writebytes ( value . getbytes ( ) ) ; }	Write lenenc string to byte buffers.
public void writebyteslenenc ( final byte [ ] value ) { if ( num_ == value . length ) { bytebuf . writebyte ( num_ ) ; return ; } writeintlenenc ( value . length ) ; bytebuf . writebytes ( value ) ; }	Write lenenc bytes to byte buffers.
public string readstringfix ( final int length ) { byte [ ] result = new byte [ length ] ; bytebuf . readbytes ( result ) ; return new string ( result ) ; }	Read fixed length string from byte buffers.
public byte [ ] readstringnulbybytes ( ) { byte [ ] result = new byte [ bytebuf . bytesbefore ( ( byte ) num_ ) ] ; bytebuf . readbytes ( result ) ; bytebuf . skipbytes ( num_ ) ; return result ; }	Read null terminated string from byte buffers and return bytes.
public string readstringeof ( ) { byte [ ] result = new byte [ bytebuf . readablebytes ( ) ] ; bytebuf . readbytes ( result ) ; return new string ( result ) ; }	Read rest of packet string from byte buffers.
public map < column , list < condition > > getconditionsmap ( ) { map < column , list < condition > > result = new linkedhashmap < > ( conditions . size ( ) , num_ ) ; for ( condition each : conditions ) { if ( ! result . containskey ( each . getcolumn ( ) ) ) { result . put ( each . getcolumn ( ) , new linkedlist < condition > ( ) ) ; } result . get ( each . getcolumn ( ) ) . add ( each ) ; } return result ; }	Get conditions map.
public andcondition optimize ( ) { andcondition result = new andcondition ( ) ; for ( condition each : conditions ) { if ( condition . class . equals ( each . getclass ( ) ) ) { result . getconditions ( ) . add ( each ) ; } } if ( result . getconditions ( ) . isempty ( ) ) { result . getconditions ( ) . add ( new nullcondition ( ) ) ; } return result ; }	Optimize and condition.
@ suppresswarnings ( str_ ) @ sneakythrows public void init ( final sqlstatementruledefinitionentity dialectruledefinitionentity , final extractorruledefinition extractorruledefinition ) { for ( sqlstatementruleentity each : dialectruledefinitionentity . getrules ( ) ) { sqlstatementrule sqlstatementrule = new sqlstatementrule ( each . getcontext ( ) , ( class < ? extends sqlstatement > ) class . forname ( each . getsqlstatementclass ( ) ) , ( sqlstatementoptimizer ) newclassinstance ( each . getoptimizerclass ( ) ) ) ; sqlstatementrule . getextractors ( ) . addall ( createextractors ( each . getextractorrulerefs ( ) , extractorruledefinition ) ) ; rules . put ( getcontextclassname ( each . getcontext ( ) ) , sqlstatementrule ) ; } }	Initialize SQL statement rule definition.
@ sneakythrows public void start ( final int port ) { try { serverbootstrap bootstrap = new serverbootstrap ( ) ; bossgroup = createeventloopgroup ( ) ; if ( bossgroup instanceof epolleventloopgroup ) { groupsepoll ( bootstrap ) ; } else { groupsnio ( bootstrap ) ; } channelfuture future = bootstrap . bind ( port ) . sync ( ) ; future . channel ( ) . closefuture ( ) . sync ( ) ; } finally { workergroup . shutdowngracefully ( ) ; bossgroup . shutdowngracefully ( ) ; backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) . close ( ) ; } }	Start Sharding-Proxy.
public void initlisteners ( ) { schemachangedlistener . watch ( changedtype . updated , changedtype . deleted ) ; propertieschangedlistener . watch ( changedtype . updated ) ; authenticationchangedlistener . watch ( changedtype . updated ) ; }	Initialize all configuration changed listeners.
@ subscribe @ sneakythrows public final synchronized void renew ( final datasourcechangedevent datasourcechangedevent ) { datasource . close ( ) ; datasource = new masterslavedatasource ( datasourceconverter . getdatasourcemap ( datasourcechangedevent . getdatasourceconfigurations ( ) ) , datasource . getmasterslaverule ( ) , datasource . getshardingproperties ( ) . getprops ( ) ) ; }	Renew master-slave data source.
@ suppresswarnings ( { str_ , str_ } ) public static int compareto ( final comparable thisvalue , final comparable othervalue , final orderdirection orderdirection , final orderdirection nullorderdirection ) { if ( null == thisvalue && null == othervalue ) { return num_ ; } if ( null == thisvalue ) { return orderdirection == nullorderdirection ? - num_ : num_ ; } if ( null == othervalue ) { return orderdirection == nullorderdirection ? num_ : - num_ ; } return orderdirection . asc == orderdirection ? thisvalue . compareto ( othervalue ) : - thisvalue . compareto ( othervalue ) ; }	Compare two object with order type.
public static xaproperties createxaproperties ( final databasetype databasetype ) { switch ( databasetype ) { case h2 : return new h2xaproperties ( ) ; case mysql : return new mysqlxaproperties ( ) ; case postgresql : return new postgresqlxaproperties ( ) ; case oracle : return new oraclexaproperties ( ) ; case sqlserver : return new sqlserverxaproperties ( ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , databasetype ) ) ; } }	Create XA properties.
public void add ( final condition condition ) { if ( andconditions . isempty ( ) ) { andconditions . add ( new andcondition ( ) ) ; } andconditions . get ( num_ ) . getconditions ( ) . add ( condition ) ; }	Add condition.
public orcondition optimize ( ) { for ( andcondition each : andconditions ) { if ( each . getconditions ( ) . get ( num_ ) instanceof nullcondition ) { orcondition result = new orcondition ( ) ; result . add ( new nullcondition ( ) ) ; return result ; } } return this ; }	Optimize or condition.
public list < condition > findconditions ( final column column ) { list < condition > result = new linkedlist < > ( ) ; for ( andcondition each : andconditions ) { result . addall ( collections2 . filter ( each . getconditions ( ) , new predicate < condition > ( ) { @ override public boolean apply ( final condition input ) { return input . getcolumn ( ) . equals ( column ) ; } } ) ) ; } return result ; }	Find conditions by column.
public void resetcolumnlabel ( final string schema ) { map < string , integer > labelandindexmap = new hashmap < > ( num_ , num_ ) ; labelandindexmap . put ( schema , num_ ) ; resetlabelandindexmap ( labelandindexmap ) ; }	Reset column label.
public optional < columndefinitionsegment > findcolumndefinition ( final string columnname , final shardingtablemetadata shardingtablemetadata ) { optional < columndefinitionsegment > result = findcolumndefinitionfrommetadata ( columnname , shardingtablemetadata ) ; return result . ispresent ( ) ? result : findcolumndefinitionfromcurrentaddclause ( columnname ) ; }	Find column definition.
public optional < columndefinitionsegment > findcolumndefinitionfrommetadata ( final string columnname , final shardingtablemetadata shardingtablemetadata ) { if ( ! shardingtablemetadata . containstable ( gettables ( ) . getsingletablename ( ) ) ) { return optional . absent ( ) ; } for ( columnmetadata each : shardingtablemetadata . get ( gettables ( ) . getsingletablename ( ) ) . getcolumns ( ) . values ( ) ) { if ( columnname . equalsignorecase ( each . getcolumnname ( ) ) ) { return optional . of ( new columndefinitionsegment ( columnname , each . getdatatype ( ) , each . isprimarykey ( ) ) ) ; } } return optional . absent ( ) ; }	Find column definition from meta data.
public collection < sqlsegment > extract ( final sqlast ast ) { collection < sqlsegment > result = new linkedlist < > ( ) ; preconditions . checkstate ( ast . getsqlstatementrule ( ) . ispresent ( ) ) ; map < parserrulecontext , integer > parametermarkerindexes = getparametermarkerindexes ( ast . getparserrulecontext ( ) ) ; for ( sqlsegmentextractor each : ast . getsqlstatementrule ( ) . get ( ) . getextractors ( ) ) { if ( each instanceof optionalsqlsegmentextractor ) { optional < ? extends sqlsegment > sqlsegment = ( ( optionalsqlsegmentextractor ) each ) . extract ( ast . getparserrulecontext ( ) , parametermarkerindexes ) ; if ( sqlsegment . ispresent ( ) ) { result . add ( sqlsegment . get ( ) ) ; } } else if ( each instanceof collectionsqlsegmentextractor ) { result . addall ( ( ( collectionsqlsegmentextractor ) each ) . extract ( ast . getparserrulecontext ( ) , parametermarkerindexes ) ) ; } } return result ; }	Extract SQL segments.
public static abstractselectparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine , final shardingtablemetadata shardingtablemetadata ) { switch ( dbtype ) { case h2 : case mysql : return new mysqlselectparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case oracle : return new oracleselectparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case sqlserver : return new sqlserverselectparser ( shardingrule , lexerengine , shardingtablemetadata ) ; case postgresql : return new postgresqlselectparser ( shardingrule , lexerengine , shardingtablemetadata ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create select parser instance.
@ override public collection < string > getslavedatasourcenames ( ) { if ( disableddatasourcenames . isempty ( ) ) { return super . getslavedatasourcenames ( ) ; } collection < string > result = new linkedlist < > ( super . getslavedatasourcenames ( ) ) ; result . removeall ( disableddatasourcenames ) ; return result ; }	Get slave data source names.
public void updatedisableddatasourcenames ( final string datasourcename , final boolean isdisabled ) { if ( isdisabled ) { disableddatasourcenames . add ( datasourcename ) ; } else { disableddatasourcenames . remove ( datasourcename ) ; } }	Update disabled data source names.
public optional < string > getalias ( final string name ) { if ( containstar ) { return optional . absent ( ) ; } string rawname = sqlutil . getexactlyvalue ( name ) ; for ( selectitem each : items ) { if ( sqlutil . getexactlyexpression ( rawname ) . equalsignorecase ( sqlutil . getexactlyexpression ( sqlutil . getexactlyvalue ( each . getexpression ( ) ) ) ) ) { return each . getalias ( ) ; } if ( rawname . equalsignorecase ( each . getalias ( ) . ornull ( ) ) ) { return optional . of ( rawname ) ; } } return optional . absent ( ) ; }	Get alias.
public list < aggregationselectitem > getaggregationselectitems ( ) { list < aggregationselectitem > result = new linkedlist < > ( ) ; for ( selectitem each : items ) { if ( each instanceof aggregationselectitem ) { aggregationselectitem aggregationselectitem = ( aggregationselectitem ) each ; result . add ( aggregationselectitem ) ; result . addall ( aggregationselectitem . getderivedaggregationselectitems ( ) ) ; } } return result ; }	Get aggregation select items.
public optional < distinctselectitem > getdistinctselectitem ( ) { for ( selectitem each : items ) { if ( each instanceof distinctselectitem ) { return optional . of ( ( distinctselectitem ) each ) ; } } return optional . absent ( ) ; }	Get distinct select item optional.
public list < aggregationdistinctselectitem > getaggregationdistinctselectitems ( ) { list < aggregationdistinctselectitem > result = new linkedlist < > ( ) ; for ( selectitem each : items ) { if ( each instanceof aggregationdistinctselectitem ) { result . add ( ( aggregationdistinctselectitem ) each ) ; } } return result ; }	Get aggregation distinct select items.
public boolean hasunqualifiedstarselectitem ( ) { for ( selectitem each : items ) { if ( each instanceof starselectitem && ! ( ( starselectitem ) each ) . getowner ( ) . ispresent ( ) ) { return bool_ ; } } return bool_ ; }	Judge has unqualified star select item.
public collection < starselectitem > getqualifiedstarselectitems ( ) { collection < starselectitem > result = new linkedlist < > ( ) ; for ( selectitem each : items ) { if ( each instanceof starselectitem && ( ( starselectitem ) each ) . getowner ( ) . ispresent ( ) ) { result . add ( ( starselectitem ) each ) ; } } return result ; }	Get qualified star select items.
public optional < starselectitem > findstarselectitem ( final string tablenameoralias ) { optional < table > table = gettables ( ) . find ( tablenameoralias ) ; if ( ! table . ispresent ( ) ) { return optional . absent ( ) ; } for ( selectitem each : items ) { if ( ! ( each instanceof starselectitem ) ) { continue ; } starselectitem starselectitem = ( starselectitem ) each ; if ( starselectitem . getowner ( ) . ispresent ( ) && gettables ( ) . find ( starselectitem . getowner ( ) . get ( ) ) . equals ( table ) ) { return optional . of ( starselectitem ) ; } } return optional . absent ( ) ; }	Find star select item via table name or alias.
public void setindexforitems ( final map < string , integer > columnlabelindexmap ) { setindexforaggregationitem ( columnlabelindexmap ) ; setindexfororderitem ( columnlabelindexmap , orderbyitems ) ; setindexfororderitem ( columnlabelindexmap , groupbyitems ) ; }	Set index for select items.
public selectstatement mergesubquerystatement ( ) { selectstatement result = processlimitforsubquery ( ) ; processitems ( result ) ; processorderbyitems ( result ) ; result . setparametersindex ( getparametersindex ( ) ) ; return result ; }	Merge subquery statement if contains.
public static void logsql ( final string logicsql , final collection < string > datasourcenames ) { log ( str_ ) ; log ( str_ , logicsql , joiner . on ( str_ ) . join ( datasourcenames ) ) ; }	Print SQL log for master slave rule.
public static void logsql ( final string logicsql , final boolean showsimple , final sqlstatement sqlstatement , final collection < routeunit > routeunits ) { log ( str_ ) ; log ( str_ , logicsql ) ; log ( str_ , sqlstatement ) ; if ( showsimple ) { logsimplemode ( routeunits ) ; } else { lognormalmode ( routeunits ) ; } }	Print SQL log for sharding rule.
@ sneakythrows public static datasource createdatasource ( final file yamlfile ) { yamlrootencryptruleconfiguration config = yamlengine . unmarshal ( yamlfile , yamlrootencryptruleconfiguration . class ) ; return encryptdatasourcefactory . createdatasource ( config . getdatasource ( ) , new encryptruleconfigurationyamlswapper ( ) . swap ( config . getencryptrule ( ) ) ) ; }	Create encrypt data source.
public token getmatchedtoken ( final int tokentype ) throws recognitionexception { token result = parser . getcurrenttoken ( ) ; boolean isidentifiercompatible = bool_ ; if ( identifiertokenindex == tokentype && identifiertokenindex > result . gettype ( ) ) { isidentifiercompatible = bool_ ; } if ( result . gettype ( ) == tokentype || isidentifiercompatible ) { if ( token . eof != tokentype && isidentifiercompatible && result instanceof commontoken ) { ( ( commontoken ) result ) . settype ( identifiertokenindex ) ; } parser . geterrorhandler ( ) . reportmatch ( parser ) ; parser . consume ( ) ; } else { result = parser . geterrorhandler ( ) . recoverinline ( parser ) ; if ( parser . getbuildparsetree ( ) && - num_ == result . gettokenindex ( ) ) { parser . getcontext ( ) . adderrornode ( parser . createerrornode ( parser . getcontext ( ) , result ) ) ; } } return result ; }	Get matched token by token type.
@ suppresswarnings ( str_ ) public static < t > t handle ( final environment environment , final string prefix , final class < t > targetclass ) { switch ( springbootversion ) { case num_ : return ( t ) v1 ( environment , prefix ) ; default : return ( t ) v2 ( environment , prefix , targetclass ) ; } }	Spring Boot 1.x is compatible with Spring Boot 2.x by Using Java Reflect.
public void addunit ( final sqlexpression [ ] columnvalues , final object [ ] columnparameters ) { if ( type == inserttype . values ) { this . units . add ( new columnvalueoptimizeresult ( columnnames , columnvalues , columnparameters ) ) ; } else { this . units . add ( new setassignmentoptimizeresult ( columnnames , columnvalues , columnparameters ) ) ; } }	Add insert optimize result uint.
public static mergeengine newinstance ( final databasetype databasetype , final shardingrule shardingrule , final sqlrouteresult routeresult , final shardingtablemetadata shardingtablemetadata , final list < queryresult > queryresults ) throws sqlexception { if ( routeresult . getsqlstatement ( ) instanceof selectstatement ) { return new dqlmergeengine ( databasetype , routeresult , queryresults ) ; } if ( routeresult . getsqlstatement ( ) instanceof dalstatement ) { return new dalmergeengine ( shardingrule , queryresults , ( dalstatement ) routeresult . getsqlstatement ( ) , shardingtablemetadata ) ; } throw new unsupportedoperationexception ( string . format ( str_ , routeresult . getsqlstatement ( ) . gettype ( ) ) ) ; }	Create merge engine instance.
public optional < tablerule > findtablerule ( final string logictablename ) { for ( tablerule each : tablerules ) { if ( each . getlogictable ( ) . equalsignorecase ( logictablename ) ) { return optional . of ( each ) ; } } return optional . absent ( ) ; }	Find table rule.
public optional < tablerule > findtablerulebyactualtable ( final string actualtablename ) { for ( tablerule each : tablerules ) { if ( each . isexisted ( actualtablename ) ) { return optional . of ( each ) ; } } return optional . absent ( ) ; }	Find table rule via actual table name.
public tablerule gettablerule ( final string logictablename ) { optional < tablerule > tablerule = findtablerule ( logictablename ) ; if ( tablerule . ispresent ( ) ) { return tablerule . get ( ) ; } if ( isbroadcasttable ( logictablename ) ) { return new tablerule ( shardingdatasourcenames . getdatasourcenames ( ) , logictablename ) ; } if ( ! strings . isnullorempty ( shardingdatasourcenames . getdefaultdatasourcename ( ) ) ) { return new tablerule ( shardingdatasourcenames . getdefaultdatasourcename ( ) , logictablename ) ; } throw new shardingconfigurationexception ( str_ , logictablename ) ; }	Get table rule.
public shardingstrategy getdatabaseshardingstrategy ( final tablerule tablerule ) { return null == tablerule . getdatabaseshardingstrategy ( ) ? defaultdatabaseshardingstrategy : tablerule . getdatabaseshardingstrategy ( ) ; }	Get database sharding strategy.
public shardingstrategy gettableshardingstrategy ( final tablerule tablerule ) { return null == tablerule . gettableshardingstrategy ( ) ? defaulttableshardingstrategy : tablerule . gettableshardingstrategy ( ) ; }	Get table sharding strategy.
public boolean isallbindingtables ( final collection < string > logictablenames ) { if ( logictablenames . isempty ( ) ) { return bool_ ; } optional < bindingtablerule > bindingtablerule = findbindingtablerule ( logictablenames ) ; if ( ! bindingtablerule . ispresent ( ) ) { return bool_ ; } collection < string > result = new treeset < > ( string . case_insensitive_order ) ; result . addall ( bindingtablerule . get ( ) . getalllogictables ( ) ) ; return ! result . isempty ( ) && result . containsall ( logictablenames ) ; }	Judge logic tables is all belong to binding encryptors.
public optional < bindingtablerule > findbindingtablerule ( final string logictablename ) { for ( bindingtablerule each : bindingtablerules ) { if ( each . haslogictable ( logictablename ) ) { return optional . of ( each ) ; } } return optional . absent ( ) ; }	Find binding table rule via logic table name.
public boolean isallbroadcasttables ( final collection < string > logictablenames ) { if ( logictablenames . isempty ( ) ) { return bool_ ; } for ( string each : logictablenames ) { if ( ! isbroadcasttable ( each ) ) { return bool_ ; } } return bool_ ; }	Judge logic tables is all belong to broadcast encryptors.
public boolean isbroadcasttable ( final string logictablename ) { for ( string each : broadcasttables ) { if ( each . equalsignorecase ( logictablename ) ) { return bool_ ; } } return bool_ ; }	Judge logic table is belong to broadcast tables.
public boolean isallindefaultdatasource ( final collection < string > logictablenames ) { for ( string each : logictablenames ) { if ( findtablerule ( each ) . ispresent ( ) || isbroadcasttable ( each ) ) { return bool_ ; } } return ! logictablenames . isempty ( ) ; }	Judge logic tables is all belong to default data source.
public boolean isshardingcolumn ( final string columnname , final string tablename ) { for ( tablerule each : tablerules ) { if ( each . getlogictable ( ) . equalsignorecase ( tablename ) && isshardingcolumn ( each , columnname ) ) { return bool_ ; } } return bool_ ; }	Judge is sharding column or not.
public optional < string > findgeneratekeycolumnname ( final string logictablename ) { for ( tablerule each : tablerules ) { if ( each . getlogictable ( ) . equalsignorecase ( logictablename ) && null != each . getgeneratekeycolumn ( ) ) { return optional . of ( each . getgeneratekeycolumn ( ) ) ; } } return optional . absent ( ) ; }	Find column name of generated key.
public string getlogictablename ( final string logicindexname ) { for ( tablerule each : tablerules ) { if ( logicindexname . equals ( each . getlogicindex ( ) ) ) { return each . getlogictable ( ) ; } } throw new shardingconfigurationexception ( str_ , logicindexname ) ; }	Get logic table name base on logic index name.
public collection < string > getlogictablenames ( final string actualtablename ) { collection < string > result = new linkedlist < > ( ) ; for ( tablerule each : tablerules ) { if ( each . isexisted ( actualtablename ) ) { result . add ( each . getlogictable ( ) ) ; } } return result ; }	Get logic table names base on actual table name.
public datanode getdatanode ( final string logictablename ) { tablerule tablerule = gettablerule ( logictablename ) ; return tablerule . getactualdatanodes ( ) . get ( num_ ) ; }	Find data node by logic table name.
public datanode getdatanode ( final string datasourcename , final string logictablename ) { tablerule tablerule = gettablerule ( logictablename ) ; for ( datanode each : tablerule . getactualdatanodes ( ) ) { if ( shardingdatasourcenames . getdatasourcenames ( ) . contains ( each . getdatasourcename ( ) ) && each . getdatasourcename ( ) . equals ( datasourcename ) ) { return each ; } } throw new shardingconfigurationexception ( str_ , datasourcename , logictablename ) ; }	Find data node by data source and logic table.
public optional < string > findactualdefaultdatasourcename ( ) { string defaultdatasourcename = shardingdatasourcenames . getdefaultdatasourcename ( ) ; if ( strings . isnullorempty ( defaultdatasourcename ) ) { return optional . absent ( ) ; } optional < string > masterdefaultdatasourcename = findmasterdatasourcename ( defaultdatasourcename ) ; return masterdefaultdatasourcename . ispresent ( ) ? masterdefaultdatasourcename : optional . of ( defaultdatasourcename ) ; }	Find actual default data source name.
public optional < masterslaverule > findmasterslaverule ( final string datasourcename ) { for ( masterslaverule each : masterslaverules ) { if ( each . containdatasourcename ( datasourcename ) ) { return optional . of ( each ) ; } } return optional . absent ( ) ; }	Find master slave rule.
public string getactualdatasourcename ( final string actualtablename ) { optional < tablerule > tablerule = findtablerulebyactualtable ( actualtablename ) ; if ( tablerule . ispresent ( ) ) { return tablerule . get ( ) . getactualdatasourcenames ( ) . iterator ( ) . next ( ) ; } if ( ! strings . isnullorempty ( shardingdatasourcenames . getdefaultdatasourcename ( ) ) ) { return shardingdatasourcenames . getdefaultdatasourcename ( ) ; } throw new shardingexception ( str_ , actualtablename ) ; }	Get actual data source name.
public boolean contains ( final string logictablename ) { return findtablerule ( logictablename ) . ispresent ( ) || findbindingtablerule ( logictablename ) . ispresent ( ) || isbroadcasttable ( logictablename ) ; }	Judge contains table in sharding rule.
public collection < string > getshardinglogictablenames ( final collection < string > logictablenames ) { collection < string > result = new linkedlist < > ( ) ; for ( string each : logictablenames ) { optional < tablerule > tablerule = findtablerule ( each ) ; if ( tablerule . ispresent ( ) ) { result . add ( each ) ; } } return result ; }	Get sharding logic table names.
void doawaituntil ( ) throws interruptedexception { lock . lock ( ) ; try { condition . await ( default_timeout_milliseconds , timeunit . milliseconds ) ; } finally { lock . unlock ( ) ; } }	Do await until default timeout milliseconds.
public static routingengine newinstance ( final shardingrule shardingrule , final shardingdatasourcemetadata shardingdatasourcemetadata , final sqlstatement sqlstatement , final optimizeresult optimizeresult ) { collection < string > tablenames = sqlstatement . gettables ( ) . gettablenames ( ) ; if ( sqltype . tcl == sqlstatement . gettype ( ) ) { return new databasebroadcastroutingengine ( shardingrule ) ; } if ( sqltype . ddl == sqlstatement . gettype ( ) ) { return new tablebroadcastroutingengine ( shardingrule , sqlstatement ) ; } if ( sqltype . dal == sqlstatement . gettype ( ) ) { return getdalroutingengine ( shardingrule , sqlstatement , tablenames ) ; } if ( sqltype . dcl == sqlstatement . gettype ( ) ) { return getdclroutingengine ( shardingrule , sqlstatement , shardingdatasourcemetadata ) ; } if ( shardingrule . isallindefaultdatasource ( tablenames ) ) { return new defaultdatabaseroutingengine ( shardingrule , tablenames ) ; } if ( shardingrule . isallbroadcasttables ( tablenames ) ) { return sqltype . dql == sqlstatement . gettype ( ) ? new unicastroutingengine ( shardingrule , tablenames ) : new databasebroadcastroutingengine ( shardingrule ) ; } if ( optimizeresult . getshardingconditions ( ) . isalwaysfalse ( ) || tablenames . isempty ( ) ) { return new unicastroutingengine ( shardingrule , tablenames ) ; } collection < string > shardingtablenames = shardingrule . getshardinglogictablenames ( tablenames ) ; if ( num_ == shardingtablenames . size ( ) || shardingrule . isallbindingtables ( shardingtablenames ) ) { return new standardroutingengine ( sqlstatement , shardingrule , shardingtablenames . iterator ( ) . next ( ) , optimizeresult ) ; }	Create new instance of routing engine.
public databaseaccessconfiguration swap ( final datasource datasource ) { datasourcepropertyprovider provider = datasourcepropertyproviderloader . getprovider ( datasource ) ; try { string url = ( string ) findgettermethod ( datasource , provider . geturlpropertyname ( ) ) . invoke ( datasource ) ; string username = ( string ) findgettermethod ( datasource , provider . getusernamepropertyname ( ) ) . invoke ( datasource ) ; string password = ( string ) findgettermethod ( datasource , provider . getpasswordpropertyname ( ) ) . invoke ( datasource ) ; return new databaseaccessconfiguration ( url , username , password ) ; } catch ( final reflectiveoperationexception ex ) { throw new shardingexception ( str_ , datasource . getclass ( ) . getname ( ) , datasourcepropertyprovider . class . getname ( ) ) ; } }	Swap data source to database access configuration.
public static abstractdescribeparser newinstance ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine ) { switch ( dbtype ) { case h2 : case mysql : return new mysqldescribeparser ( shardingrule , lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , dbtype ) ) ; } }	Create describe parser instance.
public string getrawmasterdatasourcename ( final string datasourcename ) { for ( masterslaveruleconfiguration each : shardingruleconfig . getmasterslaveruleconfigs ( ) ) { if ( each . getname ( ) . equals ( datasourcename ) ) { return each . getmasterdatasourcename ( ) ; } } return datasourcename ; }	Get raw master data source name.
public string getrandomdatasourcename ( final collection < string > datasourcenames ) { random random = new random ( ) ; int index = random . nextint ( datasourcenames . size ( ) ) ; iterator < string > iterator = datasourcenames . iterator ( ) ; for ( int i = num_ ; i < index ; i ++ ) { iterator . next ( ) ; } return iterator . next ( ) ; }	Get random data source name.
public sqlrouteresult route ( final sqlrouteresult sqlrouteresult ) { for ( masterslaverule each : masterslaverules ) { route ( each , sqlrouteresult ) ; } return sqlrouteresult ; }	Route Master slave after sharding.
public void persistconfiguration ( final string shardingschemaname , final map < string , datasourceconfiguration > datasourceconfigs , final ruleconfiguration ruleconfig , final authentication authentication , final properties props , final boolean isoverwrite ) { persistdatasourceconfiguration ( shardingschemaname , datasourceconfigs , isoverwrite ) ; persistruleconfiguration ( shardingschemaname , ruleconfig , isoverwrite ) ; persistauthentication ( authentication , isoverwrite ) ; persistproperties ( props , isoverwrite ) ; }	Persist rule configuration.
public boolean hasdatasourceconfiguration ( final string shardingschemaname ) { return ! strings . isnullorempty ( regcenter . get ( confignode . getdatasourcepath ( shardingschemaname ) ) ) ; }	Judge whether schema has data source configuration.
public boolean hasruleconfiguration ( final string shardingschemaname ) { return ! strings . isnullorempty ( regcenter . get ( confignode . getrulepath ( shardingschemaname ) ) ) ; }	Judge whether schema has rule configuration.
@ suppresswarnings ( str_ ) public map < string , datasourceconfiguration > loaddatasourceconfigurations ( final string shardingschemaname ) { map < string , yamldatasourceconfiguration > result = ( map ) yamlengine . unmarshal ( regcenter . getdirectly ( confignode . getdatasourcepath ( shardingschemaname ) ) ) ; preconditions . checkstate ( null != result && ! result . isempty ( ) , str_ ) ; return maps . transformvalues ( result , new function < yamldatasourceconfiguration , datasourceconfiguration > ( ) { @ override public datasourceconfiguration apply ( final yamldatasourceconfiguration input ) { return new datasourceconfigurationyamlswapper ( ) . swap ( input ) ; } } ) ; }	Load data source configurations.
public shardingruleconfiguration loadshardingruleconfiguration ( final string shardingschemaname ) { return new shardingruleconfigurationyamlswapper ( ) . swap ( yamlengine . unmarshal ( regcenter . getdirectly ( confignode . getrulepath ( shardingschemaname ) ) , yamlshardingruleconfiguration . class ) ) ; }	Load sharding rule configuration.
public masterslaveruleconfiguration loadmasterslaveruleconfiguration ( final string shardingschemaname ) { return new masterslaveruleconfigurationyamlswapper ( ) . swap ( yamlengine . unmarshal ( regcenter . getdirectly ( confignode . getrulepath ( shardingschemaname ) ) , yamlmasterslaveruleconfiguration . class ) ) ; }	Load master-slave rule configuration.
public void setdatabaseshardingvalue ( final comparable < ? > value ) { databaseshardingvalues . clear ( ) ; databaseshardingvalues . put ( str_ , value ) ; databaseshardingonly = bool_ ; }	Set sharding value for database sharding only. The sharding operator is {.
public void adddatabaseshardingvalue ( final string logictable , final comparable < ? > value ) { databaseshardingvalues . put ( logictable , value ) ; databaseshardingonly = bool_ ; }	Add sharding value for database. The sharding operator is {.
public void addtableshardingvalue ( final string logictable , final comparable < ? > value ) { tableshardingvalues . put ( logictable , value ) ; databaseshardingonly = bool_ ; }	Add sharding value for table. The sharding operator is {.
public static collection < comparable < ? > > getdatabaseshardingvalues ( final string logictable ) { return null == hint_manager_holder . get ( ) ? collections . < comparable < ? > > emptylist ( ) : hint_manager_holder . get ( ) . databaseshardingvalues . get ( logictable ) ; }	Get database sharding values.
public static collection < comparable < ? > > gettableshardingvalues ( final string logictable ) { return null == hint_manager_holder . get ( ) ? collections . < comparable < ? > > emptylist ( ) : hint_manager_holder . get ( ) . tableshardingvalues . get ( logictable ) ; }	Get table sharding values.
public void parse ( final dmlstatement updatestatement ) { lexerengine . accept ( defaultkeyword . set ) ; do { parsesetitem ( updatestatement ) ; } while ( lexerengine . skipifequal ( symbol . comma ) ) ; }	Parse set items.
public static object getvaluebycolumntype ( final resultset resultset , final int columnindex ) throws sqlexception { resultsetmetadata metadata = resultset . getmetadata ( ) ; switch ( metadata . getcolumntype ( columnindex ) ) { case types . bit : case types . boolean : return resultset . getboolean ( columnindex ) ; case types . tinyint : return resultset . getbyte ( columnindex ) ; case types . smallint : return resultset . getshort ( columnindex ) ; case types . integer : return resultset . getint ( columnindex ) ; case types . bigint : return resultset . getlong ( columnindex ) ; case types . numeric : case types . decimal : return resultset . getbigdecimal ( columnindex ) ; case types . float : case types . double : return resultset . getdouble ( columnindex ) ; case types . char : case types . varchar : case types . longvarchar : return resultset . getstring ( columnindex ) ; case types . binary : case types . varbinary : case types . longvarbinary : return resultset . getbytes ( columnindex ) ; case types . date : return resultset . getdate ( columnindex ) ; case types . time : return resultset . gettime ( columnindex ) ; case types . timestamp : return resultset . gettimestamp ( columnindex ) ; case types . clob : return resultset . getclob ( columnindex ) ; case types . blob : return resultset . getblob ( columnindex ) ; default : return resultset . getobject ( columnindex ) ; } }	Get value by column type.
@ subscribe public final synchronized void renew ( final datasourcechangedevent datasourcechangedevent ) throws exception { if ( ! name . equals ( datasourcechangedevent . getshardingschemaname ( ) ) ) { return ; } backenddatasource . close ( ) ; datasources . clear ( ) ; datasources . putall ( datasourceconverter . getdatasourceparametermap ( datasourcechangedevent . getdatasourceconfigurations ( ) ) ) ; backenddatasource = new jdbcbackenddatasource ( datasources ) ; }	Renew data source configuration.
public int getlength ( ) { return ownerlength + tablename . length ( ) + quotecharacter . getstartdelimiter ( ) . length ( ) + quotecharacter . getenddelimiter ( ) . length ( ) ; }	Get table token length.
public void parse ( final selectstatement selectstatement , final list < selectitem > items ) { do { selectstatement . getitems ( ) . addall ( parseselectitems ( selectstatement ) ) ; } while ( lexerengine . skipifequal ( symbol . comma ) ) ; selectstatement . setselectliststopindex ( lexerengine . getcurrenttoken ( ) . getendposition ( ) - lexerengine . getcurrenttoken ( ) . getliterals ( ) . length ( ) ) ; items . addall ( selectstatement . getitems ( ) ) ; }	Parse select list.
public string getschemaname ( final string configurationnodefullpath ) { string result = str_ ; pattern pattern = pattern . compile ( getschemapath ( ) + str_ + str_ , pattern . case_insensitive ) ; matcher matcher = pattern . matcher ( configurationnodefullpath ) ; if ( matcher . find ( ) ) { result = matcher . group ( num_ ) ; } return result ; }	Get schema name.
public static mysqlcommandpackettype getcommandpackettype ( final mysqlpacketpayload payload ) { preconditions . checkargument ( num_ == payload . readint1 ( ) , str_ ) ; return mysqlcommandpackettype . valueof ( payload . readint1 ( ) ) ; }	Get command packet type.
public static sqlparser newinstance ( final databasetype databasetype , final string sql ) { for ( shardingparseengine each : newinstanceserviceloader . newserviceinstances ( shardingparseengine . class ) ) { if ( databasetype . valueof ( each . getdatabasetype ( ) ) == databasetype ) { return each . createsqlparser ( sql ) ; } } throw new unsupportedoperationexception ( string . format ( str_ , databasetype ) ) ; }	New instance of SQL parser.
public collection < string > getdatasourcenames ( ) { collection < string > result = new hashset < > ( tableunits . size ( ) , num_ ) ; for ( tableunit each : tableunits ) { result . add ( each . getdatasourcename ( ) ) ; } return result ; }	Get all data source names.
public map < string , set < string > > getdatasourcelogictablesmap ( final collection < string > datasourcenames ) { map < string , set < string > > result = new hashmap < > ( ) ; for ( string each : datasourcenames ) { set < string > logictablenames = getlogictablenames ( each ) ; if ( ! logictablenames . isempty ( ) ) { result . put ( each , logictablenames ) ; } } return result ; }	Get map relationship between data source and logic tables via data sources' names.
public final void setcolumnvalue ( final string columnname , final object columnvalue ) { sqlexpression sqlexpression = values [ getcolumnindex ( columnname ) ] ; if ( sqlexpression instanceof sqlparametermarkerexpression ) { parameters [ getparameterindex ( sqlexpression ) ] = columnvalue ; } else { sqlexpression columnexpression = string . class == columnvalue . getclass ( ) ? new sqltextexpression ( string . valueof ( columnvalue ) ) : new sqlnumberexpression ( ( number ) columnvalue ) ; values [ getcolumnindex ( columnname ) ] = columnexpression ; } }	Set column value.
public final object getcolumnvalue ( final string columnname ) { sqlexpression sqlexpression = values [ getcolumnindex ( columnname ) ] ; if ( sqlexpression instanceof sqlparametermarkerexpression ) { return parameters [ getparameterindex ( sqlexpression ) ] ; } else if ( sqlexpression instanceof sqltextexpression ) { return ( ( sqltextexpression ) sqlexpression ) . gettext ( ) ; } else { return ( ( sqlnumberexpression ) sqlexpression ) . getnumber ( ) ; } }	Get column value.
public static commandexecutor newinstance ( final mysqlcommandpackettype commandpackettype , final commandpacket commandpacket , final backendconnection backendconnection ) { log . debug ( str_ , commandpackettype , commandpacket ) ; switch ( commandpackettype ) { case com_quit : return new mysqlcomquitexecutor ( ) ; case com_init_db : return new mysqlcominitdbexecutor ( ( mysqlcominitdbpacket ) commandpacket , backendconnection ) ; case com_field_list : return new mysqlcomfieldlistpacketexecutor ( ( mysqlcomfieldlistpacket ) commandpacket , backendconnection ) ; case com_query : return new mysqlcomquerypacketexecutor ( ( mysqlcomquerypacket ) commandpacket , backendconnection ) ; case com_stmt_prepare : return new mysqlcomstmtprepareexecutor ( ( mysqlcomstmtpreparepacket ) commandpacket , backendconnection ) ; case com_stmt_execute : return new mysqlcomstmtexecuteexecutor ( ( mysqlcomstmtexecutepacket ) commandpacket , backendconnection ) ; case com_stmt_close : return new mysqlcomstmtcloseexecutor ( ( mysqlcomstmtclosepacket ) commandpacket ) ; case com_ping : return new mysqlcompingexecutor ( ) ; default : return new mysqlunsupportedcommandexecutor ( commandpackettype ) ; } }	Create new instance of packet executor.
public set < string > getactualtablenames ( final string datasourcename , final string logictablename ) { set < string > result = new hashset < > ( routingtables . size ( ) , num_ ) ; for ( routingtable each : routingtables ) { if ( datasourcename . equalsignorecase ( this . datasourcename ) && each . getlogictablename ( ) . equalsignorecase ( logictablename ) ) { result . add ( each . getactualtablename ( ) ) ; } } return result ; }	Get actual tables' names via data source name.
public set < string > getlogictablenames ( final string datasourcename ) { set < string > result = new hashset < > ( routingtables . size ( ) , num_ ) ; for ( routingtable each : routingtables ) { if ( datasourcename . equalsignorecase ( this . datasourcename ) ) { result . add ( each . getlogictablename ( ) ) ; } } return result ; }	Get logic tables' names via data source name.
@ sneakythrows public final void recordmethodinvocation ( final class < ? > targetclass , final string methodname , final class < ? > [ ] argumenttypes , final object [ ] arguments ) { jdbcmethodinvocations . add ( new jdbcmethodinvocation ( targetclass . getmethod ( methodname , argumenttypes ) , arguments ) ) ; }	record method invocation.
public boolean next ( ) throws sqlexception { boolean result = queryresult . next ( ) ; ordervalues = result ? getordervalues ( ) : collections . < comparable < ? > > emptylist ( ) ; return result ; }	iterate next data.
public byte [ ] generaterandombytes ( final int length ) { byte [ ] result = new byte [ length ] ; for ( int i = num_ ; i < length ; i ++ ) { result [ i ] = seed [ random . nextint ( seed . length ) ] ; } return result ; }	Generate random bytes.
@ sneakythrows public map < string , tablemetadata > load ( final shardingrule shardingrule ) { map < string , tablemetadata > result = new hashmap < > ( ) ; result . putall ( loadshardingtables ( shardingrule ) ) ; result . putall ( loaddefaulttables ( shardingrule ) ) ; return result ; }	Load all table meta data.
public static optimizeengine newinstance ( final shardingrule shardingrule , final sqlstatement sqlstatement , final list < object > parameters , final generatedkey generatedkey ) { if ( sqlstatement instanceof insertstatement ) { return new insertoptimizeengine ( shardingrule , ( insertstatement ) sqlstatement , parameters , generatedkey ) ; } if ( sqlstatement instanceof selectstatement || sqlstatement instanceof dmlstatement ) { return new queryoptimizeengine ( sqlstatement . getrouteconditions ( ) . getorcondition ( ) , parameters ) ; }	Create optimize engine instance.
public static optimizeengine newinstance ( final encryptrule encryptrule , final sqlstatement sqlstatement , final list < object > parameters ) { if ( sqlstatement instanceof insertstatement ) { return new encryptinsertoptimizeengine ( encryptrule , ( insertstatement ) sqlstatement , parameters ) ; } return new encryptdefaultoptimizeengine ( ) ; }	Create encrypt optimize engine instance.
public static databaseprotocolfrontendengine newinstance ( final databasetype databasetype ) { for ( databaseprotocolfrontendengine each : newinstanceserviceloader . newserviceinstances ( databaseprotocolfrontendengine . class ) ) { if ( databasetype . valuefrom ( each . getdatabasetype ( ) ) == databasetype ) { return each ; } } throw new unsupportedoperationexception ( string . format ( str_ , databasetype ) ) ; }	Create new instance of database protocol frontend engine.
public shardingconfiguration load ( ) throws ioexception { collection < string > schemanames = new hashset < > ( ) ; yamlproxyserverconfiguration serverconfig = loadserverconfiguration ( new file ( shardingconfigurationloader . class . getresource ( config_path + server_config_file ) . getfile ( ) ) ) ; file configpath = new file ( shardingconfigurationloader . class . getresource ( config_path ) . getfile ( ) ) ; collection < yamlproxyruleconfiguration > ruleconfigurations = new linkedlist < > ( ) ; for ( file each : findruleconfigurationfiles ( configpath ) ) { optional < yamlproxyruleconfiguration > ruleconfig = loadruleconfiguration ( each , serverconfig ) ; if ( ruleconfig . ispresent ( ) ) { preconditions . checkstate ( schemanames . add ( ruleconfig . get ( ) . getschemaname ( ) ) , str_ , ruleconfig . get ( ) . getschemaname ( ) ) ; ruleconfigurations . add ( ruleconfig . get ( ) ) ; } } preconditions . checkstate ( ! ruleconfigurations . isempty ( ) || null != serverconfig . getorchestration ( ) , str_ , configpath . getpath ( ) ) ; map < string , yamlproxyruleconfiguration > ruleconfigurationmap = new hashmap < > ( ruleconfigurations . size ( ) , num_ ) ; for ( yamlproxyruleconfiguration each : ruleconfigurations ) { ruleconfigurationmap . put ( each . getschemaname ( ) , each ) ; } return new shardingconfiguration ( serverconfig , ruleconfigurationmap ) ; }	Load configuration of Sharding-Proxy.
@ suppresswarnings ( str_ ) @ sneakythrows public void init ( final fillerruledefinitionentity fillerruledefinitionentity ) { for ( fillerruleentity each : fillerruledefinitionentity . getrules ( ) ) { rules . put ( ( class < ? extends sqlsegment > ) class . forname ( each . getsqlsegmentclass ( ) ) , ( sqlsegmentfiller ) class . forname ( each . getfillerclass ( ) ) . newinstance ( ) ) ; } }	Initialize filler rule definition.
public static aliasexpressionparser createaliasexpressionparser ( final lexerengine lexerengine ) { switch ( lexerengine . getdatabasetype ( ) ) { case h2 : return new mysqlaliasexpressionparser ( lexerengine ) ; case mysql : return new mysqlaliasexpressionparser ( lexerengine ) ; case oracle : return new oraclealiasexpressionparser ( lexerengine ) ; case sqlserver : return new sqlserveraliasexpressionparser ( lexerengine ) ; case postgresql : return new postgresqlaliasexpressionparser ( lexerengine ) ; default : throw new unsupportedoperationexception ( string . format ( str_ , lexerengine . getdatabasetype ( ) ) ) ; } }	Create alias parser instance.
private inputstream trustedcertificatesinputstream ( ) {	Returns an input stream containing one or more certificate PEM files.
private x509trustmanager defaulttrustmanager ( ) throws generalsecurityexception { trustmanagerfactory trustmanagerfactory = trustmanagerfactory . getinstance ( trustmanagerfactory . getdefaultalgorithm ( ) ) ; trustmanagerfactory . init ( ( keystore ) null ) ; trustmanager [ ] trustmanagers = trustmanagerfactory . gettrustmanagers ( ) ; if ( trustmanagers . length != num_ || ! ( trustmanagers [ num_ ] instanceof x509trustmanager ) ) { throw new illegalstateexception ( str_ + arrays . tostring ( trustmanagers ) ) ; } return ( x509trustmanager ) trustmanagers [ num_ ] ; }	Returns a trust manager that trusts the VM's default certificate authorities.
private static string inet6addresstoascii ( byte [ ] address ) {	Encodes an IPv6 address in canonical form according to RFC 5952.
@ override public synchronized void onopen ( websocket websocket , response response ) { system . out . println ( str_ + response ) ; }	the body from slack is a 0-byte-buffer.
private void resetnextproxy ( httpurl url , proxy proxy ) { if ( proxy != null ) {	Prepares the proxy servers to try.
private proxy nextproxy ( ) throws ioexception { if ( ! hasnextproxy ( ) ) { throw new socketexception ( str_ + address . url ( ) . host ( ) + str_ + proxies ) ; } proxy result = proxies . get ( nextproxyindex ++ ) ; resetnextinetsocketaddress ( result ) ; return result ; }	Returns the next proxy to try.
private void resetnextinetsocketaddress ( proxy proxy ) throws ioexception {	Prepares the socket addresses to attempt for the current proxy or host.
public void awaitsuccess ( ) throws exception { futuretask < void > futuretask = results . poll ( num_ , timeunit . seconds ) ; if ( futuretask == null ) throw new assertionerror ( str_ ) ; futuretask . get ( num_ , timeunit . seconds ) ; }	Returns once the duplex conversation completes successfully.
private void readthelistuninterruptibly ( ) { boolean interrupted = bool_ ; try { while ( bool_ ) { try { readthelist ( ) ; return ; } catch ( interruptedioexception e ) { thread . interrupted ( ) ;	Reads the public suffix list treating the operation as uninterruptible.
void writeclose ( int code , bytestring reason ) throws ioexception { bytestring payload = bytestring . empty ; if ( code != num_ || reason != null ) { if ( code != num_ ) { validateclosecode ( code ) ; } buffer buffer = new buffer ( ) ; buffer . writeshort ( code ) ; if ( reason != null ) { buffer . write ( reason ) ; } payload = buffer . readbytestring ( ) ; } try { writecontrolframe ( opcode_control_close , payload ) ; } finally { writerclosed = bool_ ; } }	Send a close frame with optional code and reason.
sink newmessagesink ( int formatopcode , long contentlength ) { if ( activewriter ) { throw new illegalstateexception ( str_ ) ; } activewriter = bool_ ;	Stream a message payload as a series of frames.
private synchronized void start ( inetsocketaddress inetsocketaddress ) throws ioexception { if ( started ) throw new illegalstateexception ( str_ ) ; started = bool_ ; executor = executors . newcachedthreadpool ( util . threadfactory ( str_ , bool_ ) ) ; this . inetsocketaddress = inetsocketaddress ; if ( serversocketfactory == null ) { serversocketfactory = serversocketfactory . getdefault ( ) ; } serversocket = serversocketfactory . createserversocket ( ) ;	Starts the server and binds to the given socket address.
private void readmessage ( ) throws ioexception { while ( bool_ ) { if ( closed ) throw new ioexception ( str_ ) ; if ( framelength > num_ ) { source . readfully ( messageframebuffer , framelength ) ; if ( ! isclient ) { messageframebuffer . readandwriteunsafe ( maskcursor ) ; maskcursor . seek ( messageframebuffer . size ( ) - framelength ) ; togglemask ( maskcursor , maskkey ) ; maskcursor . close ( ) ; } } if ( isfinalframe ) break ;	Reads a message body into across one or more frames.
public synchronized headers takeheaders ( ) throws ioexception { readtimeout . enter ( ) ; try { while ( headersqueue . isempty ( ) && errorcode == null ) { waitforio ( ) ; } } finally { readtimeout . exitandthrowiftimedout ( ) ; } if ( ! headersqueue . isempty ( ) ) { return headersqueue . removefirst ( ) ; } throw errorexception != null ? errorexception : new streamresetexception ( errorcode ) ; }	Removes and returns the stream's received response headers, blocking if necessary until headershave been received.
public synchronized headers trailers ( ) throws ioexception { if ( errorcode != null ) { throw errorexception != null ? errorexception : new streamresetexception ( errorcode ) ; } if ( ! source . finished || ! source . receivebuffer . exhausted ( ) || ! source . readbuffer . exhausted ( ) ) { throw new illegalstateexception ( str_ ) ; } return source . trailers != null ? source . trailers : util . empty_headers ; }	Returns the trailers. It is only safe to call this once the source stream has been completelyexhausted.
public void writeheaders ( list < header > responseheaders , boolean outfinished , boolean flushheaders ) throws ioexception { assert ( ! thread . holdslock ( http2stream . this ) ) ; if ( responseheaders == null ) { throw new nullpointerexception ( str_ ) ; } synchronized ( this ) { this . hasresponseheaders = bool_ ; if ( outfinished ) { this . sink . finished = bool_ ; } }	Sends a reply to an incoming stream.
private realconnection findhealthyconnection ( int connecttimeout , int readtimeout , int writetimeout , int pingintervalmillis , boolean connectionretryenabled , boolean doextensivehealthchecks ) throws ioexception { while ( bool_ ) { realconnection candidate = findconnection ( connecttimeout , readtimeout , writetimeout , pingintervalmillis , connectionretryenabled ) ;	Finds a connection and returns it if it is healthy.
private realconnection findconnection ( int connecttimeout , int readtimeout , int writetimeout , int pingintervalmillis , boolean connectionretryenabled ) throws ioexception { boolean foundpooledconnection = bool_ ; realconnection result = null ; route selectedroute = null ; realconnection releasedconnection ; socket toclose ; synchronized ( connectionpool ) { if ( transmitter . iscanceled ( ) ) throw new ioexception ( str_ ) ; hasstreamfailure = bool_ ;	Returns a connection to host a new stream.
private boolean retrycurrentroute ( ) { return transmitter . connection != null && transmitter . connection . routefailurecount == num_ && util . sameconnection ( transmitter . connection . route ( ) . address ( ) . url ( ) , address . url ( ) ) ; }	Return true if the route used for the current connection should be retried, even if theconnection itself is unhealthy.
@ override public boolean send ( string text ) { if ( text == null ) throw new nullpointerexception ( str_ ) ; return send ( bytestring . encodeutf8 ( text ) , opcode_text ) ; }	Writer methods to enqueue frames.
private static headers combine ( headers cachedheaders , headers networkheaders ) { headers . builder result = new headers . builder ( ) ; for ( int i = num_ , size = cachedheaders . size ( ) ; i < size ; i ++ ) { string fieldname = cachedheaders . name ( i ) ; string value = cachedheaders . value ( i ) ; if ( str_ . equalsignorecase ( fieldname ) && value . startswith ( str_ ) ) { continue ;	Combines cached headers with a network headers as defined by RFC 7234, 4.3.4.
@ override public mockresponse dispatch ( recordedrequest request ) { httpurl requesturl = mockwebserver . url ( request . getpath ( ) ) ; string code = requesturl . queryparameter ( str_ ) ; string statestring = requesturl . queryparameter ( str_ ) ; bytestring state = statestring != null ? bytestring . decodebase64 ( statestring ) : null ; listener listener ; synchronized ( this ) { listener = listeners . get ( state ) ; } if ( code == null || listener == null ) { return new mockresponse ( ) . setresponsecode ( num_ ) . setbody ( str_ ) ; } try { oauthsession session = slackapi . exchangecode ( code , redirecturl ( ) ) ; listener . sessiongranted ( session ) ; } catch ( ioexception e ) { return new mockresponse ( ) . setresponsecode ( num_ ) . setbody ( str_ + e . getmessage ( ) ) ; } synchronized ( this ) { listeners . remove ( state ) ; }	When the browser hits the redirect URL, use the provided code to ask Slack for a session.
public mockresponse withwebsocketupgrade ( websocketlistener listener ) { setstatus ( str_ ) ; setheader ( str_ , str_ ) ; setheader ( str_ , str_ ) ; body = null ; websocketlistener = listener ; return this ; }	Attempts to perform a web socket upgrade on the connection.
public static set < string > varyfields ( headers responseheaders ) { set < string > result = collections . emptyset ( ) ; for ( int i = num_ , size = responseheaders . size ( ) ; i < size ; i ++ ) { if ( ! str_ . equalsignorecase ( responseheaders . name ( i ) ) ) continue ; string value = responseheaders . value ( i ) ; if ( result . isempty ( ) ) { result = new treeset < > ( string . case_insensitive_order ) ; } for ( string varyfield : value . split ( str_ ) ) { result . add ( varyfield . trim ( ) ) ; } } return result ; }	Returns the names of the request headers that need to be checked for equality when caching.
public static list < challenge > parsechallenges ( headers responseheaders , string headername ) { list < challenge > result = new arraylist < > ( ) ; for ( int h = num_ ; h < responseheaders . size ( ) ; h ++ ) { if ( headername . equalsignorecase ( responseheaders . name ( h ) ) ) { buffer header = new buffer ( ) . writeutf8 ( responseheaders . value ( h ) ) ; try { parsechallengeheader ( result , header ) ; } catch ( eofexception e ) { platform . get ( ) . log ( platform . warn , str_ , e ) ; } } } return result ; }	Parse RFC 7235 challenges.
private static boolean skipwhitespaceandcommas ( buffer buffer ) throws eofexception { boolean commafound = bool_ ; while ( ! buffer . exhausted ( ) ) { byte b = buffer . getbyte ( num_ ) ; if ( b == str_ ) {	Returns true if any commas were skipped.
public void requestoauthsession ( string scopes , string team ) throws exception { if ( sessionfactory == null ) { sessionfactory = new oauthsessionfactory ( slackapi ) ; sessionfactory . start ( ) ; } httpurl authorizeurl = sessionfactory . newauthorizeurl ( scopes , team , session -> { initoauthsession ( session ) ; system . out . printf ( str_ , session ) ; } ) ; system . out . printf ( str_ , authorizeurl ) ; }	Shows a browser URL to authorize this app to act as this user.
public void startrtm ( ) throws ioexception { string accesstoken ; synchronized ( this ) { accesstoken = session . access_token ; } rtmsession rtmsession = new rtmsession ( slackapi ) ; rtmsession . open ( accesstoken ) ; }	Starts a real time messaging session.
private void connecttunnel ( int connecttimeout , int readtimeout , int writetimeout , call call , eventlistener eventlistener ) throws ioexception { request tunnelrequest = createtunnelrequest ( ) ; httpurl url = tunnelrequest . url ( ) ; for ( int i = num_ ; i < max_tunnel_attempts ; i ++ ) { connectsocket ( connecttimeout , readtimeout , call , eventlistener ) ; tunnelrequest = createtunnel ( readtimeout , writetimeout , tunnelrequest , url ) ; if ( tunnelrequest == null ) break ;	Does all the work to build an HTTPS connection over a proxy tunnel.
private void connectsocket ( int connecttimeout , int readtimeout , call call , eventlistener eventlistener ) throws ioexception { proxy proxy = route . proxy ( ) ; address address = route . address ( ) ; rawsocket = proxy . type ( ) == proxy . type . direct || proxy . type ( ) == proxy . type . http ? address . socketfactory ( ) . createsocket ( ) : new socket ( proxy ) ; eventlistener . connectstart ( call , route . socketaddress ( ) , proxy ) ; rawsocket . setsotimeout ( readtimeout ) ; try { platform . get ( ) . connectsocket ( rawsocket , route . socketaddress ( ) , connecttimeout ) ; } catch ( connectexception e ) { connectexception ce = new connectexception ( str_ + route . socketaddress ( ) ) ; ce . initcause ( e ) ; throw ce ; }	Does all the work necessary to build a full HTTP or HTTPS connection on a raw socket.
private request createtunnel ( int readtimeout , int writetimeout , request tunnelrequest , httpurl url ) throws ioexception {	To make an HTTPS connection over an HTTP proxy, send an unencrypted CONNECT request to createthe proxy connection.
private request createtunnelrequest ( ) throws ioexception { request proxyconnectrequest = new request . builder ( ) . url ( route . address ( ) . url ( ) ) . method ( str_ , null ) . header ( str_ , util . hostheader ( route . address ( ) . url ( ) , bool_ ) ) . header ( str_ , str_ )	Returns a request that creates a TLS tunnel via an HTTP proxy.
public boolean ishealthy ( boolean doextensivechecks ) { if ( socket . isclosed ( ) || socket . isinputshutdown ( ) || socket . isoutputshutdown ( ) ) { return bool_ ; } if ( http2connection != null ) { return ! http2connection . isshutdown ( ) ; } if ( doextensivechecks ) { try { int readtimeout = socket . getsotimeout ( ) ; try { socket . setsotimeout ( num_ ) ; if ( source . exhausted ( ) ) { return bool_ ;	Returns true if this connection is ready to host new streams.
@ override public void onstream ( http2stream stream ) throws ioexception { stream . close ( errorcode . refused_stream , null ) ; }	Refuse incoming streams.
exchange newexchange ( interceptor . chain chain , boolean doextensivehealthchecks ) { synchronized ( connectionpool ) { if ( nomoreexchanges ) { throw new illegalstateexception ( str_ ) ; } if ( exchange != null ) { throw new illegalstateexception ( str_ + str_ ) ; } } exchangecodec codec = exchangefinder . find ( client , chain , doextensivehealthchecks ) ; exchange result = new exchange ( this , call , eventlistener , exchangefinder , codec ) ; synchronized ( connectionpool ) { this . exchange = result ; this . exchangerequestdone = bool_ ; this . exchangeresponsedone = bool_ ; return result ; } }	Returns a new exchange to carry a new request and response.
public void cancel ( ) { exchange exchangetocancel ; realconnection connectiontocancel ; synchronized ( connectionpool ) { canceled = bool_ ; exchangetocancel = exchange ; connectiontocancel = exchangefinder != null && exchangefinder . connectingconnection ( ) != null ? exchangefinder . connectingconnection ( ) : connection ; } if ( exchangetocancel != null ) { exchangetocancel . cancel ( ) ; } else if ( connectiontocancel != null ) { connectiontocancel . cancel ( ) ; } }	Immediately closes the socket connection if it's currently held.
public http2stream pushstream ( int associatedstreamid , list < header > requestheaders , boolean out ) throws ioexception { if ( client ) throw new illegalstateexception ( str_ ) ; return newstream ( associatedstreamid , requestheaders , out ) ; }	Returns a new server-initiated stream.
public http2stream newstream ( list < header > requestheaders , boolean out ) throws ioexception { return newstream ( num_ , requestheaders , out ) ; }	Returns a new locally-initiated stream.
public void shutdown ( errorcode statuscode ) throws ioexception { synchronized ( writer ) { int lastgoodstreamid ; synchronized ( this ) { if ( shutdown ) { return ; } shutdown = bool_ ; lastgoodstreamid = this . lastgoodstreamid ; }	Degrades this connection such that new streams can neither be created locally, nor acceptedfrom the remote peer.
@ override public void emitresponse ( t response ) { if ( ! isterminated ( ) ) { subject . onnext ( response ) ; valueset . set ( bool_ ) ; } else { throw new illegalstateexception ( str_ + response ) ; } }	Emit a response that should be OnNexted to an Observer.
public exception setexceptionifresponsenotreceived ( exception e , string exceptionmessage ) { exception exception = e ; if ( ! valueset . get ( ) && ! isterminated ( ) ) { if ( e == null ) { exception = new illegalstateexception ( exceptionmessage ) ; } setexceptionifresponsenotreceived ( exception ) ; }	Set an ISE if a response is not yet received otherwise skip it.
private byte [ ] wrapclass ( string classname , boolean wrapconstructors , string ... methodnames ) throws notfoundexception , ioexception , cannotcompileexception { classpool cp = classpool . getdefault ( ) ; ctclass ctclazz = cp . get ( classname ) ;	Wrap all signatures of a given method name.
protected tryablesemaphore getfallbacksemaphore ( ) { if ( fallbacksemaphoreoverride == null ) { tryablesemaphore _s = fallbacksemaphorepercircuit . get ( commandkey . name ( ) ) ; if ( _s == null ) {	Get the TryableSemaphore this HystrixCommand should use if a fallback occurs.
protected tryablesemaphore getexecutionsemaphore ( ) { if ( properties . executionisolationstrategy ( ) . get ( ) == executionisolationstrategy . semaphore ) { if ( executionsemaphoreoverride == null ) { tryablesemaphore _s = executionsemaphorepercircuit . get ( commandkey . name ( ) ) ; if ( _s == null ) {	Get the TryableSemaphore this HystrixCommand should use for execution if not running in a separate thread.
private void validatecompletablereturntype ( method commandmethod , class < ? > callbackreturntype ) { if ( void . type == callbackreturntype ) { throw new fallbackdefinitionexception ( createerrormsg ( commandmethod , method , str_ + completable . class . getsimplename ( ) ) ) ; } }	everything can be wrapped into completable except 'void'.
public fallbackmethod getfallbackmethod ( class < ? > enclosingtype , method commandmethod , boolean extended ) { if ( commandmethod . isannotationpresent ( hystrixcommand . class ) ) { return fallback_method_finder . find ( enclosingtype , commandmethod , extended ) ; } return fallbackmethod . absent ; }	Gets fallback method for command method.
public static optional < method > getmethod ( class < ? > type , string name , class < ? > ... parametertypes ) { method [ ] methods = type . getdeclaredmethods ( ) ; for ( method method : methods ) { if ( method . getname ( ) . equals ( name ) && arrays . equals ( method . getparametertypes ( ) , parametertypes ) ) { return optional . of ( method ) ; } } class < ? > superclass = type . getsuperclass ( ) ; if ( superclass != null && ! superclass . equals ( object . class ) ) { return getmethod ( superclass , name , parametertypes ) ; } else { return optional . absent ( ) ; } }	Gets method by name and parameters types using reflection,if the given type doesn't contain required method then continue applying this method for all super classes up to Object class.
public method unbride ( final method bridgemethod , class < ? > aclass ) throws ioexception , nosuchmethodexception , classnotfoundexception { if ( bridgemethod . isbridge ( ) && bridgemethod . issynthetic ( ) ) { if ( cache . containskey ( bridgemethod ) ) { return cache . get ( bridgemethod ) ; } classreader classreader = new classreader ( aclass . getname ( ) ) ; final methodsignature methodsignature = new methodsignature ( ) ; classreader . accept ( new classvisitor ( asm5 ) { @ override public methodvisitor visitmethod ( int access , string name , string desc , string signature , string [ ] exceptions ) { boolean bridge = ( access & acc_bridge ) != num_ && ( access & acc_synthetic ) != num_ ; if ( bridge && bridgemethod . getname ( ) . equals ( name ) && getparametercount ( desc ) == bridgemethod . getparametertypes ( ) . length ) { return new methodfinder ( methodsignature ) ; } return super . visitmethod ( access , name , desc , signature , exceptions ) ; } } , num_ ) ; method method = aclass . getdeclaredmethod ( methodsignature . name , methodsignature . getparametertypes ( ) ) ; cache . put ( bridgemethod , method ) ; return method ; } else { return bridgemethod ; } }	Finds generic method for the given bridge method.
public r execute ( ) { try { return queue ( ) . get ( ) ; } catch ( exception e ) { throw exceptions . sneakythrow ( decomposeexception ( e ) ) ; } }	Used for synchronous execution of command.
public static class [ ] getparametertypes ( joinpoint joinpoint ) { methodsignature signature = ( methodsignature ) joinpoint . getsignature ( ) ; method method = signature . getmethod ( ) ; return method . getparametertypes ( ) ; }	Gets parameter types of the join point.
public static method getdeclaredmethod ( class < ? > type , string methodname , class < ? > ... parametertypes ) { method method = null ; try { method = type . getdeclaredmethod ( methodname , parametertypes ) ; if ( method . isbridge ( ) ) { method = methodprovider . getinstance ( ) . unbride ( method , type ) ; } } catch ( nosuchmethodexception e ) { class < ? > superclass = type . getsuperclass ( ) ; if ( superclass != null ) { method = getdeclaredmethod ( superclass , methodname , parametertypes ) ; } } catch ( classnotfoundexception e ) { throwables . propagate ( e ) ; } catch ( ioexception e ) { throwables . propagate ( e ) ; } return method ; }	Gets declared method from specified type by mame and parameters types.
@ override protected hystrixcommand < list < object > > createcommand ( collection < collapsedrequest < object , object > > collapsedrequests ) { return new batchhystrixcommand ( hystrixcommandbuilderfactory . getinstance ( ) . create ( metaholder , collapsedrequests ) ) ; }	Creates batch command.
public observable < responsetype > submitrequest ( final requestargumenttype arg ) { if ( ! timerlistenerregistered . get ( ) && timerlistenerregistered . compareandset ( bool_ , bool_ ) ) { timerlistenerreference . set ( timer . addlistener ( new collapsedtask ( ) ) ) ; }	Submit a request to a batch.
public executionresult addevent ( hystrixeventtype eventtype ) { return new executionresult ( eventcounts . plus ( eventtype ) , starttimestamp , executionlatency , userthreadlatency , failedexecutionexception , executionexception , executionoccurred , isexecutedinthread , collapserkey ) ; }	Creates a new ExecutionResult by adding the defined 'event' to the ones on the current instance.
closure createclosure ( string rootmethodname , final object closureobj ) throws exception { if ( ! isclosurecommand ( closureobj ) ) { throw new runtimeexception ( format ( error_type_message , rootmethodname , getclosurecommandtype ( ) . getname ( ) ) . getmessage ( ) ) ; } method closuremethod = closureobj . getclass ( ) . getmethod ( invoke_method ) ; return new closure ( closuremethod , closureobj ) ; }	Creates closure.
@ override protected useraccount getfallback ( ) { return new useraccount ( usercookie . userid , usercookie . name , usercookie . accounttype , bool_ , bool_ , bool_ ) ; }	Fallback that will use data from the UserCookie and stubbed defaultsto create a UserAccount if the network call failed.
protected response handlerequest ( ) { responsebuilder builder = null ; int numberconnections = getcurrentconnections ( ) . get ( ) ; int maxnumberconnectionsallowed = getmaxnumberconcurrentconnectionsallowed ( ) ;	Maintain an open connection with the client.
public static hystrixcommandproperties . setter initializecommandproperties ( list < hystrixproperty > properties ) throws illegalargumentexception { return initializeproperties ( hystrixcommandproperties . setter ( ) , properties , cmd_prop_map , str_ ) ; }	Creates and sets Hystrix command properties.
public static hystrixthreadpoolproperties . setter initializethreadpoolproperties ( list < hystrixproperty > properties ) throws illegalargumentexception { return initializeproperties ( hystrixthreadpoolproperties . setter ( ) , properties , tp_prop_map , str_ ) ; }	Creates and sets Hystrix thread pool properties.
public static hystrixcollapserproperties . setter initializecollapserproperties ( list < hystrixproperty > properties ) { return initializeproperties ( hystrixcollapserproperties . setter ( ) , properties , collapser_prop_map , str_ ) ; }	Creates and sets Hystrix collapser properties.
@ suppresswarnings ( str_ ) public t get ( ) { if ( hystrixrequestcontext . getcontextforcurrentthread ( ) == null ) { throw new illegalstateexception ( hystrixrequestcontext . class . getsimplename ( ) + str_ ) ; } concurrenthashmap < hystrixrequestvariabledefault < ? > , lazyinitializer < ? > > variablemap = hystrixrequestcontext . getcontextforcurrentthread ( ) . state ;	Get the current value for this variable for the current request context.
public void clear ( string cachekey ) { valuecachekey key = getrequestcachekey ( cachekey ) ; if ( key != null ) { concurrenthashmap < valuecachekey , hystrixcachedobservable < ? > > cacheinstance = requestvariableforcache . get ( concurrencystrategy ) ; if ( cacheinstance == null ) { throw new illegalstateexception ( str_ ) ; } cacheinstance . remove ( key ) ; } }	Clear the cache for a given cacheKey.
boolean isignorable ( throwable throwable ) { if ( ignoreexceptions == null || ignoreexceptions . isempty ( ) ) { return bool_ ; } for ( class < ? extends throwable > ignoreexception : ignoreexceptions ) { if ( ignoreexception . isassignablefrom ( throwable . getclass ( ) ) ) { return bool_ ; } } return bool_ ; }	Check whether triggered exception is ignorable.
private void handlerequest ( httpservletrequest request , final httpservletresponse response ) throws servletexception , ioexception { final atomicboolean moredatawillbesent = new atomicboolean ( bool_ ) ; subscription samplesubscription = null ; int numberconnections = incrementandgetcurrentconcurrentconnections ( ) ; try { int maxnumberconnectionsallowed = getmaxnumberconcurrentconnectionsallowed ( ) ;	- maintain an open connection with the client- on initial connection send latest data of each requested event type- subsequently send all changes for each requested event type.
public static void reset ( ) { singleton = new hystrixmetricspublisherfactory ( ) ; singleton . commandpublishers . clear ( ) ; singleton . threadpoolpublishers . clear ( ) ; singleton . collapserpublishers . clear ( ) ; }	Resets the SINGLETON object.Clears all state from publishers.
public void clearcache ( cacheinvocationcontext < cacheremove > context ) { hystrixcachekeygenerator defaultcachekeygenerator = hystrixcachekeygenerator . getinstance ( ) ; string cachename = context . getcacheannotation ( ) . commandkey ( ) ; hystrixgeneratedcachekey hystrixgeneratedcachekey = defaultcachekeygenerator . generatecachekey ( context ) ; string key = hystrixgeneratedcachekey . getcachekey ( ) ; hystrixrequestcache . getinstance ( hystrixcommandkey . factory . askey ( cachename ) , hystrixconcurrencystrategydefault . getinstance ( ) ) . clear ( key ) ; }	Clears the cache for a given cacheKey context.
@ override public object executewithargs ( executiontype executiontype , object [ ] args ) throws commandactionexecutionexception { if ( executiontype . asynchronous == executiontype ) { closure closure = asyncclosurefactory . getinstance ( ) . createclosure ( metaholder , method , object , args ) ; return executeclj ( closure . getclosureobj ( ) , closure . getclosuremethod ( ) ) ; } return execute ( object , method , args ) ; }	Invokes the method. Also private method also can be invoked.
private object execute ( object o , method m , object ... args ) throws commandactionexecutionexception { object result = null ; try { m . setaccessible ( bool_ ) ;	Invokes the method.
public void setmetricregistry ( object metricregistry ) { if ( metricstrackerfactory != null ) { throw new illegalstateexception ( str_ ) ; } if ( metricregistry != null ) { metricregistry = getobjectorperformjndilookup ( metricregistry ) ; if ( ! safeisassignablefrom ( metricregistry , str_ ) && ! ( safeisassignablefrom ( metricregistry , str_ ) ) ) { throw new illegalargumentexception ( str_ ) ; } } this . metricregistry = metricregistry ; }	Set a MetricRegistry instance to use for registration of metrics used by HikariCP.
@ override public void close ( ) { if ( isshutdown . getandset ( bool_ ) ) { return ; } hikaripool p = pool ; if ( p != null ) { try { logger . info ( str_ , getpoolname ( ) ) ; p . shutdown ( ) ; logger . info ( str_ , getpoolname ( ) ) ; } catch ( interruptedexception e ) { logger . warn ( str_ , getpoolname ( ) , e ) ; thread . currentthread ( ) . interrupt ( ) ; } } }	Shutdown the DataSource and its associated pool.
public static set < string > getpropertynames ( final class < ? > targetclass ) { hashset < string > set = new hashset < > ( ) ; matcher matcher = getter_pattern . matcher ( str_ ) ; for ( method method : targetclass . getmethods ( ) ) { string name = method . getname ( ) ; if ( method . getparametertypes ( ) . length == num_ && matcher . reset ( name ) . matches ( ) ) { name = name . replacefirst ( str_ , str_ ) ; try { if ( targetclass . getmethod ( str_ + name , method . getreturntype ( ) ) != null ) { name = character . tolowercase ( name . charat ( num_ ) ) + name . substring ( num_ ) ; set . add ( name ) ; } } catch ( exception e ) {	Get the bean-style property names for the specified object.
void handlembeans ( final hikaripool hikaripool , final boolean register ) { if ( ! config . isregistermbeans ( ) ) { return ; } try { final mbeanserver mbeanserver = managementfactory . getplatformmbeanserver ( ) ; final objectname beanconfigname = new objectname ( str_ + poolname + str_ ) ; final objectname beanpoolname = new objectname ( str_ + poolname + str_ ) ; if ( register ) { if ( ! mbeanserver . isregistered ( beanconfigname ) ) { mbeanserver . registermbean ( config , beanconfigname ) ; mbeanserver . registermbean ( hikaripool , beanpoolname ) ; } else { logger . error ( str_ , poolname , poolname ) ; } } else if ( mbeanserver . isregistered ( beanconfigname ) ) { mbeanserver . unregistermbean ( beanconfigname ) ; mbeanserver . unregistermbean ( beanpoolname ) ; } } catch ( exception e ) { logger . warn ( str_ , poolname , ( register ? str_ : str_ ) , e ) ; } }	Register MBeans for HikariConfig and HikariPool.
private connection newconnection ( ) throws exception { final long start = currenttime ( ) ; connection connection = null ; try { string username = config . getusername ( ) ; string password = config . getpassword ( ) ; connection = ( username == null ) ? datasource . getconnection ( ) : datasource . getconnection ( username , password ) ; setupconnection ( connection ) ; lastconnectionfailure . set ( null ) ; return connection ; } catch ( exception e ) { if ( connection != null ) { quietlycloseconnection ( connection , str_ ) ; } else if ( getlastconnectionfailure ( ) == null ) { logger . debug ( str_ , poolname , e . getmessage ( ) ) ; } lastconnectionfailure . set ( e ) ; throw e ; } finally {	Obtain connection from data source.
private void setupconnection ( final connection connection ) throws connectionsetupexception { try { if ( networktimeout == uninitialized ) { networktimeout = getandsetnetworktimeout ( connection , validationtimeout ) ; } else { setnetworktimeout ( connection , validationtimeout ) ; } if ( connection . isreadonly ( ) != isreadonly ) { connection . setreadonly ( isreadonly ) ; } if ( connection . getautocommit ( ) != isautocommit ) { connection . setautocommit ( isautocommit ) ; } checkdriversupport ( connection ) ; if ( transactionisolation != defaulttransactionisolation ) { connection . settransactionisolation ( transactionisolation ) ; } if ( catalog != null ) { connection . setcatalog ( catalog ) ; } if ( schema != null ) { connection . setschema ( schema ) ; } executesql ( connection , config . getconnectioninitsql ( ) , bool_ ) ; setnetworktimeout ( connection , networktimeout ) ; } catch ( sqlexception e ) { throw new connectionsetupexception ( e ) ; } }	Setup a connection initial state.
private void checkdefaultisolation ( final connection connection ) throws sqlexception { try { defaulttransactionisolation = connection . gettransactionisolation ( ) ; if ( transactionisolation == - num_ ) { transactionisolation = defaulttransactionisolation ; } } catch ( sqlexception e ) { logger . warn ( str_ , poolname , e . getmessage ( ) ) ; if ( e . getsqlstate ( ) != null && ! e . getsqlstate ( ) . startswith ( str_ ) ) { throw e ; } } }	Check the default transaction isolation of the Connection.
private void setquerytimeout ( final statement statement , final int timeoutsec ) { if ( isquerytimeoutsupported != false ) { try { statement . setquerytimeout ( timeoutsec ) ; isquerytimeoutsupported = true ; } catch ( exception e ) { if ( isquerytimeoutsupported == uninitialized ) { isquerytimeoutsupported = false ; logger . info ( str_ , poolname , e . getmessage ( ) ) ; } } } }	Set the query timeout, if it is supported by the driver.
private void executesql ( final connection connection , final string sql , final boolean iscommit ) throws sqlexception { if ( sql != null ) { try ( statement statement = connection . createstatement ( ) ) {	Execute the user-specified init SQL.
private void setlogintimeout ( final datasource datasource ) { if ( connectiontimeout != integer . max_value ) { try { datasource . setlogintimeout ( math . max ( num_ , ( int ) milliseconds . toseconds ( num_ + connectiontimeout ) ) ) ; } catch ( exception e ) { logger . info ( str_ , poolname , e . getmessage ( ) ) ; } } }	Set the loginTimeout on the specified DataSource.
private static < t > void generateproxyclass ( class < t > primaryinterface , string superclassname , string methodbody ) throws exception { string newclassname = superclassname . replaceall ( str_ , str_ ) ; ctclass superct = classpool . getctclass ( superclassname ) ; ctclass targetct = classpool . makeclass ( newclassname , superct ) ; targetct . setmodifiers ( modifier . final ) ; system . out . println ( str_ + newclassname ) ; targetct . setmodifiers ( modifier . public ) ;	Generate Javassist Proxy Classes.
@ override public boolean add ( t element ) { if ( size < elementdata . length ) { elementdata [ size ++ ] = element ; } else {	Add an element to the tail of the FastList.
public t removelast ( ) { t element = elementdata [ -- size ] ; elementdata [ size ] = null ; return element ; }	Remove the last element from the list.
@ override public void clear ( ) { for ( int i = num_ ; i < size ; i ++ ) { elementdata [ i ] = null ; } size = num_ ; }	Clear the FastList.
public connection getconnection ( final long hardtimeout ) throws sqlexception { suspendresumelock . acquire ( ) ; final long starttime = currenttime ( ) ; try { long timeout = hardtimeout ; do { poolentry poolentry = connectionbag . borrow ( timeout , milliseconds ) ; if ( poolentry == null ) { break ;	Get a connection from the pool, or timeout after the specified number of milliseconds.
public synchronized void shutdown ( ) throws interruptedexception { try { poolstate = pool_shutdown ; if ( addconnectionexecutor == null ) {	Shutdown the pool, closing all idle connections and aborting or closingactive connections.
public void evictconnection ( connection connection ) { proxyconnection proxyconnection = ( proxyconnection ) connection ; proxyconnection . cancelleaktask ( ) ; try { softevictconnection ( proxyconnection . getpoolentry ( ) , str_ , ! connection . isclosed ( ) ) ; } catch ( sqlexception e ) {	Evict a Connection from the pool.
public void setmetricregistry ( object metricregistry ) { if ( metricregistry != null && safeisassignablefrom ( metricregistry , str_ ) ) { setmetricstrackerfactory ( new codahalemetricstrackerfactory ( ( metricregistry ) metricregistry ) ) ; } else if ( metricregistry != null && safeisassignablefrom ( metricregistry , str_ ) ) { setmetricstrackerfactory ( new micrometermetricstrackerfactory ( ( meterregistry ) metricregistry ) ) ; } else { setmetricstrackerfactory ( null ) ; } }	Set a metrics registry to be used when registering metrics collectors.
public void setmetricstrackerfactory ( metricstrackerfactory metricstrackerfactory ) { if ( metricstrackerfactory != null ) { this . metricstracker = new metricstrackerdelegate ( metricstrackerfactory . create ( config . getpoolname ( ) , getpoolstats ( ) ) ) ; } else { this . metricstracker = new nopmetricstrackerdelegate ( ) ; } }	Set the MetricsTrackerFactory to be used to create the IMetricsTracker instance used by the pool.
public void sethealthcheckregistry ( object healthcheckregistry ) { if ( healthcheckregistry != null ) { codahalehealthchecker . registerhealthchecks ( this , config , ( healthcheckregistry ) healthcheckregistry ) ; } }	Set the health check registry to be used when registering health checks.
void logpoolstate ( string ... prefix ) { if ( logger . isdebugenabled ( ) ) { logger . debug ( str_ , poolname , ( prefix . length > num_ ? prefix [ num_ ] : str_ ) , gettotalconnections ( ) , getactiveconnections ( ) , getidleconnections ( ) , getthreadsawaitingconnection ( ) ) ; } }	Log the current pool state at debug level.
private poolentry createpoolentry ( ) { try { final poolentry poolentry = newpoolentry ( ) ; final long maxlifetime = config . getmaxlifetime ( ) ; if ( maxlifetime > num_ ) {	Creating new poolEntry. If maxLifetime is configured, create a future End-of-life task with 2.5% variance fromthe maxLifetime time to ensure there is no massive die-off of Connections in the pool.
private void abortactiveconnections ( final executorservice assassinexecutor ) { for ( poolentry poolentry : connectionbag . values ( state_in_use ) ) { connection connection = poolentry . close ( ) ; try { connection . abort ( assassinexecutor ) ; } catch ( throwable e ) { quietlycloseconnection ( connection , str_ ) ; } finally { connectionbag . remove ( poolentry ) ; } } }	Attempt to abort or close active connections.
private void checkfailfast ( ) { final long initializationtimeout = config . getinitializationfailtimeout ( ) ; if ( initializationtimeout < num_ ) { return ; } final long starttime = currenttime ( ) ; do { final poolentry poolentry = createpoolentry ( ) ; if ( poolentry != null ) { if ( config . getminimumidle ( ) > num_ ) { connectionbag . add ( poolentry ) ; logger . debug ( str_ , poolname , poolentry . connection ) ; } else { quietlycloseconnection ( poolentry . close ( ) , str_ ) ; } return ; } if ( getlastconnectionfailure ( ) instanceof connectionsetupexception ) { throwpoolinitializationexception ( getlastconnectionfailure ( ) . getcause ( ) ) ; } quietlysleep ( seconds . tomillis ( num_ ) ) ; } while ( elapsedmillis ( starttime ) < initializationtimeout ) ; if ( initializationtimeout > num_ ) { throwpoolinitializationexception ( getlastconnectionfailure ( ) ) ; } }	If initializationFailFast is configured, check that we have DB connectivity.
private void throwpoolinitializationexception ( throwable t ) { logger . error ( str_ , poolname , t ) ; destroyhousekeepingexecutorservice ( ) ; throw new poolinitializationexception ( t ) ; }	Log the Throwable that caused pool initialization to fail, and then throw a PoolInitializationException withthat cause attached.
private poolstats getpoolstats ( ) { return new poolstats ( seconds . tomillis ( num_ ) ) { @ override protected void update ( ) { this . pendingthreads = hikaripool . this . getthreadsawaitingconnection ( ) ; this . idleconnections = hikaripool . this . getidleconnections ( ) ; this . totalconnections = hikaripool . this . gettotalconnections ( ) ; this . activeconnections = hikaripool . this . getactiveconnections ( ) ; this . maxconnections = config . getmaximumpoolsize ( ) ; this . minconnections = config . getminimumidle ( ) ; } } ; }	Create a PoolStats instance that will be used by metrics tracking, with a pollable resolution of 1 second.
public t borrow ( long timeout , final timeunit timeunit ) throws interruptedexception {	The method will borrow a BagEntry from the bag, blocking for thespecified timeout if none are available.
public void requite ( final t bagentry ) { bagentry . setstate ( state_not_in_use ) ; for ( int i = num_ ; waiters . get ( ) > num_ ; i ++ ) { if ( bagentry . getstate ( ) != state_not_in_use || handoffqueue . offer ( bagentry ) ) { return ; } else if ( ( i & num_ ) == num_ ) { parknanos ( microseconds . tonanos ( num_ ) ) ; } else { yield ( ) ; } } final list < object > threadlocallist = threadlist . get ( ) ; if ( threadlocallist . size ( ) < num_ ) { threadlocallist . add ( weakthreadlocals ? new weakreference < > ( bagentry ) : bagentry ) ; } }	This method will return a borrowed object to the bag.
public void add ( final t bagentry ) { if ( closed ) { logger . info ( str_ ) ; throw new illegalstateexception ( str_ ) ; } sharedlist . add ( bagentry ) ;	Add a new object to the bag for others to borrow.
public int getcount ( final int state ) { int count = num_ ; for ( iconcurrentbagentry e : sharedlist ) { if ( e . getstate ( ) == state ) { count ++ ; } } return count ; }	Get a count of the number of items in the specified state at the time of this call.
public static void registerhealthchecks ( final hikaripool pool , final hikariconfig hikariconfig , final healthcheckregistry registry ) { final properties healthcheckproperties = hikariconfig . gethealthcheckproperties ( ) ; final metricregistry metricregistry = ( metricregistry ) hikariconfig . getmetricregistry ( ) ; final long checktimeoutms = long . parselong ( healthcheckproperties . getproperty ( str_ , string . valueof ( hikariconfig . getconnectiontimeout ( ) ) ) ) ; registry . register ( metricregistry . name ( hikariconfig . getpoolname ( ) , str_ , str_ ) , new connectivityhealthcheck ( pool , checktimeoutms ) ) ; final long expected99thpercentile = long . parselong ( healthcheckproperties . getproperty ( str_ , str_ ) ) ; if ( metricregistry != null && expected99thpercentile > num_ ) { sortedmap < string , timer > timers = metricregistry . gettimers ( ( name , metric ) -> name . equals ( metricregistry . name ( hikariconfig . getpoolname ( ) , str_ , str_ ) ) ) ; if ( ! timers . isempty ( ) ) { final timer timer = timers . entryset ( ) . iterator ( ) . next ( ) . getvalue ( ) ; registry . register ( metricregistry . name ( hikariconfig . getpoolname ( ) , str_ , str_ ) , new connection99percent ( timer , expected99thpercentile ) ) ; } } }	Register Dropwizard health checks.
public static boolean safeisassignablefrom ( object obj , string classname ) { try { class < ? > clazz = class . forname ( classname ) ; return clazz . isassignablefrom ( obj . getclass ( ) ) ; } catch ( classnotfoundexception ignored ) { return bool_ ; } }	Checks whether an object is an instance of given type without throwing exception when the class is not loaded.
public static < t > t createinstance ( final string classname , final class < t > clazz , final object ... args ) { if ( classname == null ) { return null ; } try { class < ? > loaded = utilityelf . class . getclassloader ( ) . loadclass ( classname ) ; if ( args . length == num_ ) { return clazz . cast ( loaded . newinstance ( ) ) ; } class < ? > [ ] argclasses = new class < ? > [ args . length ] ; for ( int i = num_ ; i < args . length ; i ++ ) { argclasses [ i ] = args [ i ] . getclass ( ) ; } constructor < ? > constructor = loaded . getconstructor ( argclasses ) ; return clazz . cast ( constructor . newinstance ( args ) ) ; } catch ( exception e ) { throw new runtimeexception ( e ) ; } }	Create and instance of the specified class using the constructor matching the specifiedarguments.
public static threadpoolexecutor createthreadpoolexecutor ( final int queuesize , final string threadname , threadfactory threadfactory , final rejectedexecutionhandler policy ) { if ( threadfactory == null ) { threadfactory = new defaultthreadfactory ( threadname , bool_ ) ; } linkedblockingqueue < runnable > queue = new linkedblockingqueue < > ( queuesize ) ; threadpoolexecutor executor = new threadpoolexecutor ( num_ , num_ , num_ , seconds , queue , threadfactory , policy ) ; executor . allowcorethreadtimeout ( bool_ ) ; return executor ; }	Create a ThreadPoolExecutor.
public static int gettransactionisolation ( final string transactionisolationname ) { if ( transactionisolationname != null ) { try {	Get the int value of a transaction isolation level by name.
@ override public < t > eventpoller < t > newpoller ( dataprovider < t > dataprovider , sequence ... gatingsequences ) { return eventpoller . newinstance ( dataprovider , this , new sequence ( ) , cursor , gatingsequences ) ; }	Creates an event poller for this sequence that will use the supplied data provider andgating sequences.
public eventhandlergroup < t > after ( final eventprocessor ... processors ) { for ( final eventprocessor processor : processors ) { consumerrepository . add ( processor ) ; } return new eventhandlergroup < > ( this , consumerrepository , util . getsequencesfor ( processors ) ) ; }	Create a group of event processors to be used as a dependency.
public < a > void publishevents ( final eventtranslatoronearg < t , a > eventtranslator , final a [ ] arg ) { ringbuffer . publishevents ( eventtranslator , arg ) ; }	Publish a batch of events to the ring buffer.
private boolean hasbacklog ( ) { final long cursor = ringbuffer . getcursor ( ) ; for ( final sequence consumer : consumerrepository . getlastsequenceinchain ( bool_ ) ) { if ( cursor > consumer . get ( ) ) { return bool_ ; } } return bool_ ; }	Confirms if all messages have been consumed by all event processors.
public ringbuffer < t > start ( final executor executor ) { if ( ! started . compareandset ( bool_ , bool_ ) ) { throw new illegalstateexception ( str_ ) ; } final long cursor = ringbuffer . getcursor ( ) ; worksequence . set ( cursor ) ; for ( workprocessor < ? > processor : workprocessors ) { processor . getsequence ( ) . set ( cursor ) ; executor . execute ( processor ) ; } return ringbuffer ; }	Start the worker pool processing events in sequence.
private void notifystart ( ) { if ( eventhandler instanceof lifecycleaware ) { try { ( ( lifecycleaware ) eventhandler ) . onstart ( ) ; } catch ( final throwable ex ) { exceptionhandler . handleonstartexception ( ex ) ; } } }	Notifies the EventHandler when this processor is starting up.
private void notifyshutdown ( ) { if ( eventhandler instanceof lifecycleaware ) { try { ( ( lifecycleaware ) eventhandler ) . onshutdown ( ) ; } catch ( final throwable ex ) { exceptionhandler . handleonshutdownexception ( ex ) ; } } }	Notifies the EventHandler immediately prior to this processor shutting down.
public long addandget ( final long increment ) { long currentvalue ; long newvalue ; do { currentvalue = get ( ) ; newvalue = currentvalue + increment ; } while ( ! compareandset ( currentvalue , newvalue ) ) ; return newvalue ; }	Atomically add the supplied value.
public static < e > ringbuffer < e > createmultiproducer ( eventfactory < e > factory , int buffersize , waitstrategy waitstrategy ) { multiproducersequencer sequencer = new multiproducersequencer ( buffersize , waitstrategy ) ; return new ringbuffer < e > ( factory , sequencer ) ; }	Create a new multiple producer RingBuffer with the specified wait strategy.
public static < e > ringbuffer < e > createsingleproducer ( eventfactory < e > factory , int buffersize , waitstrategy waitstrategy ) { singleproducersequencer sequencer = new singleproducersequencer ( buffersize , waitstrategy ) ; return new ringbuffer < e > ( factory , sequencer ) ; }	Create a new single producer RingBuffer with the specified wait strategy.
public static decoderresult decode ( bitmatrix image , resultpoint imagetopleft , resultpoint imagebottomleft , resultpoint imagetopright , resultpoint imagebottomright , int mincodewordwidth , int maxcodewordwidth ) throws notfoundexception , formatexception , checksumexception { boundingbox boundingbox = new boundingbox ( image , imagetopleft , imagebottomleft , imagetopright , imagebottomright ) ; detectionresultrowindicatorcolumn leftrowindicatorcolumn = null ; detectionresultrowindicatorcolumn rightrowindicatorcolumn = null ; detectionresult detectionresult ; for ( boolean firstpass = bool_ ; ; firstpass = bool_ ) { if ( imagetopleft != null ) { leftrowindicatorcolumn = getrowindicatorcolumn ( image , boundingbox , imagetopleft , bool_ , mincodewordwidth , maxcodewordwidth ) ; } if ( imagetopright != null ) { rightrowindicatorcolumn = getrowindicatorcolumn ( image , boundingbox , imagetopright , bool_ , mincodewordwidth , maxcodewordwidth ) ; } detectionresult = merge ( leftrowindicatorcolumn , rightrowindicatorcolumn ) ; if ( detectionresult == null ) { throw notfoundexception . getnotfoundinstance ( ) ; } boundingbox resultbox = detectionresult . getboundingbox ( ) ; if ( firstpass && resultbox != null && ( resultbox . getminy ( ) < boundingbox . getminy ( ) || resultbox . getmaxy ( ) > boundingbox . getmaxy ( ) ) ) { boundingbox = resultbox ; } else { break ; } } detectionresult . setboundingbox ( boundingbox ) ; int maxbarcodecolumn = detectionresult . getbarcodecolumncount ( ) + num_ ; detectionresult . setdetectionresultcolumn ( num_ , leftrowindicatorcolumn ) ; detectionresult . setdetectionresultcolumn ( maxbarcodecolumn , rightrowindicatorcolumn ) ; boolean lefttoright = leftrowindicatorcolumn != null ; for ( int barcodecolumncount = num_ ; barcodecolumncount <= maxbarcodecolumn ; barcodecolumncount ++ ) { int barcodecolumn = lefttoright ? barcodecolumncount : maxbarcodecolumn - barcodecolumncount ; if ( detectionresult . getdetectionresultcolumn ( barcodecolumn ) != null ) {	than it should be.
private static void verifycodewordcount ( int [ ] codewords , int numeccodewords ) throws formatexception { if ( codewords . length < num_ ) {	Verify that all is OK with the codeword array.
void remask ( ) { if ( parsedformatinfo == null ) { return ;	Revert the mask removal done while reading the code words.
void mirror ( ) { for ( int x = num_ ; x < bitmatrix . getwidth ( ) ; x ++ ) { for ( int y = x + num_ ; y < bitmatrix . getheight ( ) ; y ++ ) { if ( bitmatrix . get ( x , y ) != bitmatrix . get ( y , x ) ) { bitmatrix . flip ( y , x ) ; bitmatrix . flip ( x , y ) ; } } } }	Mirror the bit matrix in order to attempt a second reading.
public static charsequence downloadviahttp ( string uri , contenttype type ) throws ioexception { return downloadviahttp ( uri , type , integer . max_value ) ; }	Downloads the entire resource instead of part.
private boolean crosscheckdiagonal ( int centeri , int centerj ) { int [ ] statecount = getcrosscheckstatecount ( ) ;	After a vertical and horizontal scan finds a potential finder pattern, this method"cross-cross-cross-checks" by scanning down diagonally through the center of the possiblefinder pattern to see if the same proportion is detected.
private static double squareddistance ( finderpattern a , finderpattern b ) { double x = a . getx ( ) - b . getx ( ) ; double y = a . gety ( ) - b . gety ( ) ; return x * x + y * y ; }	Get square of distance between a and b.
private static bitmatrix bitmatrixfrombitarray ( byte [ ] [ ] input , int margin ) {	This takes an array holding the values of the PDF 417.
private static byte [ ] [ ] rotatearray ( byte [ ] [ ] bitarray ) { byte [ ] [ ] temp = new byte [ bitarray [ num_ ] . length ] [ bitarray . length ] ; for ( int ii = num_ ; ii < bitarray . length ; ii ++ ) {	Takes and rotates the it 90 degrees.
private static int tonarrowwidepattern ( int [ ] counters ) { int numcounters = counters . length ; int maxnarrowcounter = num_ ; int widecounters ; do { int mincounter = integer . max_value ; for ( int counter : counters ) { if ( counter < mincounter && counter > maxnarrowcounter ) { mincounter = counter ; } } maxnarrowcounter = mincounter ; widecounters = num_ ; int totalwidecounterswidth = num_ ; int pattern = num_ ; for ( int i = num_ ; i < numcounters ; i ++ ) { int counter = counters [ i ] ; if ( counter > maxnarrowcounter ) { pattern |= num_ << ( numcounters - num_ - i ) ; widecounters ++ ; totalwidecounterswidth += counter ; } } if ( widecounters == num_ ) {	per image when using some of our blackbox images.
private static list < resultpoint [ ] > detect ( boolean multiple , bitmatrix bitmatrix ) { list < resultpoint [ ] > barcodecoordinates = new arraylist < > ( ) ; int row = num_ ; int column = num_ ; boolean foundbarcodeinrow = bool_ ; while ( row < bitmatrix . getheight ( ) ) { resultpoint [ ] vertices = findvertices ( bitmatrix , row , column ) ; if ( vertices [ num_ ] == null && vertices [ num_ ] == null ) { if ( ! foundbarcodeinrow ) {	Detects PDF417 codes in an image. Only checks 0 degree rotation.
private static resultpoint [ ] findvertices ( bitmatrix matrix , int startrow , int startcolumn ) { int height = matrix . getheight ( ) ; int width = matrix . getwidth ( ) ; resultpoint [ ] result = new resultpoint [ num_ ] ; copytoresult ( result , findrowswithpattern ( matrix , height , width , startrow , startcolumn , start_pattern ) , indexes_start_pattern ) ; if ( result [ num_ ] != null ) { startcolumn = ( int ) result [ num_ ] . getx ( ) ; startrow = ( int ) result [ num_ ] . gety ( ) ; } copytoresult ( result , findrowswithpattern ( matrix , height , width , startrow , startcolumn , stop_pattern ) , indexes_stop_pattern ) ; return result ; }	Locate the vertices and the codewords area of a black blob using the Startand Stop patterns as locators.
public synchronized void opendriver ( surfaceholder holder ) throws ioexception { opencamera thecamera = camera ; if ( thecamera == null ) { thecamera = opencamerainterface . open ( requestedcameraid ) ; if ( thecamera == null ) { throw new ioexception ( str_ ) ; } camera = thecamera ; } if ( ! initialized ) { initialized = bool_ ; configmanager . initfromcameraparameters ( thecamera ) ; if ( requestedframingrectwidth > num_ && requestedframingrectheight > num_ ) { setmanualframingrect ( requestedframingrectwidth , requestedframingrectheight ) ; requestedframingrectwidth = num_ ; requestedframingrectheight = num_ ; } } camera cameraobject = thecamera . getcamera ( ) ; camera . parameters parameters = cameraobject . getparameters ( ) ; string parametersflattened = parameters == null ? null : parameters . flatten ( ) ;	Opens the camera driver and initializes the hardware parameters.
public synchronized void closedriver ( ) { if ( camera != null ) { camera . getcamera ( ) . release ( ) ; camera = null ;	Closes the camera driver if still in use.
public synchronized rect getframingrect ( ) { if ( framingrect == null ) { if ( camera == null ) { return null ; } point screenresolution = configmanager . getscreenresolution ( ) ; if ( screenresolution == null ) {	Calculates the framing rect which the UI should draw to show the user where to place thebarcode.
public synchronized void setmanualframingrect ( int width , int height ) { if ( initialized ) { point screenresolution = configmanager . getscreenresolution ( ) ; if ( width > screenresolution . x ) { width = screenresolution . x ; } if ( height > screenresolution . y ) { height = screenresolution . y ; } int leftoffset = ( screenresolution . x - width ) / num_ ; int topoffset = ( screenresolution . y - height ) / num_ ; framingrect = new rect ( leftoffset , topoffset , leftoffset + width , topoffset + height ) ; log . d ( tag , str_ + framingrect ) ; framingrectinpreview = null ; } else { requestedframingrectwidth = width ; requestedframingrectheight = height ; } }	Allows third party apps to specify the scanning rectangle dimensions, rather than determinethem automatically based on screen resolution.
public planaryuvluminancesource buildluminancesource ( byte [ ] data , int width , int height ) { rect rect = getframingrectinpreview ( ) ; if ( rect == null ) { return null ; }	A factory method to build the appropriate LuminanceSource object based on the formatof the preview buffers, as described by Camera.Parameters.
@ override public uriparsedresult parse ( result result ) { string rawtext = getmassagedtext ( result ) ;	query, path or nothing.
public aztecdetectorresult detect ( boolean ismirror ) throws notfoundexception {	Detects an Aztec Code in an image.
private void extractparameters ( resultpoint [ ] bullseyecorners ) throws notfoundexception { if ( ! isvalid ( bullseyecorners [ num_ ] ) || ! isvalid ( bullseyecorners [ num_ ] ) || ! isvalid ( bullseyecorners [ num_ ] ) || ! isvalid ( bullseyecorners [ num_ ] ) ) { throw notfoundexception . getnotfoundinstance ( ) ; } int length = num_ * nbcenterlayers ;	Extracts the number of data layers and data blocks from the layer around the bull's eye.
private static int getcorrectedparameterdata ( long parameterdata , boolean compact ) throws notfoundexception { int numcodewords ; int numdatacodewords ; if ( compact ) { numcodewords = num_ ; numdatacodewords = num_ ; } else { numcodewords = num_ ; numdatacodewords = num_ ; } int numeccodewords = numcodewords - numdatacodewords ; int [ ] parameterwords = new int [ numcodewords ] ; for ( int i = numcodewords - num_ ; i >= num_ ; -- i ) { parameterwords [ i ] = ( int ) parameterdata & num_ ; parameterdata >>= num_ ; } try { reedsolomondecoder rsdecoder = new reedsolomondecoder ( genericgf . aztec_param ) ; rsdecoder . decode ( parameterwords , numeccodewords ) ; } catch ( reedsolomonexception ignored ) { throw notfoundexception . getnotfoundinstance ( ) ; }	Corrects the parameter bits using Reed-Solomon algorithm.
private bitmatrix samplegrid ( bitmatrix image , resultpoint topleft , resultpoint topright , resultpoint bottomright , resultpoint bottomleft ) throws notfoundexception { gridsampler sampler = gridsampler . getinstance ( ) ; int dimension = getdimension ( ) ; float low = dimension / num_ - nbcenterlayers ; float high = dimension / num_ + nbcenterlayers ; return sampler . samplegrid ( image , dimension , dimension , low , low ,	Creates a BitMatrix by sampling the provided image.topLeft, topRight, bottomRight, and bottomLeft are the centers of the squares on thediagonal just outside the bull's eye.
private int sampleline ( resultpoint p1 , resultpoint p2 , int size ) { int result = num_ ; float d = distance ( p1 , p2 ) ; float modulesize = d / size ; float px = p1 . getx ( ) ; float py = p1 . gety ( ) ; float dx = modulesize * ( p2 . getx ( ) - p1 . getx ( ) ) / d ; float dy = modulesize * ( p2 . gety ( ) - p1 . gety ( ) ) / d ; for ( int i = num_ ; i < size ; i ++ ) { if ( image . get ( mathutils . round ( px + i * dx ) , mathutils . round ( py + i * dy ) ) ) { result |= num_ << ( size - i - num_ ) ; } } return result ; }	Samples a line.
private int getcolor ( point p1 , point p2 ) { float d = distance ( p1 , p2 ) ; float dx = ( p2 . getx ( ) - p1 . getx ( ) ) / d ; float dy = ( p2 . gety ( ) - p1 . gety ( ) ) / d ; int error = num_ ; float px = p1 . getx ( ) ; float py = p1 . gety ( ) ; boolean colormodel = image . get ( p1 . getx ( ) , p1 . gety ( ) ) ; int imax = ( int ) math . ceil ( d ) ; for ( int i = num_ ; i < imax ; i ++ ) { px += dx ; py += dy ; if ( image . get ( mathutils . round ( px ) , mathutils . round ( py ) ) != colormodel ) { error ++ ; } } float errratio = error / d ; if ( errratio > num_ && errratio < num_ ) { return num_ ; } return ( errratio <= num_ ) == colormodel ? num_ : - num_ ; }	Gets the color of a segment.
private point getfirstdifferent ( point init , boolean color , int dx , int dy ) { int x = init . getx ( ) + dx ; int y = init . gety ( ) + dy ; while ( isvalid ( x , y ) && image . get ( x , y ) == color ) { x += dx ; y += dy ; } x -= dx ; y -= dy ; while ( isvalid ( x , y ) && image . get ( x , y ) == color ) { x += dx ; } x -= dx ; while ( isvalid ( x , y ) && image . get ( x , y ) == color ) { y += dy ; } y -= dy ; return new point ( x , y ) ; }	Gets the coordinate of the first point with a different color in the given direction.
private static void decodehanzisegment ( bitsource bits , stringbuilder result , int count ) throws formatexception {	See specification GBT 18284-2000.
private static void changenetworkwep ( wifimanager wifimanager , wifiparsedresult wifiresult ) { wificonfiguration config = changenetworkcommon ( wifiresult ) ; config . wepkeys [ num_ ] = quotenonhex ( wifiresult . getpassword ( ) , num_ , num_ , num_ ) ; config . weptxkeyindex = num_ ; config . allowedauthalgorithms . set ( wificonfiguration . authalgorithm . shared ) ; config . allowedkeymanagement . set ( wificonfiguration . keymgmt . none ) ; config . allowedgroupciphers . set ( wificonfiguration . groupcipher . tkip ) ; config . allowedgroupciphers . set ( wificonfiguration . groupcipher . ccmp ) ; config . allowedgroupciphers . set ( wificonfiguration . groupcipher . wep40 ) ; config . allowedgroupciphers . set ( wificonfiguration . groupcipher . wep104 ) ; updatenetwork ( wifimanager , config ) ; }	Adding a WEP network.
private static void changenetworkwpa ( wifimanager wifimanager , wifiparsedresult wifiresult ) { wificonfiguration config = changenetworkcommon ( wifiresult ) ;	Adding a WPA or WPA2 network.
private static void changenetworkunencrypted ( wifimanager wifimanager , wifiparsedresult wifiresult ) { wificonfiguration config = changenetworkcommon ( wifiresult ) ; config . allowedkeymanagement . set ( wificonfiguration . keymgmt . none ) ; updatenetwork ( wifimanager , config ) ; }	Adding an open, unsecured network.
private static string converttoquotedstring ( string s ) { if ( s == null || s . isempty ( ) ) { return null ; }	Encloses the incoming string inside double quotes, if it isn't already quoted.
@ override public charsequence getdisplaycontents ( ) { wifiparsedresult wifiresult = ( wifiparsedresult ) getresult ( ) ; return wifiresult . getssid ( ) + str_ + wifiresult . getnetworkencryption ( ) + str_ ; }	Display the name of the network and the network type to the user.
private static float crossproductz ( resultpoint pointa , resultpoint pointb , resultpoint pointc ) { float bx = pointb . x ; float by = pointb . y ; return ( ( pointc . x - bx ) * ( pointa . y - by ) ) - ( ( pointc . y - by ) * ( pointa . x - bx ) ) ; }	Returns the z component of the cross product between vectors BC and BA.
private void encodecontentsfromzxingintent ( intent intent ) {	but we use platform specific code like PhoneNumberUtils, so it can't.
private void encodecontentsfromshareintent ( intent intent ) throws writerexception {	Handles send intents from multitude of Android applications.
private void encodefromstreamextra ( intent intent ) throws writerexception { format = barcodeformat . qr_code ; bundle bundle = intent . getextras ( ) ; if ( bundle == null ) { throw new writerexception ( str_ ) ; } uri uri = bundle . getparcelable ( intent . extra_stream ) ; if ( uri == null ) { throw new writerexception ( str_ ) ; } byte [ ] vcard ; string vcardstring ; try ( inputstream stream = activity . getcontentresolver ( ) . openinputstream ( uri ) ) { if ( stream == null ) { throw new writerexception ( str_ + uri ) ; } bytearrayoutputstream baos = new bytearrayoutputstream ( ) ; byte [ ] buffer = new byte [ num_ ] ; int bytesread ; while ( ( bytesread = stream . read ( buffer ) ) > num_ ) { baos . write ( buffer , num_ , bytesread ) ; } vcard = baos . tobytearray ( ) ; vcardstring = new string ( vcard , num_ , vcard . length , standardcharsets . utf_8 ) ; } catch ( ioexception ioe ) { throw new writerexception ( ioe ) ; } log . d ( tag , str_ ) ; log . d ( tag , vcardstring ) ; result result = new result ( vcardstring , vcard , null , barcodeformat . qr_code ) ; parsedresult parsedresult = resultparser . parseresult ( result ) ; if ( ! ( parsedresult instanceof addressbookparsedresult ) ) { throw new writerexception ( str_ ) ; } encodeqrcodecontents ( ( addressbookparsedresult ) parsedresult ) ; if ( contents == null || contents . isempty ( ) ) { throw new writerexception ( str_ ) ; } }	Handles send intents from the Contacts app, retrieving a contact as a VCARD.
private void setcounters ( bitarray row ) throws notfoundexception { counterlength = num_ ;	Records the size of all runs of white and black pixels, starting with white.This is just like recordPattern, except it records all the counters, anduses our builtin "counters" member for storage.
@ override public result decode ( binarybitmap image , map < decodehinttype , ? > hints ) throws notfoundexception , formatexception { try { return dodecode ( image , hints ) ; } catch ( notfoundexception nfe ) { boolean tryharder = hints != null && hints . containskey ( decodehinttype . try_harder ) ; if ( tryharder && image . isrotatesupported ( ) ) { binarybitmap rotatedimage = image . rotatecounterclockwise ( ) ; result result = dodecode ( rotatedimage , hints ) ;	Note that we don't try rotation without the try harder flag, even if rotation was supported.
@ override public bitmatrix getblackmatrix ( ) throws notfoundexception { if ( matrix != null ) { return matrix ; } luminancesource source = getluminancesource ( ) ; int width = source . getwidth ( ) ; int height = source . getheight ( ) ; if ( width >= minimum_dimension && height >= minimum_dimension ) { byte [ ] luminances = source . getmatrix ( ) ; int subwidth = width > > block_size_power ; if ( ( width & block_size_mask ) != num_ ) { subwidth ++ ; } int subheight = height > > block_size_power ; if ( ( height & block_size_mask ) != num_ ) { subheight ++ ; } int [ ] [ ] blackpoints = calculateblackpoints ( luminances , subwidth , subheight , width , height ) ; bitmatrix newmatrix = new bitmatrix ( width , height ) ; calculatethresholdforblock ( luminances , subwidth , subheight , width , height , blackpoints , newmatrix ) ; matrix = newmatrix ; } else {	Calculates the final BitMatrix once for all requests.
private static void thresholdblock ( byte [ ] luminances , int xoffset , int yoffset , int threshold , int stride , bitmatrix matrix ) { for ( int y = num_ , offset = yoffset * stride + xoffset ; y < block_size ; y ++ , offset += stride ) { for ( int x = num_ ; x < block_size ; x ++ ) {	Applies a single threshold to a block of pixels.
private int mapindextoaction ( int index ) { if ( index < buttoncount ) { int count = - num_ ; for ( int x = num_ ; x < max_button_count ; x ++ ) { if ( fields [ x ] ) { count ++ ; } if ( count == index ) { return x ; } } } return - num_ ; }	positions, based on which fields are present in this barcode.
@ override public charsequence getdisplaycontents ( ) { addressbookparsedresult result = ( addressbookparsedresult ) getresult ( ) ; stringbuilder contents = new stringbuilder ( num_ ) ; parsedresult . maybeappend ( result . getnames ( ) , contents ) ; int nameslength = contents . length ( ) ; string pronunciation = result . getpronunciation ( ) ; if ( pronunciation != null && ! pronunciation . isempty ( ) ) { contents . append ( str_ ) ; contents . append ( pronunciation ) ; contents . append ( str_ ) ; } parsedresult . maybeappend ( result . gettitle ( ) , contents ) ; parsedresult . maybeappend ( result . getorg ( ) , contents ) ; parsedresult . maybeappend ( result . getaddresses ( ) , contents ) ; string [ ] numbers = result . getphonenumbers ( ) ; if ( numbers != null ) { for ( string number : numbers ) { if ( number != null ) { parsedresult . maybeappend ( formatphone ( number ) , contents ) ; } } } parsedresult . maybeappend ( result . getemails ( ) , contents ) ; parsedresult . maybeappend ( result . geturls ( ) , contents ) ; string birthday = result . getbirthday ( ) ; if ( birthday != null && ! birthday . isempty ( ) ) { long date = parsedate ( birthday ) ; if ( date >= num_ ) { parsedresult . maybeappend ( dateformat . getdateinstance ( dateformat . medium ) . format ( date ) , contents ) ; } } parsedresult . maybeappend ( result . getnote ( ) , contents ) ; if ( nameslength > num_ ) {	Overriden so we can hyphenate phone numbers, format birthdays, and bold the name.
private static void formatnames ( iterable < list < string > > names ) { if ( names != null ) { for ( list < string > list : names ) { string name = list . get ( num_ ) ; string [ ] components = new string [ num_ ] ; int start = num_ ; int end ; int componentindex = num_ ; while ( componentindex < components . length - num_ && ( end = name . indexof ( str_ , start ) ) >= num_ ) { components [ componentindex ] = name . substring ( start , end ) ; componentindex ++ ; start = end + num_ ; } components [ componentindex ] = name . substring ( start ) ; stringbuilder newname = new stringbuilder ( num_ ) ; maybeappendcomponent ( components , num_ , newname ) ; maybeappendcomponent ( components , num_ , newname ) ; maybeappendcomponent ( components , num_ , newname ) ; maybeappendcomponent ( components , num_ , newname ) ; maybeappendcomponent ( components , num_ , newname ) ; list . set ( num_ , newname . tostring ( ) . trim ( ) ) ; } } }	Formats name fields of the form "Public;John;Q.;Reverend;III" into a form like"Reverend John Q.
byte [ ] getscaledrow ( int scale ) { byte [ ] output = new byte [ row . length * scale ] ; for ( int i = num_ ; i < output . length ; i ++ ) { output [ i ] = row [ i / scale ] ; } return output ; }	This function scales the row.
static int applymaskpenaltyrule4 ( bytematrix matrix ) { int numdarkcells = num_ ; byte [ ] [ ] array = matrix . getarray ( ) ; int width = matrix . getwidth ( ) ; int height = matrix . getheight ( ) ; for ( int y = num_ ; y < height ; y ++ ) { byte [ ] arrayy = array [ y ] ; for ( int x = num_ ; x < width ; x ++ ) { if ( arrayy [ x ] == num_ ) { numdarkcells ++ ; } } } int numtotalcells = matrix . getheight ( ) * matrix . getwidth ( ) ; int fivepercentvariances = math . abs ( numdarkcells * num_ - numtotalcells ) * num_ / numtotalcells ; return fivepercentvariances * n4 ; }	Apply mask penalty rule 4 and return the penalty.
private static int applymaskpenaltyrule1internal ( bytematrix matrix , boolean ishorizontal ) { int penalty = num_ ; int ilimit = ishorizontal ? matrix . getheight ( ) : matrix . getwidth ( ) ; int jlimit = ishorizontal ? matrix . getwidth ( ) : matrix . getheight ( ) ; byte [ ] [ ] array = matrix . getarray ( ) ; for ( int i = num_ ; i < ilimit ; i ++ ) { int numsamebitcells = num_ ; int prevbit = - num_ ; for ( int j = num_ ; j < jlimit ; j ++ ) { int bit = ishorizontal ? array [ i ] [ j ] : array [ j ] [ i ] ; if ( bit == prevbit ) { numsamebitcells ++ ; } else { if ( numsamebitcells >= num_ ) { penalty += n1 + ( numsamebitcells - num_ ) ; } numsamebitcells = num_ ;	Helper function for applyMaskPenaltyRule1.
@ override public addressbookparsedresult parse ( result result ) { string rawtext = getmassagedtext ( result ) ; if ( ! rawtext . startswith ( str_ ) ) { return null ; } string firstname = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string lastname = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string fullname = buildname ( firstname , lastname ) ; string title = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string org = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string [ ] addresses = matchdocomoprefixedfield ( str_ , rawtext , bool_ ) ; string phonenumber1 = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string phonenumber2 = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string phonenumber3 = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; string email = matchsingledocomoprefixedfield ( str_ , rawtext , bool_ ) ; return new addressbookparsedresult ( maybewrap ( fullname ) , null , null , buildphonenumbers ( phonenumber1 , phonenumber2 , phonenumber3 ) , null , maybewrap ( email ) , null , null , null , addresses , null , org , null , title , null , null ) ; }	DoCoMo's proposed formats.
public void setrange ( int start , int end ) { if ( end < start || start < num_ || end > size ) { throw new illegalargumentexception ( ) ; } if ( end == start ) { return ; } end -- ;	Sets a range of bits.
public boolean isrange ( int start , int end , boolean value ) { if ( end < start || start < num_ || end > size ) { throw new illegalargumentexception ( ) ; } if ( end == start ) { return bool_ ;	Efficient method to check if a range of bits is set, or not set.
public void appendbits ( int value , int numbits ) { if ( numbits < num_ || numbits > num_ ) { throw new illegalargumentexception ( str_ ) ; } ensurecapacity ( size + numbits ) ; for ( int numbitsleft = numbits ; numbitsleft > num_ ; numbitsleft -- ) { appendbit ( ( ( value > > ( numbitsleft - num_ ) ) & num_ ) == num_ ) ; } }	Appends the least-significant bits, from value, in order from most-significant toleast-significant.
public void reverse ( ) { int [ ] newbits = new int [ bits . length ] ;	Reverses all bits in the array.
private static int determineconsecutivetextcount ( charsequence msg , int startpos ) { int len = msg . length ( ) ; int idx = startpos ; while ( idx < len ) { char ch = msg . charat ( idx ) ; int numericcount = num_ ; while ( numericcount < num_ && isdigit ( ch ) && idx < len ) { numericcount ++ ; idx ++ ; if ( idx < len ) { ch = msg . charat ( idx ) ; } } if ( numericcount >= num_ ) { return idx - startpos - numericcount ; } if ( numericcount > num_ ) {	Determines the number of consecutive characters that are encodable using text compaction.
private static int determineconsecutivebinarycount ( string msg , int startpos , charset encoding ) throws writerexception { charsetencoder encoder = encoding . newencoder ( ) ; int len = msg . length ( ) ; int idx = startpos ; while ( idx < len ) { char ch = msg . charat ( idx ) ; int numericcount = num_ ; while ( numericcount < num_ && isdigit ( ch ) ) { numericcount ++ ;	Determines the number of consecutive characters that are encodable using binary compaction.
public static int determineconsecutivedigitcount ( charsequence msg , int startpos ) { int count = num_ ; int len = msg . length ( ) ; int idx = startpos ; if ( idx < len ) { char ch = msg . charat ( idx ) ; while ( isdigit ( ch ) && idx < len ) { count ++ ; idx ++ ; if ( idx < len ) { ch = msg . charat ( idx ) ; } } } return count ; }	Determines the number of consecutive characters that are encodable using numeric compaction.
final void searchmap ( string address ) { launchintent ( new intent ( intent . action_view , uri . parse ( str_ + uri . encode ( address ) ) ) ) ; }	Do a geo search using the address as the query.
final void openproductsearch ( string upc ) { uri uri = uri . parse ( str_ + localemanager . getproductsearchcountrytld ( activity ) + str_ + upc + str_ ) ; launchintent ( new intent ( intent . action_view , uri ) ) ; }	Uses the mobile-specific version of Product Search, which is formatted for small screens.
private void decode ( byte [ ] data , int width , int height ) { long start = system . nanotime ( ) ; result rawresult = null ; planaryuvluminancesource source = activity . getcameramanager ( ) . buildluminancesource ( data , width , height ) ; if ( source != null ) { binarybitmap bitmap = new binarybitmap ( new hybridbinarizer ( source ) ) ; try { rawresult = multiformatreader . decodewithstate ( bitmap ) ; } catch ( readerexception re ) {	Decode the data within the viewfinder rectangle, and time how long it took.
private resultpoint [ ] detectsolid1 ( resultpoint [ ] cornerpoints ) {	Detect a solid side which has minimum transition.
private resultpoint [ ] detectsolid2 ( resultpoint [ ] points ) {	Detect a second solid side next to first solid side.
private resultpoint correcttopright ( resultpoint [ ] points ) {	Calculates the corner position of the white top right module.
private resultpoint [ ] shifttomodulecenter ( resultpoint [ ] points ) {	Shift the edge points to the module center.
protected void startactivityforresult ( intent intent , int code ) { if ( fragment == null ) { activity . startactivityforresult ( intent , code ) ; } else { fragment . startactivityforresult ( intent , code ) ; } }	Start an activity. This method is defined to allow different methods of activity starting fornewer versions of Android and for compatibility library.
public final alertdialog sharetext ( charsequence text , charsequence type ) { intent intent = new intent ( ) ; intent . addcategory ( intent . category_default ) ; intent . setaction ( bs_package + str_ ) ; intent . putextra ( str_ , type ) ; intent . putextra ( str_ , text ) ; string targetapppackage = findtargetapppackage ( intent ) ; if ( targetapppackage == null ) { return showdownloaddialog ( ) ; } intent . setpackage ( targetapppackage ) ; intent . addflags ( intent . flag_activity_clear_top ) ; intent . addflags ( flag_new_doc ) ; attachmoreextras ( intent ) ; if ( fragment == null ) { activity . startactivity ( intent ) ; } else { fragment . startactivity ( intent ) ; } return null ; }	Shares the given text by encoding it as a barcode, such that another user canscan the text off the screen of the device.
@ override public bitarray getblackrow ( int y , bitarray row ) throws notfoundexception { luminancesource source = getluminancesource ( ) ; int width = source . getwidth ( ) ; if ( row == null || row . getsize ( ) < width ) { row = new bitarray ( width ) ; } else { row . clear ( ) ; } initarrays ( width ) ; byte [ ] localluminances = source . getrow ( y , luminances ) ; int [ ] localbuckets = buckets ; for ( int x = num_ ; x < width ; x ++ ) { localbuckets [ ( localluminances [ x ] & num_ ) > > luminance_shift ] ++ ; } int blackpoint = estimateblackpoint ( localbuckets ) ; if ( width < num_ ) {	Applies simple sharpening to the row data to improve performance of the 1D Readers.
@ override public bitmatrix getblackmatrix ( ) throws notfoundexception { luminancesource source = getluminancesource ( ) ; int width = source . getwidth ( ) ; int height = source . getheight ( ) ; bitmatrix matrix = new bitmatrix ( width , height ) ;	Does not sharpen the data, as this call is intended to only be used by 2D Readers.
state latchandappend ( int mode , int value ) {	necessary different) mode, and then a code.
state shiftandappend ( int mode , int value ) {	to a different mode to output a single value.
state addbinaryshiftchar ( int index ) { token token = this . token ; int mode = this . mode ; int bitcount = this . bitcount ; if ( this . mode == highlevelencoder . mode_punct || this . mode == highlevelencoder . mode_digit ) {	output in Binary Shift mode.
state endbinaryshift ( int index ) { if ( binaryshiftbytecount == num_ ) { return this ; } token token = this . token ; token = token . addbinaryshift ( index - binaryshiftbytecount , binaryshiftbytecount ) ;	Binary Shift mode.
boolean isbetterthanorequalto ( state other ) { int newmodebitcount = this . bitcount + ( highlevelencoder . latch_table [ this . mode ] [ other . mode ] > > num_ ) ; if ( this . binaryshiftbytecount < other . binaryshiftbytecount ) {	state under all possible circumstances.
private static bitmatrix encodelowlevel ( defaultplacement placement , symbolinfo symbolinfo , int width , int height ) { int symbolwidth = symbolinfo . getsymboldatawidth ( ) ; int symbolheight = symbolinfo . getsymboldataheight ( ) ; bytematrix matrix = new bytematrix ( symbolinfo . getsymbolwidth ( ) , symbolinfo . getsymbolheight ( ) ) ; int matrixy = num_ ; for ( int y = num_ ; y < symbolheight ; y ++ ) {	Encode the given symbol info to a bit matrix.
private static bitmatrix convertbytematrixtobitmatrix ( bytematrix matrix , int reqwidth , int reqheight ) { int matrixwidth = matrix . getwidth ( ) ; int matrixheight = matrix . getheight ( ) ; int outputwidth = math . max ( reqwidth , matrixwidth ) ; int outputheight = math . max ( reqheight , matrixheight ) ; int multiple = math . min ( outputwidth / matrixwidth , outputheight / matrixheight ) ; int leftpadding = ( outputwidth - ( matrixwidth * multiple ) ) / num_ ; int toppadding = ( outputheight - ( matrixheight * multiple ) ) / num_ ; bitmatrix output ;	Convert the ByteMatrix to BitMatrix.
private static int skipwhitespace ( bitarray row ) throws notfoundexception { int width = row . getsize ( ) ; int endstart = row . getnextset ( num_ ) ; if ( endstart == width ) { throw notfoundexception . getnotfoundinstance ( ) ; } return endstart ; }	Skip all whitespace until we get to the first black line.
public bitarray getrow ( int y , bitarray row ) { if ( row == null || row . getsize ( ) < width ) { row = new bitarray ( width ) ; } else { row . clear ( ) ; } int offset = y * rowsize ; for ( int x = num_ ; x < rowsize ; x ++ ) { row . setbulk ( x * num_ , bits [ offset + x ] ) ; } return row ; }	A fast method to retrieve one row of data from the matrix as a BitArray.
public int [ ] getenclosingrectangle ( ) { int left = width ; int top = height ; int right = - num_ ; int bottom = - num_ ; for ( int y = num_ ; y < height ; y ++ ) { for ( int x32 = num_ ; x32 < rowsize ; x32 ++ ) { int thebits = bits [ y * rowsize + x32 ] ; if ( thebits != num_ ) { if ( y < top ) { top = y ; } if ( y > bottom ) { bottom = y ; } if ( x32 * num_ < left ) { int bit = num_ ; while ( ( thebits << ( num_ - bit ) ) == num_ ) { bit ++ ; } if ( ( x32 * num_ + bit ) < left ) { left = x32 * num_ + bit ; } } if ( x32 * num_ + num_ > right ) { int bit = num_ ; while ( ( thebits > > > bit ) == num_ ) { bit -- ; } if ( ( x32 * num_ + bit ) > right ) { right = x32 * num_ + bit ; } } } } } if ( right < left || bottom < top ) { return null ; } return new int [ ] { left , top , right - left + num_ , bottom - top + num_ } ; }	This is useful in detecting the enclosing rectangle of a 'pure' barcode.
public int [ ] gettopleftonbit ( ) { int bitsoffset = num_ ; while ( bitsoffset < bits . length && bits [ bitsoffset ] == num_ ) { bitsoffset ++ ; } if ( bitsoffset == bits . length ) { return null ; } int y = bitsoffset / rowsize ; int x = ( bitsoffset % rowsize ) * num_ ; int thebits = bits [ bitsoffset ] ; int bit = num_ ; while ( ( thebits << ( num_ - bit ) ) == num_ ) { bit ++ ; } x += bit ; return new int [ ] { x , y } ; }	This is useful in detecting a corner of a 'pure' barcode.
static void buildmatrix ( bitarray databits , errorcorrectionlevel eclevel , version version , int maskpattern , bytematrix matrix ) throws writerexception { clearmatrix ( matrix ) ; embedbasicpatterns ( version , matrix ) ;	success, store the result in "matrix" and return true.
static void embedbasicpatterns ( version version , bytematrix matrix ) throws writerexception {	- Position adjustment patterns, if need be.
static void embedtypeinfo ( errorcorrectionlevel eclevel , int maskpattern , bytematrix matrix ) throws writerexception { bitarray typeinfobits = new bitarray ( ) ; maketypeinfobits ( eclevel , maskpattern , typeinfobits ) ; for ( int i = num_ ; i < typeinfobits . getsize ( ) ; ++ i ) {	Embed type information. On success, modify the matrix.
static int calculatebchcode ( int value , int poly ) { if ( poly == num_ ) { throw new illegalargumentexception ( str_ ) ; }	operations. We don't care if coefficients are positive or negative.
private static void maybeembedpositionadjustmentpatterns ( version version , bytematrix matrix ) { if ( version . getversionnumber ( ) < num_ ) {	Embed position adjustment patterns if need be.
list < expandedpair > decoderow2pairs ( int rownumber , bitarray row ) throws notfoundexception { boolean done = bool_ ; while ( ! done ) { try { this . pairs . add ( retrievenextpair ( row , this . pairs , rownumber ) ) ; } catch ( notfoundexception nfe ) { if ( this . pairs . isempty ( ) ) { throw nfe ; }	Not private for testing.
private list < expandedpair > checkrows ( list < expandedrow > collectedrows , int currentrow ) throws notfoundexception { for ( int i = currentrow ; i < rows . size ( ) ; i ++ ) { expandedrow row = rows . get ( i ) ; this . pairs . clear ( ) ; for ( expandedrow collectedrow : collectedrows ) { this . pairs . addall ( collectedrow . getpairs ( ) ) ; } this . pairs . addall ( row . getpairs ( ) ) ; if ( ! isvalidsequence ( this . pairs ) ) { continue ; } if ( checkchecksum ( ) ) { return this . pairs ; } list < expandedrow > rs = new arraylist < > ( collectedrows ) ; rs . add ( row ) ; try {	Recursion is used to implement backtracking.
private static boolean isvalidsequence ( list < expandedpair > pairs ) { for ( int [ ] sequence : finder_pattern_sequences ) { if ( pairs . size ( ) > sequence . length ) { continue ; } boolean stop = bool_ ; for ( int j = num_ ; j < pairs . size ( ) ; j ++ ) { if ( pairs . get ( j ) . getfinderpattern ( ) . getvalue ( ) != sequence [ j ] ) { stop = bool_ ; break ; } } if ( stop ) { return bool_ ; } } return bool_ ; }	either complete or a prefix.
private static void removepartialrows ( list < expandedpair > pairs , list < expandedrow > rows ) { for ( iterator < expandedrow > iterator = rows . iterator ( ) ; iterator . hasnext ( ) ; ) { expandedrow r = iterator . next ( ) ; if ( r . getpairs ( ) . size ( ) == pairs . size ( ) ) { continue ; } boolean allfound = bool_ ; for ( expandedpair p : r . getpairs ( ) ) { boolean found = bool_ ; for ( expandedpair pp : pairs ) { if ( p . equals ( pp ) ) { found = bool_ ; break ; } } if ( ! found ) { allfound = bool_ ; break ; } } if ( allfound ) {	Remove all the rows that contains only specified pairs.
private static boolean ispartialrow ( iterable < expandedpair > pairs , iterable < expandedrow > rows ) { for ( expandedrow r : rows ) { boolean allfound = bool_ ; for ( expandedpair p : pairs ) { boolean found = bool_ ; for ( expandedpair pp : r . getpairs ( ) ) { if ( p . equals ( pp ) ) { found = bool_ ; break ; } } if ( ! found ) { allfound = bool_ ; break ; } } if ( allfound ) {	Returns true when one of the rows already contains all the pairs.
static result constructresult ( list < expandedpair > pairs ) throws notfoundexception , formatexception { bitarray binary = bitarraybuilder . buildbitarray ( pairs ) ; abstractexpandeddecoder decoder = abstractexpandeddecoder . createdecoder ( binary ) ; string resultingstring = decoder . parseinformation ( ) ; resultpoint [ ] firstpoints = pairs . get ( num_ ) . getfinderpattern ( ) . getresultpoints ( ) ; resultpoint [ ] lastpoints = pairs . get ( pairs . size ( ) - num_ ) . getfinderpattern ( ) . getresultpoints ( ) ; return new result ( resultingstring , null , new resultpoint [ ] { firstpoints [ num_ ] , firstpoints [ num_ ] , lastpoints [ num_ ] , lastpoints [ num_ ] } , barcodeformat . rss_expanded ) ; }	Not private for unit testing.
private static int calculatemaskpenalty ( bytematrix matrix ) { return maskutil . applymaskpenaltyrule1 ( matrix ) + maskutil . applymaskpenaltyrule2 ( matrix ) + maskutil . applymaskpenaltyrule3 ( matrix ) + maskutil . applymaskpenaltyrule4 ( matrix ) ; }	Basically it applies four rules and summate all penalties.
private static version recommendversion ( errorcorrectionlevel eclevel , mode mode , bitarray headerbits , bitarray databits ) throws writerexception {	Decides the smallest version of QR code that will contain all of the provided data.
static void appendlengthinfo ( int numletters , version version , mode mode , bitarray bits ) throws writerexception { int numbits = mode . getcharactercountbits ( version ) ; if ( numletters >= ( num_ << numbits ) ) { throw new writerexception ( numletters + str_ + ( ( num_ << numbits ) - num_ ) ) ; } bits . appendbits ( numletters , numbits ) ; }	Append length info. On success, store the result in "bits".
@ override public productparsedresult parse ( result result ) { barcodeformat format = result . getbarcodeformat ( ) ; if ( ! ( format == barcodeformat . upc_a || format == barcodeformat . upc_e || format == barcodeformat . ean_8 || format == barcodeformat . ean_13 ) ) { return null ; } string rawtext = getmassagedtext ( result ) ; if ( ! isstringofdigits ( rawtext , rawtext . length ( ) ) ) { return null ; }	Treat all UPC and EAN variants as UPCs, in the sense that they are all product barcodes.
private int [ ] determinedimensions ( int sourcecodewords , int errorcorrectioncodewords ) throws writerexception { float ratio = num_ ; int [ ] dimension = null ; for ( int cols = mincols ; cols <= maxcols ; cols ++ ) { int rows = calculatenumberofrows ( sourcecodewords , errorcorrectioncodewords , cols ) ; if ( rows < minrows ) { break ; } if ( rows > maxrows ) { continue ; } float newratio = ( ( float ) ( num_ * cols + num_ ) * default_module_width ) / ( rows * height ) ;	Determine optimal nr of columns and rows for the specified number ofcodewords.
public void applymirroredcorrection ( resultpoint [ ] points ) { if ( ! mirrored || points == null || points . length < num_ ) { return ; } resultpoint bottomleft = points [ num_ ] ; points [ num_ ] = points [ num_ ] ; points [ num_ ] = bottomleft ;	Apply the result points' order correction due to mirroring.
void setvalue ( int value ) { integer confidence = values . get ( value ) ; if ( confidence == null ) { confidence = num_ ; } confidence ++ ; values . put ( value , confidence ) ; }	Add an occurrence of a value.
int [ ] getvalue ( ) { int maxconfidence = - num_ ; collection < integer > result = new arraylist < > ( ) ; for ( entry < integer , integer > entry : values . entryset ( ) ) { if ( entry . getvalue ( ) > maxconfidence ) { maxconfidence = entry . getvalue ( ) ; result . clear ( ) ; result . add ( entry . getkey ( ) ) ; } else if ( entry . getvalue ( ) == maxconfidence ) { result . add ( entry . getkey ( ) ) ; } } return pdf417common . tointarray ( result ) ; }	Determines the maximum occurrence of a set value and returns all values which were set with this occurrence.
private collection < state > updatestatelistforchar ( iterable < state > states , int index ) { collection < state > result = new linkedlist < > ( ) ; for ( state state : states ) { updatestateforchar ( state , index , result ) ; } return simplifystates ( result ) ; }	non-optimal states.
private void updatestateforchar ( state state , int index , collection < state > result ) { char ch = ( char ) ( text [ index ] & num_ ) ; boolean charincurrenttable = char_map [ state . getmode ( ) ] [ ch ] > num_ ; state statenobinary = null ; for ( int mode = num_ ; mode <= mode_punct ; mode ++ ) { int charinmode = char_map [ mode ] [ ch ] ; if ( charinmode > num_ ) { if ( statenobinary == null ) {	the "result" list.
@ override public charsequence getdisplaycontents ( ) { string contents = getresult ( ) . getdisplayresult ( ) ; contents = contents . replace ( str_ , str_ ) ; return formatphone ( contents ) ; }	Overriden so we can take advantage of Android's phone number hyphenation routines.
private void drawresultpoints ( bitmap barcode , float scalefactor , result rawresult ) { resultpoint [ ] points = rawresult . getresultpoints ( ) ; if ( points != null && points . length > num_ ) { canvas canvas = new canvas ( barcode ) ; paint paint = new paint ( ) ; paint . setcolor ( getresources ( ) . getcolor ( r . color . result_points ) ) ; if ( points . length == num_ ) { paint . setstrokewidth ( num_ ) ; drawline ( canvas , paint , points [ num_ ] , points [ num_ ] , scalefactor ) ; } else if ( points . length == num_ && ( rawresult . getbarcodeformat ( ) == barcodeformat . upc_a || rawresult . getbarcodeformat ( ) == barcodeformat . ean_13 ) ) {	Superimpose a line for 1D or dots for 2D to highlight the key features of the barcode.
private resultpoint [ ] centeredges ( resultpoint y , resultpoint z , resultpoint x , resultpoint t ) {	recenters the points of a constant distance towards the center.
private boolean containsblackpoint ( int a , int b , int fixed , boolean horizontal ) { if ( horizontal ) { for ( int x = a ; x <= b ; x ++ ) { if ( image . get ( x , fixed ) ) { return bool_ ; } } } else { for ( int y = a ; y <= b ; y ++ ) { if ( image . get ( fixed , y ) ) { return bool_ ; } } } return bool_ ; }	Determines whether a segment contains a black point.
private void addcalendarevent ( string summary , long start , boolean allday , long end , string location , string description , string [ ] attendees ) { intent intent = new intent ( intent . action_insert ) ; intent . settype ( str_ ) ; intent . putextra ( str_ , start ) ; if ( allday ) { intent . putextra ( str_ , bool_ ) ; } if ( end < num_ ) { if ( allday ) {	Sends an intent to create a new calendar event by prepopulating the Add Event UI.
private static string getencodeddata ( boolean [ ] correctedbits ) { int endindex = correctedbits . length ; table latchtable = table . upper ;	Gets the string encoded in the aztec code bits.
private static table gettable ( char t ) { switch ( t ) { case str_ : return table . lower ; case str_ : return table . punct ; case str_ : return table . mixed ; case str_ : return table . digit ; case str_ : return table . binary ; case str_ : default : return table . upper ; } }	gets the table corresponding to the char passed.
private boolean [ ] extractbits ( bitmatrix matrix ) { boolean compact = ddata . iscompact ( ) ; int layers = ddata . getnblayers ( ) ; int basematrixsize = ( compact ? num_ : num_ ) + layers * num_ ;	Gets the array of bits from an Aztec Code matrix.
private static int readcode ( boolean [ ] rawbits , int startindex , int length ) { int res = num_ ; for ( int i = startindex ; i < startindex + length ; i ++ ) { res <<= num_ ; if ( rawbits [ i ] ) { res |= num_ ; } } return res ; }	Reads a code of given length and at given index in an array of bits.
private static byte readbyte ( boolean [ ] rawbits , int startindex ) { int n = rawbits . length - startindex ; if ( n >= num_ ) { return ( byte ) readcode ( rawbits , startindex , num_ ) ; } return ( byte ) ( readcode ( rawbits , startindex , n ) << ( num_ - n ) ) ; }	Reads a code of length 8 in an array of bits, padding with zeros.
static byte [ ] convertboolarraytobytearray ( boolean [ ] boolarr ) { byte [ ] bytearr = new byte [ ( boolarr . length + num_ ) / num_ ] ; for ( int i = num_ ; i < bytearr . length ; i ++ ) { bytearr [ i ] = readbyte ( boolarr , num_ * i ) ; } return bytearr ; }	Packs a bit array into bytes, most significant bit first.
public static string convertupcetoupca ( string upce ) { char [ ] upcechars = new char [ num_ ] ; upce . getchars ( num_ , num_ , upcechars , num_ ) ; stringbuilder result = new stringbuilder ( num_ ) ; result . append ( upce . charat ( num_ ) ) ; char lastchar = upcechars [ num_ ] ; switch ( lastchar ) { case str_ : case str_ : case str_ : result . append ( upcechars , num_ , num_ ) ; result . append ( lastchar ) ; result . append ( str_ ) ; result . append ( upcechars , num_ , num_ ) ; break ; case str_ : result . append ( upcechars , num_ , num_ ) ; result . append ( str_ ) ; result . append ( upcechars , num_ , num_ ) ; break ; case str_ : result . append ( upcechars , num_ , num_ ) ; result . append ( str_ ) ; result . append ( upcechars [ num_ ] ) ; break ; default : result . append ( upcechars , num_ , num_ ) ; result . append ( str_ ) ; result . append ( lastchar ) ; break ; }	Expands a UPC-E value back into its full, equivalent UPC-A code value.
@ override public result decode ( binarybitmap image , map < decodehinttype , ? > hints ) throws notfoundexception { sethints ( hints ) ; return decodeinternal ( image ) ; }	Decode an image using the hints provided.
private void utah ( int row , int col , int pos ) { module ( row - num_ , col - num_ , pos , num_ ) ; module ( row - num_ , col - num_ , pos , num_ ) ; module ( row - num_ , col - num_ , pos , num_ ) ; module ( row - num_ , col - num_ , pos , num_ ) ; module ( row - num_ , col , pos , num_ ) ; module ( row , col - num_ , pos , num_ ) ; module ( row , col - num_ , pos , num_ ) ; module ( row , col , pos , num_ ) ; }	Places the 8 bits of a utah-shaped symbol character in ECC200.
private static string massageuri ( string uri ) { uri = uri . trim ( ) ; int protocolend = uri . indexof ( str_ ) ; if ( protocolend < num_ || iscolonfollowedbyportnumber ( uri , protocolend ) ) {	Transforms a string that represents a URI into something more proper, by adding or canonicalizingthe protocol.
public static simplepagedecorator first ( ) { list < simplepagedecorator > decorators = all ( ) ; return decorators . isempty ( ) ? null : decorators . get ( num_ ) ; }	The first found LoginDecarator, there can only be one.
protected map < computer , t > monitor ( ) throws interruptedexception { map < computer , t > data = new hashmap < > ( ) ; for ( computer c : jenkins . getinstance ( ) . getcomputers ( ) ) { try { thread . currentthread ( ) . setname ( str_ + c . getdisplayname ( ) + str_ + getdisplayname ( ) ) ; if ( c . getchannel ( ) == null ) data . put ( c , null ) ; else data . put ( c , monitor ( c ) ) ; } catch ( runtimeexception | ioexception e ) { logger . log ( level . warning , str_ + c . getdisplayname ( ) + str_ + getdisplayname ( ) , e ) ; } catch ( interruptedexception e ) { throw ( interruptedexception ) new interruptedexception ( str_ + c . getdisplayname ( ) + str_ + getdisplayname ( ) + str_ ) . initcause ( e ) ; } } return data ; }	Performs monitoring across the board.
public t get ( computer c ) { if ( record == null || ! record . data . containskey ( c ) ) {	Obtains the monitoring result currently available, or null if no data is available.
public boolean isignored ( ) { nodemonitor m = computerset . getmonitors ( ) . get ( this ) ; return m == null || m . isignored ( ) ; }	Is this monitor currently ignored?.
protected boolean markonline ( computer c ) { if ( isignored ( ) || c . isonline ( ) ) return bool_ ;	Utility method to mark the computer online for derived classes.
protected boolean markoffline ( computer c , offlinecause oc ) { if ( isignored ( ) || c . istemporarilyoffline ( ) ) return bool_ ;	Utility method to mark the computer offline for derived classes.
public string getcrumb ( servletrequest request ) { string crumb = null ; if ( request != null ) { crumb = ( string ) request . getattribute ( crumb_attribute ) ; } if ( crumb == null ) { crumb = issuecrumb ( request , getdescriptor ( ) . getcrumbsalt ( ) ) ; if ( request != null ) { if ( ( crumb != null ) && crumb . length ( ) > num_ ) { request . setattribute ( crumb_attribute , crumb ) ; } else { request . removeattribute ( crumb_attribute ) ; } } } return crumb ; }	Get a crumb value based on user specific information in the request.
public boolean validatecrumb ( servletrequest request ) { crumbissuerdescriptor < crumbissuer > desc = getdescriptor ( ) ; string crumbfield = desc . getcrumbrequestfield ( ) ; string crumbsalt = desc . getcrumbsalt ( ) ; return validatecrumb ( request , crumbsalt , request . getparameter ( crumbfield ) ) ; }	Get a crumb from a request parameter and validate it against other datain the current request.
public boolean validatecrumb ( servletrequest request , multipartformdataparser parser ) { crumbissuerdescriptor < crumbissuer > desc = getdescriptor ( ) ; string crumbfield = desc . getcrumbrequestfield ( ) ; string crumbsalt = desc . getcrumbsalt ( ) ; return validatecrumb ( request , crumbsalt , parser . get ( crumbfield ) ) ; }	Get a crumb from multipart form data and validate it against other datain the current request.
@ initializer public static void initstaplercrumbissuer ( ) { webapp . get ( jenkins . getinstance ( ) . servletcontext ) . setcrumbissuer ( new org . kohsuke . stapler . crumbissuer ( ) { @ override public string issuecrumb ( staplerrequest request ) { crumbissuer ci = jenkins . getinstance ( ) . getcrumbissuer ( ) ; return ci != null ? ci . getcrumb ( request ) : default . issuecrumb ( request ) ; } @ override public void validatecrumb ( staplerrequest request , string submittedcrumb ) { crumbissuer ci = jenkins . getinstance ( ) . getcrumbissuer ( ) ; if ( ci == null ) { default . validatecrumb ( request , submittedcrumb ) ; } else { if ( ! ci . validatecrumb ( request , ci . getdescriptor ( ) . getcrumbsalt ( ) , submittedcrumb ) ) throw new securityexception ( str_ ) ; } } } ) ; }	Sets up Stapler to use our crumb issuer.
public string getpublickey ( ) { rsapublickey key = instanceidentityprovider . rsa . getpublickey ( ) ; if ( key == null ) { return null ; } byte [ ] encoded = base64 . encodebase64 ( key . getencoded ( ) ) ; int index = num_ ; stringbuilder buf = new stringbuilder ( encoded . length + num_ ) ; while ( index < encoded . length ) { int len = math . min ( num_ , encoded . length - index ) ; if ( index > num_ ) { buf . append ( str_ ) ; } buf . append ( new string ( encoded , index , len , charsets . utf_8 ) ) ; index += len ; } return string . format ( str_ , buf . tostring ( ) ) ; }	Returns the PEM encoded public key.
public string getfingerprint ( ) { rsapublickey key = instanceidentityprovider . rsa . getpublickey ( ) ; if ( key == null ) { return null ; }	Returns the fingerprint of the public key.
public void dojson ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { if ( req . getparameter ( str_ ) == null || permit ( req ) ) { setheaders ( rsp ) ; rsp . serveexposedbean ( req , bean , req . getparameter ( str_ ) == null ? flavor . json : flavor . jsonp ) ; } else { rsp . senderror ( httpurlconnection . http_forbidden , str_ ) ; } }	Exposes the bean as JSON.
public void dopython ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { setheaders ( rsp ) ; rsp . serveexposedbean ( req , bean , flavor . python ) ; }	Exposes the bean as Python literal.
@ restricted ( noexternaluse . class ) public static causeaction getbuildcause ( parameterizedjob job , staplerrequest req ) { cause cause ; @ suppresswarnings ( str_ ) hudson . model . buildauthorizationtoken authtoken = job . getauthtoken ( ) ; if ( authtoken != null && authtoken . gettoken ( ) != null && req . getparameter ( str_ ) != null ) {	Computes the build cause, using RemoteCause or UserCause as appropriate.
public static @ checkfornull < t extends trigger < ? > > t gettrigger ( job < ? , ? > job , class < t > clazz ) { if ( ! ( job instanceof parameterizedjob ) ) { return null ; } for ( trigger < ? > t : ( ( parameterizedjob < ? , ? > ) job ) . gettriggers ( ) . values ( ) ) { if ( clazz . isinstance ( t ) ) { return clazz . cast ( t ) ; } } return null ; }	Checks for the existence of a specific trigger on a job.
public synchronized string get ( ) { confidentialstore cs = confidentialstore . get ( ) ; if ( secret == null || cs != lastcs ) { lastcs = cs ; try { byte [ ] payload = load ( ) ; if ( payload == null ) { payload = cs . randombytes ( length / num_ ) ; store ( payload ) ; } secret = util . tohexstring ( payload ) . substring ( num_ , length ) ; } catch ( ioexception e ) { throw new error ( str_ + getid ( ) , e ) ; } } return secret ; }	Returns the persisted hex string value.If the value isn't persisted, a new random value is created.
public void replaceby ( map < ? extends k , ? extends v > data ) { map < k , v > d = copy ( ) ; d . clear ( ) ; d . putall ( data ) ; update ( d ) ; }	Atomically replaces the entire map by the copy of the specified map.
public @ checkfornull filepath getworkspaceroot ( ) { filepath r = getrootpath ( ) ; if ( r == null ) return null ; return r . child ( workspace_root ) ; }	Root directory on this agent where all the job workspaces are laid out.
@ nonnull public launcher createlauncher ( tasklistener listener ) { slavecomputer c = getcomputer ( ) ; if ( c == null ) { listener . error ( str_ + name + str_ ) ; return new launcher . dummylauncher ( listener ) ; } else {	Creates a launcher for the agent.
public static void skip ( datainputstream in ) throws ioexception { byte [ ] preamble = new byte [ preamble . length ] ; in . readfully ( preamble ) ; if ( ! arrays . equals ( preamble , preamble ) ) return ;	Skips the encoded console note.
public static int findpreamble ( byte [ ] buf , int start , int len ) { int e = start + len - preamble . length + num_ ; outer : for ( int i = start ; i < e ; i ++ ) { if ( buf [ i ] == preamble [ num_ ] ) {	Locates the preamble in the given buffer.
public static list < string > removenotes ( collection < string > loglines ) { list < string > r = new arraylist < > ( loglines . size ( ) ) ; for ( string l : loglines ) r . add ( removenotes ( l ) ) ; return r ; }	Removes the embedded console notes in the given log lines.
public static string removenotes ( string line ) { while ( bool_ ) { int idx = line . indexof ( preamble_str ) ; if ( idx < num_ ) return line ; int e = line . indexof ( postamble_str , idx ) ; if ( e < num_ ) return line ; line = line . substring ( num_ , idx ) + line . substring ( e + postamble_str . length ( ) ) ; } }	Removes the embedded console notes in the given log line.
protected string getdisplaynameof ( method e , t i ) { class < ? > c = e . getdeclaringclass ( ) ; string key = displaynameof ( i ) ; if ( key . length ( ) == num_ ) return c . getsimplename ( ) + str_ + e . getname ( ) ; try { resourcebundleholder rb = resourcebundleholder . get ( c . getclassloader ( ) . loadclass ( c . getpackage ( ) . getname ( ) + str_ ) ) ; return rb . format ( key ) ; } catch ( classnotfoundexception x ) { logger . log ( warning , str_ + x . getmessage ( ) + str_ + e . tostring ( ) , x ) ; return key ; } catch ( missingresourceexception x ) { logger . log ( warning , str_ + key + str_ + c . getpackage ( ) . getname ( ) + str_ , x ) ; return key ; } }	Obtains the display name of the given initialization task.
protected void invoke ( method e ) { try { class < ? > [ ] pt = e . getparametertypes ( ) ; object [ ] args = new object [ pt . length ] ; for ( int i = num_ ; i < args . length ; i ++ ) args [ i ] = lookup ( pt [ i ] ) ; e . invoke ( modifier . isstatic ( e . getmodifiers ( ) ) ? null : lookup ( e . getdeclaringclass ( ) ) , args ) ; } catch ( illegalaccessexception x ) { throw ( error ) new illegalaccesserror ( ) . initcause ( x ) ; } catch ( invocationtargetexception x ) { throw new error ( x ) ; } }	Invokes the given initialization method.
private object lookup ( class < ? > type ) { jenkins j = jenkins . getinstance ( ) ; assert j != null : str_ ; if ( type == jenkins . class || type == hudson . class ) return j ; injector i = j . getinjector ( ) ; if ( i != null ) return i . getinstance ( type ) ; throw new illegalargumentexception ( str_ + type ) ; }	Determines the parameter injection of the initialization method.
@ nonnull public string getdescription ( ) { stapler stapler = stapler . getcurrent ( ) ; if ( stapler != null ) { try { webapp webapp = webapp . getcurrent ( ) ; metaclass meta = webapp . getmetaclass ( this ) ; script s = meta . loadtearoff ( jellyclasstearoff . class ) . findscript ( str_ ) ; if ( s == null ) { return str_ ; } defaultscriptinvoker dsi = new defaultscriptinvoker ( ) ; stringwriter sw = new stringwriter ( ) ; xmloutput xml = dsi . createxmloutput ( sw , bool_ ) ; dsi . invokescript ( stapler . getcurrentrequest ( ) , stapler . getcurrentresponse ( ) , s , this , xml ) ; return sw . tostring ( ) ; } catch ( exception e ) { logger . log ( level . warning , null , e ) ; return str_ ; } } else { return str_ ; } }	A description of this kind of item type.
@ checkfornull @ deprecated public string geticonfilepath ( string size ) { if ( ! stringutils . isblank ( geticonfilepathpattern ( ) ) ) { return geticonfilepathpattern ( ) . replace ( str_ , size ) ; } return null ; }	An icon file path associated to a specific size.
public maveninstallation getmaven ( ) { for ( maveninstallation i : getdescriptor ( ) . getinstallations ( ) ) { if ( mavenname != null && mavenname . equals ( i . getname ( ) ) ) return i ; } return null ; }	Gets the Maven to invoke,or null to invoke the default one.
protected void buildenvvars ( envvars env , maveninstallation mi ) throws ioexception , interruptedexception { if ( mi != null ) {	Build up the environment variables toward the Maven launch.
public static boolean checkisreachable ( inetaddress ia , int timeout ) throws ioexception { for ( computerpinger pinger : computerpinger . all ( ) ) { try { if ( pinger . isreachable ( ia , timeout ) ) { return bool_ ; } } catch ( ioexception e ) { logger . fine ( str_ + pinger + str_ + e . getmessage ( ) ) ; } } return bool_ ; }	Is this computer reachable via the given address?.
protected pluginstrategy createpluginstrategy ( ) { string strategyname = systemproperties . getstring ( pluginstrategy . class . getname ( ) ) ; if ( strategyname != null ) { try { class < ? > klazz = getclass ( ) . getclassloader ( ) . loadclass ( strategyname ) ; object strategy = klazz . getconstructor ( pluginmanager . class ) . newinstance ( this ) ; if ( strategy instanceof pluginstrategy ) { logger . info ( str_ + strategyname ) ; return ( pluginstrategy ) strategy ; } else { logger . warning ( str_ + strategyname + str_ ) ; } } catch ( classnotfoundexception e ) { logger . warning ( str_ + strategyname ) ; } catch ( exception e ) { logger . log ( warning , str_ + strategyname + str_ , e ) ; } logger . info ( str_ ) ; }	Creates a hudson.PluginStrategy, looking at the corresponding system property.
@ checkfornull public pluginwrapper getplugin ( string shortname ) { for ( pluginwrapper p : getplugins ( ) ) { if ( p . getshortname ( ) . equals ( shortname ) ) return p ; } return null ; }	Get the plugin instance with the given short name.
public void stop ( ) { for ( pluginwrapper p : activeplugins ) { p . stop ( ) ; p . releaseclassloader ( ) ; } activeplugins . clear ( ) ;	Orderly terminates all the plugins.
@ restricted ( donotuse . class )	Get the list of all plugins - available and installed.
@ requirepost @ restricted ( donotuse . class )	Installs a list of plugins from a JSON POST.
@ requirepost public httpresponse douploadplugin ( staplerrequest req ) throws ioexception , servletexception { try { jenkins . getinstance ( ) . checkpermission ( upload_plugins ) ; servletfileupload upload = new servletfileupload ( new diskfileitemfactory ( ) ) ;	Uploads a plugin.
public map < string , versionnumber > parserequestedplugins ( inputstream configxml ) throws ioexception { final map < string , versionnumber > requestedplugins = new treemap < > ( ) ; try { saxparserfactory . newinstance ( ) . newsaxparser ( ) . parse ( configxml , new defaulthandler ( ) { @ override public void startelement ( string uri , string localname , string qname , attributes attributes ) throws saxexception { string plugin = attributes . getvalue ( str_ ) ; if ( plugin == null ) { return ; } if ( ! plugin . matches ( str_ ) ) { throw new saxexception ( str_ + plugin ) ; } int at = plugin . indexof ( str_ ) ; string shortname = plugin . substring ( num_ , at ) ; versionnumber existing = requestedplugins . get ( shortname ) ; versionnumber requested = new versionnumber ( plugin . substring ( at + num_ ) ) ; if ( existing == null || existing . compareto ( requested ) < num_ ) { requestedplugins . put ( shortname , requested ) ; } } @ override public inputsource resolveentity ( string publicid , string systemid ) throws ioexception , saxexception { return restrictiveentityresolver . instance . resolveentity ( publicid , systemid ) ; } } ) ; } catch ( saxexception x ) { throw new ioexception ( str_ , x ) ; } catch ( parserconfigurationexception e ) { throw new assertionerror ( e ) ;	Parses configuration XML files and picks up references to XML files.
public jfreechart createchart ( categorydataset ds ) { final jfreechart chart = chartfactory . createlinechart ( null ,	Creates a trend chart.
protected void updatecounts ( loadstatisticssnapshot current ) { definedexecutors . update ( current . getdefinedexecutors ( ) ) ; onlineexecutors . update ( current . getonlineexecutors ( ) ) ; connectingexecutors . update ( current . getconnectingexecutors ( ) ) ; busyexecutors . update ( current . getbusyexecutors ( ) ) ; idleexecutors . update ( current . getidleexecutors ( ) ) ; availableexecutors . update ( current . getavailableexecutors ( ) ) ; queuelength . update ( current . getqueuelength ( ) ) ; }	Updates all the series from the current snapshot.
public loadstatisticssnapshot computesnapshot ( ) { if ( modern ) { return computesnapshot ( jenkins . getinstance ( ) . getqueue ( ) . getbuildableitems ( ) ) ; } else { int t = computetotalexecutors ( ) ; int i = computeidleexecutors ( ) ; return new loadstatisticssnapshot ( t , t , math . max ( i - t , num_ ) , math . max ( t - i , num_ ) , i , i , computequeuelength ( ) ) ; } }	Computes a self-consistent snapshot of the load statistics.Note: The original method of computing load statistics would compute the total and idle counts independentlywhich could lead to counting errors while jobs started in between the different state counting operations.By returning a {.
protected loadstatisticssnapshot computesnapshot ( iterable < queue . buildableitem > queue ) { final loadstatisticssnapshot . builder builder = loadstatisticssnapshot . builder ( ) ; final iterable < node > nodes = getnodes ( ) ; if ( nodes != null ) { for ( node node : nodes ) { builder . with ( node ) ; } } int q = num_ ; if ( queue != null ) { for ( queue . buildableitem item : queue ) { for ( subtask st : item . task . getsubtasks ( ) ) { if ( matches ( item , st ) ) q ++ ; } } } return builder . withqueuelength ( q ) . build ( ) ; }	Computes the self-consistent snapshot with the specified queue items.
protected void eol ( byte [ ] in , int sz ) throws ioexception { int next = consolenote . findpreamble ( in , num_ , sz ) ;	Called after we read the whole line of plain text.
public final void process ( ) throws ioexception , servletexception { if ( permission != null ) try { if ( subject == null ) throw new accessdeniedexception ( str_ ) ; subject . checkpermission ( permission ) ; } catch ( accessdeniedexception e ) {	Runs the validation code.
protected final file getfileparameter ( string paramname ) { return new file ( util . fixnull ( request . getparameter ( paramname ) ) ) ; }	Gets the parameter as a file.
public void respond ( string html ) throws ioexception , servletexception { response . setcontenttype ( str_ ) ; response . getwriter ( ) . print ( html ) ; }	Sends out an arbitrary HTML fragment.
public void dopng ( staplerrequest req , staplerresponse rsp ) throws ioexception { if ( req . checkifmodified ( timestamp , rsp ) ) return ; try { bufferedimage image = render ( req , null ) ; rsp . setcontenttype ( str_ ) ; servletoutputstream os = rsp . getoutputstream ( ) ; imageio . write ( image , str_ , os ) ; os . close ( ) ; } catch ( error e ) { if ( e . getmessage ( ) . contains ( str_ ) ) { rsp . sendredirect2 ( req . getcontextpath ( ) + str_ ) ; return ; } throw e ;	Renders a graph.
public void domap ( staplerrequest req , staplerresponse rsp ) throws ioexception { if ( req . checkifmodified ( timestamp , rsp ) ) return ; chartrenderinginfo info = new chartrenderinginfo ( ) ; render ( req , info ) ; rsp . setcontenttype ( str_ ) ; rsp . getwriter ( ) . println ( chartutilities . getimagemap ( str_ , info ) ) ; }	Renders a clickable map.
public long getinitialdelay ( ) { long l = random . nextlong ( ) ;	Gets the number of milliseconds til the first execution. By default it chooses the value randomly between 0 and {.
public void recordcauseofinterruption ( run < ? , ? > build , tasklistener listener ) { list < causeofinterruption > r ;	report cause of interruption and record it to the build, if available.
public @ checkfornull queue . executable getcurrentexecutable ( ) { lock . readlock ( ) . lock ( ) ; try { return executable ; } finally { lock . readlock ( ) . unlock ( ) ; } }	Returns the current build this executor is running.
public @ checkfornull asynchronousexecution getasynchronousexecution ( ) { lock . readlock ( ) . lock ( ) ; try { return asynchronousexecution ; } finally { lock . readlock ( ) . unlock ( ) ; } }	If currently running in asynchronous mode, returns that handle.
@ exported public int getprogress ( ) { long d = executableestimatedduration ; if ( d <= num_ ) { return default_estimated_duration ; } int num = ( int ) ( getelapsedtime ( ) * num_ / d ) ; if ( num >= num_ ) { num = num_ ; } return num ; }	Returns the progress of the current build in the number between 0-100.
@ exported public boolean islikelystuck ( ) { lock . readlock ( ) . lock ( ) ; try { if ( executable == null ) { return bool_ ; } } finally { lock . readlock ( ) . unlock ( ) ; } long elapsed = getelapsedtime ( ) ; long d = executableestimatedduration ; if ( d >= num_ ) {	Returns true if the current build is likely stuck.
public long gettimespentinqueue ( ) { lock . readlock ( ) . lock ( ) ; try { return starttime - workunit . context . item . buildablestartmilliseconds ; } finally { lock . readlock ( ) . unlock ( ) ; } }	Returns the number of milli-seconds the currently executing job spent in the queuewaiting for an available executor.
public string getestimatedremainingtime ( ) { long d = executableestimatedduration ; if ( d < num_ ) { return messages . executor_notavailable ( ) ; } long eta = d - getelapsedtime ( ) ; if ( eta <= num_ ) { return messages . executor_notavailable ( ) ; } return util . gettimespanstring ( eta ) ; }	Computes a human-readable text that shows the expected remaining timeuntil the build completes.
@ requirepost public httpresponse dostop ( ) { lock . writelock ( ) . lock ( ) ;	Stops the current build.
public boolean hasstoppermission ( ) { lock . readlock ( ) . lock ( ) ; try { return executable != null && getparentof ( executable ) . getownertask ( ) . hasabortpermission ( ) ; } finally { lock . readlock ( ) . unlock ( ) ; } }	Checks if the current user has a permission to stop this build.
public long getidlestartmilliseconds ( ) { if ( isidle ( ) ) return math . max ( creationtime , owner . getconnecttime ( ) ) ; else { return math . max ( starttime + math . max ( num_ , executableestimatedduration ) , system . currenttimemillis ( ) + num_ ) ; } }	Returns when this executor started or should start being idle.
public < t > t newimpersonatingproxy ( class < t > type , t core ) { return new interceptingproxy ( ) { protected object call ( object o , method m , object [ ] args ) throws throwable { final executor old = impersonation . get ( ) ; impersonation . set ( executor . this ) ; try { return m . invoke ( o , args ) ; } finally { impersonation . set ( old ) ; } } } . wrap ( type , core ) ; }	Creates a proxy object that executes the callee in the context that impersonatesthis executor.
public static @ checkfornull executor currentexecutor ( ) { thread t = thread . currentthread ( ) ; if ( t instanceof executor ) return ( executor ) t ; return impersonation . get ( ) ; }	Returns the executor of the current thread or null if current thread is not an executor.
@ checkfornull public static executor of ( executable executable ) { jenkins jenkins = jenkins . getinstanceornull ( ) ;	Finds the executor currently running a given process.
public searchresult getsuggestions ( staplerrequest req , string query ) { set < string > paths = new hashset < > ( ) ;	Gets the list of suggestions that match the given query.
private searchindex makesuggestindex ( staplerrequest req ) { searchindexbuilder builder = new searchindexbuilder ( ) ; for ( ancestor a : req . getancestors ( ) ) { if ( a . getobject ( ) instanceof searchablemodelobject ) { searchablemodelobject smo = ( searchablemodelobject ) a . getobject ( ) ; builder . add ( smo . getsearchindex ( ) ) ; } } return builder . make ( ) ; }	Creates merged search index for suggestion.
static suggesteditem findclosestsuggesteditem ( list < suggesteditem > r , string query ) { for ( suggesteditem curitem : r ) { if ( logger . isloggable ( level . fine ) ) { logger . fine ( string . format ( str_ , curitem . item . getsearchurl ( ) , query ) ) ; } if ( curitem . item . getsearchurl ( ) . contains ( util . rawencode ( query ) ) ) { return curitem ; } }	When there are multiple suggested items, this method can narrow down the resultsetto the SuggestedItem that has a url that contains the query.
public static suggesteditem find ( searchindex index , string query , searchablemodelobject searchcontext ) { list < suggesteditem > r = find ( mode . find , index , query , searchcontext ) ; if ( r . isempty ( ) ) { return null ; } else if ( num_ == r . size ( ) ) { return r . get ( num_ ) ; } else {	Performs a search and returns the match, or null if no match was foundor more than one match was found.
private inputstream transformforwindows ( inputstream src ) throws ioexception { bufferedreader r = new bufferedreader ( new inputstreamreader ( src ) ) ; bytearrayoutputstream out = new bytearrayoutputstream ( ) ; try ( printstream p = new printstream ( out ) ) { string line ; while ( ( line = r . readline ( ) ) != null ) { if ( ! line . startswith ( str_ ) && functions . iswindows ( ) ) line = line . replace ( str_ , str_ ) ; p . println ( line ) ; } } return new bytearrayinputstream ( out . tobytearray ( ) ) ; }	Transform path for Windows.
@ requirepost public httpresponse doapproveall ( ) throws ioexception { stringbuilder buf = new stringbuilder ( ) ; for ( class c : rejected . get ( ) ) { buf . append ( c . getname ( ) ) . append ( str_ ) ; } whitelisted . append ( buf . tostring ( ) ) ; return httpresponses . ok ( ) ; }	Approves all the currently rejected subjects.
public void setcrumbsalt ( string salt ) { if ( util . fixemptyandtrim ( salt ) == null ) { crumbsalt = str_ ; } else { crumbsalt = salt ; } }	Set the salt value.
public void setcrumbrequestfield ( string requestfield ) { if ( util . fixemptyandtrim ( requestfield ) == null ) { crumbrequestfield = crumbissuer . default_crumb_name ; } else { crumbrequestfield = requestfield ; } }	Set the request parameter name.
public string sign ( string msg ) { try { rsaprivatekey key = getprivatekey ( ) ; signature sig = signature . getinstance ( signing_algorithm + str_ + key . getalgorithm ( ) ) ; sig . initsign ( key ) ; sig . update ( msg . getbytes ( standardcharsets . utf_8 ) ) ; return hudson . remoting . base64 . encode ( sig . sign ( ) ) ; } catch ( generalsecurityexception e ) { throw new securityexception ( e ) ; } }	Sign a message and base64 encode the signature.
public static void drain ( inputstream in ) throws ioexception { org . apache . commons . io . ioutils . copy ( in , new nullstream ( ) ) ; in . close ( ) ; }	Drains the input stream and closes it.
public static inputstream skip ( inputstream in , long size ) throws ioexception { datainputstream di = new datainputstream ( in ) ; while ( size > num_ ) { int chunk = ( int ) math . min ( skip_buffer . length , size ) ; di . readfully ( skip_buffer , num_ , chunk ) ; size -= chunk ; } return in ; }	Fully skips the specified size from the given input stream. {.
public static string readfirstline ( inputstream is , string encoding ) throws ioexception { try ( bufferedreader reader = new bufferedreader ( encoding == null ? new inputstreamreader ( is ) : new inputstreamreader ( is , encoding ) ) ) { return reader . readline ( ) ; } }	Read the first line of the given stream, close it, and return that line.
private static void _transform ( source source , result out ) throws transformerexception { transformerfactory factory = transformerfactory . newinstance ( ) ; factory . setfeature ( xmlconstants . feature_secure_processing , bool_ ) ;	potentially unsafe XML transformation.
public void calcfillsettings ( string field , map < string , object > attributes ) { string capitalizedfieldname = stringutils . capitalize ( field ) ; string methodname = str_ + capitalizedfieldname + str_ ; method method = reflectionutils . getpublicmethodnamed ( getclass ( ) , methodname ) ; if ( method == null ) throw new illegalstateexception ( string . format ( str_ , getclass ( ) , methodname ) ) ;	Computes the list of other form fields that the given field depends on, via the doFillXyzItems method,and sets that as the 'fillDependsOn' attribute.
public void calcautocompletesettings ( string field , map < string , object > attributes ) { string capitalizedfieldname = stringutils . capitalize ( field ) ; string methodname = str_ + capitalizedfieldname ; method method = reflectionutils . getpublicmethodnamed ( getclass ( ) , methodname ) ; if ( method == null ) return ;	Computes the auto-completion setting.
public propertytype getglobalpropertytype ( string field ) { if ( globalpropertytypes == null ) globalpropertytypes = buildpropertytypes ( getclass ( ) ) ; return globalpropertytypes . get ( field ) ; }	Obtains the property type of the given field of this descriptor.
protected void addhelpfileredirect ( string fieldname , class < ? extends describable > owner , string fieldnametoredirectto ) { helpredirect . put ( fieldname , new helpredirect ( owner , fieldnametoredirectto ) ) ; }	Tells Jenkins that the help file for the field 'fieldName' is defined in the help file forthe 'fieldNameToRedirectTo' in the 'owner' class.
public static @ checkfornull < t extends descriptor > t findbyid ( collection < ? extends t > list , string id ) { for ( t d : list ) { if ( d . getid ( ) . equals ( id ) ) return d ; } return null ; }	Finds a descriptor from a collection by its ID.
public static @ checkfornull < t extends descriptor > t find ( collection < ? extends t > list , string string ) { t d = findbyclassname ( list , string ) ; if ( d != null ) { return d ; } return findbyid ( list , string ) ; }	Finds a descriptor from a collection by its class name or ID.
private url trytoresolveredirects ( url base , string authorization ) { try { httpurlconnection con = ( httpurlconnection ) base . openconnection ( ) ; if ( authorization != null ) { con . addrequestproperty ( str_ , authorization ) ; } con . getinputstream ( ) . close ( ) ; base = con . geturl ( ) ; } catch ( exception ex ) {	As this transport mode is using POST, it is necessary to resolve possible redirections using GET first.
protected final @ nonnull result < t > monitordetailed ( ) throws interruptedexception { map < computer , future < t > > futures = new hashmap < > ( ) ; set < computer > skipped = new hashset < > ( ) ; for ( computer c : jenkins . getinstance ( ) . getcomputers ( ) ) { try { virtualchannel ch = c . getchannel ( ) ; futures . put ( c , null ) ;	Perform monitoring with detailed reporting.
private static httpurlconnection open ( url url ) throws ioexception { httpurlconnection c = ( httpurlconnection ) url . openconnection ( ) ; c . setreadtimeout ( timeout ) ; c . setconnecttimeout ( timeout ) ; return c ; }	Connects to the given HTTP URL and configure time out, to avoid infinite hang.
public boolean shoulddisplay ( ) throws ioexception , servletexception { if ( ! functions . haspermission ( jenkins . administer ) ) { return bool_ ; } staplerrequest req = stapler . getcurrentrequest ( ) ; if ( req == null ) { return bool_ ; } list < ancestor > ancestors = req . getancestors ( ) ; if ( ancestors == null || ancestors . size ( ) == num_ ) {	Whether the administrative monitors notifier should be shown.
@ nonnull public static synchronized scheduledexecutorservice get ( ) { if ( executorservice == null ) {	Returns the scheduled executor service used by all timed tasks in Jenkins.
@ override protected void onunsuccessfulauthentication ( httpservletrequest request , httpservletresponse response , authenticationexception failed ) throws ioexception { super . onunsuccessfulauthentication ( request , response , failed ) ; logger . log ( level . fine , str_ , failed ) ; authentication auth = failed . getauthentication ( ) ; if ( auth != null ) { securitylistener . firefailedtologin ( auth . getname ( ) ) ; } }	Leave the information about login failure.
public static boolean hasfilter ( filter filter ) { jenkins j = jenkins . getinstanceornull ( ) ; pluginservletfilter container = null ; if ( j != null ) { container = getinstance ( j . servletcontext ) ; } if ( j == null || container == null ) { return legacy . contains ( filter ) ; } else { return container . list . contains ( filter ) ; } }	Checks whether the given filter is already registered in the chain.
protected void updatecomputerlist ( final boolean automaticslavelaunch ) { final map < node , computer > computers = getcomputermap ( ) ; final set < computer > old = new hashset < computer > ( computers . size ( ) ) ; queue . withlock ( new runnable ( ) { @ override public void run ( ) { map < string , computer > byname = new hashmap < string , computer > ( ) ; for ( computer c : computers . values ( ) ) { old . add ( c ) ; node node = c . getnode ( ) ; if ( node == null ) continue ;	Updates Computers. This method tries to reuse existing {.
public static formvalidation error ( throwable e , string message ) { return _error ( kind . error , e , message ) ; }	Sends out a string error message, with optional "show details" link that expands to the full stack trace.
public static formvalidation validateexecutable ( string exe , filevalidator exevalidator ) {	Makes sure that the given string points to an executable file.
public static formvalidation validatenonnegativeinteger ( string value ) { try { if ( integer . parseint ( value ) < num_ ) return error ( hudson . model . messages . hudson_notanonnegativenumber ( ) ) ; return ok ( ) ; } catch ( numberformatexception e ) { return error ( hudson . model . messages . hudson_notanumber ( ) ) ; } }	Makes sure that the given string is a non-negative integer.
public static formvalidation validatepositiveinteger ( string value ) { try { if ( integer . parseint ( value ) <= num_ ) return error ( hudson . model . messages . hudson_notapositivenumber ( ) ) ; return ok ( ) ; } catch ( numberformatexception e ) { return error ( hudson . model . messages . hudson_notanumber ( ) ) ; } }	Makes sure that the given string is a positive integer.
public static formvalidation validaterequired ( string value ) { if ( util . fixemptyandtrim ( value ) == null ) return error ( messages . formvalidation_validaterequired ( ) ) ; return ok ( ) ; }	Makes sure that the given string is not null or empty.
public static formvalidation validatebase64 ( string value , boolean allowwhitespace , boolean allowempty , string errormessage ) { try { string v = value ; if ( ! allowwhitespace ) { if ( v . indexof ( str_ ) >= num_ || v . indexof ( str_ ) >= num_ ) return error ( errormessage ) ; } v = v . trim ( ) ; if ( ! allowempty && v . length ( ) == num_ ) return error ( errormessage ) ; base64 . getdecoder ( ) . decode ( v . getbytes ( standardcharsets . utf_8 ) ) ; return ok ( ) ; } catch ( illegalargumentexception e ) { return error ( errormessage ) ; } }	Makes sure that the given string is a base64 encoded text.
public synchronized byte [ ] mac ( byte [ ] message ) { confidentialstore cs = confidentialstore . get ( ) ; if ( mac == null || cs != lastcs ) { lastcs = cs ; mac = createmac ( ) ; } return chop ( mac . dofinal ( message ) ) ; }	Computes the message authentication code for the specified byte sequence.
public string mac ( string message ) { return util . tohexstring ( mac ( message . getbytes ( standardcharsets . utf_8 ) ) ) ; }	Computes the message authentication code and return it as a string.While redundant, often convenient.
public < u extends t > list < u > getall ( class < u > type ) { list < u > r = new arraylist < > ( ) ; for ( t t : data ) if ( type . isinstance ( t ) ) r . add ( type . cast ( t ) ) ; return r ; }	Gets all instances that matches the given type.
public void remove ( class < ? extends t > type ) throws ioexception { for ( t t : data ) { if ( t . getclass ( ) == type ) { data . remove ( t ) ; onmodified ( ) ; return ; } } }	Removes an instance by its type.
public void replace ( t from , t to ) throws ioexception { list < t > copy = new arraylist < > ( data . getview ( ) ) ; for ( int i = num_ ; i < copy . size ( ) ; i ++ ) { if ( copy . get ( i ) . equals ( from ) ) copy . set ( i , to ) ; } data . replaceby ( copy ) ; }	A convenience method to replace a single item.This method shouldn't be used when you are replacing a lot of stuffas copy-on-write semantics make this rather slow.
private runlist < r > limit ( final countingpredicate < r > predicate ) { size = null ; first = null ; final iterable < r > nested = base ; base = new iterable < r > ( ) { public iterator < r > iterator ( ) { return hudson . util . iterators . limit ( nested . iterator ( ) , predicate ) ; } @ override public string tostring ( ) { return iterables . tostring ( this ) ; } } ; return this ; }	Returns the first streak of the elements that satisfy the given predicate.For example, {.
public runlist < r > bytimestamp ( final long start , final long end ) { return limit ( new countingpredicate < r > ( ) { public boolean apply ( int index , r r ) { return start <= r . gettimeinmillis ( ) ; } } ) . filter ( new predicate < r > ( ) { public boolean apply ( r r ) { return r . gettimeinmillis ( ) < end ; } } ) ; }	Filter the list by timestamp.{.
@ override public void rewritehudsonwar ( file by ) throws ioexception { file dest = gethudsonwar ( ) ;	On Windows, jenkins.war is locked, so we place a new version under a special name,which is picked up by the service wrapper upon restart.
public static boolean isallready ( ) throws ioexception , interruptedexception { for ( restartlistener listener : all ( ) ) { if ( ! listener . isreadytorestart ( ) ) return bool_ ; } return bool_ ; }	Returns true iff all the listeners OKed the restart.
protected boolean isignoreddir ( file dir ) {	Decides if this directory is worth visiting or not.
@ override public long skip ( long n ) throws ioexception { byte [ ] buf = new byte [ ( int ) math . min ( n , num_ * num_ ) ] ; return read ( buf , num_ , buf . length ) ; }	To record the bytes we've skipped, convert the call to read.
public static list < computerpanelbox > all ( computer computer ) { list < computerpanelbox > boxs = new arraylist < > ( ) ; for ( computerpanelbox box : extensionlist . lookup ( computerpanelbox . class ) ) { box . setcomputer ( computer ) ; boxs . add ( box ) ; } return boxs ; }	Create boxes for the given computer in its page.
public static string [ ] interninplace ( string [ ] input ) { if ( input == null ) { return null ; } else if ( input . length == num_ ) { return empty_string_array ; } for ( int i = num_ ; i < input . length ; i ++ ) { input [ i ] = util . intern ( input [ i ] ) ; } return input ; }	Returns the input strings, but with all values interned.
public final pollingresult poll ( abstractproject < ? , ? > project , launcher launcher , filepath workspace , tasklistener listener , scmrevisionstate baseline ) throws ioexception , interruptedexception { if ( is1_346orlater ( ) ) {	Convenience method for the caller to handle the backward compatibility between pre 1.345 SCMs.
public static list < scmdescriptor < ? > > _for ( @ checkfornull final job project ) { if ( project == null ) return all ( ) ; final descriptor pd = jenkins . getinstance ( ) . getdescriptor ( ( class ) project . getclass ( ) ) ; list < scmdescriptor < ? > > r = new arraylist < scmdescriptor < ? > > ( ) ; for ( scmdescriptor < ? > scmdescriptor : all ( ) ) { if ( ! scmdescriptor . isapplicable ( project ) ) continue ; if ( pd instanceof toplevelitemdescriptor ) { toplevelitemdescriptor apd = ( toplevelitemdescriptor ) pd ; if ( ! apd . isapplicable ( scmdescriptor ) ) continue ; } r . add ( scmdescriptor ) ; } return r ; }	Determines which kinds of SCMs are applicable to a given project.
private boolean haspermissiontoseetoken ( ) {	Only for legacy token.
@ deprecated public void changeapitoken ( ) throws ioexception {	Only usable if the user still has the legacy API token.
public void run ( action [ ] additionalactions ) { if ( job == null ) { return ; } descriptorimpl d = getdescriptor ( ) ; logger . fine ( str_ + job ) ; if ( d . synchronouspolling ) { logger . fine ( str_ + str_ ) ; new runner ( additionalactions ) . run ( ) ; } else {	Run the SCM trigger with additional build actions.
public static boolean execute ( abstractbuild build , buildlistener listener ) { printstream logger = listener . getlogger ( ) ;	Convenience method to trigger downstream builds.
public boolean canrun ( final resourcelist resources ) { try { return _withlock ( new callable < boolean > ( ) { @ override public boolean call ( ) { return ! inuse . iscollidingwith ( resources ) ; } } ) ; } catch ( exception e ) { throw new illegalstateexception ( str_ ) ; } }	Checks if an activity that requires the given resource listcan run immediately. This method is really only useful as a hint, sinceanother activity might acquire resources before the callergets to call {.
public resource getmissingresource ( final resourcelist resources ) { try { return _withlock ( new callable < resource > ( ) { @ override public resource call ( ) { return resources . getconflict ( inuse ) ; } } ) ; } catch ( exception e ) { throw new illegalstateexception ( str_ ) ; } }	Of the resource in the given resource list, return the one that'scurrently in use.
@ override public void add ( toplevelitem item ) throws ioexception { synchronized ( this ) { jobnames . add ( item . getrelativenamefrom ( getowner ( ) . getitemgroup ( ) ) ) ; } save ( ) ; }	Adds the given item to this view.
@ override public boolean remove ( toplevelitem item ) throws ioexception { synchronized ( this ) { string name = item . getrelativenamefrom ( getowner ( ) . getitemgroup ( ) ) ; if ( ! jobnames . remove ( name ) ) return bool_ ; } save ( ) ; return bool_ ; }	Removes given item from this view.
@ restricted ( noexternaluse . class )	Determines the initial state of the checkbox.
@ override public void ononline ( computer c , tasklistener listener ) throws ioexception , interruptedexception { synchronized ( this ) { future . cancel ( bool_ ) ; future = timer . get ( ) . schedule ( monitor_updater , num_ , timeunit . seconds ) ; } }	Triggers the update with 5 seconds quiet period, to avoid triggering data check too oftenwhen multiple agents become online at about the same time.
@ exported ( name = str_ ) public string getassignedlabelstring ( ) { if ( canroam || assignednode == null ) return null ; try { labelexpression . parseexpression ( assignednode ) ; return assignednode ; } catch ( antlrexception e ) {	Gets the textual representation of the assigned label as it was entered by the user.
public void setassignedlabel ( label l ) throws ioexception { if ( l == null ) { canroam = bool_ ; assignednode = null ; } else { canroam = bool_ ; if ( l == jenkins . getinstance ( ) . getselflabel ( ) ) assignednode = null ; else assignednode = l . getexpression ( ) ; } save ( ) ; }	Sets the assigned label.
private abstractbuild getbuildfordeprecatedmethods ( ) { executor e = executor . currentexecutor ( ) ; if ( e != null ) { executable exe = e . getcurrentexecutable ( ) ; if ( exe instanceof abstractbuild ) { abstractbuild b = ( abstractbuild ) exe ; if ( b . getproject ( ) == this ) return b ; } } r lb = getlastbuild ( ) ; if ( lb != null ) return lb ; return null ; }	Various deprecated methods in this class all need the 'current' build.
public final @ checkfornull filepath getsomeworkspace ( ) { r b = getsomebuildwithworkspace ( ) ; if ( b != null ) return b . getworkspace ( ) ; for ( workspacebrowser browser : extensionlist . lookup ( workspacebrowser . class ) ) { filepath f = browser . getworkspace ( this ) ; if ( f != null ) return f ; } return null ; }	Gets a workspace for some build of this project.
public final r getsomebuildwithworkspace ( ) { int cnt = num_ ; for ( r b = getlastbuild ( ) ; cnt < num_ && b != null ; b = b . getpreviousbuild ( ) ) { filepath ws = b . getworkspace ( ) ; if ( ws != null ) return b ; } return null ; }	Gets some build that has a live workspace.
public boolean schedulebuild ( int quietperiod , cause c , action ... actions ) { return schedulebuild2 ( quietperiod , c , actions ) != null ; }	Schedules a build.Important: the actions should be persistable without outside references (e.g.
public boolean schedulepolling ( ) { if ( isdisabled ( ) ) return bool_ ; scmtrigger scmt = gettrigger ( scmtrigger . class ) ; if ( scmt == null ) return bool_ ; scmt . run ( ) ; return bool_ ; }	Schedules a polling of this project.
public resourcelist getresourcelist ( ) { final set < resourceactivity > resourceactivities = getresourceactivities ( ) ; final list < resourcelist > resourcelists = new arraylist < resourcelist > ( num_ + resourceactivities . size ( ) ) ; for ( resourceactivity activity : resourceactivities ) { if ( activity != this && activity != null ) {	List of necessary resources to perform the build of this project.
private void calcpollingbaseline ( abstractbuild build , launcher launcher , tasklistener listener ) throws ioexception , interruptedexception { scmrevisionstate baseline = build . getaction ( scmrevisionstate . class ) ; if ( baseline == null ) { try { baseline = getscm ( ) . calcrevisionsfrombuild ( build , launcher , listener ) ; } catch ( abstractmethoderror e ) { baseline = scmrevisionstate . none ;	Pushes the baseline up to the newly checked out revision.
public pollingresult poll ( tasklistener listener ) { scm scm = getscm ( ) ; if ( scm == null ) { listener . getlogger ( ) . println ( messages . abstractproject_noscm ( ) ) ; return no_changes ; } if ( ! isbuildable ( ) ) { listener . getlogger ( ) . println ( messages . abstractproject_disabled ( ) ) ; return no_changes ; } scmdecisionhandler veto = scmdecisionhandler . firstshouldpollveto ( this ) ; if ( veto != null ) { listener . getlogger ( ) . println ( messages . abstractproject_pollingvetoed ( veto ) ) ; return no_changes ; } r lb = getlastbuild ( ) ; if ( lb == null ) { listener . getlogger ( ) . println ( messages . abstractproject_nobuilds ( ) ) ; return isinqueue ( ) ? no_changes : build_now ; } if ( pollingbaseline == null ) { r success = getlastsuccessfulbuild ( ) ;	Checks if there's any update in SCM, and returns true if any is found.
private boolean isallsuitablenodesoffline ( r build ) { label label = getassignedlabel ( ) ; list < node > allnodes = jenkins . getinstance ( ) . getnodes ( ) ; if ( label != null ) {	Returns true if all suitable nodes for the job are offline.
public boolean hasparticipant ( user user ) { for ( r build = getlastbuild ( ) ; build != null ; build = build . getpreviousbuild ( ) ) if ( build . hasparticipant ( user ) ) return bool_ ; return bool_ ; }	Returns true if this user has made a commit to this project.
public < t extends trigger > t gettrigger ( class < t > clazz ) { for ( trigger p : triggers ( ) ) { if ( clazz . isinstance ( p ) ) return clazz . cast ( p ) ; } return null ; }	Gets the specific trigger, or null if the property is not configured for this job.
private void checkandrecord ( abstractproject that , treemap < integer , rangeset > r , collection < r > builds ) { for ( r build : builds ) { rangeset rs = build . getdownstreamrelationship ( that ) ; if ( rs == null || rs . isempty ( ) ) continue ; int n = build . getnumber ( ) ; rangeset value = r . get ( n ) ; if ( value == null ) r . put ( n , rs ) ; else value . add ( rs ) ; } }	Helper method for getDownstreamRelationship.For each given build, find the build number range of the given project and put that into the map.
@ deprecated public int getdelay ( staplerrequest req ) throws servletexception { string delay = req . getparameter ( str_ ) ; if ( delay == null ) return getquietperiod ( ) ; try {	Computes the delay by taking the default value and the override in the request parameter into the account.
public directorybrowsersupport dows ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception , interruptedexception { checkpermission ( item . workspace ) ; filepath ws = getsomeworkspace ( ) ; if ( ( ws == null ) || ( ! ws . exists ( ) ) ) {	Serves the workspace files.
@ requirepost public httpresponse dodowipeoutworkspace ( ) throws ioexception , servletexception , interruptedexception { checkpermission ( functions . iswipeoutpermissionenabled ( ) ? wipeout : build ) ; r b = getsomebuildwithworkspace ( ) ; filepath ws = b != null ? b . getworkspace ( ) : null ; if ( ws != null && getscm ( ) . processworkspacebeforedeletion ( this , ws , b . getbuilton ( ) ) ) { ws . deleterecursive ( ) ; for ( workspacelistener wl : workspacelistener . all ( ) ) { wl . afterdelete ( this ) ; } return new httpredirect ( str_ ) ; } else {	Wipes out the workspace.
static string paren ( labeloperatorprecedence op , label l ) { if ( op . compareto ( l . precedence ( ) ) < num_ ) return str_ + l . getexpression ( ) + str_ ; return l . getexpression ( ) ; }	Puts the label name into a parenthesis if the given operator will have a higher precedence.
public static list < integer > sequence ( final int start , int end , final int step ) { final int size = ( end - start ) / step ; if ( size < num_ ) throw new illegalargumentexception ( str_ ) ; return new abstractlist < integer > ( ) { public integer get ( int index ) { if ( index < num_ || index >= size ) throw new indexoutofboundsexception ( ) ; return start + index * step ; } public int size ( ) { return size ; } } ; }	Returns a list that represents [start,end).For example sequence(1,5,1)={1,2,3,4}, and sequence(7,1,-2)={7.5,3}.
public static < t > iterator < t > removenull ( final iterator < t > itr ) { return com . google . common . collect . iterators . filter ( itr , predicates . notnull ( ) ) ; }	Wraps another iterator and throws away nulls.
public static < t > iterator < t > limit ( final iterator < ? extends t > base , final countingpredicate < ? super t > filter ) { return new iterator < t > ( ) { private t next ; private boolean end ; private int index = num_ ; public boolean hasnext ( ) { fetch ( ) ; return next != null ; } public t next ( ) { fetch ( ) ; t r = next ; next = null ; return r ; } private void fetch ( ) { if ( next == null && ! end ) { if ( base . hasnext ( ) ) { next = base . next ( ) ; if ( ! filter . apply ( index ++ , next ) ) { next = null ; end = bool_ ; } } else { end = bool_ ; } } } public void remove ( ) { throw new unsupportedoperationexception ( ) ; } } ; }	Returns the elements in the base iterator until it hits any element that doesn't satisfy the filter.Then the rest of the elements in the base iterator gets ignored.
public static initstrategy get ( classloader cl ) throws ioexception { iterator < initstrategy > it = serviceloader . load ( initstrategy . class , cl ) . iterator ( ) ; if ( ! it . hasnext ( ) ) { return new initstrategy ( ) ;	Obtains the instance to be used.
public void override ( string key , string value ) { if ( value == null || value . length ( ) == num_ ) { remove ( key ) ; return ; } int idx = key . indexof ( str_ ) ; if ( idx > num_ ) { string realkey = key . substring ( num_ , idx ) ; string v = get ( realkey ) ; if ( v == null ) v = value ; else {	Overrides the current entry by the given entry. Handles {.
public static void resolve ( map < string , string > env ) { for ( map . entry < string , string > entry : env . entryset ( ) ) { entry . setvalue ( util . replacemacro ( entry . getvalue ( ) , env ) ) ; } }	Resolves environment variables against each other.
public void addline ( string line ) { int sep = line . indexof ( str_ ) ; if ( sep > num_ ) { put ( line . substring ( num_ , sep ) , line . substring ( sep + num_ ) ) ; } }	Takes a string that looks like "a=b" and adds that to this map.
public static envvars getremote ( virtualchannel channel ) throws ioexception , interruptedexception { if ( channel == null ) return new envvars ( str_ , str_ ) ; return channel . call ( new getenvvars ( ) ) ; }	Obtains the environment variables of a remote peer.
public @ nonnull acl getacl ( final @ nonnull view item ) { return acl . lambda ( ( a , permission ) -> { acl base = item . getowner ( ) . getacl ( ) ; boolean haspermission = base . haspermission ( a , permission ) ; if ( ! haspermission && permission == view . read ) { return base . haspermission ( a , view . configure ) || ! item . getitems ( ) . isempty ( ) ; } return haspermission ; } ) ; }	Implementation can choose to provide different ACL for different views.This can be used as a basis for more fine-grained access control.
@ override @ requirepost public httpresponse dododelete ( ) throws ioexception { checkpermission ( delete ) ; try { t node = getnode ( ) ; if ( node != null ) {	When the agent is deleted, free the node right away.
public synchronized boolean remove ( e e ) { list < e > n = new arraylist < > ( core ) ; boolean r = n . remove ( e ) ; core = n ; return r ; }	Removes an item from the list.
public iterator < e > iterator ( ) { final iterator < ? extends e > itr = core . iterator ( ) ; return new iterator < e > ( ) { private e last ; public boolean hasnext ( ) { return itr . hasnext ( ) ; } public e next ( ) { return last = itr . next ( ) ; } public void remove ( ) { copyonwritelist . this . remove ( last ) ; } } ; }	Returns an iterator.
public static file getlogsroot ( ) { string tagslogspath = systemproperties . getstring ( logs_root_path_property ) ; if ( tagslogspath == null ) { return new file ( jenkins . get ( ) . getrootdir ( ) , str_ ) ; } else { level loglevel = level . info ; if ( already_logged ) { loglevel = level . fine ; } logger . log ( loglevel , str_ , logs_root_path_property ) ; already_logged = bool_ ; return new file ( tagslogspath ) ; } }	The root path that should be used to put logs related to the tasks running in Jenkins.
private < r > collection < r > copy ( iterable < r > src ) { return lists . newarraylist ( src ) ; }	Creates a copy since we'll be deleting some entries from them.
public void closeentry ( ) throws ioexception { if ( this . assemlen > num_ ) { for ( int i = this . assemlen ; i < this . assembuf . length ; ++ i ) { this . assembuf [ i ] = num_ ; } this . buffer . writerecord ( this . assembuf ) ; this . currbytes += this . assemlen ; this . assemlen = num_ ; } if ( this . currbytes < this . currsize ) { throw new ioexception ( str_ + currname + str_ + this . currbytes + str_ + this . currsize + str_ ) ; } }	Close an entry. This method MUST be called for all fileentries that contain data. The reason is that we mustbuffer data written to the stream in order to satisfythe buffer's record based writes. Thus, there may bedata fragments still being assembled that must be writtento the output stream before this entry is closed and thenext entry written.
public void setfullname ( string name ) { if ( util . fixemptyandtrim ( name ) == null ) name = id ; this . fullname = name ; }	Sets the human readable name of the user.If the input parameter is empty, the user's ID will be set.
public < t extends userproperty > t getproperty ( class < t > clazz ) { for ( userproperty p : properties ) { if ( clazz . isinstance ( p ) ) return clazz . cast ( p ) ; } return null ; }	Gets the specific property, or null.
public static @ nonnull collection < user > getall ( ) { final idstrategy strategy = idstrategy ( ) ; arraylist < user > users = new arraylist < > ( allusers . values ( ) ) ; users . sort ( ( o1 , o2 ) -> strategy . compare ( o1 . getid ( ) , o2 . getid ( ) ) ) ; return users ; }	Gets all the users.
@ deprecated public static void clear ( ) { if ( extensionlist . lookup ( allusers . class ) . isempty ( ) ) { return ; } useridmapper . getinstance ( ) . clear ( ) ; allusers . clear ( ) ; }	Called by tests in the JTH.
public synchronized void save ( ) throws ioexception { if ( ! isidorfullnameallowed ( id ) ) { throw formvalidation . error ( messages . user_illegalusername ( id ) ) ; } if ( ! isidorfullnameallowed ( fullname ) ) { throw formvalidation . error ( messages . user_illegalfullname ( fullname ) ) ; } if ( bulkchange . contains ( this ) ) { return ; } xmlfile xmlfile = new xmlfile ( xstream , constructuserconfigfile ( ) ) ; xmlfile . write ( this ) ; saveablelistener . fireonchange ( this , xmlfile ) ; }	Save the user configuration.
public void delete ( ) throws ioexception { string idkey = idstrategy ( ) . keyfor ( id ) ; file existinguserfolder = getexistinguserfolder ( ) ; useridmapper . getinstance ( ) . remove ( id ) ; allusers . remove ( id ) ; deleteexistinguserfolder ( existinguserfolder ) ; userdetailscache . get ( ) . invalidate ( idkey ) ; }	Deletes the data directory and removes this user from Hudson.
@ requirepost public void dododelete ( staplerrequest req , staplerresponse rsp ) throws ioexception { checkpermission ( jenkins . administer ) ; if ( idstrategy ( ) . equals ( id , jenkins . getauthentication ( ) . getname ( ) ) ) { rsp . senderror ( httpservletresponse . sc_bad_request , str_ ) ; return ; } delete ( ) ; rsp . sendredirect2 ( str_ ) ; }	Deletes this user from Hudson.
public boolean candelete ( ) { final idstrategy strategy = idstrategy ( ) ; return haspermission ( jenkins . administer ) && ! strategy . equals ( id , jenkins . getauthentication ( ) . getname ( ) ) && useridmapper . getinstance ( ) . ismapped ( id ) ; }	With ADMINISTER permission, can delete users with persisted data but can't delete self.
public list < action > getpropertyactions ( ) { list < action > actions = new arraylist < > ( ) ; for ( userproperty userprop : getproperties ( ) . values ( ) ) { if ( userprop instanceof action ) { actions . add ( ( action ) userprop ) ; } } return collections . unmodifiablelist ( actions ) ; }	Return all properties that are also actions.
public list < action > gettransientactions ( ) { list < action > actions = new arraylist < > ( ) ; for ( transientuseractionfactory factory : transientuseractionfactory . all ( ) ) { actions . addall ( factory . createfor ( this ) ) ; } return collections . unmodifiablelist ( actions ) ; }	Return all transient actions associated with this user.
public boolean iscollidingwith ( resource that , int count ) { assert that != null ; for ( resource r = that ; r != null ; r = r . parent ) if ( this . equals ( r ) && r . numconcurrentwrite < count ) return bool_ ; for ( resource r = this ; r != null ; r = r . parent ) if ( that . equals ( r ) && r . numconcurrentwrite < count ) return bool_ ; return bool_ ; }	Checks the resource collision.
private void copy ( staplerrequest req , staplerresponse rsp , file dir , url src , string name ) throws servletexception , ioexception { try { fileutils . copyurltofile ( src , new file ( dir , name ) ) ; } catch ( ioexception e ) { logger . log ( level . severe , str_ + name , e ) ; senderror ( str_ + name + str_ + e . getmessage ( ) , req , rsp ) ; throw new abortexception ( ) ; } }	Copies a single resource into the target folder, by the given name, and handle errors gracefully.
protected final void senderror ( exception e , staplerrequest req , staplerresponse rsp ) throws servletexception , ioexception { senderror ( e . getmessage ( ) , req , rsp ) ; }	Displays the error in a page.
static int runelevated ( file jenkinsexe , string command , tasklistener out , file pwd ) throws ioexception , interruptedexception { try { return new locallauncher ( out ) . launch ( ) . cmds ( jenkinsexe , command ) . stdout ( out ) . pwd ( pwd ) . join ( ) ; } catch ( ioexception e ) { if ( e . getmessage ( ) . contains ( str_ ) && e . getmessage ( ) . contains ( str_ ) ) {	Invokes jenkins.exe with a SCM management command.
private void keeplastupdatedunique ( ) { map < string , singletokenstats > temp = new hashmap < > ( ) ; this . tokenstats . foreach ( candidate -> { singletokenstats current = temp . get ( candidate . tokenuuid ) ; if ( current == null ) { temp . put ( candidate . tokenuuid , candidate ) ; } else { int comparison = singletokenstats . comp_by_last_use_then_counter . compare ( current , candidate ) ; if ( comparison < num_ ) {	In case of duplicate entries, we keep only the last updated element.
@ exported ( visibility = num_ ) public list < cause > getcauses ( ) { list < cause > r = new arraylist < > ( ) ; for ( map . entry < cause , integer > entry : causebag . entryset ( ) ) { r . addall ( collections . ncopies ( entry . getvalue ( ) , entry . getkey ( ) ) ) ; } return collections . unmodifiablelist ( r ) ; }	Lists all causes of this build.Note that the current implementation does not preserve insertion order of duplicates.
public < t extends cause > t findcause ( class < t > type ) { for ( cause c : causebag . keyset ( ) ) if ( type . isinstance ( c ) ) return type . cast ( c ) ; return null ; }	Finds the cause of the specific type.
public static @ checkfornull string getvalidtimezone ( string timezone ) { string [ ] validids = timezone . getavailableids ( ) ; for ( string str : validids ) { if ( str != null && str . equals ( timezone ) ) { return timezone ; } } return null ; }	Checks if given timezone string is supported by TimeZone and returnsthe same string if valid, null otherwise.
public static iterable < descriptor > listlegacyinstances ( ) { return new iterable < descriptor > ( ) { public iterator < descriptor > iterator ( ) { return new adaptediterator < extensioncomponent < descriptor > , descriptor > ( new flatteniterator < extensioncomponent < descriptor > , copyonwritearraylist < extensioncomponent < descriptor > > > ( legacydescriptors . values ( ) ) { protected iterator < extensioncomponent < descriptor > > expand ( copyonwritearraylist < extensioncomponent < descriptor > > v ) { return v . iterator ( ) ; } } ) { protected descriptor adapt ( extensioncomponent < descriptor > item ) { return item . getinstance ( ) ; } } ; } } ; }	List up all the legacy instances currently in use.
public void setvalue ( string name , string value ) { byte [ ] bytes = value . getbytes ( standardcharsets . utf_16le ) ; int newlength = bytes . length + num_ ;	Writes a String value.
public void setvalue ( string name , int value ) { byte [ ] data = new byte [ num_ ] ; data [ num_ ] = ( byte ) ( value & num_ ) ; data [ num_ ] = ( byte ) ( ( value > > num_ ) & num_ ) ; data [ num_ ] = ( byte ) ( ( value > > num_ ) & num_ ) ; data [ num_ ] = ( byte ) ( ( value > > num_ ) & num_ ) ; check ( advapi32 . instance . regsetvalueex ( handle , name , num_ , winnt . reg_dword , data , data . length ) ) ; }	Writes a DWORD value.
public boolean valueexists ( string name ) { intbyreference ptype , lpcbdata ; byte [ ] lpdata = new byte [ num_ ] ; ptype = new intbyreference ( ) ; lpcbdata = new intbyreference ( ) ; outer : while ( bool_ ) { int r = advapi32 . instance . regqueryvalueex ( handle , name , null , ptype , lpdata , lpcbdata ) ; switch ( r ) { case winerror . error_more_data : lpdata = new byte [ lpcbdata . getvalue ( ) ] ; continue outer ; case winerror . error_file_not_found : return bool_ ; case winerror . error_success : return bool_ ; default : throw new jnaexception ( r ) ; } } }	Does a specified value exist?.
public collection < string > getsubkeys ( ) { winbase . filetime lpftlastwritetime ; treeset < string > subkeys = new treeset < > ( ) ; char [ ] lpname = new char [ num_ ] ; intbyreference lpcname = new intbyreference ( num_ ) ; lpftlastwritetime = new winbase . filetime ( ) ; int dwindex = num_ ; while ( advapi32 . instance . regenumkeyex ( handle , dwindex , lpname , lpcname , null , null , null , lpftlastwritetime ) == winerror . error_success ) { subkeys . add ( new string ( lpname , num_ , lpcname . getvalue ( ) ) ) ; lpcname . setvalue ( num_ ) ; dwindex ++ ; } return subkeys ; }	Get all sub keys of a key.
public treemap < string , object > getvalues ( ) { int dwindex , result ; char [ ] lpvaluename ; byte [ ] lpdata ; intbyreference lpcchvaluename , lptype , lpcbdata ; string name ; treemap < string , object > values = new treemap < > ( string . case_insensitive_order ) ; lpvaluename = new char [ num_ ] ; lpcchvaluename = new intbyreference ( num_ ) ; lptype = new intbyreference ( ) ; lpdata = new byte [ num_ ] ; lpcbdata = new intbyreference ( ) ; lpcbdata . setvalue ( num_ ) ; dwindex = num_ ; outer : while ( bool_ ) { result = advapi32 . instance . regenumvalue ( handle , dwindex , lpvaluename , lpcchvaluename , null , lptype , lpdata , lpcbdata ) ; switch ( result ) { case winerror . error_no_more_items : return values ; case winerror . error_more_data : lpdata = new byte [ lpcbdata . getvalue ( ) ] ; lpcchvaluename = new intbyreference ( num_ ) ; continue outer ; case winerror . error_success : name = new string ( lpvaluename , num_ , lpcchvaluename . getvalue ( ) ) ; switch ( lptype . getvalue ( ) ) { case winnt . reg_sz : values . put ( name , convertbuffertostring ( lpdata ) ) ; break ; case winnt . reg_dword : values . put ( name , convertbuffertoint ( lpdata ) ) ; break ; default : break ;	Get all values under a key.
public void precheckout ( abstractbuild < ? , ? > build , launcher launcher , buildlistener listener ) throws ioexception , interruptedexception { abstractproject < ? , ? > project = build . getproject ( ) ; if ( project instanceof buildableitemwithbuildwrappers ) { buildableitemwithbuildwrappers biwbw = ( buildableitemwithbuildwrappers ) project ; for ( buildwrapper bw : biwbw . getbuildwrapperslist ( ) ) bw . precheckout ( build , launcher , listener ) ; } }	Performs the pre checkout step.This method is called by the {.
public solution getsolution ( string id ) { for ( solution s : solution . all ( ) ) if ( s . id . equals ( id ) ) return s ; return null ; }	Binds a solution to the URL.
public url getindexpage ( ) {	Returns the URL of the index page jelly script.
@ exported public string geturl ( ) {	Gets the URL that shows more information about this plugin.
@ exported public string getlongname ( ) { string name = manifest . getmainattributes ( ) . getvalue ( str_ ) ; if ( name != null ) return name ; return shortname ; }	Returns a one-line descriptive name of this plugin.
@ exported public yesnomaybe supportsdynamicload ( ) { string v = manifest . getmainattributes ( ) . getvalue ( str_ ) ; if ( v == null ) return yesnomaybe . maybe ; return boolean . parseboolean ( v ) ? yesnomaybe . yes : yesnomaybe . no ; }	Does this plugin supports dynamic loading?.
@ exported public @ checkfornull string getrequiredcoreversion ( ) { string v = manifest . getmainattributes ( ) . getvalue ( str_ ) ; if ( v != null ) return v ; v = manifest . getmainattributes ( ) . getvalue ( str_ ) ; if ( v != null ) return v ; return null ; }	Returns the required Jenkins core version of this plugin.
public void stop ( ) { plugin plugin = getplugin ( ) ; if ( plugin != null ) { try { logger . log ( level . fine , str_ , shortname ) ; plugin . stop ( ) ; } catch ( throwable t ) { logger . log ( warning , str_ + shortname , t ) ; } } else { logger . log ( level . fine , str_ , shortname ) ; }	Terminates the plugin.
public void enable ( ) throws ioexception { if ( ! disablefile . exists ( ) ) { logger . log ( level . finest , str_ , getshortname ( ) ) ; return ; } if ( ! disablefile . delete ( ) ) throw new ioexception ( str_ + disablefile ) ; }	Enables this plugin next time Jenkins runs.
private void disablewithoutcheck ( ) throws ioexception {	Disable a plugin wihout checking any dependency.
@ exported public string getbackupversion ( ) { file backup = getbackupfile ( ) ; if ( backup . exists ( ) ) { try { try ( jarfile backupplugin = new jarfile ( backup ) ) { return backupplugin . getmanifest ( ) . getmainattributes ( ) . getvalue ( str_ ) ; } } catch ( ioexception e ) { logger . log ( warning , str_ + backup , e ) ; return null ; } } else { return null ; } }	returns the version of the backed up plugin,or null if there's no back up.
protected synchronized thread start ( boolean forcerestart ) { if ( ! forcerestart && isfixingactive ( ) ) { fixthread . interrupt ( ) ; } if ( forcerestart || ! isfixingactive ( ) ) { fixthread = new fixthread ( ) ; fixthread . start ( ) ; } return fixthread ; }	Starts the background fixing activity.
public static void dotrackback ( object it , staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { string url = req . getparameter ( str_ ) ; rsp . setstatus ( httpservletresponse . sc_ok ) ; rsp . setcontenttype ( str_ ) ; try ( printwriter pw = rsp . getwriter ( ) ) { pw . println ( str_ ) ; pw . println ( str_ + ( url != null ? num_ : num_ ) + str_ ) ; if ( url == null ) { pw . println ( str_ ) ; } pw . println ( str_ ) ; } }	Parses trackback ping.
public static < e > void forwardtorss ( string title , string url , collection < ? extends e > entries , feedadapter < e > adapter , staplerrequest req , httpservletresponse rsp ) throws ioexception , servletexception { req . setattribute ( str_ , adapter ) ; req . setattribute ( str_ , title ) ; req . setattribute ( str_ , url ) ; req . setattribute ( str_ , entries ) ; req . setattribute ( str_ , jenkins . getinstance ( ) . getrooturl ( ) ) ; string flavor = req . getparameter ( str_ ) ; if ( flavor == null ) flavor = str_ ; flavor = flavor . replace ( str_ , str_ ) ;	Sends the RSS feed to the client.
public string getname ( ) { string name = getclass ( ) . getname ( ) ; name = name . substring ( name . lastindexof ( str_ ) + num_ ) ;	Gets the command name. For example, if the CLI is invoked as {.
@ restricted ( noexternaluse . class ) public final string getsinglelinesummary ( ) { bytearrayoutputstream out = new bytearrayoutputstream ( ) ; getcmdlineparser ( ) . printsinglelineusage ( out ) ; return out . tostring ( ) ; }	Get single line summary as a string.
@ restricted ( noexternaluse . class ) public final string getusage ( ) { bytearrayoutputstream out = new bytearrayoutputstream ( ) ; getcmdlineparser ( ) . printusage ( out ) ; return out . tostring ( ) ; }	Get usage as a string.
@ restricted ( noexternaluse . class ) public final string getlongdescription ( ) { bytearrayoutputstream out = new bytearrayoutputstream ( ) ; printstream ps = new printstream ( out ) ; printusagesummary ( ps ) ; ps . close ( ) ; return out . tostring ( ) ; }	Get long description as a string.
protected final filepath preferredlocation ( toolinstallation tool , node node ) { if ( node == null ) { throw new illegalargumentexception ( str_ ) ; } string home = util . fixemptyandtrim ( tool . gethome ( ) ) ; if ( home == null ) { home = sanitize ( tool . getdescriptor ( ) . getid ( ) ) + file . separatorchar + sanitize ( tool . getname ( ) ) ; } filepath root = node . getrootpath ( ) ; if ( root == null ) { throw new illegalargumentexception ( str_ + node . getdisplayname ( ) + str_ ) ; } return root . child ( str_ ) . child ( home ) ; }	Convenience method to find a location to install a tool.
private string getfilename ( string possiblypathname ) { possiblypathname = possiblypathname . substring ( possiblypathname . lastindexof ( str_ ) + num_ ) ; possiblypathname = possiblypathname . substring ( possiblypathname . lastindexof ( str_ ) + num_ ) ; return possiblypathname ; }	Strip off the path portion if the given path contains it.
@ suppressfbwarnings ( value = str_ , justification = str_ ) protected object readresolve ( ) { if ( allowemptyarchive == null ) { this . allowemptyarchive = systemproperties . getboolean ( artifactarchiver . class . getname ( ) + str_ ) ; } if ( defaultexcludes == null ) { defaultexcludes = bool_ ; } if ( casesensitive == null ) { casesensitive = bool_ ; } return this ; }	Backwards compatibility for older builds.
private void applyforcedchanges ( ) {	Put here the different changes that are enforced after an update.
public boolean isdue ( ) { if ( isuptodate ) return bool_ ;	Do we need to show the upgrade wizard prompt?.
public boolean isshowupgradewizard ( ) { httpsession session = stapler . getcurrentrequest ( ) . getsession ( bool_ ) ; if ( session != null ) { return boolean . true . equals ( session . getattribute ( show_upgrade_wizard_flag ) ) ; } return bool_ ; }	Whether to show the upgrade wizard.
public httpresponse doshowupgradewizard ( ) throws exception { jenkins . getinstance ( ) . checkpermission ( jenkins . administer ) ; httpsession session = stapler . getcurrentrequest ( ) . getsession ( bool_ ) ; session . setattribute ( show_upgrade_wizard_flag , bool_ ) ; return httpresponses . redirecttocontextroot ( ) ; }	Call this to show the upgrade wizard.
public httpresponse dohideupgradewizard ( ) { jenkins . getinstance ( ) . checkpermission ( jenkins . administer ) ; httpsession session = stapler . getcurrentrequest ( ) . getsession ( bool_ ) ; if ( session != null ) { session . removeattribute ( show_upgrade_wizard_flag ) ; } return httpresponses . redirecttocontextroot ( ) ; }	Call this to hide the upgrade wizard.
@ requirepost public httpresponse dosnooze ( ) throws ioexception { jenkins . getinstance ( ) . checkpermission ( jenkins . administer ) ; file f = setupwizard . getupdatestatefile ( ) ; fileutils . touch ( f ) ; f . setlastmodified ( system . currenttimemillis ( ) + timeunit . days . tomillis ( num_ ) ) ; logger . log ( fine , str_ ) ; return httpresponses . redirecttocontextroot ( ) ; }	Snooze the upgrade wizard notice.
private void deleteifempty ( file dir ) { string [ ] r = dir . list ( ) ; if ( r == null ) return ;	Deletes a directory if it's empty.
private boolean check ( file fingerprintfile , tasklistener listener ) { try { fingerprint fp = loadfingerprint ( fingerprintfile ) ; if ( fp == null || ! fp . isalive ( ) ) { listener . getlogger ( ) . println ( str_ + fingerprintfile ) ; fingerprintfile . delete ( ) ; return bool_ ; } else {	Examines the file and returns true if a file was deleted.
private boolean iswhitelisted ( rolesensitive subject , collection < role > expected ) { for ( callablewhitelist w : callablewhitelist . all ( ) ) { if ( w . iswhitelisted ( subject , expected , context ) ) return bool_ ; } return bool_ ; }	Is this subject class name whitelisted?.
public @ checkfornull t get ( string key ) throws ioexception { return get ( key , bool_ , null ) ; }	Finds the data object that matches the given key if available, or nullif not found.
public string getperformancestats ( ) { int total = totalquery . get ( ) ; int hit = cachehit . get ( ) ; int weakref = weakreflost . get ( ) ; int failure = loadfailure . get ( ) ; int miss = total - hit - weakref ; return messageformat . format ( str_ , total , hit , weakref , failure , miss ) ; }	Gets the short summary of performance statistics.
private static boolean hassomeuser ( ) { for ( user u : user . getall ( ) ) if ( u . getproperty ( details . class ) != null ) return bool_ ; return bool_ ; }	Computes if this Hudson has some user accounts configured. This is used to check for the initial.
@ override public httpresponse commencesignup ( final federatedidentity identity ) {	Show the sign up page with the data from the identity.
@ requirepost public user docreateaccount ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { return _docreateaccount ( req , rsp , str_ ) ; }	Creates an user account.
@ suppresswarnings ( str_ ) private void loginandtakeback ( staplerrequest req , staplerresponse rsp , user u ) throws servletexception , ioexception { httpsession session = req . getsession ( bool_ ) ; if ( session != null ) {	Lets the current user silently login as the given user and report back accordingly.
@ requirepost public void docreateaccountbyadmin ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { createaccountbyadmin ( req , rsp , str_ , str_ ) ;	Creates a user account.
@ requirepost public void docreatefirstaccount ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { if ( hassomeuser ( ) ) { rsp . senderror ( sc_unauthorized , str_ ) ; return ; } user u = createaccount ( req , rsp , bool_ , str_ ) ; if ( u != null ) { trytomakeadmin ( u ) ; loginandtakeback ( req , rsp , u ) ; } }	Creates a first admin user account.
private void trytomakeadmin ( user u ) { authorizationstrategy as = jenkins . getinstance ( ) . getauthorizationstrategy ( ) ; for ( permissionadder adder : extensionlist . lookup ( permissionadder . class ) ) { if ( adder . add ( as , u , jenkins . administer ) ) { return ; } } }	Try to make this user a super-user.
public user createaccount ( string username , string password ) throws ioexception { user user = user . getbyid ( username , bool_ ) ; user . addproperty ( details . fromplainpassword ( password ) ) ; securitylistener . fireusercreated ( user . getid ( ) ) ; return user ; }	Creates a new user account by registering a password to the user.
public user createaccountwithhashedpassword ( string username , string hashedpassword ) throws ioexception { if ( ! password_encoder . ispasswordhashed ( hashedpassword ) ) { throw new illegalargumentexception ( str_ ) ; } user user = user . getbyid ( username , bool_ ) ; user . addproperty ( details . fromhashedpassword ( hashedpassword ) ) ; securitylistener . fireusercreated ( user . getid ( ) ) ; return user ; }	Creates a new user account by registering a JBCrypt Hashed password with the user.
public list < user > getallusers ( ) { list < user > r = new arraylist < user > ( ) ; for ( user u : user . getall ( ) ) { if ( u . getproperty ( details . class ) != null ) r . add ( u ) ; } collections . sort ( r ) ; return r ; }	All users who can login to the system.
@ restricted ( noexternaluse . class ) public user getuser ( string id ) { return user . getbyid ( id , user . allow_user_creation_via_url && haspermission ( jenkins . administer ) ) ; }	This is to map users under the security realm URL.This in turn helps us set up the right navigation breadcrumb.
@ javascriptmethod public httpresponse render ( ) { return new httpresponse ( ) { public void generateresponse ( staplerrequest req , staplerresponse rsp , object node ) throws ioexception , servletexception { try { new defaultscriptinvoker ( ) { @ override protected jellycontext createcontext ( staplerrequest req , staplerresponse rsp , script script , object it ) { jellycontext context = super . createcontext ( req , rsp , script , it ) ; for ( int i = bodystack . length - num_ ; i > num_ ; i -- ) {	Renders the captured fragment.
public synchronized void abort ( throwable cause ) { if ( cause == null ) throw new illegalargumentexception ( ) ; if ( aborted != null ) return ;	When one of the work unit is aborted, call this method to abort all the other work units.
public treestring intern ( final string s ) { if ( s == null ) return null ; return root . intern ( s ) . node ; }	Interns a string.
public static channel forprocess ( string name , executorservice execservice , inputstream in , outputstream out , outputstream header , final proc proc ) throws ioexception { channelbuilder cb = new channelbuilder ( name , execservice ) { @ override public channel build ( commandtransport transport ) throws ioexception { return new channel ( this , transport ) { @ override public synchronized void terminate ( ioexception e ) { super . terminate ( e ) ; try { proc . kill ( ) ; } catch ( ioexception x ) {	Creates a channel that wraps a remote process, so that when we shut down the connectionwe kill the process.
public void doprogresstext ( staplerrequest req , staplerresponse rsp ) throws ioexception { rsp . setcontenttype ( str_ ) ; rsp . setstatus ( httpservletresponse . sc_ok ) ; if ( ! source . exists ( ) ) {	Implements the progressive text handling.This method is used as a "web method" with progressiveText.jelly.
@ override public void restart ( ) throws ioexception , interruptedexception { jenkins jenkins = jenkins . getinstanceornull ( ) ;	In SMF managed environment, just commit a suicide and the service will be restarted by SMF.
public boolean isapplicable ( class < ? extends t > targettype ) { class < ? extends t > applicable = functions . gettypeparameter ( clazz , getp ( ) , num_ ) ; return applicable . isassignablefrom ( targettype ) ; }	Returns true if this property type is applicable to thegiven target type.
protected @ nonnull file getlogdir ( ) { file dir = new file ( jenkins . getinstance ( ) . getrootdir ( ) , str_ + nodename ) ; if ( ! dir . exists ( ) && ! dir . mkdirs ( ) ) { logger . severe ( str_ + dir . getabsolutepath ( ) ) ; } return dir ; }	Directory where rotated agent logs are stored.The method also creates a log directory if required.
@ restricted ( noexternaluse . class ) public list < displayexecutor > getdisplayexecutors ( ) {	Used to render the list of executors.
@ exported public final boolean isidle ( ) { if ( ! oneoffexecutors . isempty ( ) ) return bool_ ; for ( executor e : executors ) if ( ! e . isidle ( ) ) return bool_ ; return bool_ ; }	Returns true if all the executors of this computer are idle.
public final long getidlestartmilliseconds ( ) { long firstidle = long . min_value ; for ( executor e : oneoffexecutors ) { firstidle = math . max ( firstidle , e . getidlestartmilliseconds ( ) ) ; } for ( executor e : executors ) { firstidle = math . max ( firstidle , e . getidlestartmilliseconds ( ) ) ; } return firstidle ; }	Returns the time when this computer last became idle.
public final long getdemandstartmilliseconds ( ) { long firstdemand = long . max_value ; for ( queue . buildableitem item : jenkins . getinstance ( ) . getqueue ( ) . getbuildableitems ( this ) ) { firstdemand = math . min ( item . buildablestartmilliseconds , firstdemand ) ; } return firstdemand ; }	Returns the time when this computer first became in demand.
@ exported ( inline = bool_ ) public map < string , object > getmonitordata ( ) { map < string , object > r = new hashmap < > ( ) ; if ( haspermission ( connect ) ) { for ( nodemonitor monitor : nodemonitor . getall ( ) ) r . put ( monitor . getclass ( ) . getname ( ) , monitor . data ( this ) ) ; } return r ; }	Expose monitoring data for the remote API.
public void dodumpexporttable ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception , interruptedexception {	Dumps the contents of the export table.
public void doscript ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { _doscript ( req , rsp , str_ ) ; }	For system diagnostics.Run arbitrary Groovy script.
public void updatebyxml ( final inputstream source ) throws ioexception , servletexception { checkpermission ( configure ) ; node result = ( node ) jenkins . xstream2 . fromxml ( source ) ; jenkins . getinstance ( ) . getnodesobject ( ) . replacenode ( this . getnode ( ) , result ) ; }	Updates Job by its XML definition.
@ requirepost public httpresponse dododelete ( ) throws ioexception { checkpermission ( delete ) ; node node = getnode ( ) ; if ( node != null ) { jenkins . getinstance ( ) . removenode ( node ) ; } else { abstractcibase app = jenkins . getinstance ( ) ; app . removecomputer ( this ) ; } return new httpredirect ( str_ ) ; }	Really deletes the agent.
public void doprogressivelog ( staplerrequest req , staplerresponse rsp ) throws ioexception { getlogtext ( ) . doprogresstext ( req , rsp ) ; }	Handles incremental log.
public permalink findnearest ( string id ) { list < string > ids = new arraylist < > ( ) ; for ( permalink p : this ) ids . add ( p . getid ( ) ) ; string nearest = editdistance . findnearest ( id , ids ) ; if ( nearest == null ) return null ; return get ( nearest ) ; }	Finds the closest name match by its ID.
public static boolean isrelativepath ( string path ) { if ( path . startswith ( str_ ) ) return bool_ ; if ( path . startswith ( str_ ) && path . length ( ) > num_ && path . indexof ( str_ , num_ ) != - num_ ) return bool_ ;	A mostly accurate check of whether a path is a relative path or not.
public static boolean isdescendant ( file forparent , file potentialchild ) throws ioexception { path child = filetopath ( potentialchild . getabsolutefile ( ) ) . normalize ( ) ; path parent = filetopath ( forparent . getabsolutefile ( ) ) . normalize ( ) ; return child . startswith ( parent ) ; }	A check if a file path is a descendant of a parent path.
public static file createtempdir ( ) throws ioexception {	Creates a new temporary directory.
@ checkfornull public static string getwin32errormessage ( int n ) { try { resourcebundle rb = resourcebundle . getbundle ( str_ ) ; return rb . getstring ( str_ + n ) ; } catch ( missingresourceexception e ) { logger . log ( level . warning , str_ , e ) ; return null ; } }	Gets a human readable message for the given Win32 error code.
@ deprecated public static string encoderfc2396 ( string url ) { try { return new uri ( null , url , null ) . toasciistring ( ) ; } catch ( urisyntaxexception e ) { logger . log ( level . warning , str_ , url ) ;	Encodes the URL by RFC 2396.I thought there's another spec that refers to UTF-8 as the encoding,but don't remember it right now.
public list < scc < n > > getstronglyconnectedcomponents ( ) { final map < n , node > nodes = new hashmap < > ( ) ; for ( n n : nodes ( ) ) { nodes . put ( n , new node ( n ) ) ; } final list < scc < n > > sccs = new arraylist < > ( ) ; class tarjan { int index = num_ ; int sccindex = num_ ; stack < node > pending = new stack < > ( ) ; void traverse ( ) { for ( node n : nodes . values ( ) ) { if ( n . index == - num_ ) visit ( n ) ; } } void visit ( node v ) { v . index = v . lowlink = index ++ ; pending . push ( v ) ; for ( n q : v . edges ( ) ) { node w = nodes . get ( q ) ; if ( w . index == - num_ ) { visit ( w ) ; v . lowlink = math . min ( v . lowlink , w . lowlink ) ; } else if ( pending . contains ( w ) ) { v . lowlink = math . min ( v . lowlink , w . index ) ; } } if ( v . lowlink == v . index ) {	Performs the Tarjan's algorithm and computes strongly-connected components from thesink to source order.See http://en.wikipedia.org/wiki/Tarjan's_strongly_connected_components_algorithm.
public void setnodes ( final @ nonnull collection < ? extends node > nodes ) throws ioexception { queue . withlock ( new runnable ( ) { @ override public void run ( ) { set < string > toremove = new hashset < > ( nodes . this . nodes . keyset ( ) ) ; for ( node n : nodes ) { final string name = n . getnodename ( ) ; toremove . remove ( name ) ; nodes . this . nodes . put ( name , n ) ; } nodes . this . nodes . keyset ( ) . removeall ( toremove ) ;	Sets the list of nodes.
public void addnode ( final @ nonnull node node ) throws ioexception { node oldnode = nodes . get ( node . getnodename ( ) ) ; if ( node != oldnode ) {	Adds a node. If a node of the same name already exists then that node will be replaced.
private void persistnode ( final @ nonnull node node ) throws ioexception {	Actually persists a node on disk.
public boolean replacenode ( final node oldone , final @ nonnull node newone ) throws ioexception { if ( oldone == nodes . get ( oldone . getnodename ( ) ) ) {	Replace node of given name.
@ checkfornull public node getnode ( string name ) { return name == null ? null : nodes . get ( name ) ; }	Returns the named node.
public void load ( ) throws ioexception { final file nodesdir = getnodesdir ( ) ; final file [ ] subdirs = nodesdir . listfiles ( new filefilter ( ) { public boolean accept ( file child ) { return child . isdirectory ( ) ; } } ) ; final map < string , node > newnodes = new treemap < > ( ) ; if ( subdirs != null ) { for ( file subdir : subdirs ) { try { xmlfile xmlfile = new xmlfile ( jenkins . xstream , new file ( subdir , str_ ) ) ; if ( xmlfile . exists ( ) ) { node node = ( node ) xmlfile . read ( ) ; newnodes . put ( node . getnodename ( ) , node ) ; } } catch ( ioexception e ) { logger . getlogger ( nodes . class . getname ( ) ) . log ( level . warning , str_ + subdir , e ) ; } } } queue . withlock ( new runnable ( ) { @ override public void run ( ) { nodes . entryset ( ) . removeif ( stringnodeentry -> ! ( stringnodeentry . getvalue ( ) instanceof ephemeralnode ) ) ; nodes . putall ( newnodes ) ; jenkins . updatecomputerlist ( ) ; jenkins . trimlabels ( ) ; } } ) ; }	Loads the nodes from disk.
private file getnodesdir ( ) throws ioexception { final file nodesdir = new file ( jenkins . getrootdir ( ) , str_ ) ; if ( ! nodesdir . isdirectory ( ) && ! nodesdir . mkdirs ( ) ) { throw new ioexception ( string . format ( str_ , nodesdir ) ) ; } return nodesdir ; }	Returns the directory that the nodes are stored in.
public string getformatteddescription ( ) { try { return jenkins . getinstance ( ) . getmarkupformatter ( ) . translate ( description ) ; } catch ( ioexception e ) { logger . warning ( str_ ) ; return str_ ; } }	return parameter description, applying the configured MarkupFormatter for jenkins instance.
@ checkfornull public parametervalue createvalue ( clicommand command , string value ) throws ioexception , interruptedexception { throw new abortexception ( str_ + getclass ( ) + str_ ) ; }	Create a parameter value from the string given in the CLI.
public static string tonamelist ( collection < ? extends item > items ) { stringbuilder buf = new stringbuilder ( ) ; for ( item item : items ) { if ( buf . length ( ) > num_ ) buf . append ( str_ ) ; buf . append ( item . getfullname ( ) ) ; } return buf . tostring ( ) ; }	Converts a list of items into a comma-separated list of full names.
public static method getpublicmethodnamed ( class c , string methodname ) { for ( method m : c . getmethods ( ) ) if ( m . getname ( ) . equals ( methodname ) ) return m ; return null ; }	Finds a public method of the given name, regardless of its parameter definitions,.
public static boolean isdefaultjdkvalid ( node n ) { try { tasklistener listener = new streamtasklistener ( new nullstream ( ) ) ; launcher launcher = n . createlauncher ( listener ) ; return launcher . launch ( ) . cmds ( str_ , str_ ) . stdout ( listener ) . join ( ) == num_ ; } catch ( ioexception | interruptedexception e ) { return bool_ ; } }	Checks if "java" is in PATH on the given node.
public markuptext . subtext findtoken ( pattern pattern ) { string text = gettext ( ) ; matcher m = pattern . matcher ( text ) ; if ( m . find ( ) ) return createsubtext ( m ) ; return null ; }	Find the first occurrence of the given pattern in this text, or null.
public list < markuptext . subtext > findtokens ( pattern pattern ) { string text = gettext ( ) ; matcher m = pattern . matcher ( text ) ; list < subtext > r = new arraylist < > ( ) ; while ( m . find ( ) ) { int idx = m . start ( ) ; if ( idx > num_ ) { char ch = text . charat ( idx - num_ ) ; if ( character . isletter ( ch ) || character . isdigit ( ch ) ) continue ;	Find all "tokens" that match the given pattern in this text.
public static int waitforexitprocess ( pointer hprocess ) throws interruptedexception { while ( bool_ ) { if ( thread . interrupted ( ) ) throw new interruptedexception ( ) ; kernel32 . instance . waitforsingleobject ( hprocess , num_ ) ; intbyreference exitcode = new intbyreference ( ) ; exitcode . setvalue ( - num_ ) ; kernel32 . instance . getexitcodeprocess ( hprocess , exitcode ) ; int v = exitcode . getvalue ( ) ; if ( v != kernel32 . still_active ) { return v ; } } }	Given the process handle, waits for its completion and returns the exit code.
@ requirepost @ restricted ( noexternaluse . class ) public httpresponse docreateadminuser ( staplerrequest req , staplerresponse rsp ) throws ioexception { jenkins j = jenkins . getinstance ( ) ; j . checkpermission ( jenkins . administer ) ;	Called during the initial setup to create an admin user.
@ restricted ( donotuse . class )	Returns the initial plugin list in JSON format.
@ checkfornull public jsonarray getplatformpluginupdates ( ) { final versionnumber version = getcurrentlevel ( ) ; if ( version == null ) { return null ; } return getplatformpluginsforupdate ( version , jenkins . getversion ( ) ) ; }	Provides the list of platform plugin updates from the last timethe upgrade was run.
public installstate getinstallstate ( string name ) { if ( name == null ) { return null ; } return installstate . valueof ( name ) ; }	Returns an installState by name.
private reactorlistener buildreactorlistener ( ) throws ioexception { list < reactorlistener > r = lists . newarraylist ( serviceloader . load ( initreactorlistener . class , thread . currentthread ( ) . getcontextclassloader ( ) ) ) ; r . add ( new reactorlistener ( ) { final level level = level . parse ( configuration . getstringconfigparameter ( str_ , str_ ) ) ; public void ontaskstarted ( task t ) { logger . log ( level , str_ , getdisplayname ( t ) ) ; } public void ontaskcompleted ( task t ) { logger . log ( level , str_ , getdisplayname ( t ) ) ; } public void ontaskfailed ( task t , throwable err , boolean fatal ) { logger . log ( severe , str_ + getdisplayname ( t ) , err ) ; } public void onattained ( milestone milestone ) { level lv = level ; string s = str_ + milestone . tostring ( ) ; if ( milestone instanceof initmilestone ) { lv = level . info ;	Aggregates all the listeners into one and returns it.
public static string unprotect ( string data ) { if ( data == null ) return null ; try { cipher cipher = secret . getcipher ( algorithm ) ; cipher . init ( cipher . decrypt_mode , des_key ) ; string plaintext = new string ( cipher . dofinal ( base64 . getdecoder ( ) . decode ( data . getbytes ( standardcharsets . utf_8 ) ) ) , standardcharsets . utf_8 ) ; if ( plaintext . endswith ( magic ) ) return plaintext . substring ( num_ , plaintext . length ( ) - num_ ) ; return null ; } catch ( generalsecurityexception | illegalargumentexception e ) { return null ; } }	Returns null if fails to decrypt properly.
static synchronized void cleartldoverrides ( ) { inuse = bool_ ; countrycodetldsplus = memoryreductionutil . empty_string_array ; countrycodetldsminus = memoryreductionutil . empty_string_array ; generictldsplus = memoryreductionutil . empty_string_array ; generictldsminus = memoryreductionutil . empty_string_array ; }	For use by unit test code only.
public static string [ ] gettldentries ( domainvalidator . arraytype table ) { final string [ ] array ; switch ( table ) { case country_code_minus : array = countrycodetldsminus ; break ; case country_code_plus : array = countrycodetldsplus ; break ; case generic_minus : array = generictldsminus ; break ; case generic_plus : array = generictldsplus ; break ; case generic_ro : array = generic_tlds ; break ; case country_code_ro : array = country_code_tlds ; break ; case infrastructure_ro : array = infrastructure_tlds ; break ; case local_ro : array = local_tlds ; break ; default : throw new illegalargumentexception ( str_ + table ) ; } return arrays . copyof ( array , array . length ) ;	Get a copy of the internal array.
public annotatedlargetext obtainlog ( ) { weakreference < annotatedlargetext > l = log ; if ( l == null ) return null ; return l . get ( ) ; }	Obtains the log file. The default implementation get this from {.
public void doprogressivelog ( staplerrequest req , staplerresponse rsp ) throws ioexception { annotatedlargetext text = obtainlog ( ) ; if ( text != null ) { text . doprogresstext ( req , rsp ) ; return ; } rsp . setstatus ( httpservletresponse . sc_ok ) ; }	Handles incremental log output.
@ requirepost public synchronized void doclearerror ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { getacl ( ) . checkpermission ( getpermission ( ) ) ; if ( workerthread != null && ! workerthread . isrunning ( ) ) workerthread = null ; rsp . sendredirect ( str_ ) ; }	Clears the error status.
public class < ? > type ( ) { type type = types . getbaseclass ( getclass ( ) , consoleannotatorfactory . class ) ; if ( type instanceof parameterizedtype ) return types . erasure ( types . gettypeargument ( type , num_ ) ) ; else return object . class ; }	For which context type does this annotator work?.
public static extensioncomponentset union ( final collection < ? extends extensioncomponentset > base ) { return new extensioncomponentset ( ) { @ override public < t > collection < extensioncomponent < t > > find ( class < t > type ) { list < extensioncomponent < t > > r = lists . newarraylist ( ) ; for ( extensioncomponentset d : base ) r . addall ( d . find ( type ) ) ; return r ; } } ; }	Computes the union of all the given delta.
public iterator < r > iterator ( ) { return new iterator < r > ( ) { r last = null ; r next = newestbuild ( ) ; public boolean hasnext ( ) { return next != null ; } public r next ( ) { last = next ; if ( last != null ) next = last . getpreviousbuild ( ) ; else throw new nosuchelementexception ( ) ; return last ; } public void remove ( ) { if ( last == null ) throw new unsupportedoperationexception ( ) ; removevalue ( last ) ; } } ; }	Walks through builds, newer ones first.
protected boolean isvalidquery ( string query ) { if ( query == null ) { return bool_ ; } return query_pattern . matcher ( query ) . matches ( ) ; }	Returns true if the query is null or it's a properly formatted query string.
public static < v , t extends throwable > v execute ( tasklistener listener , string rootusername , string rootpassword , final callable < v , t > closure ) throws t , ioexception , interruptedexception { virtualchannel ch = start ( listener , rootusername , rootpassword ) ; try { return ch . call ( closure ) ; } finally { ch . close ( ) ; ch . join ( num_ ) ;	Starts a new privilege-escalated environment, execute a closure, and shut it down.
public synchronized void download ( staplerrequest req , staplerresponse rsp ) throws interruptedexception , ioexception { rsp . setstatus ( httpservletresponse . sc_ok ) ;	This is where we send the data to the client.
public synchronized void upload ( staplerrequest req , staplerresponse rsp ) throws interruptedexception , ioexception { rsp . setstatus ( httpservletresponse . sc_ok ) ; inputstream in = req . getinputstream ( ) ; if ( diy_chunking ) { in = new chunkedinputstream ( in ) ; }	This is where we receive inputs from the client.
public static void register ( ) { if ( main . isunittest && jenkins_loc == null ) { mockoff ( ) ; return ; } classfilter . setdefault ( new classfilterimpl ( ) ) ; if ( suppress_all ) { logger . warning ( str_ ) ; } else if ( suppress_whitelist ) { logger . warning ( str_ ) ; } }	Register this implementation as the default in the system.
public boolean isvalidinet4address ( string inet4address ) {	Validates an IPv4 address.
public static void report ( saveable obj , string version ) { olddatamonitor odm = get ( jenkins . getinstance ( ) ) ; try { saveablereference ref = referto ( obj ) ; while ( bool_ ) { versionrange vr = odm . data . get ( ref ) ; if ( vr != null && odm . data . replace ( ref , vr , new versionrange ( vr , version , null ) ) ) { break ; } else if ( odm . data . putifabsent ( ref , new versionrange ( null , version , null ) ) == null ) { break ; } } } catch ( illegalargumentexception ex ) { logger . log ( level . warning , str_ , ex ) ; } }	Inform monitor that some data in a deprecated format has been loaded,and converted in-memory to a new structure.
public static void report ( unmarshallingcontext context , string version ) { robustreflectionconverter . adderrorincontext ( context , new reportexception ( version ) ) ; }	Inform monitor that some data in a deprecated format has been loaded, duringXStream unmarshalling when the Saveable containing this object is not available.
public static void report ( saveable obj , collection < throwable > errors ) { stringbuilder buf = new stringbuilder ( ) ; int i = num_ ; for ( throwable e : errors ) { if ( e instanceof reportexception ) { report ( obj , ( ( reportexception ) e ) . version ) ; } else { if ( ++ i > num_ ) buf . append ( str_ ) ; buf . append ( e . getclass ( ) . getsimplename ( ) ) . append ( str_ ) . append ( e . getmessage ( ) ) ; } } if ( buf . length ( ) == num_ ) return ; jenkins j = jenkins . getinstanceornull ( ) ; if ( j == null ) {	Inform monitor that some unreadable data was found while loading.
@ restricted ( noexternaluse . class ) public iterator < versionnumber > getversionlist ( ) { treeset < versionnumber > set = new treeset < versionnumber > ( ) ; for ( versionrange vr : data . values ( ) ) { if ( vr . max != null ) { set . add ( vr . max ) ; } } return set . iterator ( ) ; }	Sorted list of unique max-versions in the data set.
@ requirepost public httpresponse doupgrade ( staplerrequest req , staplerresponse rsp ) { final string thruverparam = req . getparameter ( str_ ) ; final versionnumber thruver = thruverparam . equals ( str_ ) ? null : new versionnumber ( thruverparam ) ; saveandremoveentries ( new predicate < map . entry < saveablereference , versionrange > > ( ) { @ override public boolean apply ( map . entry < saveablereference , versionrange > entry ) { versionnumber version = entry . getvalue ( ) . max ; return version != null && ( thruver == null || ! version . isnewerthan ( thruver ) ) ; } } ) ; return httpresponses . forwardtopreviouspage ( ) ; }	Save all or some of the files to persist data in the new forms.Remove those items from the data map.
public void dologout ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { httpsession session = req . getsession ( bool_ ) ; if ( session != null ) session . invalidate ( ) ; authentication auth = securitycontextholder . getcontext ( ) . getauthentication ( ) ; securitycontextholder . clearcontext ( ) ;	Handles the logout processing. The default implementation erases the session and do a few other clean up, thenredirect the user to the URL specified by {.
public final void docaptcha ( staplerrequest req , staplerresponse rsp ) throws ioexception { if ( captchasupport != null ) { string id = req . getsession ( ) . getid ( ) ; rsp . setcontenttype ( str_ ) ;	Generates a captcha image.
protected final boolean validatecaptcha ( string text ) { if ( captchasupport != null ) { string id = stapler . getcurrentrequest ( ) . getsession ( ) . getid ( ) ; return captchasupport . validatecaptcha ( id , text ) ; }	Validates the captcha.
@ restricted ( donotuse . class ) public static string getfrom ( ) { string from = null , returnvalue = null ; final staplerrequest request = stapler . getcurrentrequest ( ) ;	Perform a calculation where we should go back after successful login.
public static httpresponseexception success ( final string destination ) { return new httpresponseexception ( ) { public void generateresponse ( staplerrequest req , staplerresponse rsp , object node ) throws ioexception , servletexception { if ( isapply ( req ) ) {	Generates the response for the form submission in such a way that it handles the "apply" buttoncorrectly.
public boolean iscontainedby ( permissionscope s ) { if ( this == s ) return bool_ ; for ( permissionscope c : containers ) { if ( c . iscontainedby ( s ) ) return bool_ ; } return bool_ ; }	Returns true if this scope is directly or indirectly contained by the given scope.
public int available ( ) throws ioexception { if ( this . entrysize - this . entryoffset > integer . max_value ) { return integer . max_value ; } return ( int ) ( this . entrysize - this . entryoffset ) ; }	Get the available data that can be read from the currententry in the archive.
public int read ( byte [ ] buf , int offset , int numtoread ) throws ioexception { int totalread = num_ ; if ( this . entryoffset >= this . entrysize ) { return - num_ ; } if ( ( numtoread + this . entryoffset ) > this . entrysize ) { numtoread = ( int ) ( this . entrysize - this . entryoffset ) ; } if ( this . readbuf != null ) { int sz = ( numtoread > this . readbuf . length ) ? this . readbuf . length : numtoread ; system . arraycopy ( thi